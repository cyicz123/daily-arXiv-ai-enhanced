<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 66]
- [cs.CV](#cs.CV) [Total: 69]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [eess.IV](#eess.IV) [Total: 8]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 10]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Polysemy of Synthetic Neurons Towards a New Type of Explanatory Categorical Vector Spaces](https://arxiv.org/abs/2505.07831)
*Michael Pichat,William Pogrund,Paloma Pichat,Judicael Poumay,Armanouche Gasparian,Samuel Demarchi,Martin Corbet,Alois Georgeon,Michael Veillet-Guillem*

Main category: cs.CL

TLDR: 论文提出了一种几何方法，将第n层神经元定义为具有非正交基的分类向量空间，通过层内注意力过程识别关键分类区域，提升语言模型效率。


<details>
  <summary>Details</summary>
Motivation: 理解人工神经网络中多义神经元的本质，并提出一种更高效的几何定义方法。

Method: 将神经元定义为分类向量空间，利用层内注意力识别关键分类区域。

Result: 提出了一种更高效的神经元定义方法，能够提升语言模型的性能。

Conclusion: 几何定义神经元的方法为理解多义神经元提供了新视角，并优化了语言模型的效率。

Abstract: The polysemantic nature of synthetic neurons in artificial intelligence
language models is currently understood as the result of a necessary
superposition of distributed features within the latent space. We propose an
alternative approach, geometrically defining a neuron in layer n as a
categorical vector space with a non-orthogonal basis, composed of categorical
sub-dimensions extracted from preceding neurons in layer n-1. This categorical
vector space is structured by the activation space of each neuron and enables,
via an intra-neuronal attention process, the identification and utilization of
a critical categorical zone for the efficiency of the language model - more
homogeneous and located at the intersection of these different categorical
sub-dimensions.

</details>

### [2] [A Tale of Two Identities: An Ethical Audit of Human and AI-Crafted Personas](https://arxiv.org/abs/2505.07850)
*Pranav Narayanan Venkit,Jiayi Li,Yingfan Zhou,Sarah Rajtmajer,Shomir Wilson*

Main category: cs.CL

TLDR: 论文研究了LLM生成的合成人物在种族身份上的表现问题，揭示了算法偏见和刻板印象的危害。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在数据有限领域（如健康、隐私和HCI）中生成合成人物的应用增多，需要评估其对少数群体身份的表现是否公平。

Method: 采用混合方法（细读、词汇分析和参数化创造力框架）比较1512个LLM生成人物与人类撰写内容。

Result: LLM过度强调种族标记，使用文化编码语言，生成的人物在句法上复杂但叙事上简化，导致刻板印象、异化等社会技术危害。

Conclusion: 提出“算法他者化”概念，建议设计叙事感知评估指标和以社区为中心的验证协议。

Abstract: As LLMs (large language models) are increasingly used to generate synthetic
personas particularly in data-limited domains such as health, privacy, and HCI,
it becomes necessary to understand how these narratives represent identity,
especially that of minority communities. In this paper, we audit synthetic
personas generated by 3 LLMs (GPT4o, Gemini 1.5 Pro, Deepseek 2.5) through the
lens of representational harm, focusing specifically on racial identity. Using
a mixed methods approach combining close reading, lexical analysis, and a
parameterized creativity framework, we compare 1512 LLM generated personas to
human-authored responses. Our findings reveal that LLMs disproportionately
foreground racial markers, overproduce culturally coded language, and construct
personas that are syntactically elaborate yet narratively reductive. These
patterns result in a range of sociotechnical harms, including stereotyping,
exoticism, erasure, and benevolent bias, that are often obfuscated by
superficially positive narrations. We formalize this phenomenon as algorithmic
othering, where minoritized identities are rendered hypervisible but less
authentic. Based on these findings, we offer design recommendations for
narrative-aware evaluation metrics and community-centered validation protocols
for synthetic identity generation.

</details>

### [3] [Joint Detection of Fraud and Concept Drift inOnline Conversations with LLM-Assisted Judgment](https://arxiv.org/abs/2505.07852)
*Ali Senol,Garima Agrawal,Huan Liu*

Main category: cs.CL

TLDR: 提出了一种两阶段框架，结合集成分类模型和概念漂移分析，用于检测数字通信平台中的虚假交互，提高实时欺诈检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 数字通信平台中的虚假交互问题尚未得到充分解决，传统静态异常检测方法难以适应动态对话变化，易误判良性话题转换（概念漂移）为欺诈行为。

Method: 采用两阶段检测框架：1）使用集成分类模型识别可疑对话；2）通过概念漂移分析（OCDD）和大型语言模型（LLM）判断是否为欺诈或良性话题转换。

Result: 在社交工程聊天场景数据集上验证，框架在准确性和可解释性方面优于传统方法，并对比了模块化方法与双LLM基线的性能。

Conclusion: 提出的框架能有效区分欺诈行为和良性话题转换，为实时欺诈检测提供了更可靠的解决方案。

Abstract: Detecting fake interactions in digital communication platforms remains a
challenging and insufficiently addressed problem. These interactions may appear
as harmless spam or escalate into sophisticated scam attempts, making it
difficult to flag malicious intent early. Traditional detection methods often
rely on static anomaly detection techniques that fail to adapt to dynamic
conversational shifts. One key limitation is the misinterpretation of benign
topic transitions referred to as concept drift as fraudulent behavior, leading
to either false alarms or missed threats. We propose a two stage detection
framework that first identifies suspicious conversations using a tailored
ensemble classification model. To improve the reliability of detection, we
incorporate a concept drift analysis step using a One Class Drift Detector
(OCDD) to isolate conversational shifts within flagged dialogues. When drift is
detected, a large language model (LLM) assesses whether the shift indicates
fraudulent manipulation or a legitimate topic change. In cases where no drift
is found, the behavior is inferred to be spam like. We validate our framework
using a dataset of social engineering chat scenarios and demonstrate its
practical advantages in improving both accuracy and interpretability for real
time fraud detection. To contextualize the trade offs, we compare our modular
approach against a Dual LLM baseline that performs detection and judgment using
different language models.

</details>

### [4] [CrashSage: A Large Language Model-Centered Framework for Contextual and Interpretable Traffic Crash Analysis](https://arxiv.org/abs/2505.07853)
*Hao Zhen,Jidong J. Yang*

Main category: cs.CL

TLDR: CrashSage是一个基于大型语言模型（LLM）的框架，通过表格到文本转换、上下文感知数据增强、模型微调和可解释性技术，提升交通事故分析的性能。


<details>
  <summary>Details</summary>
Motivation: 全球每年因交通事故造成大量生命和经济损失，现有方法难以捕捉复杂关系和语义信息，亟需更高效的分析工具。

Method: 提出CrashSage框架，包括表格到文本转换、数据增强、LLaMA3-8B模型微调和梯度解释技术。

Result: CrashSage在事故严重性推断上优于基线方法，并提供了模型决策的可解释性。

Conclusion: CrashSage为交通事故分析提供了更高效、透明的解决方案，有助于针对性安全干预。

Abstract: Road crashes claim over 1.3 million lives annually worldwide and incur global
economic losses exceeding \$1.8 trillion. Such profound societal and financial
impacts underscore the urgent need for road safety research that uncovers crash
mechanisms and delivers actionable insights. Conventional statistical models
and tree ensemble approaches typically rely on structured crash data,
overlooking contextual nuances and struggling to capture complex relationships
and underlying semantics. Moreover, these approaches tend to incur significant
information loss, particularly in narrative elements related to multi-vehicle
interactions, crash progression, and rare event characteristics. This study
presents CrashSage, a novel Large Language Model (LLM)-centered framework
designed to advance crash analysis and modeling through four key innovations.
First, we introduce a tabular-to-text transformation strategy paired with
relational data integration schema, enabling the conversion of raw,
heterogeneous crash data into enriched, structured textual narratives that
retain essential structural and relational context. Second, we apply
context-aware data augmentation using a base LLM model to improve narrative
coherence while preserving factual integrity. Third, we fine-tune the LLaMA3-8B
model for crash severity inference, demonstrating superior performance over
baseline approaches, including zero-shot, zero-shot with chain-of-thought
prompting, and few-shot learning, with multiple models (GPT-4o, GPT-4o-mini,
LLaMA3-70B). Finally, we employ a gradient-based explainability technique to
elucidate model decisions at both the individual crash level and across broader
risk factor dimensions. This interpretability mechanism enhances transparency
and enables targeted road safety interventions by providing deeper insights
into the most influential factors.

</details>

### [5] [Unpacking Robustness in Inflectional Languages: Adversarial Evaluation and Mechanistic Insights](https://arxiv.org/abs/2505.07856)
*Paweł Walkowiak,Marek Klonowski,Marcin Oleksy,Arkadiusz Janz*

Main category: cs.CL

TLDR: 本文研究了对抗攻击在屈折语言中的表现，提出了一种基于Edge Attribution Patching（EAP）的新评估协议，并通过波兰语和英语的平行语料库分析了屈折变化对模型鲁棒性的影响。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击方法主要针对非屈折语言（如英语），而屈折语言（如波兰语）的表现尚未充分研究。本文旨在填补这一空白，探究屈折变化对模型鲁棒性的影响。

Method: 设计了基于EAP的新评估协议，使用波兰语和英语的平行语料库（包括屈折和同义词变体），并基于MultiEmo数据集创建新基准。

Result: 通过新协议和基准，揭示了屈折变化与模型鲁棒性之间的关系，并识别了模型中与屈折相关的机制性元素。

Conclusion: 屈折语言中的对抗攻击表现与非屈折语言不同，新协议和基准为研究模型在屈折语言中的鲁棒性提供了有效工具。

Abstract: Various techniques are used in the generation of adversarial examples,
including methods such as TextBugger which introduce minor, hardly visible
perturbations to words leading to changes in model behaviour. Another class of
techniques involves substituting words with their synonyms in a way that
preserves the text's meaning but alters its predicted class, with TextFooler
being a prominent example of such attacks. Most adversarial example generation
methods are developed and evaluated primarily on non-inflectional languages,
typically English. In this work, we evaluate and explain how adversarial
attacks perform in inflectional languages. To explain the impact of inflection
on model behaviour and its robustness under attack, we designed a novel
protocol inspired by mechanistic interpretability, based on Edge Attribution
Patching (EAP) method. The proposed evaluation protocol relies on parallel
task-specific corpora that include both inflected and syncretic variants of
texts in two languages -- Polish and English. To analyse the models and explain
the relationship between inflection and adversarial robustness, we create a new
benchmark based on task-oriented dataset MultiEmo, enabling the identification
of mechanistic inflection-related elements of circuits within the model and
analyse their behaviour under attack.

</details>

### [6] [Enhanced Urdu Intent Detection with Large Language Models and Prototype-Informed Predictive Pipelines](https://arxiv.org/abs/2505.07857)
*Faiza Hassan,Summra Saleem,Kashif Javed,Muhammad Nabeel Asim,Abdur Rehman,Andreas Dengel*

Main category: cs.CL

TLDR: 本文提出了一种针对乌尔都语的意图检测方法LLMPIA，结合对比学习和原型注意力机制，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语作为全球第十大语言，其意图检测领域缺乏小样本学习策略的支持，现有方法无法处理未见类别。

Method: 采用对比学习利用无标签数据重新训练预训练语言模型，结合原型注意力机制构建LLMPIA管道。

Result: 在ATIS和Web Queries数据集上，LLMPIA分别达到最高98.25%和84.42%的F1分数，显著优于现有方法。

Conclusion: LLMPIA为乌尔都语意图检测提供了高效解决方案，验证了其在小样本和传统任务中的优越性。

Abstract: Multifarious intent detection predictors are developed for different
languages, including English, Chinese and French, however, the field remains
underdeveloped for Urdu, the 10th most spoken language. In the realm of
well-known languages, intent detection predictors utilize the strategy of
few-shot learning and prediction of unseen classes based on the model training
on seen classes. However, Urdu language lacks few-shot strategy based intent
detection predictors and traditional predictors are focused on prediction of
the same classes which models have seen in the train set. To empower Urdu
language specific intent detection, this introduces a unique contrastive
learning approach that leverages unlabeled Urdu data to re-train pre-trained
language models. This re-training empowers LLMs representation learning for the
downstream intent detection task. Finally, it reaps the combined potential of
pre-trained LLMs and the prototype-informed attention mechanism to create a
comprehensive end-to-end LLMPIA intent detection pipeline. Under the paradigm
of proposed predictive pipeline, it explores the potential of 6 distinct
language models and 13 distinct similarity computation methods. The proposed
framework is evaluated on 2 public benchmark datasets, namely ATIS encompassing
5836 samples and Web Queries having 8519 samples. Across ATIS dataset under
4-way 1 shot and 4-way 5 shot experimental settings LLMPIA achieved 83.28% and
98.25% F1-Score and on Web Queries dataset produced 76.23% and 84.42% F1-Score,
respectively. In an additional case study on the Web Queries dataset under same
classes train and test set settings, LLMPIA outperformed state-of-the-art
predictor by 53.55% F1-Score.

</details>

### [7] [Scaling Laws for Speculative Decoding](https://arxiv.org/abs/2505.07858)
*Siyuan Yan,Mo Zhu,Guo-qing Jiang,Jianfei Wang,Jiaxing Chen,Wentai Zhang,Xiang Liao,Xiao Cui,Chen Zhang,Zhuoran Song,Ran Zhu*

Main category: cs.CL

TLDR: 论文研究了通过密集LLM架构的推测解码技术，发现对数线性缩放规律，并开发了Scylla系统，显著提升了推理效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在推理密集型任务中需要高效解码，但现有方法在解码效率的缩放规律上研究不足。

Method: 通过研究预训练令牌量、草稿模型容量和解码批量大小三个维度的对数线性缩放规律，开发了Scylla系统。

Result: Scylla在解码接受率和吞吐量上优于EAGLE2和EAGLE3，尤其在摘要和问答任务中表现突出。

Conclusion: 系统性缩放对高效LLM推理具有变革潜力，Scylla为实际部署提供了显著性能提升。

Abstract: The escalating demand for efficient decoding in large language models (LLMs)
is particularly critical for reasoning-intensive architectures like OpenAI-o3
and DeepSeek-R1, which depend on extended chain-of-thought reasoning. This
study investigates speculative decoding techniques through dense LLM
architectures to establish foundational insights for accelerating reasoning
tasks. While speculative decoding methods leveraging parallel
draft-verification cycles have emerged as promising acceleration techniques,
the scaling laws governing decoding efficiency remain under-explored compared
to conventional backbone LLMs developed through Pretraining->SFT->RLHF training
paradigms. In this work, we discover Log-linear Scaling Laws (Theorem 1.1, 1.2
and 1.3) governing draft model acceptance rate (or decoding speed) across three
dimensions: pretraining token volume, draft model capacity, and decoding batch
size. Building on these laws, we achieve Scylla, which coordinates
multi-dimensional scaling for popular LLMs (Llama2/3, Qwen2.5). Empirical
validation shows Scylla achieves 1.5-2.2 higher acceptance rate than EAGLE2 and
0.3 higher than EAGLE3 at temperature T = 0, with peak performance gains on
summarization and QA tasks (Figure 2). Industrial inference engine deployments
demonstrate 2X decoding throughput improvements over EAGLE2 (Table 5),
validating the transformative potential of systematic scaling for efficient LLM
inference. Code will be released later.

</details>

### [8] [Boosting Performance on ARC is a Matter of Perspective](https://arxiv.org/abs/2505.07859)
*Daniel Franzen,Jan Disselhoff,David Hartmann*

Main category: cs.CL

TLDR: 本文提出了一种通过任务特定数据增强和深度优先搜索算法提升LLM在ARC-AGI任务中表现的方法，实现了71.6%的得分，并强调了其透明性和低成本优势。


<details>
  <summary>Details</summary>
Motivation: ARC-AGI任务对大型语言模型（LLMs）的抽象推理能力提出了挑战，揭示了其局限性。

Method: 在训练、生成和评分阶段使用任务特定数据增强，结合深度优先搜索算法生成多样化的候选解，并利用LLM作为生成器和评分器。

Result: 在公开ARC-AGI评估集上获得71.6%的得分（286.5/400任务），表现优于其他公开方法。

Conclusion: 该方法在透明性、可复现性和低成本方面具有显著优势，尽管闭源方法得分更高。

Abstract: The Abstraction and Reasoning Corpus (ARC-AGI) poses a significant challenge
for large language models (LLMs), exposing limitations in their abstract
reasoning abilities. In this work, we leverage task-specific data augmentations
throughout the training, generation, and scoring phases, and employ a
depth-first search algorithm to generate diverse, high-probability candidate
solutions. Furthermore, we utilize the LLM not only as a generator but also as
a scorer, using its output probabilities to select the most promising
solutions. Our method achieves a score of 71.6% (286.5/400 solved tasks) on the
public ARC-AGI evaluation set, demonstrating state-of-the-art performance among
publicly available approaches. While concurrent closed-source work has reported
higher scores, our method distinguishes itself through its transparency,
reproducibility, and remarkably low inference cost, averaging only around 2ct
per task on readily available hardware (we assume a price of 36ct/hour for a
Nvidia 4090 GPU).

</details>

### [9] [Scalable LLM Math Reasoning Acceleration with Low-rank Distillation](https://arxiv.org/abs/2505.07861)
*Harry Dong,Bilge Acun,Beidi Chen,Yuejie Chi*

Main category: cs.CL

TLDR: Caprese是一种低成本蒸馏方法，用于恢复因高效推理方法部署而丢失的数学推理能力，同时不影响语言任务性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的数学推理需要大量计算资源和时间，现有高效推理方法虽在语言任务中表现良好，但会严重降低数学性能。

Method: Caprese通过仅添加约1%的参数和20K合成训练样本，在不扰动原始权重的情况下，恢复数学推理能力。

Result: Caprese显著减少了活跃参数数量（如Gemma 2 9B和Llama 3.1 8B减少约2B），并降低延迟（如Qwen 2.5 14B生成2048个令牌时延迟减少11%）。

Conclusion: Caprese是一种高效且低成本的方法，能恢复数学推理能力并优化模型性能。

Abstract: Due to long generations, large language model (LLM) math reasoning demands
significant computational resources and time. While many existing efficient
inference methods have been developed with excellent performance preservation
on language tasks, they often severely degrade math performance. In this paper,
we propose Caprese, a low-cost distillation method to recover lost capabilities
from deploying efficient inference methods, focused primarily in feedforward
blocks. With original weights unperturbed, roughly 1% of additional parameters,
and only 20K synthetic training samples, we are able to recover much if not all
of the math capabilities lost from efficient inference for thinking LLMs and
without harm to language tasks for instruct LLMs. Moreover, Caprese slashes the
number of active parameters (~2B cut for Gemma 2 9B and Llama 3.1 8B) and
integrates cleanly into existing model layers to reduce latency (>11% reduction
to generate 2048 tokens with Qwen 2.5 14B) while encouraging response brevity.

</details>

### [10] [Graph Laplacian Wavelet Transformer via Learnable Spectral Decomposition](https://arxiv.org/abs/2505.07862)
*Andrew Kiruluta,Eric Lundy,Priscilla Burity*

Main category: cs.CL

TLDR: 论文提出了一种名为Graph Wavelet Transformer（GWT）的新架构，用于解决现有序列到序列模型在结构化语言任务中因点积自注意力机制导致的二次复杂度问题。


<details>
  <summary>Details</summary>
Motivation: 现有模型依赖点积自注意力机制，计算和内存复杂度为输入长度的二次方，限制了效率。

Method: 引入GWT架构，利用可学习的多尺度小波变换替代点积自注意力，基于显式图拉普拉斯算子（源自句法或语义解析）。

Result: 多尺度谱分解为图结构序列建模提供了可解释、高效且表达能力强的替代方案。

Conclusion: GWT为结构化语言任务提供了一种更高效的建模方法，优于传统自注意力机制。

Abstract: Existing sequence to sequence models for structured language tasks rely
heavily on the dot product self attention mechanism, which incurs quadratic
complexity in both computation and memory for input length N. We introduce the
Graph Wavelet Transformer (GWT), a novel architecture that replaces this
bottleneck with a learnable, multi scale wavelet transform defined over an
explicit graph Laplacian derived from syntactic or semantic parses. Our
analysis shows that multi scale spectral decomposition offers an interpretable,
efficient, and expressive alternative to quadratic self attention for graph
structured sequence modeling.

</details>

### [11] [QoSBERT: An Uncertainty-Aware Approach based on Pre-trained Language Models for Service Quality Prediction](https://arxiv.org/abs/2505.07863)
*Ziliang Wang,Xiaohong Zhang,Ze Shi Li,Meng Yan*

Main category: cs.CL

TLDR: QoSBERT是一个基于预训练语言模型的语义回归框架，用于预测云服务的QoS指标，并首次引入不确定性估计模块，显著提升了预测准确性和可信度。


<details>
  <summary>Details</summary>
Motivation: 传统QoS模型依赖手工特征工程且仅提供点估计，缺乏对预测置信度的评估，限制了其在实际应用中的可信度。

Method: QoSBERT将用户和服务元数据编码为自然语言描述，利用预训练语言模型进行语义理解，并结合蒙特卡洛Dropout进行不确定性估计。

Result: 在标准数据集上，QoSBERT在响应时间和吞吐量预测上分别降低了11.7%和6.9%的MAE，同时提供了校准良好的置信区间。

Conclusion: QoSBERT不仅提升了预测准确性，还提供了可靠的不确定性量化，为更可信的服务选择和优化奠定了基础。

Abstract: Accurate prediction of Quality of Service (QoS) metrics is fundamental for
selecting and managing cloud based services. Traditional QoS models rely on
manual feature engineering and yield only point estimates, offering no insight
into the confidence of their predictions. In this paper, we propose QoSBERT,
the first framework that reformulates QoS prediction as a semantic regression
task based on pre trained language models. Unlike previous approaches relying
on sparse numerical features, QoSBERT automatically encodes user service
metadata into natural language descriptions, enabling deep semantic
understanding. Furthermore, we integrate a Monte Carlo Dropout based
uncertainty estimation module, allowing for trustworthy and risk-aware service
quality prediction, which is crucial yet underexplored in existing QoS models.
QoSBERT applies attentive pooling over contextualized embeddings and a
lightweight multilayer perceptron regressor, fine tuned jointly to minimize
absolute error. We further exploit the resulting uncertainty estimates to
select high quality training samples, improving robustness in low resource
settings. On standard QoS benchmark datasets, QoSBERT achieves an average
reduction of 11.7% in MAE and 6.7% in RMSE for response time prediction, and
6.9% in MAE for throughput prediction compared to the strongest baselines,
while providing well calibrated confidence intervals for robust and trustworthy
service quality estimation. Our approach not only advances the accuracy of
service quality prediction but also delivers reliable uncertainty
quantification, paving the way for more trustworthy, data driven service
selection and optimization.

</details>

### [12] [Efficient Fairness Testing in Large Language Models: Prioritizing Metamorphic Relations for Bias Detection](https://arxiv.org/abs/2505.07870)
*Suavis Giramata,Madhusudan Srinivasan,Venkat Naidu Gudivada,Upulee Kanewala*

Main category: cs.CL

TLDR: 本文提出了一种基于句子多样性的蜕变关系（MRs）优先级排序方法，用于高效检测大型语言模型（LLMs）中的公平性问题。实验表明，该方法在故障检测率和首次故障时间上优于随机和基于距离的优先级排序，且接近基于故障的优先级排序效果，同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的广泛应用，其输出中的公平性和潜在偏见问题日益突出。由于测试用例数量庞大，全面测试不可行，因此需要一种高效的蜕变关系优先级排序方法来检测公平性问题。

Method: 采用基于句子多样性的方法计算和排序蜕变关系（MRs），以优化故障检测。

Result: 实验结果显示，该方法在故障检测率上比随机排序高22%，比基于距离的排序高12%，同时首次故障时间分别减少15%和8%。其效果接近基于故障的排序（差距5%），但计算成本显著降低。

Conclusion: 基于多样性的蜕变关系优先级排序方法能有效提升大型语言模型公平性测试的效率和效果。

Abstract: Large Language Models (LLMs) are increasingly deployed in various
applications, raising critical concerns about fairness and potential biases in
their outputs. This paper explores the prioritization of metamorphic relations
(MRs) in metamorphic testing as a strategy to efficiently detect fairness
issues within LLMs. Given the exponential growth of possible test cases,
exhaustive testing is impractical; therefore, prioritizing MRs based on their
effectiveness in detecting fairness violations is crucial. We apply a sentence
diversity-based approach to compute and rank MRs to optimize fault detection.
Experimental results demonstrate that our proposed prioritization approach
improves fault detection rates by 22% compared to random prioritization and 12%
compared to distance-based prioritization, while reducing the time to the first
failure by 15% and 8%, respectively. Furthermore, our approach performs within
5% of fault-based prioritization in effectiveness, while significantly reducing
the computational cost associated with fault labeling. These results validate
the effectiveness of diversity-based MR prioritization in enhancing fairness
testing for LLMs.

</details>

### [13] [Evaluating Financial Sentiment Analysis with Annotators Instruction Assisted Prompting: Enhancing Contextual Interpretation and Stock Prediction Accuracy](https://arxiv.org/abs/2505.07871)
*A M Muntasir Rahman,Ajim Uddin,Guiling "Grace" Wang*

Main category: cs.CL

TLDR: 论文提出了一种新的评估提示方法（AIAP），通过整合人类标注者的任务指令，改进金融情感分析（FSA）中LLMs的性能，并在新数据集WSBS上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 金融情感分析（FSA）因金融语言的复杂性而面临独特挑战，现有基准数据集的主观性导致LLMs性能评估不公平。

Method: 引入Annotators' Instruction Assisted Prompt（AIAP），将人类标注者的详细任务指令整合到LLMs的提示框架中，以标准化情感理解。

Result: AIAP显著提升LLMs性能（最高提升9.08），并提出基于模型置信度的情感索引方法，增强股票价格预测。

Conclusion: AIAP为FSA提供了更公平和上下文丰富的评估方法，同时展示了WSB作为金融文本来源的重要性。

Abstract: Financial sentiment analysis (FSA) presents unique challenges to LLMs that
surpass those in typical sentiment analysis due to the nuanced language used in
financial contexts. The prowess of these models is often undermined by the
inherent subjectivity of sentiment classifications in existing benchmark
datasets like Financial Phrasebank. These datasets typically feature undefined
sentiment classes that reflect the highly individualized perspectives of
annotators, leading to significant variability in annotations. This variability
results in an unfair expectation for LLMs during benchmarking, where they are
tasked to conjecture the subjective viewpoints of human annotators without
sufficient context. In this paper, we introduce the Annotators' Instruction
Assisted Prompt, a novel evaluation prompt designed to redefine the task
definition of FSA for LLMs. By integrating detailed task instructions
originally intended for human annotators into the LLMs' prompt framework, AIAP
aims to standardize the understanding of sentiment across both human and
machine interpretations, providing a fair and context-rich foundation for
sentiment analysis. We utilize a new dataset, WSBS, derived from the
WallStreetBets subreddit to demonstrate how AIAP significantly enhances LLM
performance by aligning machine operations with the refined task definitions.
Experimental results demonstrate that AIAP enhances LLM performance
significantly, with improvements up to 9.08. This context-aware approach not
only yields incremental gains in performance but also introduces an innovative
sentiment-indexing method utilizing model confidence scores. This method
enhances stock price prediction models and extracts more value from the
financial sentiment analysis, underscoring the significance of WSB as a
critical source of financial text. Our research offers insights into both
improving FSA through better evaluation methods.

</details>

### [14] [The Sound of Populism: Distinct Linguistic Features Across Populist Variants](https://arxiv.org/abs/2505.07874)
*Yu Wang,Runxi Yu,Zhongyuan Wang,Jing He*

Main category: cs.CL

TLDR: 该研究通过结合LIWC特征和RoBERTa模型，分析了美国政治演讲中的民粹主义声音，揭示了其直接、自信的语言风格及其在不同民粹主义维度中的差异。


<details>
  <summary>Details</summary>
Motivation: 探索民粹主义在政治演讲中的语言表现，揭示其情感和风格特征。

Method: 结合LIWC情感和风格特征与RoBERTa模型，分析美国总统就职演说和国情咨文中的民粹主义语言。

Result: 民粹主义演讲具有直接、自信的语言风格，右翼民粹主义和人民中心主义更情感化，而左翼和反精英主义则相对克制。

Conclusion: 民粹主义语言风格是战略性的，不同维度在情感表达上存在显著差异。

Abstract: This study explores the sound of populism by integrating the classic
Linguistic Inquiry and Word Count (LIWC) features, which capture the emotional
and stylistic tones of language, with a fine-tuned RoBERTa model, a
state-of-the-art context-aware language model trained to detect nuanced
expressions of populism. This approach allows us to uncover the auditory
dimensions of political rhetoric in U.S. presidential inaugural and State of
the Union addresses. We examine how four key populist dimensions (i.e.,
left-wing, right-wing, anti-elitism, and people-centrism) manifest in the
linguistic markers of speech, drawing attention to both commonalities and
distinct tonal shifts across these variants. Our findings reveal that populist
rhetoric consistently features a direct, assertive ``sound" that forges a
connection with ``the people'' and constructs a charismatic leadership persona.
However, this sound is not simply informal but strategically calibrated.
Notably, right-wing populism and people-centrism exhibit a more emotionally
charged discourse, resonating with themes of identity, grievance, and crisis,
in contrast to the relatively restrained emotional tones of left-wing and
anti-elitist expressions.

</details>

### [15] [Recovering Event Probabilities from Large Language Model Embeddings via Axiomatic Constraints](https://arxiv.org/abs/2505.07883)
*Jian-Qiao Zhu,Haijiang Yan,Thomas L. Griffiths*

Main category: cs.CL

TLDR: 论文探讨了如何从LLM嵌入中恢复符合概率论公理的相干事件概率，提出了一种基于变分自编码器的方法，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: LLM生成的事件概率存在不连贯性，违反概率论公理，因此需要探索是否能从嵌入中恢复相干概率。

Method: 通过扩展的变分自编码器（VAE）在潜在空间中强制概率论公理约束（如加法规则），使事件概率自然涌现。

Result: 实验表明，从嵌入中恢复的概率比LLM直接生成的更连贯，且更接近真实概率。

Conclusion: 该方法能有效恢复相干事件概率，为不确定性事件提供更准确的估计。

Abstract: Rational decision-making under uncertainty requires coherent degrees of
belief in events. However, event probabilities generated by Large Language
Models (LLMs) have been shown to exhibit incoherence, violating the axioms of
probability theory. This raises the question of whether coherent event
probabilities can be recovered from the embeddings used by the models. If so,
those derived probabilities could be used as more accurate estimates in events
involving uncertainty. To explore this question, we propose enforcing axiomatic
constraints, such as the additive rule of probability theory, in the latent
space learned by an extended variational autoencoder (VAE) applied to LLM
embeddings. This approach enables event probabilities to naturally emerge in
the latent space as the VAE learns to both reconstruct the original embeddings
and predict the embeddings of semantically related events. We evaluate our
method on complementary events (i.e., event A and its complement, event not-A),
where the true probabilities of the two events must sum to 1. Experiment
results on open-weight language models demonstrate that probabilities recovered
from embeddings exhibit greater coherence than those directly reported by the
corresponding models and align closely with the true probabilities.

</details>

### [16] [Development of a WAZOBIA-Named Entity Recognition System](https://arxiv.org/abs/2505.07884)
*S. E Emedem,I. E Onyenwe,E. G Onyedinma*

Main category: cs.CL

TLDR: 该研究开发了针对尼日利亚三大主要语言（豪萨语、约鲁巴语和伊博语）的WAZOBIA-NER系统，填补了低资源语言在命名实体识别（NER）领域的空白。


<details>
  <summary>Details</summary>
Motivation: 现有NER系统主要针对英语和欧洲语言，非洲语言资源匮乏，研究旨在解决这一问题。

Method: 结合条件随机场（CRF）、BiLSTM、BERT和RNN等机器学习与深度学习技术，并利用OCR处理图像文本。

Result: 系统在精确率、召回率、F1分数和准确率上表现优异，分别为0.9511、0.9400、0.9564和0.9301。

Conclusion: 研究表明，利用当前NLP框架和迁移学习可为低资源非洲语言构建强大的NER工具。

Abstract: Named Entity Recognition NER is very crucial for various natural language
processing applications, including information extraction, machine translation,
and sentiment analysis. Despite the ever-increasing interest in African
languages within computational linguistics, existing NER systems focus mainly
on English, European, and a few other global languages, leaving a significant
gap for under-resourced languages. This research presents the development of a
WAZOBIA-NER system tailored for the three most prominent Nigerian languages:
Hausa, Yoruba, and Igbo. This research begins with a comprehensive compilation
of annotated datasets for each language, addressing data scarcity and
linguistic diversity challenges. Exploring the state-of-the-art machine
learning technique, Conditional Random Fields (CRF) and deep learning models
such as Bidirectional Long Short-Term Memory (BiLSTM), Bidirectional Encoder
Representation from Transformers (Bert) and fine-tune with a Recurrent Neural
Network (RNN), the study evaluates the effectiveness of these approaches in
recognizing three entities: persons, organizations, and locations. The system
utilizes optical character recognition (OCR) technology to convert textual
images into machine-readable text, thereby enabling the Wazobia system to
accept both input text and textual images for extraction purposes. The system
achieved a performance of 0.9511 in precision, 0.9400 in recall, 0.9564 in
F1-score, and 0.9301 in accuracy. The model's evaluation was conducted across
three languages, with precision, recall, F1-score, and accuracy as key
assessment metrics. The Wazobia-NER system demonstrates that it is feasible to
build robust NER tools for under-resourced African languages using current NLP
frameworks and transfer learning.

</details>

### [17] [PLHF: Prompt Optimization with Few-Shot Human Feedback](https://arxiv.org/abs/2505.07886)
*Chun-Pai Yang,Kan Zheng,Shou-De Lin*

Main category: cs.CL

TLDR: PLHF是一个基于人类反馈的提示优化框架，通过单轮反馈实现高效优化，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理输出质量难以评估的任务，缺乏明确指标时优化提示成为挑战。

Method: PLHF采用特定评估模块作为质量指标，仅需单轮人类反馈完成优化。

Result: 在公开和工业数据集上，PLHF优于先前的输出评分策略。

Conclusion: PLHF为无明确指标的任务提供了一种高效的提示优化解决方案。

Abstract: Automatic prompt optimization frameworks are developed to obtain suitable
prompts for large language models (LLMs) with respect to desired output quality
metrics. Although existing approaches can handle conventional tasks such as
fixed-solution question answering, defining the metric becomes complicated when
the output quality cannot be easily assessed by comparisons with standard
golden samples. Consequently, optimizing the prompts effectively and
efficiently without a clear metric becomes a critical challenge. To address the
issue, we present PLHF (which stands for "P"rompt "L"earning with "H"uman
"F"eedback), a few-shot prompt optimization framework inspired by the
well-known RLHF technique. Different from naive strategies, PLHF employs a
specific evaluator module acting as the metric to estimate the output quality.
PLHF requires only a single round of human feedback to complete the entire
prompt optimization process. Empirical results on both public and industrial
datasets show that PLHF outperforms prior output grading strategies for LLM
prompt optimizations.

</details>

### [18] [Implementing Long Text Style Transfer with LLMs through Dual-Layered Sentence and Paragraph Structure Extraction and Mapping](https://arxiv.org/abs/2505.07888)
*Yusen Wu,Xiaotie Deng*

Main category: cs.CL

TLDR: 论文提出了一种基于零样本学习的分层框架ZeroStylus，用于长文本风格迁移，结合句子级风格适应和段落级结构连贯性，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决长文本风格迁移中保持句法和语义一致性的挑战，避免依赖平行语料库或LLM微调。

Method: 采用分层模板获取和模板引导生成的两阶段框架，动态构建句子和段落模板库。

Result: 实验显示在风格一致性、内容保留和表达质量上优于基线方法，平均得分6.90 vs 6.70。

Conclusion: ZeroStylus框架为无需平行语料或微调的长文本风格迁移提供了新能力。

Abstract: This paper addresses the challenge in long-text style transfer using
zero-shot learning of large language models (LLMs), proposing a hierarchical
framework that combines sentence-level stylistic adaptation with
paragraph-level structural coherence. We argue that in the process of effective
paragraph-style transfer, to preserve the consistency of original syntactic and
semantic information, it is essential to perform style transfer not only at the
sentence level but also to incorporate paragraph-level semantic considerations,
while ensuring structural coherence across inter-sentential relationships. Our
proposed framework, ZeroStylus, operates through two systematic phases:
hierarchical template acquisition from reference texts and template-guided
generation with multi-granular matching. The framework dynamically constructs
sentence and paragraph template repositories, enabling context-aware
transformations while preserving inter-sentence logical relationships.
Experimental evaluations demonstrate significant improvements over baseline
methods, with structured rewriting achieving 6.90 average score compared to
6.70 for direct prompting approaches in tri-axial metrics assessing style
consistency, content preservation, and expression quality. Ablation studies
validate the necessity of both template hierarchies during style transfer,
showing higher content preservation win rate against sentence-only approaches
through paragraph-level structural encoding, as well as direct prompting method
through sentence-level pattern extraction and matching. The results establish
new capabilities for coherent long-text style transfer without requiring
parallel corpora or LLM fine-tuning.

</details>

### [19] [BioProBench: Comprehensive Dataset and Benchmark in Biological Protocol Understanding and Reasoning](https://arxiv.org/abs/2505.07889)
*Yuyang Liu,Liuzhenghao Lv,Xiancheng Zhang,Li Yuan,Yonghong Tian*

Main category: cs.CL

TLDR: BioProBench是一个大规模、多任务的生物协议理解与推理基准，包含五个核心任务，评估了12种主流LLM，发现它们在深度推理和结构化生成任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 生物协议对生命科学研究至关重要，但LLM在这类高度专业化、准确性要求高的文本上的系统性评估有限。

Method: 基于27K原始协议构建BioProBench，生成556K高质量结构化实例，评估12种LLM在五个核心任务上的表现。

Result: LLM在表面理解任务上表现良好，但在深度推理和结构化生成任务上表现较差，开源模型在某些任务上接近闭源模型水平。

Conclusion: 生物协议的程序性推理对当前LLM仍具挑战性，BioProBench为诊断局限性和指导AI系统开发提供了标准化框架。

Abstract: Biological protocols are fundamental to reproducible and safe life science
research. While LLMs excel on general tasks, their systematic evaluation on
these highly specialized, accuracy-critical, and inherently procedural texts
remains limited. In this work, we present BioProBench, the first large-scale,
integrated multi-task benchmark for biological protocol understanding and
reasoning. While limited benchmarks have touched upon specific aspects like
protocol QA, BioProBench provides a comprehensive suite of five core tasks:
Protocol Question Answering, Step Ordering, Error Correction, Protocol
Generation, and Protocol Reasoning, enabling a holistic evaluation of LLMs on
procedural biological texts. Built upon 27K original protocols, it yields
nearly 556K high-quality structured instances. We evaluate 12 mainstream
open/closed-source LLMs on BioProBench. Experimental results reveal that while
top models preform well on surface understanding tasks, struggle significantly
with deep reasoning and structured generation tasks like ordering and
generation. Furthermore, model comparisons reveal diverse performance: certain
open-source models approach closed-source levels on some tasks, yet
bio-specific small models lag behind general LLMs, indicating limitations on
complex procedural content. Overall, our findings underscore that procedural
reasoning within biological protocols represents a significant challenge for
current LLMs. BioProBench serves as a standardized framework to diagnose these
specific limitations and guide the development of AI systems better equipped
for safely automating complex scientific procedures. The code and data are
available at: https://github.com/YuyangSunshine/bioprotocolbench and
https://huggingface.co/datasets/GreatCaptainNemo/BioProBench.

</details>

### [20] [TSLFormer: A Lightweight Transformer Model for Turkish Sign Language Recognition Using Skeletal Landmarks](https://arxiv.org/abs/2505.07890)
*Kutay Ertürk,Furkan Altınışık,İrem Sarıaltın,Ömer Nezih Gerek*

Main category: cs.CL

TLDR: TSLFormer是一种轻量级且鲁棒的土耳其手语识别模型，将手势视为有序的字符串语言，仅使用3D关节位置作为输入，通过序列到序列的翻译方法实现高效识别。


<details>
  <summary>Details</summary>
Motivation: 手语识别通常依赖复杂的RGB或深度视频数据，计算成本高。本研究旨在通过仅使用3D关节位置，降低输入维度，同时保留语义信息，实现轻量化和高效识别。

Method: 使用Google的Mediapipe库提取手和躯干的3D关节位置作为输入，采用基于自注意力机制的序列到序列翻译方法（TSLFormer），捕捉手势序列的时间共现和运动模式。

Result: 在AUTSL数据集（36,000样本，227个单词）上表现优异，计算成本低，证明关节输入足以支持实时、移动和辅助通信系统。

Conclusion: TSLFormer展示了基于关节输入的手语识别方法的有效性，为听力障碍者的实时辅助通信系统提供了可行方案。

Abstract: This study presents TSLFormer, a light and robust word-level Turkish Sign
Language (TSL) recognition model that treats sign gestures as ordered,
string-like language. Instead of using raw RGB or depth videos, our method only
works with 3D joint positions - articulation points - extracted using Google's
Mediapipe library, which focuses on the hand and torso skeletal locations. This
creates efficient input dimensionality reduction while preserving important
semantic gesture information.
  Our approach revisits sign language recognition as sequence-to-sequence
translation, inspired by the linguistic nature of sign languages and the
success of transformers in natural language processing. Since TSLFormer uses
the self-attention mechanism, it effectively captures temporal co-occurrence
within gesture sequences and highlights meaningful motion patterns as words
unfold.
  Evaluated on the AUTSL dataset with over 36,000 samples and 227 different
words, TSLFormer achieves competitive performance with minimal computational
cost. These results show that joint-based input is sufficient for enabling
real-time, mobile, and assistive communication systems for hearing-impaired
individuals.

</details>

### [21] [TrumorGPT: Graph-Based Retrieval-Augmented Large Language Model for Fact-Checking](https://arxiv.org/abs/2505.07891)
*Ching Nam Hang,Pei-Duo Yu,Chee Wei Tan*

Main category: cs.CL

TLDR: TrumorGPT是一种基于生成式AI的事实核查工具，专注于健康领域，通过语义知识图谱和动态更新技术区分真实与虚假信息。


<details>
  <summary>Details</summary>
Motivation: 社交媒体时代，虚假信息迅速传播，尤其是健康领域的谣言对社会构成威胁，需要高效的事实核查工具。

Method: TrumorGPT利用大型语言模型（LLM）和少样本学习构建语义健康知识图谱，结合图增强生成技术（GraphRAG）动态更新数据。

Result: 在大量健康数据集测试中，TrumorGPT表现出色，能有效核查公共卫生声明，提升信息准确性。

Conclusion: TrumorGPT为对抗健康相关虚假信息提供了创新解决方案，增强了数字时代信息的可信度。

Abstract: In the age of social media, the rapid spread of misinformation and rumors has
led to the emergence of infodemics, where false information poses a significant
threat to society. To combat this issue, we introduce TrumorGPT , a novel
generative artificial intelligence solution designed for fact-checking in the
health domain. TrumorGPT aims to distinguish "trumors", which are
health-related rumors that turn out to be true, providing a crucial tool in
differentiating between mere speculation and verified facts. This framework
leverages a large language model (LLM) with few-shot learning for semantic
health knowledge graph construction and semantic reasoning. TrumorGPT
incorporates graph-based retrieval-augmented generation (GraphRAG) to address
the hallucination issue common in LLMs and the limitations of static training
data. GraphRAG involves accessing and utilizing information from regularly
updated semantic health knowledge graphs that consist of the latest medical
news and health information, ensuring that fact-checking by TrumorGPT is based
on the most recent data. Evaluating with extensive healthcare datasets,
TrumorGPT demonstrates superior performance in fact-checking for public health
claims. Its ability to effectively conduct fact-checking across various
platforms marks a critical step forward in the fight against health-related
misinformation, enhancing trust and accuracy in the digital information age.

</details>

### [22] [LongCodeBench: Evaluating Coding LLMs at 1M Context Windows](https://arxiv.org/abs/2505.07897)
*Stefano Rando,Luca Romani,Alessio Sampieri,Yuta Kyuragi,Luca Franco,Fabio Galasso,Tatsunori Hashimoto,John Yang*

Main category: cs.CL

TLDR: 论文介绍了LongCodeBench（LCB），一个用于测试长上下文模型中代码理解和修复能力的基准，发现长上下文仍是所有模型的弱点。


<details>
  <summary>Details</summary>
Motivation: 现代长上下文模型的极端上下文长度使得构建真实的长上下文基准变得困难，需要找到实际场景来测试这些能力。

Method: 通过从真实GitHub问题中提取数据，构建了QA（LongCodeQA）和bug修复（LongSWE-Bench）任务，分层评估模型性能。

Result: 所有模型在长上下文任务中表现下降，例如Claude 3.5 Sonnet从29%降至3%，Qwen2.5从70.2%降至40%。

Conclusion: 长上下文能力仍是当前模型的短板，需要进一步改进。

Abstract: Context lengths for models have grown rapidly, from thousands to millions of
tokens in just a few years. The extreme context sizes of modern long-context
models have made it difficult to construct realistic long-context benchmarks --
not only due to the cost of collecting million-context tasks but also in
identifying realistic scenarios that require significant contexts. We identify
code comprehension and repair as a natural testbed and challenge task for
long-context models and introduce LongCodeBench (LCB), a benchmark to test LLM
coding abilities in long-context scenarios. Our benchmark tests both the
comprehension and repair capabilities of LCLMs in realistic and important
settings by drawing from real-world GitHub issues and constructing QA
(LongCodeQA) and bug fixing (LongSWE-Bench) tasks. We carefully stratify the
complexity of our benchmark, enabling us to evaluate models across different
scales -- ranging from Qwen2.5 14B Instruct to Google's flagship Gemini model.
We find that long-context remains a weakness for all models, with performance
drops such as from 29% to 3% for Claude 3.5 Sonnet, or from 70.2% to 40% for
Qwen2.5.

</details>

### [23] [DeltaEdit: Enhancing Sequential Editing in Large Language Models by Controlling Superimposed Noise](https://arxiv.org/abs/2505.07899)
*Ding Cao,Yuchen Cai,Rongxi Guo,Xuesong He,Guiquan Liu*

Main category: cs.CL

TLDR: DeltaEdit通过动态正交约束策略优化更新参数，显著提升长期知识编辑的成功率，减少编辑间的干扰。


<details>
  <summary>Details</summary>
Motivation: 现有连续知识编辑方法在长期编辑后成功率显著下降，因模型输出偏离目标，称为叠加噪声累积问题。

Method: 提出DeltaEdit，采用动态正交约束策略优化更新参数，减少编辑间的干扰。

Result: DeltaEdit在编辑成功率和泛化能力保留上显著优于现有方法。

Conclusion: DeltaEdit能确保模型在长期连续编辑下保持稳定可靠的性能。

Abstract: Sequential knowledge editing techniques aim to continuously update the
knowledge in large language models at a low cost, preventing the models from
generating outdated or incorrect information. However, existing sequential
editing methods suffer from a significant decline in editing success rates
after long-term editing. Through theoretical analysis and experiments, we
identify that as the number of edits increases, the model's output increasingly
deviates from the desired target, leading to a drop in editing success rates.
We refer to this issue as the accumulation of superimposed noise problem. To
address this, we identify the factors contributing to this deviation and
propose DeltaEdit, a novel method that optimizes update parameters through a
dynamic orthogonal constraints strategy, effectively reducing interference
between edits to mitigate deviation. Experimental results demonstrate that
DeltaEdit significantly outperforms existing methods in edit success rates and
the retention of generalization capabilities, ensuring stable and reliable
model performance even under extensive sequential editing.

</details>

### [24] [SEM: Reinforcement Learning for Search-Efficient Large Language Models](https://arxiv.org/abs/2505.07903)
*Zeyang Sha,Shiwen Cui,Weiqiang Wang*

Main category: cs.CL

TLDR: 论文提出SEM框架，通过强化学习优化LLMs的搜索行为，减少冗余搜索并保持准确性。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在何时调用搜索引擎与依赖内部知识之间的决策问题，避免现有方法导致的冗余搜索和成本过高。

Method: 结合MuSiQue和MMLU构建平衡数据集，设计结构化推理模板，采用GRPO进行后训练，优化搜索行为。

Result: 实验表明，SEM显著减少了冗余搜索操作，同时在多个基准测试中保持或提高了答案准确性。

Conclusion: SEM框架提升了LLMs的推理效率，并扩展了其明智利用外部知识的能力。

Abstract: Recent advancements in Large Language Models(LLMs) have demonstrated their
capabilities not only in reasoning but also in invoking external tools,
particularly search engines. However, teaching models to discern when to invoke
search and when to rely on their internal knowledge remains a significant
challenge. Existing reinforcement learning approaches often lead to redundant
search behaviors, resulting in inefficiencies and over-cost. In this paper, we
propose SEM, a novel post-training reinforcement learning framework that
explicitly trains LLMs to optimize search usage. By constructing a balanced
dataset combining MuSiQue and MMLU, we create scenarios where the model must
learn to distinguish between questions it can answer directly and those
requiring external retrieval. We design a structured reasoning template and
employ Group Relative Policy Optimization(GRPO) to post-train the model's
search behaviors. Our reward function encourages accurate answering without
unnecessary search while promoting effective retrieval when needed.
Experimental results demonstrate that our method significantly reduces
redundant search operations while maintaining or improving answer accuracy
across multiple challenging benchmarks. This framework advances the model's
reasoning efficiency and extends its capability to judiciously leverage
external knowledge.

</details>

### [25] [Re$^2$: A Consistency-ensured Dataset for Full-stage Peer Review and Multi-turn Rebuttal Discussions](https://arxiv.org/abs/2505.07920)
*Daoze Zhang,Zhijian Bao,Sihang Du,Zhiyi Zhao,Kuangling Zhang,Dezheng Bao,Yang Yang*

Main category: cs.CL

TLDR: 论文提出了Re^2数据集，解决了现有同行评审数据集的三大局限性，支持动态交互任务，以缓解评审负担。


<details>
  <summary>Details</summary>
Motivation: 同行评审系统因投稿量激增和低质量重复提交而超负荷，现有数据集在多样性、一致性和交互支持上不足。

Method: 构建Re^2数据集，包含大量初始投稿、评审意见和反驳，并采用多轮对话范式支持动态交互任务。

Result: Re^2数据集包含19,926份初始投稿、70,668条评审意见和53,818条反驳，覆盖24个会议和21个研讨会。

Conclusion: Re^2数据集为作者和评审提供了实用工具，有望缓解评审负担并提升评审质量。

Abstract: Peer review is a critical component of scientific progress in the fields like
AI, but the rapid increase in submission volume has strained the reviewing
system, which inevitably leads to reviewer shortages and declines review
quality. Besides the growing research popularity, another key factor in this
overload is the repeated resubmission of substandard manuscripts, largely due
to the lack of effective tools for authors to self-evaluate their work before
submission. Large Language Models (LLMs) show great promise in assisting both
authors and reviewers, and their performance is fundamentally limited by the
quality of the peer review data. However, existing peer review datasets face
three major limitations: (1) limited data diversity, (2) inconsistent and
low-quality data due to the use of revised rather than initial submissions, and
(3) insufficient support for tasks involving rebuttal and reviewer-author
interactions. To address these challenges, we introduce the largest
consistency-ensured peer review and rebuttal dataset named Re^2, which
comprises 19,926 initial submissions, 70,668 review comments, and 53,818
rebuttals from 24 conferences and 21 workshops on OpenReview. Moreover, the
rebuttal and discussion stage is framed as a multi-turn conversation paradigm
to support both traditional static review tasks and dynamic interactive LLM
assistants, providing more practical guidance for authors to refine their
manuscripts and helping alleviate the growing review burden. Our data and code
are available in https://anonymous.4open.science/r/ReviewBench_anon/.

</details>

### [26] [Assessing and Mitigating Medical Knowledge Drift and Conflicts in Large Language Models](https://arxiv.org/abs/2505.07968)
*Weiyi Wu,Xinwen Xu,Chongyang Gao,Xingjian Diao,Siting Li,Lucas A. Salas,Jiang Gui*

Main category: cs.CL

TLDR: 研究探讨了大型语言模型（LLMs）在医疗指南演变中的表现，发现其难以拒绝过时建议且常支持矛盾指导。提出了两种缓解策略，结合使用效果最佳。


<details>
  <summary>Details</summary>
Motivation: LLMs在医疗领域潜力巨大，但面临适应快速变化的医学知识的挑战，可能导致过时或矛盾的治疗建议。

Method: 开发了DriftMedQA基准模拟指南演变，评估了七种先进LLMs的时序可靠性，并探索了检索增强生成和偏好微调两种缓解策略。

Result: 评估显示LLMs难以拒绝过时建议且常支持矛盾指导。两种策略结合使用效果最佳。

Conclusion: 需提升LLMs对时间变化的鲁棒性，以确保其在临床实践中的可靠性。

Abstract: Large Language Models (LLMs) have great potential in the field of health
care, yet they face great challenges in adapting to rapidly evolving medical
knowledge. This can lead to outdated or contradictory treatment suggestions.
This study investigated how LLMs respond to evolving clinical guidelines,
focusing on concept drift and internal inconsistencies. We developed the
DriftMedQA benchmark to simulate guideline evolution and assessed the temporal
reliability of various LLMs. Our evaluation of seven state-of-the-art models
across 4,290 scenarios demonstrated difficulties in rejecting outdated
recommendations and frequently endorsing conflicting guidance. Additionally, we
explored two mitigation strategies: Retrieval-Augmented Generation and
preference fine-tuning via Direct Preference Optimization. While each method
improved model performance, their combination led to the most consistent and
reliable results. These findings underscore the need to improve LLM robustness
to temporal shifts to ensure more dependable applications in clinical practice.

</details>

### [27] [Task-Adaptive Semantic Communications with Controllable Diffusion-based Data Regeneration](https://arxiv.org/abs/2505.07980)
*Fupei Guo,Achintha Wijesinghe,Songyang Zhang,Zhi Ding*

Main category: cs.CL

TLDR: 提出了一种基于扩散模型的任务自适应语义通信框架，动态调整语义信息传递以适应不同下游任务。


<details>
  <summary>Details</summary>
Motivation: 传统通信以比特传递为主，而语义通信旨在传递语义信息以提高带宽效率，需适应不同下游任务需求。

Method: 采用扩散模型，初始传输深度压缩的通用语义表示，接收端生成任务需求反馈，发送端通过注意力机制更新语义传输。

Result: 测试表明该方法能自适应保留任务关键信息，同时保持高压缩效率。

Conclusion: 该框架有效实现了任务自适应的语义通信，为下一代网络提供了新思路。

Abstract: Semantic communications represent a new paradigm of next-generation
networking that shifts bit-wise data delivery to conveying the semantic
meanings for bandwidth efficiency. To effectively accommodate various potential
downstream tasks at the receiver side, one should adaptively convey the most
critical semantic information. This work presents a novel task-adaptive
semantic communication framework based on diffusion models that is capable of
dynamically adjusting the semantic message delivery according to various
downstream tasks. Specifically, we initialize the transmission of a
deep-compressed general semantic representation from the transmitter to enable
diffusion-based coarse data reconstruction at the receiver. The receiver
identifies the task-specific demands and generates textual prompts as feedback.
Integrated with the attention mechanism, the transmitter updates the semantic
transmission with more details to better align with the objectives of the
intended receivers. Our test results demonstrate the efficacy of the proposed
method in adaptively preserving critical task-relevant information for semantic
communications while preserving high compression efficiency.

</details>

### [28] [Large Language Models and Arabic Content: A Review](https://arxiv.org/abs/2505.08004)
*Haneh Rhel,Dmitri Roussinov*

Main category: cs.CL

TLDR: 本文概述了大型语言模型（LLMs）在阿拉伯语自然语言处理（NLP）中的应用，探讨了其挑战、现有模型及优化技术。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语资源稀缺且语言复杂，研究旨在展示LLMs在阿拉伯语NLP中的潜力与进展。

Method: 综述了预训练LLMs在阿拉伯语NLP中的应用，包括微调和提示工程等技术。

Result: LLMs在多语言语料库训练下表现优异，能处理阿拉伯语多样任务和方言。

Conclusion: LLMs在阿拉伯语NLP中的应用呈上升趋势，未来需更多资源和优化技术。

Abstract: Over the past three years, the rapid advancement of Large Language Models
(LLMs) has had a profound impact on multiple areas of Artificial Intelligence
(AI), particularly in Natural Language Processing (NLP) across diverse
languages, including Arabic. Although Arabic is considered one of the most
widely spoken languages across 27 countries in the Arabic world and used as a
second language in some other non-Arabic countries as well, there is still a
scarcity of Arabic resources, datasets, and tools. Arabic NLP tasks face
various challenges due to the complexities of the Arabic language, including
its rich morphology, intricate structure, and diverse writing standards, among
other factors. Researchers have been actively addressing these challenges,
demonstrating that pre-trained Large Language Models (LLMs) trained on
multilingual corpora achieve significant success in various Arabic NLP tasks.
This study provides an overview of using large language models (LLMs) for the
Arabic language, highlighting early pre-trained Arabic Language models across
various NLP applications and their ability to handle diverse Arabic content
tasks and dialects. It also provides an overview of how techniques like
finetuning and prompt engineering can enhance the performance of these models.
Additionally, the study summarizes common Arabic benchmarks and datasets while
presenting our observations on the persistent upward trend in the adoption of
LLMs.

</details>

### [29] [TiSpell: A Semi-Masked Methodology for Tibetan Spelling Correction covering Multi-Level Error with Data Augmentation](https://arxiv.org/abs/2505.08037)
*Yutong Liu,Feng Xiao,Ziyue Zhang,Yongbin Yu,Cheng Huang,Fan Gao,Xiangxiang Wang,Ma-bao Ban,Manping Fan,Thupten Tsering,Cheng Huang,Gadeng Luosang,Renzeng Duojie,Nyima Tashi*

Main category: cs.CL

TLDR: 论文提出了一种多层次的藏文拼写校正方法TiSpell，结合字符和音节级错误校正，并通过数据增强生成训练集。实验证明其优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注单层次校正，缺乏对字符和音节级错误的有效整合，且缺乏针对藏文的开源数据集或增强方法。

Method: 提出数据增强方法生成多级错误，并设计半掩码模型TiSpell，同时校正字符和音节级错误。

Result: 在模拟和真实数据上，TiSpell优于基线模型，与最先进方法性能相当。

Conclusion: TiSpell通过半掩码策略和多级数据增强，有效解决了藏文多级拼写校正问题。

Abstract: Multi-level Tibetan spelling correction addresses errors at both the
character and syllable levels within a unified model. Existing methods focus
mainly on single-level correction and lack effective integration of both
levels. Moreover, there are no open-source datasets or augmentation methods
tailored for this task in Tibetan. To tackle this, we propose a data
augmentation approach using unlabeled text to generate multi-level corruptions,
and introduce TiSpell, a semi-masked model capable of correcting both
character- and syllable-level errors. Although syllable-level correction is
more challenging due to its reliance on global context, our semi-masked
strategy simplifies this process. We synthesize nine types of corruptions on
clean sentences to create a robust training set. Experiments on both simulated
and real-world data demonstrate that TiSpell, trained on our dataset,
outperforms baseline models and matches the performance of state-of-the-art
approaches, confirming its effectiveness.

</details>

### [30] [FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning](https://arxiv.org/abs/2505.08054)
*Zhehao Zhang,Weijie Xu,Fanyou Wu,Chandan K. Reddy*

Main category: cs.CL

TLDR: FalseReject是一个资源库，包含16k看似有毒的查询和结构化响应，旨在减少LLMs对良性查询的过度拒绝。通过图引导的多智能体交互框架生成多样化提示，并通过监督微调显著减少不必要的拒绝。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在安全对齐中对良性查询过度拒绝的问题，提升模型在敏感场景中的实用性。

Method: 提出FalseReject资源库，包含16k查询和结构化响应；采用图引导的多智能体交互框架生成多样化提示；通过监督微调优化模型。

Result: 在29个SOTA LLMs上测试，FalseReject显著减少不必要的拒绝，同时保持安全性和语言能力。

Conclusion: FalseReject有效解决了LLMs的过度拒绝问题，提升了模型的实用性和安全性。

Abstract: Safety alignment approaches in large language models (LLMs) often lead to the
over-refusal of benign queries, significantly diminishing their utility in
sensitive scenarios. To address this challenge, we introduce FalseReject, a
comprehensive resource containing 16k seemingly toxic queries accompanied by
structured responses across 44 safety-related categories. We propose a
graph-informed adversarial multi-agent interaction framework to generate
diverse and complex prompts, while structuring responses with explicit
reasoning to aid models in accurately distinguishing safe from unsafe contexts.
FalseReject includes training datasets tailored for both standard
instruction-tuned models and reasoning-oriented models, as well as a
human-annotated benchmark test set. Our extensive benchmarking on 29
state-of-the-art (SOTA) LLMs reveals persistent over-refusal challenges.
Empirical results demonstrate that supervised finetuning with FalseReject
substantially reduces unnecessary refusals without compromising overall safety
or general language capabilities.

</details>

### [31] [HYPERNYM MERCURY: Token Optimization through Semantic Field Constriction and Reconstruction from Hypernyms. A New Text Compression Method](https://arxiv.org/abs/2505.08058)
*Chris Forrester,Octavia Sulea*

Main category: cs.CL

TLDR: 提出了一种新颖的文本表示方法和语义压缩技术，可实现90%以上的标记减少，同时保持高语义相似性。


<details>
  <summary>Details</summary>
Motivation: 在NLP和下一代智能AI中，计算优化是一个重要任务，尤其是通过减少提示标记来提升效率。

Method: 采用专利待决的文本表示方案和首次提出的词级语义压缩技术，支持无损压缩和粒度控制。

Result: 在开源数据（如《德古拉》）上验证了段落级别的有效性，结果跨多种类型和模型一致。

Conclusion: 该技术显著减少了标记数量，同时保持了语义完整性，具有广泛的应用潜力。

Abstract: Compute optimization using token reduction of LLM prompts is an emerging task
in the fields of NLP and next generation, agentic AI. In this white paper, we
introduce a novel (patent pending) text representation scheme and a
first-of-its-kind word-level semantic compression of paragraphs that can lead
to over 90\% token reduction, while retaining high semantic similarity to the
source text. We explain how this novel compression technique can be lossless
and how the detail granularity is controllable. We discuss benchmark results
over open source data (i.e. Bram Stoker's Dracula available through Project
Gutenberg) and show how our results hold at the paragraph level, across
multiple genres and models.

</details>

### [32] [Are LLMs complicated ethical dilemma analyzers?](https://arxiv.org/abs/2505.08106)
*Jiashen,Du,Jesse Yao,Allen Liu,Zhekai Zhang*

Main category: cs.CL

TLDR: 论文研究了大型语言模型（LLMs）是否能模拟人类伦理推理，并通过基准数据集和复合指标评估了多个前沿LLMs的表现。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在伦理决策中是否可以作为人类判断的可信代理。

Method: 使用包含196个现实伦理困境的基准数据集，通过复合指标（BLEU、Damerau-Levenshtein距离等）评估LLMs的表现。

Result: LLMs在词汇和结构对齐上优于非专家人类，但在历史背景和复杂解决策略方面表现不佳。

Conclusion: LLMs在伦理决策中表现出潜力，但仍存在局限性，尤其是在需要抽象推理的任务中。

Abstract: One open question in the study of Large Language Models (LLMs) is whether
they can emulate human ethical reasoning and act as believable proxies for
human judgment. To investigate this, we introduce a benchmark dataset
comprising 196 real-world ethical dilemmas and expert opinions, each segmented
into five structured components: Introduction, Key Factors, Historical
Theoretical Perspectives, Resolution Strategies, and Key Takeaways. We also
collect non-expert human responses for comparison, limited to the Key Factors
section due to their brevity. We evaluate multiple frontier LLMs (GPT-4o-mini,
Claude-3.5-Sonnet, Deepseek-V3, Gemini-1.5-Flash) using a composite metric
framework based on BLEU, Damerau-Levenshtein distance, TF-IDF cosine
similarity, and Universal Sentence Encoder similarity. Metric weights are
computed through an inversion-based ranking alignment and pairwise AHP
analysis, enabling fine-grained comparison of model outputs to expert
responses. Our results show that LLMs generally outperform non-expert humans in
lexical and structural alignment, with GPT-4o-mini performing most consistently
across all sections. However, all models struggle with historical grounding and
proposing nuanced resolution strategies, which require contextual abstraction.
Human responses, while less structured, occasionally achieve comparable
semantic similarity, suggesting intuitive moral reasoning. These findings
highlight both the strengths and current limitations of LLMs in ethical
decision-making.

</details>

### [33] [Putting It All into Context: Simplifying Agents with LCLMs](https://arxiv.org/abs/2505.08120)
*Mingjian Jiang,Yangjun Ruan,Luis Lastras,Pavan Kapanipathi,Tatsunori Hashimoto*

Main category: cs.CL

TLDR: 研究表明，在SWE-bench任务中，简单地将环境信息输入长上下文语言模型（LCLM）并优化提示，可以取得与复杂代理架构相当的效果。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型代理架构的复杂性是否必要，尤其是在SWE-bench等挑战性任务中。

Method: 使用长上下文语言模型（如Gemini-1.5-Pro和Gemini-2.5-Pro）直接处理任务，无需复杂架构或工具。

Result: Gemini-1.5-Pro达到38%的解决率，Gemini-2.5-Pro达到50.8%，两阶段方法（结合Gemini-1.5-Pro和Claude-3.7）达到48.6%。

Conclusion: 在某些任务中，简化架构可能足够高效，而更强大的模型可以进一步提升性能。

Abstract: Recent advances in language model (LM) agents have demonstrated significant
potential for automating complex real-world tasks. To make progress on these
difficult tasks, LM agent architectures have become increasingly complex, often
incorporating multi-step retrieval tools, multiple agents, and scaffolding
adapted to the underlying LM. In this work, we investigate whether all of this
complexity is necessary, or if parts of these scaffolds can be removed on
challenging tasks like SWE-bench. We show that in the case of SWE-bench, simply
putting the entire environment into the context of a long context language
model (LCLM) and properly prompting the model makes it competitive with
carefully tuned, complex agent scaffolds. We show that a Gemini-1.5-Pro model
without any scaffolding or tools achieves 38% on SWE-Bench-Verified, comparable
with approaches using carefully tuned agent scaffolds (32%). While the
unscaffolded approach with Gemini-1.5-Pro falls short of the strongest agentic
architectures, we demonstrate that the more capable Gemini-2.5-Pro using the
same unscaffolded approach directly attains a 50.8% solve rate. Additionally, a
two-stage approach combining Gemini-1.5-Pro with Claude-3.7 achieves a
competitive 48.6% solve rate.

</details>

### [34] [ALOHA: Empowering Multilingual Agent for University Orientation with Hierarchical Retrieval](https://arxiv.org/abs/2505.08130)
*Mingxu Tao,Bowen Tang,Mingxuan Ma,Yining Zhang,Hourun Li,Feifan Wen,Hao Ma,Jia Yang*

Main category: cs.CL

TLDR: ALOHA系统通过分层检索和多语言支持解决校园信息检索问题，优于商业聊天机器人和搜索引擎。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在校园特定信息检索中的不足，尤其是多语言和实时性需求。

Method: 开发ALOHA系统，结合分层检索和外部API，提供交互式服务。

Result: 系统在多语言查询中表现优异，已为超过12,000人提供服务。

Conclusion: ALOHA系统有效提升了校园信息检索的准确性和用户体验。

Abstract: The rise of Large Language Models~(LLMs) revolutionizes information
retrieval, allowing users to obtain required answers through complex
instructions within conversations. However, publicly available services remain
inadequate in addressing the needs of faculty and students to search
campus-specific information. It is primarily due to the LLM's lack of
domain-specific knowledge and the limitation of search engines in supporting
multilingual and timely scenarios. To tackle these challenges, we introduce
ALOHA, a multilingual agent enhanced by hierarchical retrieval for university
orientation. We also integrate external APIs into the front-end interface to
provide interactive service. The human evaluation and case study show our
proposed system has strong capabilities to yield correct, timely, and
user-friendly responses to the queries in multiple languages, surpassing
commercial chatbots and search engines. The system has been deployed and has
provided service for more than 12,000 people.

</details>

### [35] [Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage](https://arxiv.org/abs/2505.08167)
*Ruilin Liu,Zhixiao Zhao,Jieqiong Li,Chang Liu,Dongbo Wang*

Main category: cs.CL

TLDR: 提出了一种结合双向思维链和奖励机制的新训练方法，用于解决领域特定大语言模型在微调过程中面临的偏见、知识继承错误和灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在微调过程中因非物质文化遗产数据导致的偏见、知识继承错误和灾难性遗忘问题。

Method: 提出了一种结合双向思维链（正向和反向推理）和奖励机制的训练方法，优化模型决策过程并提升输出质量。

Result: 实验表明，该方法在准确性、Bleu-4和Rouge-L得分上优于其他方法，并在多个领域数据集上表现出良好的泛化能力。

Conclusion: 该方法为多领域模型训练提供了有效解决方案，具有广泛的应用潜力。

Abstract: The rapid development of large language models (LLMs) has provided
significant support and opportunities for the advancement of domain-specific
LLMs. However, fine-tuning these large models using Intangible Cultural
Heritage (ICH) data inevitably faces challenges such as bias, incorrect
knowledge inheritance, and catastrophic forgetting. To address these issues, we
propose a novel training method that integrates a bidirectional chains of
thought and a reward mechanism. This method is built upon ICH-Qwen, a large
language model specifically designed for the field of intangible cultural
heritage. The proposed method enables the model to not only perform forward
reasoning but also enhances the accuracy of the generated answers by utilizing
reverse questioning and reverse reasoning to activate the model's latent
knowledge. Additionally, a reward mechanism is introduced during training to
optimize the decision-making process. This mechanism improves the quality of
the model's outputs through structural and content evaluations with different
weighting schemes. We conduct comparative experiments on ICH-Qwen, with results
demonstrating that our method outperforms 0-shot, step-by-step reasoning,
knowledge distillation, and question augmentation methods in terms of accuracy,
Bleu-4, and Rouge-L scores on the question-answering task. Furthermore, the
paper highlights the effectiveness of combining the bidirectional chains of
thought and reward mechanism through ablation experiments. In addition, a
series of generalizability experiments are conducted, with results showing that
the proposed method yields improvements on various domain-specific datasets and
advanced models in areas such as Finance, Wikidata, and StrategyQA. This
demonstrates that the method is adaptable to multiple domains and provides a
valuable approach for model training in future applications across diverse
fields.

</details>

### [36] [Exploiting Text Semantics for Few and Zero Shot Node Classification on Text-attributed Graph](https://arxiv.org/abs/2505.08168)
*Yuxiang Wang,Xiao Yan,Shiyu Jin,Quanqing Xu,Chuang Hu,Yuanyuan Zhu,Bo Du,Jia Wu,Jiawei Jiang*

Main category: cs.CL

TLDR: 本文提出了一种文本语义增强方法（TSA），通过引入更多文本语义监督信号，提升了文本属性图（TAG）上少样本和零样本节点分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要基于图增强技术训练节点和文本嵌入，而文本增强技术尚未充分探索。TSA旨在通过文本语义增强提升分类性能。

Method: 设计了两种文本语义增强技术：正语义匹配（检索相似嵌入的文本）和负语义对比（构造相反语义的文本描述）。

Result: 在5个数据集上评估，TSA在13个基准模型中表现最佳，通常比最佳基线模型准确率提升5%以上。

Conclusion: TSA通过文本语义增强显著提升了TAG上节点分类的准确性，证明了文本增强的有效性。

Abstract: Text-attributed graph (TAG) provides a text description for each graph node,
and few- and zero-shot node classification on TAGs have many applications in
fields such as academia and social networks. Existing work utilizes various
graph-based augmentation techniques to train the node and text embeddings,
while text-based augmentations are largely unexplored. In this paper, we
propose Text Semantics Augmentation (TSA) to improve accuracy by introducing
more text semantic supervision signals. Specifically, we design two
augmentation techniques, i.e., positive semantics matching and negative
semantics contrast, to provide more reference texts for each graph node or text
description. Positive semantic matching retrieves texts with similar embeddings
to match with a graph node. Negative semantic contrast adds a negative prompt
to construct a text description with the opposite semantics, which is
contrasted with the original node and text. We evaluate TSA on 5 datasets and
compare with 13 state-of-the-art baselines. The results show that TSA
consistently outperforms all baselines, and its accuracy improvements over the
best-performing baseline are usually over 5%.

</details>

### [37] [A Head to Predict and a Head to Question: Pre-trained Uncertainty Quantification Heads for Hallucination Detection in LLM Outputs](https://arxiv.org/abs/2505.08200)
*Artem Shelmanov,Ekaterina Fadeeva,Akim Tsvigun,Ivan Tsvigun,Zhuohan Xie,Igor Kiselev,Nico Daheim,Caiqi Zhang,Artem Vazhentsev,Mrinmaya Sachan,Preslav Nakov,Timothy Baldwin*

Main category: cs.CL

TLDR: 论文提出预训练的不确定性量化（UQ）模块，显著提升大语言模型（LLMs）检测幻觉的能力，优于无监督方法，并在多语言任务中表现出强泛化性。


<details>
  <summary>Details</summary>
Motivation: LLMs常生成虚假信息（幻觉），且难以检测。不确定性量化（UQ）可评估模型输出的可靠性，但现有方法多为无监督，效果有限。

Method: 引入预训练的UQ模块（辅助监督模块），利用Transformer架构和LLM注意力图特征，增强不确定性捕捉能力。

Result: 实验表明，该方法在幻觉检测上表现优异，支持跨领域和多语言任务，并公开了预训练模块和代码。

Conclusion: 预训练的UQ模块显著提升LLMs的幻觉检测能力，具有强泛化性和实用性。

Abstract: Large Language Models (LLMs) have the tendency to hallucinate, i.e., to
sporadically generate false or fabricated information. This presents a major
challenge, as hallucinations often appear highly convincing and users generally
lack the tools to detect them. Uncertainty quantification (UQ) provides a
framework for assessing the reliability of model outputs, aiding in the
identification of potential hallucinations. In this work, we introduce
pre-trained UQ heads: supervised auxiliary modules for LLMs that substantially
enhance their ability to capture uncertainty compared to unsupervised UQ
methods. Their strong performance stems from the powerful Transformer
architecture in their design and informative features derived from LLM
attention maps. Experimental evaluation shows that these heads are highly
robust and achieve state-of-the-art performance in claim-level hallucination
detection across both in-domain and out-of-domain prompts. Moreover, these
modules demonstrate strong generalization to languages they were not explicitly
trained on. We pre-train a collection of UQ heads for popular LLM series,
including Mistral, Llama, and Gemma 2. We publicly release both the code and
the pre-trained heads.

</details>

### [38] [Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement](https://arxiv.org/abs/2505.08245)
*Haoran Ye,Jing Jin,Yuhang Xie,Xin Zhang,Guojie Song*

Main category: cs.CL

TLDR: 本文介绍了LLM心理测量学这一新兴跨学科领域，利用心理测量工具和理论评估大型语言模型（LLMs），旨在解决传统评估方法的不足，推动以人为中心的AI发展。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法难以应对LLMs的快速发展，需引入心理测量学来量化人类心理特征，如人格和智力，以更全面评估LLMs。

Method: 通过整合心理测量学的工具、理论和方法，系统研究其在LLMs评估中的作用，包括基准原则、方法论改进和结果验证。

Result: 提出了LLM心理测量学的结构化框架，为跨学科研究者提供资源，推动更全面的评估范式。

Conclusion: LLM心理测量学为未来评估范式提供了行动指南，促进以人为中心的AI系统发展，造福社会。

Abstract: The rapid advancement of large language models (LLMs) has outpaced
traditional evaluation methodologies. It presents novel challenges, such as
measuring human-like psychological constructs, navigating beyond static and
task-specific benchmarks, and establishing human-centered evaluation. These
challenges intersect with Psychometrics, the science of quantifying the
intangible aspects of human psychology, such as personality, values, and
intelligence. This survey introduces and synthesizes an emerging
interdisciplinary field of LLM Psychometrics, which leverages psychometric
instruments, theories, and principles to evaluate, understand, and enhance
LLMs. We systematically explore the role of Psychometrics in shaping
benchmarking principles, broadening evaluation scopes, refining methodologies,
validating results, and advancing LLM capabilities. This paper integrates
diverse perspectives to provide a structured framework for researchers across
disciplines, enabling a more comprehensive understanding of this nascent field.
Ultimately, we aim to provide actionable insights for developing future
evaluation paradigms that align with human-level AI and promote the advancement
of human-centered AI systems for societal benefit. A curated repository of LLM
psychometric resources is available at
https://github.com/valuebyte-ai/Awesome-LLM-Psychometrics.

</details>

### [39] [Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration](https://arxiv.org/abs/2505.08261)
*Rishabh Agrawal,Himanshu Kumar*

Main category: cs.CL

TLDR: 本文提出了一种自适应上下文压缩（ACC）技术和混合CAG-RAG框架，以优化大语言模型在知识密集型任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管缓存增强生成（CAG）减少了检索延迟并简化了系统设计，但在处理大规模动态知识库时仍存在挑战。

Method: 引入自适应上下文压缩（ACC）动态管理上下文输入，并提出混合CAG-RAG框架，结合选择性检索以补充预加载内容。

Result: 实验表明，该方法能显著提升可扩展性、效率和多跳推理性能。

Conclusion: 提出的技术为实际知识集成问题提供了实用解决方案。

Abstract: The rapid progress in large language models (LLMs) has paved the way for
novel approaches in knowledge-intensive tasks. Among these, Cache-Augmented
Generation (CAG) has emerged as a promising alternative to Retrieval-Augmented
Generation (RAG). CAG minimizes retrieval latency and simplifies system design
by preloading knowledge into the model's context. However, challenges persist
in scaling CAG to accommodate large and dynamic knowledge bases effectively.
This paper introduces Adaptive Contextual Compression (ACC), an innovative
technique designed to dynamically compress and manage context inputs, enabling
efficient utilization of the extended memory capabilities of modern LLMs. To
further address the limitations of standalone CAG, we propose a Hybrid CAG-RAG
Framework, which integrates selective retrieval to augment preloaded contexts
in scenarios requiring additional information. Comprehensive evaluations on
diverse datasets highlight the proposed methods' ability to enhance
scalability, optimize efficiency, and improve multi-hop reasoning performance,
offering practical solutions for real-world knowledge integration challenges.

</details>

### [40] [Evaluating the Effectiveness of Black-Box Prompt Optimization as the Scale of LLMs Continues to Grow](https://arxiv.org/abs/2505.08303)
*Ziyu Zhou,Yihang Wu,Jingyuan Yang,Zhan Xiao,Rongjun Li*

Main category: cs.CL

TLDR: 黑盒提示优化方法在小规模LLMs中表现良好，但在大规模LLMs（如DeepSeek V3和Gemini 2.0 Flash）中效果有限，且随着模型规模增大，优化效果逐渐减弱。


<details>
  <summary>Details</summary>
Motivation: 研究黑盒提示优化方法在大规模LLMs中的有效性，探讨模型规模对优化效果的影响。

Method: 选择三种黑盒优化方法，在多个大规模LLMs（DeepSeek V3、Gemini 2.0 Flash）及不同规模LLMs（Qwen 2.5系列）上进行实验。

Result: 黑盒优化方法在大规模LLMs中效果有限，且模型规模越大，优化效果越差。

Conclusion: 模型规模是影响黑盒提示优化效果的关键因素，未来研究需针对大规模LLMs开发更有效的优化方法。

Abstract: Black-Box prompt optimization methods have emerged as a promising strategy
for refining input prompts to better align large language models (LLMs),
thereby enhancing their task performance. Although these methods have
demonstrated encouraging results, most studies and experiments have primarily
focused on smaller-scale models (e.g., 7B, 14B) or earlier versions (e.g.,
GPT-3.5) of LLMs. As the scale of LLMs continues to increase, such as with
DeepSeek V3 (671B), it remains an open question whether these black-box
optimization techniques will continue to yield significant performance
improvements for models of such scale. In response to this, we select three
well-known black-box optimization methods and evaluate them on large-scale LLMs
(DeepSeek V3 and Gemini 2.0 Flash) across four NLU and NLG datasets. The
results show that these black-box prompt optimization methods offer only
limited improvements on these large-scale LLMs. Furthermore, we hypothesize
that the scale of the model is the primary factor contributing to the limited
benefits observed. To explore this hypothesis, we conducted experiments on LLMs
of varying sizes (Qwen 2.5 series, ranging from 7B to 72B) and observed an
inverse scaling law, wherein the effectiveness of black-box optimization
methods diminished as the model size increased.

</details>

### [41] [AM-Thinking-v1: Advancing the Frontier of Reasoning at 32B Scale](https://arxiv.org/abs/2505.08311)
*Yunjie Ji,Xiaoyu Tian,Sitong Zhao,Haotian Wang,Shuaiting Chen,Yiping Peng,Han Zhao,Xiangang Li*

Main category: cs.CL

TLDR: AM-Thinking-v1是一个32B密集语言模型，在数学和编码能力上表现优异，超越DeepSeek-R1，媲美顶级MoE模型。


<details>
  <summary>Details</summary>
Motivation: 展示开源社区在32B规模模型上实现高性能的潜力，平衡性能和实用性。

Method: 基于开源Qwen2.5-32B模型，结合监督微调和强化学习的后训练流程。

Result: 在AIME 2024、2025和LiveCodeBench上分别取得85.3、74.4和70.3的高分。

Conclusion: AM-Thinking-v1证明了开源模型在中等规模上的高性能，推动协作创新。

Abstract: We present AM-Thinking-v1, a 32B dense language model that advances the
frontier of reasoning, embodying the collaborative spirit of open-source
innovation. Outperforming DeepSeek-R1 and rivaling leading Mixture-of-Experts
(MoE) models like Qwen3-235B-A22B and Seed1.5-Thinking, AM-Thinking-v1 achieves
impressive scores of 85.3 on AIME 2024, 74.4 on AIME 2025, and 70.3 on
LiveCodeBench, showcasing state-of-the-art mathematical and coding capabilities
among open-source models of similar scale.
  Built entirely from the open-source Qwen2.5-32B base model and publicly
available queries, AM-Thinking-v1 leverages a meticulously crafted
post-training pipeline - combining supervised fine-tuning and reinforcement
learning - to deliver exceptional reasoning capabilities. This work
demonstrates that the open-source community can achieve high performance at the
32B scale, a practical sweet spot for deployment and fine-tuning. By striking a
balance between top-tier performance and real-world usability, we hope
AM-Thinking-v1 inspires further collaborative efforts to harness mid-scale
models, pushing reasoning boundaries while keeping accessibility at the core of
innovation. We have open-sourced our model on
\href{https://huggingface.co/a-m-team/AM-Thinking-v1}{Hugging Face}.

</details>

### [42] [On the Geometry of Semantics in Next-token Prediction](https://arxiv.org/abs/2505.08348)
*Yize Zhao,Christos Thrampoulidis*

Main category: cs.CL

TLDR: 论文研究了现代语言模型如何通过简单的下一个词预测（NTP）训练目标隐式地提取和编码语义与语法概念。


<details>
  <summary>Details</summary>
Motivation: 探索NTP训练目标如何引导模型学习潜在语义和语法概念，以理解语言模型中的意义表示。

Method: 通过奇异值分解（SVD）分析中心化的数据稀疏矩阵，揭示模型如何隐式地编码语言结构。

Result: 发现最重要的SVD因子在训练早期被学习，并提出基于谱聚类的嵌入方法识别可解释的语义。

Conclusion: 研究连接了分布语义、神经崩溃几何和神经网络训练动态，揭示了NTP隐式偏置如何塑造语言模型中的意义表示。

Abstract: Modern language models demonstrate a remarkable ability to capture linguistic
meaning despite being trained solely through next-token prediction (NTP). We
investigate how this conceptually simple training objective leads models to
extract and encode latent semantic and grammatical concepts. Our analysis
reveals that NTP optimization implicitly guides models to encode concepts via
singular value decomposition (SVD) factors of a centered data-sparsity matrix
that captures next-word co-occurrence patterns. While the model never
explicitly constructs this matrix, learned word and context embeddings
effectively factor it to capture linguistic structure. We find that the most
important SVD factors are learned first during training, motivating the use of
spectral clustering of embeddings to identify human-interpretable semantics,
including both classical k-means and a new orthant-based method directly
motivated by our interpretation of concepts. Overall, our work bridges
distributional semantics, neural collapse geometry, and neural network training
dynamics, providing insights into how NTP's implicit biases shape the emergence
of meaning representations in language models.

</details>

### [43] [Alignment Drift in CEFR-prompted LLMs for Interactive Spanish Tutoring](https://arxiv.org/abs/2505.08351)
*Mina Almasi,Ross Deans Kristensen-McLachlan*

Main category: cs.CL

TLDR: 研究探讨了大型语言模型（LLMs）作为第二语言学习自适应导师的潜力，评估系统提示是否能可靠控制生成文本难度。实验发现提示虽有效但不稳定。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在个性化语言学习中的应用，尤其是如何通过提示控制文本难度以适应学生水平。

Method: 使用7B至12B参数的开源LLMs模拟师生对话，通过CEFR提示控制文本难度，评估其效果。

Result: 提示能约束输出但不稳定（对齐漂移），LLMs可作为低成本评估工具。

Conclusion: LLMs在自适应导师中潜力有限，提示需改进以支持长期互动。

Abstract: This paper investigates the potentials of Large Language Models (LLMs) as
adaptive tutors in the context of second-language learning. In particular, we
evaluate whether system prompting can reliably constrain LLMs to generate only
text appropriate to the student's competence level. We simulate full
teacher-student dialogues in Spanish using instruction-tuned, open-source LLMs
ranging in size from 7B to 12B parameters. Dialogues are generated by having an
LLM alternate between tutor and student roles with separate chat histories. The
output from the tutor model is then used to evaluate the effectiveness of
CEFR-based prompting to control text difficulty across three proficiency levels
(A1, B1, C1). Our findings suggest that while system prompting can be used to
constrain model outputs, prompting alone is too brittle for sustained,
long-term interactional contexts - a phenomenon we term alignment drift. Our
results provide insights into the feasibility of LLMs for personalized,
proficiency-aligned adaptive tutors and provide a scalable method for low-cost
evaluation of model performance without human participants.

</details>

### [44] [Towards Contamination Resistant Benchmarks](https://arxiv.org/abs/2505.08389)
*Rahmatullah Musawi,Sheng Lu*

Main category: cs.CL

TLDR: 论文提出了一种基于凯撒密码的污染抵抗基准，用于更严格地评估大型语言模型（LLMs），揭示了当前LLMs在污染控制下的局限性。


<details>
  <summary>Details</summary>
Motivation: 快速发展的LLMs需要更可靠的评估方法，污染问题是当前评估中的主要挑战。

Method: 提出基于凯撒密码的污染抵抗基准，并在多种设置下测试广泛使用的LLMs。

Result: LLMs在污染控制下表现不佳，揭示了其真实能力的局限性。

Conclusion: 该研究为开发污染抵抗基准提供了贡献，有助于更严格地评估LLMs并理解其真实能力。

Abstract: The rapid development of large language models (LLMs) has transformed the
landscape of natural language processing. Evaluating LLMs properly is crucial
for understanding their potential and addressing concerns such as safety.
However, LLM evaluation is confronted by various factors, among which
contamination stands out as a key issue that undermines the reliability of
evaluations. In this work, we introduce the concept of contamination resistance
to address this challenge. We propose a benchmark based on Caesar ciphers
(e.g., "ab" to "bc" when the shift is 1), which, despite its simplicity, is an
excellent example of a contamination resistant benchmark. We test this
benchmark on widely used LLMs under various settings, and we find that these
models struggle with this benchmark when contamination is controlled. Our
findings reveal issues in current LLMs and raise important questions regarding
their true capabilities. Our work contributes to the development of
contamination resistant benchmarks, enabling more rigorous LLM evaluation and
offering insights into the true capabilities and limitations of LLMs.

</details>

### [45] [Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping](https://arxiv.org/abs/2505.08392)
*Ren Zhuang,Ben Wang,Shuifa Sun*

Main category: cs.CL

TLDR: 论文提出Adaptive GoGI-Skip框架，通过动态压缩Chain-of-Thought（CoT）提示，提高推理效率，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 当前CoT压缩技术依赖静态压缩率和通用重要性指标，可能导致关键信息丢失或无法适应复杂推理任务。

Method: 提出Goal-Gradient Importance（GoGI）指标和Adaptive Dynamic Skipping（ADS）机制，动态调整压缩率。

Result: 在多个推理基准测试中，平均减少45%的CoT标记，推理速度提升1.6-2.0倍，同时保持高准确性。

Conclusion: Adaptive GoGI-Skip在效率和准确性之间取得显著平衡，优于现有基线。

Abstract: Large Language Models leverage Chain-of-Thought (CoT) prompting for complex
tasks, but their reasoning traces are often excessively verbose and
inefficient, leading to significant computational costs and latency. Current
CoT compression techniques typically rely on generic importance metrics and
static compression rates, which may inadvertently remove functionally critical
tokens or fail to adapt to varying reasoning complexity. To overcome these
limitations, we propose Adaptive GoGI-Skip, a novel framework learning dynamic
CoT compression via supervised fine-tuning. This approach introduces two
synergistic innovations: (1) Goal-Gradient Importance (GoGI), a novel metric
accurately identifying functionally relevant tokens by measuring the gradient
influence of their intermediate representations on the final answer loss, and
(2) Adaptive Dynamic Skipping (ADS), a mechanism dynamically regulating the
compression rate based on runtime model uncertainty while ensuring local
coherence through an adaptive N-token constraint. To our knowledge, this is the
first work unifying a goal-oriented, gradient-based importance metric with
dynamic, uncertainty-aware skipping for CoT compression. Trained on compressed
MATH data, Adaptive GoGI-Skip demonstrates strong cross-domain generalization
across diverse reasoning benchmarks including AIME, GPQA, and GSM8K. It
achieves substantial efficiency gains - reducing CoT token counts by over 45%
on average and delivering 1.6-2.0 times inference speedups - while maintaining
high reasoning accuracy. Notably, it significantly outperforms existing
baselines by preserving accuracy even at high effective compression rates,
advancing the state of the art in the CoT reasoning efficiency-accuracy
trade-off.

</details>

### [46] [TUMS: Enhancing Tool-use Abilities of LLMs with Multi-structure Handlers](https://arxiv.org/abs/2505.08402)
*Aiyao He,Sijia Cui,Shuai Xu,Yanna Wang,Bo Xu*

Main category: cs.CL

TLDR: 论文提出TUMS框架，通过将工具级处理转为参数级处理，提升LLMs的工具使用能力，实验显示在ToolQA基准上性能显著提升。


<details>
  <summary>Details</summary>
Motivation: LLMs在与外部工具集成时面临非可执行动作和参数错误问题，现有方法未考虑不同工具的难度差异。

Method: TUMS框架包含意图识别器、任务分解器、子任务处理器和执行器，通过参数级处理优化工具调用。

Result: 在ToolQA基准上，TUMS在简单和困难任务上分别提升19.6%和50.6%。

Conclusion: TUMS有效提升LLMs的工具使用能力，并通过消融实验验证各组件贡献，为未来研究提供启示。

Abstract: Recently, large language models(LLMs) have played an increasingly important
role in solving a wide range of NLP tasks, leveraging their capabilities of
natural language understanding and generating. Integration with external tools
further enhances LLMs' effectiveness, providing more precise, timely, and
specialized responses. However, LLMs still encounter difficulties with
non-executable actions and improper actions, which are primarily attributed to
incorrect parameters. The process of generating parameters by LLMs is confined
to the tool level, employing the coarse-grained strategy without considering
the different difficulties of various tools. To address this issue, we propose
TUMS, a novel framework designed to enhance the tool-use capabilities of LLMs
by transforming tool-level processing into parameter-level processing.
Specifically, our framework consists of four key components: (1) an intent
recognizer that identifies the user's intent to help LLMs better understand the
task; (2) a task decomposer that breaks down complex tasks into simpler
subtasks, each involving a tool call; (3) a subtask processor equipped with
multi-structure handlers to generate accurate parameters; and (4) an executor.
Our empirical studies have evidenced the effectiveness and efficiency of the
TUMS framework with an average of 19.6\% and 50.6\% improvement separately on
easy and hard benchmarks of ToolQA, meanwhile, we demonstrated the key
contribution of each part with ablation experiments, offering more insights and
stimulating future research on Tool-augmented LLMs.

</details>

### [47] [Hakim: Farsi Text Embedding Model](https://arxiv.org/abs/2505.08435)
*Mehran Sarmadi,Morteza Alikhani,Erfan Zinvandi,Zahra Pourbahman*

Main category: cs.CL

TLDR: Hakim是一种新型波斯语文本嵌入模型，性能提升8.5%，并引入三个新数据集支持训练。


<details>
  <summary>Details</summary>
Motivation: 波斯语在大规模嵌入研究中代表性不足，需提升其语言理解能力。

Method: 提出基于BERT的基线模型和RetroMAE模型，并引入三个新数据集。

Result: Hakim在FaMTEB基准测试中表现优于现有模型，适用于聊天机器人和RAG系统。

Conclusion: 这些贡献为波斯语语言理解奠定了基础。

Abstract: Recent advancements in text embedding have significantly improved natural
language understanding across many languages, yet Persian remains notably
underrepresented in large-scale embedding research. In this paper, we present
Hakim, a novel state-of-the-art Persian text embedding model that achieves a
8.5% performance improvement over existing approaches on the FaMTEB benchmark,
outperforming all previously developed Persian language models. As part of this
work, we introduce three new datasets - Corpesia, Pairsia-sup, and
Pairsia-unsup - to support supervised and unsupervised training scenarios.
Additionally, Hakim is designed for applications in chatbots and
retrieval-augmented generation (RAG) systems, particularly addressing retrieval
tasks that require incorporating message history within these systems. We also
propose a new baseline model built on the BERT architecture. Our language model
consistently achieves higher accuracy across various Persian NLP tasks, while
the RetroMAE-based model proves particularly effective for textual information
retrieval applications. Together, these contributions establish a new
foundation for advancing Persian language understanding.

</details>

### [48] [A document processing pipeline for the construction of a dataset for topic modeling based on the judgments of the Italian Supreme Court](https://arxiv.org/abs/2505.08439)
*Matteo Marulli,Glauco Panattoni,Marco Bertini*

Main category: cs.CL

TLDR: 为解决意大利法律研究中主题建模缺乏公开数据集的问题，开发了一个文档处理流程，生成匿名数据集，显著提升了主题建模效果。


<details>
  <summary>Details</summary>
Motivation: 意大利法律研究中缺乏公开数据集，限制了最高法院判决中法律主题的分析。

Method: 集成了文档布局分析（YOLOv8x）、光学字符识别和文本匿名化的处理流程，并应用BERTopic提取主题，利用大语言模型生成标签和摘要。

Result: 文档布局分析和OCR模块表现优异，数据集显著提升了主题建模的多样性和一致性。Claude Sonnet 3.7在标签和摘要任务中表现良好。

Conclusion: 开发的流程和数据集有效解决了意大利法律研究中主题建模的数据限制问题，并为类似研究提供了参考。

Abstract: Topic modeling in Italian legal research is hindered by the lack of public
datasets, limiting the analysis of legal themes in Supreme Court judgments. To
address this, we developed a document processing pipeline that produces an
anonymized dataset optimized for topic modeling.
  The pipeline integrates document layout analysis (YOLOv8x), optical character
recognition, and text anonymization. The DLA module achieved a mAP@50 of 0.964
and a mAP@50-95 of 0.800. The OCR detector reached a mAP@50-95 of 0.9022, and
the text recognizer (TrOCR) obtained a character error rate of 0.0047 and a
word error rate of 0.0248. Compared to OCR-only methods, our dataset improved
topic modeling with a diversity score of 0.6198 and a coherence score of
0.6638.
  We applied BERTopic to extract topics and used large language models to
generate labels and summaries. Outputs were evaluated against domain expert
interpretations. Claude Sonnet 3.7 achieved a BERTScore F1 of 0.8119 for
labeling and 0.9130 for summarization.

</details>

### [49] [IterKey: Iterative Keyword Generation with LLMs for Enhanced Retrieval Augmented Generation](https://arxiv.org/abs/2505.08450)
*Kazuki Hayashi,Hidetaka Kamigaito,Shinya Kouda,Taro Watanabe*

Main category: cs.CL

TLDR: IterKey是一个基于稀疏检索的LLM驱动框架，通过迭代生成关键词提升RAG的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决密集检索方法缺乏可解释性和稀疏检索方法无法完全捕捉查询意图的问题。

Method: IterKey包含三个阶段：生成检索关键词、基于检索文档生成答案、验证答案。若验证失败，则迭代优化关键词。

Result: 在四个QA任务中，IterKey比BM25-based RAG和简单基线方法提高了5%到20%的准确率，性能接近密集检索方法。

Conclusion: IterKey通过LLM迭代优化稀疏检索，有效平衡了准确性和可解释性。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a way to complement the
in-context knowledge of Large Language Models (LLMs) by integrating external
documents. However, real-world applications demand not only accuracy but also
interpretability. While dense retrieval methods provide high accuracy, they
lack interpretability; conversely, sparse retrieval methods offer transparency
but often fail to capture the full intent of queries due to their reliance on
keyword matching. To address these issues, we introduce IterKey, an LLM-driven
iterative keyword generation framework that enhances RAG via sparse retrieval.
IterKey consists of three LLM-driven stages: generating keywords for retrieval,
generating answers based on retrieved documents, and validating the answers. If
validation fails, the process iteratively repeats with refined keywords. Across
four QA tasks, experimental results show that IterKey achieves 5% to 20%
accuracy improvements over BM25-based RAG and simple baselines. Its performance
is comparable to dense retrieval-based RAG and prior iterative query refinement
methods using dense models. In summary, IterKey is a novel BM25-based approach
leveraging LLMs to iteratively refine RAG, effectively balancing accuracy with
interpretability.

</details>

### [50] [RepCali: High Efficient Fine-tuning Via Representation Calibration in Latent Space for Pre-trained Language Models](https://arxiv.org/abs/2505.08463)
*Fujun Zhang,XiangDong Su*

Main category: cs.CL

TLDR: RepCali方法通过校准预训练语言模型（PLM）的潜在空间表示，解决编码器与解码器输入不匹配问题，显著提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: PLM在微调后仍存在编码器表示与解码器最优输入不匹配的问题，影响性能。

Method: 在编码器后添加校准模块，校准潜在空间表示作为解码器输入。

Result: 在25个PLM模型和8个任务中验证，RepCali显著提升性能，优于基准微调方法。

Conclusion: RepCali是一种通用、即插即用的方法，能有效提升PLM在下游任务中的表现。

Abstract: Fine-tuning pre-trained language models (PLMs) has become a dominant paradigm
in applying PLMs to downstream tasks. However, with limited fine-tuning, PLMs
still struggle with the discrepancies between the representation obtained from
the PLMs' encoder and the optimal input to the PLMs' decoder. This paper
tackles this challenge by learning to calibrate the representation of PLMs in
the latent space. In the proposed representation calibration method (RepCali),
we integrate a specific calibration block to the latent space after the encoder
and use the calibrated output as the decoder input. The merits of the proposed
RepCali include its universality to all PLMs with encoder-decoder
architectures, its plug-and-play nature, and ease of implementation. Extensive
experiments on 25 PLM-based models across 8 tasks (including both English and
Chinese datasets) demonstrate that the proposed RepCali offers desirable
enhancements to PLMs (including LLMs) and significantly improves the
performance of downstream tasks. Comparison experiments across 4 benchmark
tasks indicate that RepCali is superior to the representative fine-tuning
baselines.

</details>

### [51] [Large Language Models Meet Stance Detection: A Survey of Tasks, Methods, Applications, Challenges and Future Directions](https://arxiv.org/abs/2505.08464)
*Lata Pangtey,Anukriti Bhatnagar,Shubhi Bansal,Shahid Shafi Dar,Nagendra Kumar*

Main category: cs.CL

TLDR: 这篇综述文章系统分析了基于大语言模型（LLMs）的立场检测方法，提出了新的分类法，并讨论了应用、挑战及未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有调查缺乏对LLMs在立场检测中应用的全面覆盖，本文旨在填补这一空白。

Method: 通过系统分析，提出基于学习方式、数据模态和目标关系的分类法，并评估技术和数据集。

Result: 总结了LLMs在立场检测中的优势与局限，并探讨了关键应用和挑战。

Conclusion: 文章为研究人员和实践者提供了未来发展的指导，强调了新兴趋势和开放挑战。

Abstract: Stance detection is essential for understanding subjective content across
various platforms such as social media, news articles, and online reviews.
Recent advances in Large Language Models (LLMs) have revolutionized stance
detection by introducing novel capabilities in contextual understanding,
cross-domain generalization, and multimodal analysis. Despite these
progressions, existing surveys often lack comprehensive coverage of approaches
that specifically leverage LLMs for stance detection. To bridge this critical
gap, our review article conducts a systematic analysis of stance detection,
comprehensively examining recent advancements of LLMs transforming the field,
including foundational concepts, methodologies, datasets, applications, and
emerging challenges. We present a novel taxonomy for LLM-based stance detection
approaches, structured along three key dimensions: 1) learning methods,
including supervised, unsupervised, few-shot, and zero-shot; 2) data
modalities, such as unimodal, multimodal, and hybrid; and 3) target
relationships, encompassing in-target, cross-target, and multi-target
scenarios. Furthermore, we discuss the evaluation techniques and analyze
benchmark datasets and performance trends, highlighting the strengths and
limitations of different architectures. Key applications in misinformation
detection, political analysis, public health monitoring, and social media
moderation are discussed. Finally, we identify critical challenges such as
implicit stance expression, cultural biases, and computational constraints,
while outlining promising future directions, including explainable stance
reasoning, low-resource adaptation, and real-time deployment frameworks. Our
survey highlights emerging trends, open challenges, and future directions to
guide researchers and practitioners in developing next-generation stance
detection systems powered by large language models.

</details>

### [52] [Judging the Judges: Can Large Vision-Language Models Fairly Evaluate Chart Comprehension and Reasoning?](https://arxiv.org/abs/2505.08468)
*Md Tahmid Rahman Laskar,Mohammed Saidul Islam,Ridwan Mahbub,Ahmed Masry,Mizanur Rahman,Amran Bhuiyan,Mir Tafseer Nayeem,Shafiq Joty,Enamul Hoque,Jimmy Huang*

Main category: cs.CL

TLDR: 论文评估了13种开源大型视觉语言模型（LVLM）作为图表理解任务的自动评估工具，发现部分模型性能接近GPT-4，但存在位置偏好和长度偏差等问题。


<details>
  <summary>Details</summary>
Motivation: 现有的图表理解任务评估成本高且耗时，限制了实际应用。利用LVLM作为评估工具可以简化流程，但面临数据集、模型访问和成本等挑战。

Method: 设计了成对和点对评估任务，涵盖事实正确性、信息量和相关性等标准，并分析了格式遵循、位置一致性和指令遵循等指标。

Result: 实验结果显示开源LVLM评估性能差异显著，部分模型与GPT-4评估结果一致率达80%，而其他模型低于10%。

Conclusion: 开源LVLM可作为图表任务的低成本自动评估工具，但仍需解决位置偏好和长度偏差等问题。

Abstract: Charts are ubiquitous as they help people understand and reason with data.
Recently, various downstream tasks, such as chart question answering,
chart2text, and fact-checking, have emerged. Large Vision-Language Models
(LVLMs) show promise in tackling these tasks, but their evaluation is costly
and time-consuming, limiting real-world deployment. While using LVLMs as judges
to assess the chart comprehension capabilities of other LVLMs could streamline
evaluation processes, challenges like proprietary datasets, restricted access
to powerful models, and evaluation costs hinder their adoption in industrial
settings. To this end, we present a comprehensive evaluation of 13 open-source
LVLMs as judges for diverse chart comprehension and reasoning tasks. We design
both pairwise and pointwise evaluation tasks covering criteria like factual
correctness, informativeness, and relevancy. Additionally, we analyze LVLM
judges based on format adherence, positional consistency, length bias, and
instruction-following. We focus on cost-effective LVLMs (<10B parameters)
suitable for both research and commercial use, following a standardized
evaluation protocol and rubric to measure the LVLM judge's accuracy.
Experimental results reveal notable variability: while some open LVLM judges
achieve GPT-4-level evaluation performance (about 80% agreement with GPT-4
judgments), others struggle (below ~10% agreement). Our findings highlight that
state-of-the-art open-source LVLMs can serve as cost-effective automatic
evaluators for chart-related tasks, though biases such as positional preference
and length bias persist.

</details>

### [53] [LCES: Zero-shot Automated Essay Scoring via Pairwise Comparisons Using Large Language Models](https://arxiv.org/abs/2505.08498)
*Takumi Shibata,Yuichi Miyamura*

Main category: cs.CL

TLDR: 论文提出了一种基于大语言模型（LLM）的对比性作文评分方法（LCES），通过将评分任务转化为成对比较，解决了传统零样本方法因模型偏见和不一致评分导致的问题。


<details>
  <summary>Details</summary>
Motivation: 现有零样本方法直接生成绝对分数，容易与人工评分不一致。LCES旨在通过成对比较提高评分的准确性和鲁棒性。

Method: 将作文评分任务转化为成对比较，利用LLM判断两篇作文的优劣，并通过RankNet将比较结果转换为连续分数。

Result: 实验表明，LCES在准确性和计算效率上优于传统零样本方法，且在不同LLM模型上表现稳健。

Conclusion: LCES为现实中的零样本作文评分提供了一种高效且可靠的解决方案。

Abstract: Recent advances in large language models (LLMs) have enabled zero-shot
automated essay scoring (AES), providing a promising way to reduce the cost and
effort of essay scoring in comparison with manual grading. However, most
existing zero-shot approaches rely on LLMs to directly generate absolute
scores, which often diverge from human evaluations owing to model biases and
inconsistent scoring. To address these limitations, we propose LLM-based
Comparative Essay Scoring (LCES), a method that formulates AES as a pairwise
comparison task. Specifically, we instruct LLMs to judge which of two essays is
better, collect many such comparisons, and convert them into continuous scores.
Considering that the number of possible comparisons grows quadratically with
the number of essays, we improve scalability by employing RankNet to
efficiently transform LLM preferences into scalar scores. Experiments using AES
benchmark datasets show that LCES outperforms conventional zero-shot methods in
accuracy while maintaining computational efficiency. Moreover, LCES is robust
across different LLM backbones, highlighting its applicability to real-world
zero-shot AES.

</details>

### [54] [Reassessing Graph Linearization for Sequence-to-sequence AMR Parsing: On the Advantages and Limitations of Triple-Based Encoding](https://arxiv.org/abs/2505.08504)
*Jeongwoo Kang,Maximin Coavoux,Cédric Lopez,Didier Schwab*

Main category: cs.CL

TLDR: 论文提出了一种基于三元组的线性化方法，用于改进AMR图的序列化表示，解决了Penman编码在深度图和节点重入时的局限性。


<details>
  <summary>Details</summary>
Motivation: Penman编码在表示深度图和节点重入时存在局限性，如节点距离远和关系类型翻倍的问题。

Method: 提出了一种基于三元组的线性化方法，并与Penman编码进行比较。

Result: 三元组方法在表示图结构时仍有改进空间，未能完全超越Penman的简洁性和嵌套结构的明确表示。

Conclusion: 三元组编码虽能解决部分问题，但需进一步优化以更好地与Penman编码竞争。

Abstract: Sequence-to-sequence models are widely used to train Abstract Meaning
Representation (Banarescu et al., 2013, AMR) parsers. To train such models, AMR
graphs have to be linearized into a one-line text format. While Penman encoding
is typically used for this purpose, we argue that it has limitations: (1) for
deep graphs, some closely related nodes are located far apart in the linearized
text (2) Penman's tree-based encoding necessitates inverse roles to handle node
re-entrancy, doubling the number of relation types to predict. To address these
issues, we propose a triple-based linearization method and compare its
efficiency with Penman linearization. Although triples are well suited to
represent a graph, our results suggest room for improvement in triple encoding
to better compete with Penman's concise and explicit representation of a nested
graph structure.

</details>

### [55] [Are We Paying Attention to Her? Investigating Gender Disambiguation and Attention in Machine Translation](https://arxiv.org/abs/2505.08546)
*Chiara Manna,Afra Alishahi,Frédéric Blain,Eva Vanmassenhove*

Main category: cs.CL

TLDR: 论文提出了一种新的评估指标MPA，用于衡量NMT模型对性别线索的依赖程度，发现模型更倾向于忽略性别线索而依赖统计性别刻板印象。


<details>
  <summary>Details</summary>
Motivation: 传统评估指标未能充分捕捉NMT系统对上下文性别线索的整合程度，因此需要更精准的评估方法。

Method: 提出Minimal Pair Accuracy (MPA)指标，通过最小对句子（仅性别代词不同）评估模型对性别线索的依赖。

Result: 模型在大多数情况下忽略性别线索，依赖刻板印象；在反刻板情况下，更倾向于考虑男性线索而忽略女性线索。

Conclusion: NMT模型对性别线索的处理存在偏差，男性线索引发更分散的响应，女性线索则更集中和专门化。

Abstract: While gender bias in modern Neural Machine Translation (NMT) systems has
received much attention, traditional evaluation metrics do not to fully capture
the extent to which these systems integrate contextual gender cues. We propose
a novel evaluation metric called Minimal Pair Accuracy (MPA), which measures
the reliance of models on gender cues for gender disambiguation. MPA is
designed to go beyond surface-level gender accuracy metrics by focusing on
whether models adapt to gender cues in minimal pairs -- sentence pairs that
differ solely in the gendered pronoun, namely the explicit indicator of the
target's entity gender in the source language (EN). We evaluate a number of NMT
models on the English-Italian (EN--IT) language pair using this metric, we show
that they ignore available gender cues in most cases in favor of (statistical)
stereotypical gender interpretation. We further show that in anti-stereotypical
cases, these models tend to more consistently take masculine gender cues into
account while ignoring the feminine cues. Furthermore, we analyze the attention
head weights in the encoder component and show that while all models encode
gender information to some extent, masculine cues elicit a more diffused
response compared to the more concentrated and specialized responses to
feminine gender cues.

</details>

### [56] [Small but Significant: On the Promise of Small Language Models for Accessible AIED](https://arxiv.org/abs/2505.08588)
*Yumou Wei,Paulo Carvalho,John Stamper*

Main category: cs.CL

TLDR: 论文指出，尽管GPT等大型语言模型（LLMs）在教育领域受到广泛关注，但小型语言模型（SLMs）在资源受限机构中的应用潜力被忽视。通过实验证明，SLMs如Phi-2能有效解决教育中的关键问题。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在教育领域的流行趋势，并强调SLMs在资源受限环境中的潜在价值。

Method: 通过关键词搜索分析AIED 2024论文中LLMs的使用情况，并以Phi-2为例验证SLMs在知识组件发现中的有效性。

Result: 61%的AIED 2024论文使用LLMs，43%提及GPT；SLMs如Phi-2在无需复杂提示策略下表现良好。

Conclusion: 呼吁更多关注SLMs在教育中的应用，以实现更公平、高效的AI工具普及。

Abstract: GPT has become nearly synonymous with large language models (LLMs), an
increasingly popular term in AIED proceedings. A simple keyword-based search
reveals that 61% of the 76 long and short papers presented at AIED 2024
describe novel solutions using LLMs to address some of the long-standing
challenges in education, and 43% specifically mention GPT. Although LLMs
pioneered by GPT create exciting opportunities to strengthen the impact of AI
on education, we argue that the field's predominant focus on GPT and other
resource-intensive LLMs (with more than 10B parameters) risks neglecting the
potential impact that small language models (SLMs) can make in providing
resource-constrained institutions with equitable and affordable access to
high-quality AI tools. Supported by positive results on knowledge component
(KC) discovery, a critical challenge in AIED, we demonstrate that SLMs such as
Phi-2 can produce an effective solution without elaborate prompting strategies.
Hence, we call for more attention to developing SLM-based AIED approaches.

</details>

### [57] [Enhancing Thyroid Cytology Diagnosis with RAG-Optimized LLMs and Pa-thology Foundation Models](https://arxiv.org/abs/2505.08590)
*Hussien Al-Asi,Jordan P Reynolds,Shweta Agarwal,Bryan J Dangott,Aziza Nassar,Zeynettin Akkus*

Main category: cs.CL

TLDR: 该研究探索了结合检索增强生成（RAG）和病理学基础模型的AI方法，用于甲状腺细胞学诊断，提高了诊断效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决细胞学解释、标准化和诊断准确性方面的挑战，提升甲状腺细胞学诊断的效率和一致性。

Method: 结合RAG增强的大型语言模型（LLMs）和病理学基础模型，利用知识库动态检索相关信息，并通过高分辨率病理图像训练模型。

Result: 该方法显著提高了诊断效率和可解释性，基础模型UNI在预测甲状腺细胞学样本的手术病理诊断中AUC达到0.73-0.93。

Conclusion: 该研究为AI辅助甲状腺细胞病理学提供了有效方法，展示了RAG与病理学专用LLMs结合的潜力。

Abstract: Advancements in artificial intelligence (AI) are transforming pathology by
integrat-ing large language models (LLMs) with retrieval-augmented generation
(RAG) and domain-specific foundation models. This study explores the
application of RAG-enhanced LLMs coupled with pathology foundation models for
thyroid cytology diagnosis, addressing challenges in cytological
interpretation, standardization, and diagnostic accuracy. By leveraging a
curated knowledge base, RAG facilitates dy-namic retrieval of relevant case
studies, diagnostic criteria, and expert interpreta-tion, improving the
contextual understanding of LLMs. Meanwhile, pathology foun-dation models,
trained on high-resolution pathology images, refine feature extrac-tion and
classification capabilities. The fusion of these AI-driven approaches en-hances
diagnostic consistency, reduces variability, and supports pathologists in
dis-tinguishing benign from malignant thyroid lesions. Our results demonstrate
that integrating RAG with pathology-specific LLMs significantly improves
diagnostic efficiency and interpretability, paving the way for AI-assisted
thyroid cytopathology, with foundation model UNI achieving AUC 0.73-0.93 for
correct prediction of surgi-cal pathology diagnosis from thyroid cytology
samples.

</details>

### [58] [Automatic Task Detection and Heterogeneous LLM Speculative Decoding](https://arxiv.org/abs/2505.08600)
*Danying Ge,Jianhua Gao,Qizhi Jiang,Yifei Feng,Weixing Ji*

Main category: cs.CL

TLDR: 提出了一种针对下游任务优化的推测解码算法，通过任务分区和异构草稿模型提升解码效率。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法在解码速度和接受率之间存在权衡，难以保证多样化任务的效率。

Method: 采用自动任务分区和分配方法，结合异构草稿模型和在线轻量级提示分类器。

Result: 草稿准确率提升6%至50%，推理速度提升1.10倍至2.64倍。

Conclusion: 该方法显著提升了推测解码在下游任务中的效率和准确性。

Abstract: Speculative decoding, which combines a draft model with a target model, has
emerged as an effective approach to accelerate large language model (LLM)
inference. However, existing methods often face a trade-off between the
acceptance rate and decoding speed in downstream tasks due to the limited
capacity of the draft model, making it difficult to ensure efficiency across
diverse tasks. To address this problem, we propose a speculative decoding
algorithm tailored for downstream task optimization. It includes an automatic
task partitioning and assigning method, which automatically categorizes
downstream tasks into different sub-tasks and assigns them to a set of
heterogeneous draft models. Each draft model is aligned with the target model
using task-specific data, thereby enhancing the consistency of inference
results. In addition, our proposed method incorporates an online lightweight
prompt classifier to dynamically route prompts to the appropriate draft model.
Experimental results demonstrate that the proposed method improves draft
accuracy by 6% to 50% over vanilla speculative decoding, while achieving a
speedup of 1.10x to 2.64x in LLM inference.

</details>

### [59] [Scaling Context, Not Parameters: Training a Compact 7B Language Model for Efficient Long-Context Processing](https://arxiv.org/abs/2505.08651)
*Chen Wu,Yin Song*

Main category: cs.CL

TLDR: MegaBeam-Mistral-7B是一个支持512K标记上下文长度的语言模型，解决了长上下文训练的实际限制，适用于合规监控等任务。


<details>
  <summary>Details</summary>
Motivation: 解决长上下文训练的实际限制，支持现实任务如合规监控和验证。

Method: 开发了一个7B参数模型，支持512K标记上下文长度。

Result: 在HELMET和RULER基准测试中表现优异，是唯一在BABILong上无需RAG或微调即可实现竞争性长程推理的开放模型。

Conclusion: 模型已开源，下载量超过10万次，适用于长上下文任务。

Abstract: We present MegaBeam-Mistral-7B, a language model that supports 512K-token
context length. Our work addresses practical limitations in long-context
training, supporting real-world tasks such as compliance monitoring and
verification. Evaluated on three long-context benchmarks, our 7B-parameter
model demonstrates superior in-context learning performance on HELMET and
robust retrieval and tracing capability on RULER. It is currently the only open
model to achieve competitive long-range reasoning on BABILong at 512K context
length without RAG or targeted fine-tuning. Released as fully open source under
the Apache 2.0 license, the model has been downloaded over 100,000 times on
Hugging Face. Model available at:
https://huggingface.co/aws-prototyping/MegaBeam-Mistral-7B-512k

</details>

### [60] [Revealing economic facts: LLMs know more than they say](https://arxiv.org/abs/2505.08662)
*Marcus Buckmann,Quynh Anh Nguyen,Edward Hill*

Main category: cs.CL

TLDR: 研究发现，大型语言模型（LLM）的隐藏状态可用于估计和填补经济与金融统计数据，且效果优于模型的文本输出。


<details>
  <summary>Details</summary>
Motivation: 探索LLM隐藏状态是否包含比直接文本输出更丰富的经济信息。

Method: 使用简单线性模型训练LLM隐藏状态，并提出无需目标变量标签的迁移学习方法。

Result: 隐藏状态在少量标注数据下表现优异，迁移学习进一步提升了估计准确性。

Conclusion: 隐藏状态在经济统计任务中具有实用价值，尤其在超分辨率和数据填补方面。

Abstract: We investigate whether the hidden states of large language models (LLMs) can
be used to estimate and impute economic and financial statistics. Focusing on
county-level (e.g. unemployment) and firm-level (e.g. total assets) variables,
we show that a simple linear model trained on the hidden states of open-source
LLMs outperforms the models' text outputs. This suggests that hidden states
capture richer economic information than the responses of the LLMs reveal
directly. A learning curve analysis indicates that only a few dozen labelled
examples are sufficient for training. We also propose a transfer learning
method that improves estimation accuracy without requiring any labelled data
for the target variable. Finally, we demonstrate the practical utility of
hidden-state representations in super-resolution and data imputation tasks.

</details>

### [61] [Adaptive Schema-aware Event Extraction with Retrieval-Augmented Generation](https://arxiv.org/abs/2505.08690)
*Sheng Liang,Hang Lv,Zhihao Wen,Yaxiong Wu,Yongyue Zhang,Hao Wang,Yong Liu*

Main category: cs.CL

TLDR: 论文提出了一种自适应模式感知事件抽取（ASEE）方法，结合模式改写和检索增强生成，解决了现有事件抽取中的模式固定和基准缺失问题，并通过MD-SEE基准验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有事件抽取方法存在模式固定和缺乏联合模式匹配与抽取的基准问题，大语言模型虽有潜力但存在模式幻觉和上下文窗口限制。

Method: 提出ASEE方法，结合模式改写和检索增强生成，动态检索改写模式并生成目标结构。

Result: 在MD-SEE基准上，ASEE表现出强适应性，显著提升了事件抽取的准确性。

Conclusion: ASEE通过动态模式适应和检索增强生成，有效解决了事件抽取中的关键挑战，并在多领域、多语言场景中表现出色。

Abstract: Event extraction (EE) is a fundamental task in natural language processing
(NLP) that involves identifying and extracting event information from
unstructured text. Effective EE in real-world scenarios requires two key steps:
selecting appropriate schemas from hundreds of candidates and executing the
extraction process. Existing research exhibits two critical gaps: (1) the rigid
schema fixation in existing pipeline systems, and (2) the absence of benchmarks
for evaluating joint schema matching and extraction. Although large language
models (LLMs) offer potential solutions, their schema hallucination tendencies
and context window limitations pose challenges for practical deployment. In
response, we propose Adaptive Schema-aware Event Extraction (ASEE), a novel
paradigm combining schema paraphrasing with schema retrieval-augmented
generation. ASEE adeptly retrieves paraphrased schemas and accurately generates
targeted structures. To facilitate rigorous evaluation, we construct the
Multi-Dimensional Schema-aware Event Extraction (MD-SEE) benchmark, which
systematically consolidates 12 datasets across diverse domains, complexity
levels, and language settings. Extensive evaluations on MD-SEE show that our
proposed ASEE demonstrates strong adaptability across various scenarios,
significantly improving the accuracy of event extraction.

</details>

### [62] [NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context](https://arxiv.org/abs/2505.08734)
*Ben Yao,Qiuchi Li,Yazhou Zhang,Siyu Yang,Bohan Zhang,Prayag Tiwari,Jing Qin*

Main category: cs.CL

TLDR: 该研究首次提出了护理价值对齐的基准，包含五个核心价值维度，并通过实地研究收集了1,100个实例，进一步生成了2,200个标注实例。评估了23个先进LLM，发现DeepSeek-V3和Claude 3.5 Sonnet表现最佳，同时揭示了正义是最难评估的价值维度。


<details>
  <summary>Details</summary>
Motivation: 为临床环境中开发价值敏感的LLM提供基础。

Method: 通过五个月的实地研究收集实例，并生成对抗性数据集，评估23个LLM的表现。

Result: DeepSeek-V3在简单数据集上表现最佳（94.55），Claude 3.5 Sonnet在复杂数据集上领先（89.43）；正义是最难评估的价值维度；上下文学习显著提升对齐效果。

Conclusion: 该研究为临床环境中LLM的价值对齐提供了重要基准和工具。

Abstract: This work introduces the first benchmark for nursing value alignment,
consisting of five core value dimensions distilled from international nursing
codes: Altruism, Human Dignity, Integrity, Justice, and Professionalism. The
benchmark comprises 1,100 real-world nursing behavior instances collected
through a five-month longitudinal field study across three hospitals of varying
tiers. These instances are annotated by five clinical nurses and then augmented
with LLM-generated counterfactuals with reversed ethic polarity. Each original
case is paired with a value-aligned and a value-violating version, resulting in
2,200 labeled instances that constitute the Easy-Level dataset. To increase
adversarial complexity, each instance is further transformed into a
dialogue-based format that embeds contextual cues and subtle misleading
signals, yielding a Hard-Level dataset. We evaluate 23 state-of-the-art (SoTA)
LLMs on their alignment with nursing values. Our findings reveal three key
insights: (1) DeepSeek-V3 achieves the highest performance on the Easy-Level
dataset (94.55), where Claude 3.5 Sonnet outperforms other models on the
Hard-Level dataset (89.43), significantly surpassing the medical LLMs; (2)
Justice is consistently the most difficult nursing value dimension to evaluate;
and (3) in-context learning significantly improves alignment. This work aims to
provide a foundation for value-sensitive LLMs development in clinical settings.
The dataset and the code are available at
https://huggingface.co/datasets/Ben012345/NurValues.

</details>

### [63] [Probability Consistency in Large Language Models: Theoretical Foundations Meet Empirical Discrepancies](https://arxiv.org/abs/2505.08739)
*Xiaoliang Luo,Xinyi Xu,Michael Ramscar,Bradley C. Love*

Main category: cs.CL

TLDR: 论文证明自回归大语言模型（LLM）在不同分词顺序下学习一致概率分布的能力，提出序列困惑度对任何分解顺序（如前向、后向或随机排列）不变的理论基础，并揭示先前研究的方法缺陷。通过实验发现LLM存在位置偏差，导致概率分布不一致。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在不同分词顺序下是否能学习一致概率分布，为理解LLM学习机制和评估方法提供理论基础。

Method: 理论证明序列困惑度对分解顺序不变，并重新训练GPT-2模型（前向、后向和随机排列顺序）进行实验验证。

Result: 实验显示LLM存在系统性偏差，随机排列顺序与前后向模型差异显著，归因于自注意力机制的位置和局部性偏差。

Conclusion: 研究为理解LLM位置偏差提供了新视角，并提出了检测概率分布不一致性的方法。

Abstract: Can autoregressive large language models (LLMs) learn consistent probability
distributions when trained on sequences in different token orders? We prove
formally that for any well-defined probability distribution, sequence
perplexity is invariant under any factorization, including forward, backward,
or arbitrary permutations. This result establishes a rigorous theoretical
foundation for studying how LLMs learn from data and defines principled
protocols for empirical evaluation. Applying these protocols, we show that
prior studies examining ordering effects suffer from critical methodological
flaws. We retrain GPT-2 models across forward, backward, and arbitrary permuted
orders on scientific text. We find systematic deviations from theoretical
invariance across all orderings with arbitrary permutations strongly deviating
from both forward and backward models, which largely (but not completely)
agreed with one another. Deviations were traceable to differences in
self-attention, reflecting positional and locality biases in processing. Our
theoretical and empirical results provide novel avenues for understanding
positional biases in LLMs and suggest methods for detecting when LLMs'
probability distributions are inconsistent and therefore untrustworthy.

</details>

### [64] [AC-Reason: Towards Theory-Guided Actual Causality Reasoning with Large Language Models](https://arxiv.org/abs/2505.08750)
*Yanxi Zhang,Xin Cong,Zhong Zhang,Xiao Liu,Dongyan Zhao,Yesai Wu*

Main category: cs.CL

TLDR: 提出AC-Reason框架，结合形式因果理论提升LLM在因果推理中的表现，并引入AC-Bench基准验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法缺乏形式因果理论支持，导致解释性不足。

Method: 提出半形式推理框架AC-Reason，通过理论指导算法回答因果查询，并构建AC-Bench基准。

Result: AC-Reason显著提升LLM性能，GPT-4 + AC-Reason在BBH-CJ和AC-Bench上分别达到75.04%和71.82%准确率。

Conclusion: 结合形式因果理论对LLM性能提升显著，AC-Reason算法贡献最大。

Abstract: Actual causality (AC), a fundamental aspect of causal reasoning (CR), is
responsible for attribution and responsibility assignment in real-world
scenarios. However, existing LLM-based methods lack grounding in formal AC
theory, resulting in limited interpretability. Therefore, we propose AC-Reason,
a semi-formal reasoning framework that identifies causally relevant events
within an AC scenario, infers the values of their formal causal factors (e.g.,
sufficiency, necessity, and normality), and answers AC queries via a
theory-guided algorithm with explanations. While AC-Reason does not explicitly
construct a causal graph, it operates over variables in the underlying causal
structure to support principled reasoning. To enable comprehensive evaluation,
we introduce AC-Bench, a new benchmark built upon and substantially extending
Big-Bench Hard Causal Judgment (BBH-CJ). AC-Bench comprises ~1K carefully
annotated samples, each with detailed reasoning steps and focuses solely on
actual causation. The case study shows that synthesized samples in AC-Bench
present greater challenges for LLMs. Extensive experiments on BBH-CJ and
AC-Bench show that AC-Reason consistently improves LLM performance over
baselines. On BBH-CJ, all tested LLMs surpass the average human rater accuracy
of 69.60%, with GPT-4 + AC-Reason achieving 75.04%. On AC-Bench, GPT-4 +
AC-Reason again achieves the highest accuracy of 71.82%. AC-Bench further
enables fine-grained analysis of reasoning faithfulness, revealing that only
Qwen-2.5-72B-Instruct, Claude-3.5-Sonnet, and GPT-4o exhibit faithful
reasoning, whereas GPT-4 tends to exploit shortcuts. Finally, our ablation
study proves that integrating AC theory into LLMs is highly effective, with the
proposed algorithm contributing the most significant performance gains.

</details>

### [65] [Aya Vision: Advancing the Frontier of Multilingual Multimodality](https://arxiv.org/abs/2505.08751)
*Saurabh Dash,Yiyang Nan,John Dang,Arash Ahmadian,Shivalika Singh,Madeline Smith,Bharat Venkitesh,Vlad Shmyhlo,Viraat Aryabumi,Walter Beller-Morales,Jeremy Pekmez,Jason Ozuzu,Pierre Richemond,Acyr Locatelli,Nick Frosst,Phil Blunsom,Aidan Gomez,Ivan Zhang,Marzieh Fadaee,Manoj Govindassamy,Sudip Roy,Matthias Gallé,Beyza Ermis,Ahmet Üstün,Sara Hooker*

Main category: cs.CL

TLDR: 论文提出了一种解决多语言多模态模型构建挑战的新方法，包括数据合成和模型合并技术，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 构建多语言多模态模型面临数据稀缺、模态对齐和灾难性遗忘等挑战，需要创新解决方案。

Method: 开发了合成标注框架以生成高质量多语言多模态数据，并提出了跨模态模型合并技术以减少灾难性遗忘。

Result: Aya-Vision-8B和Aya-Vision-32B在性能上超越了更大规模的模型，如Qwen-2.5-VL-7B和LLaMA-3.2-90B-Vision。

Conclusion: 该研究在多语言多模态领域取得了显著进展，提供了高效计算与高性能并重的技术方案。

Abstract: Building multimodal language models is fundamentally challenging: it requires
aligning vision and language modalities, curating high-quality instruction
data, and avoiding the degradation of existing text-only capabilities once
vision is introduced. These difficulties are further magnified in the
multilingual setting, where the need for multimodal data in different languages
exacerbates existing data scarcity, machine translation often distorts meaning,
and catastrophic forgetting is more pronounced. To address the aforementioned
challenges, we introduce novel techniques spanning both data and modeling.
First, we develop a synthetic annotation framework that curates high-quality,
diverse multilingual multimodal instruction data, enabling Aya Vision models to
produce natural, human-preferred responses to multimodal inputs across many
languages. Complementing this, we propose a cross-modal model merging technique
that mitigates catastrophic forgetting, effectively preserving text-only
capabilities while simultaneously enhancing multimodal generative performance.
Aya-Vision-8B achieves best-in-class performance compared to strong multimodal
models such as Qwen-2.5-VL-7B, Pixtral-12B, and even much larger
Llama-3.2-90B-Vision. We further scale this approach with Aya-Vision-32B, which
outperforms models more than twice its size, such as Molmo-72B and
LLaMA-3.2-90B-Vision. Our work advances multilingual progress on the
multi-modal frontier, and provides insights into techniques that effectively
bend the need for compute while delivering extremely high performance.

</details>

### [66] [HealthBench: Evaluating Large Language Models Towards Improved Human Health](https://arxiv.org/abs/2505.08775)
*Rahul K. Arora,Jason Wei,Rebecca Soskin Hicks,Preston Bowman,Joaquin Quiñonero-Candela,Foivos Tsimpourlas,Michael Sharman,Meghan Shah,Andrea Vallone,Alex Beutel,Johannes Heidecke,Karan Singhal*

Main category: cs.CL

TLDR: HealthBench是一个开源基准测试，用于评估大型语言模型在医疗领域的性能和安全性，包含多轮对话和医生制定的评分标准，显示模型性能的逐步提升。


<details>
  <summary>Details</summary>
Motivation: 开发一个更真实、开放的评估工具，以衡量语言模型在医疗场景中的表现，促进模型发展和医疗应用。

Method: 基于5,000个多轮对话和48,562个评分标准，由262名医生制定，覆盖多种医疗场景和行为维度。

Result: 模型性能稳步提升（如GPT-4o得分为32%），小模型表现尤为显著（如GPT-4.1 nano优于GPT-4o且成本更低）。

Conclusion: HealthBench为模型开发和医疗应用提供了实用基准，推动技术进步以造福人类健康。

Abstract: We present HealthBench, an open-source benchmark measuring the performance
and safety of large language models in healthcare. HealthBench consists of
5,000 multi-turn conversations between a model and an individual user or
healthcare professional. Responses are evaluated using conversation-specific
rubrics created by 262 physicians. Unlike previous multiple-choice or
short-answer benchmarks, HealthBench enables realistic, open-ended evaluation
through 48,562 unique rubric criteria spanning several health contexts (e.g.,
emergencies, transforming clinical data, global health) and behavioral
dimensions (e.g., accuracy, instruction following, communication). HealthBench
performance over the last two years reflects steady initial progress (compare
GPT-3.5 Turbo's 16% to GPT-4o's 32%) and more rapid recent improvements (o3
scores 60%). Smaller models have especially improved: GPT-4.1 nano outperforms
GPT-4o and is 25 times cheaper. We additionally release two HealthBench
variations: HealthBench Consensus, which includes 34 particularly important
dimensions of model behavior validated via physician consensus, and HealthBench
Hard, where the current top score is 32%. We hope that HealthBench grounds
progress towards model development and applications that benefit human health.

</details>

<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [67] [MilChat: Introducing Chain of Thought Reasoning and GRPO to a Multimodal Small Language Model for Remote Sensing](https://arxiv.org/abs/2505.07984)
*Aybora Koksal,A. Aydin Alatan*

Main category: cs.CV

TLDR: MilChat是一种轻量级多模态语言模型，专为分析偏远地区的遥感图像（如导弹发射场）而设计，通过专家验证的数据集和强化学习优化，显著优于通用模型。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在专业领域（如军事遥感）的效果有限，需要资源高效和领域特定的适配。

Method: 使用2B参数的开源MLLM进行监督微调，结合链式思维推理注释和GRPO优化，提升对军事关键线索的检测能力。

Result: 在MilData基准测试中，召回率达80%，精确率达98%，优于通用模型和现有遥感适配方法。

Conclusion: 针对特定领域的微调和强化学习在专业应用中具有显著效果。

Abstract: Remarkable capabilities in understanding and generating text-image content
have been demonstrated by recent advancements in multimodal large language
models (MLLMs). However, their effectiveness in specialized
domains-particularly those requiring resource-efficient and domain-specific
adaptations-has remained limited. In this work, a lightweight multimodal
language model termed MilChat is introduced, specifically adapted to analyze
remote sensing imagery in secluded areas, including challenging missile launch
sites. A new dataset, MilData, was compiled by verifying hundreds of aerial
images through expert review, and subtle military installations were
highlighted via detailed captions. Supervised fine-tuning on a 2B-parameter
open-source MLLM with chain-of-thought (CoT) reasoning annotations was
performed, enabling more accurate and interpretable explanations. Additionally,
Group Relative Policy Optimization (GRPO) was leveraged to enhance the model's
ability to detect critical domain-specific cues-such as defensive layouts and
key military structures-while minimizing false positives on civilian scenes.
Through empirical evaluations, it has been shown that MilChat significantly
outperforms both larger, general-purpose multimodal models and existing remote
sensing-adapted approaches on open-ended captioning and classification metrics.
Over 80% recall and 98% precision were achieved on the newly proposed MilData
benchmark, underscoring the potency of targeted fine-tuning and reinforcement
learning in specialized real-world applications.

</details>

### [68] [Vision Foundation Model Embedding-Based Semantic Anomaly Detection](https://arxiv.org/abs/2505.07998)
*Max Peter Ronecker,Matthew Foutter,Amine Elhafsi,Daniele Gammelli,Ihor Barakaiev,Marco Pavone,Daniel Watzenig*

Main category: cs.CV

TLDR: 该论文提出了一种基于视觉基础模型的语义异常检测框架，通过比较运行时图像与安全场景数据库的嵌入，实现异常检测与定位。


<details>
  <summary>Details</summary>
Motivation: 语义异常可能导致自主系统推理失败，因此需要一种高效的方法检测此类异常。

Method: 提出两种框架变体：基于原始网格嵌入和基于实例分割的对象中心表示，并引入过滤机制减少误报。

Result: 在CARLA模拟异常测试中，基于实例的方法性能接近GPT-4o，并能精确定位异常。

Conclusion: 视觉基础模型的嵌入在实时异常检测中具有潜在应用价值。

Abstract: Semantic anomalies are contextually invalid or unusual combinations of
familiar visual elements that can cause undefined behavior and failures in
system-level reasoning for autonomous systems. This work explores semantic
anomaly detection by leveraging the semantic priors of state-of-the-art vision
foundation models, operating directly on the image. We propose a framework that
compares local vision embeddings from runtime images to a database of nominal
scenarios in which the autonomous system is deemed safe and performant. In this
work, we consider two variants of the proposed framework: one using raw
grid-based embeddings, and another leveraging instance segmentation for
object-centric representations. To further improve robustness, we introduce a
simple filtering mechanism to suppress false positives. Our evaluations on
CARLA-simulated anomalies show that the instance-based method with filtering
achieves performance comparable to GPT-4o, while providing precise anomaly
localization. These results highlight the potential utility of vision
embeddings from foundation models for real-time anomaly detection in autonomous
systems.

</details>

### [69] [RDD: Robust Feature Detector and Descriptor using Deformable Transformer](https://arxiv.org/abs/2505.08013)
*Gonglin Chen,Tianwen Fu,Haiwei Chen,Wenbin Teng,Hanyuan Xiao,Yajie Zhao*

Main category: cs.CV

TLDR: 提出了一种基于可变形Transformer的鲁棒关键点检测与描述方法（RDD），通过可变形自注意力机制捕获全局上下文和几何不变性，显著提升了在视角变化等挑战性场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 在结构从运动和SLAM中，特征检测与描述在视角变化等挑战性场景下的鲁棒性问题尚未解决，现有方法未能有效利用长距离关系中的视觉线索。

Method: 提出RDD方法，利用可变形Transformer的可变形自注意力机制，聚焦关键位置，降低搜索空间复杂度并建模几何不变性。同时结合Air-to-Ground数据集和MegaDepth数据集进行训练。

Result: RDD在稀疏匹配任务中优于所有现有方法，并能实现半稠密匹配。此外，引入了两个新基准测试，验证了方法的全面性能。

Conclusion: RDD通过全局上下文建模和几何不变性学习，显著提升了特征检测与描述的鲁棒性，适用于多种挑战性场景。

Abstract: As a core step in structure-from-motion and SLAM, robust feature detection
and description under challenging scenarios such as significant viewpoint
changes remain unresolved despite their ubiquity. While recent works have
identified the importance of local features in modeling geometric
transformations, these methods fail to learn the visual cues present in
long-range relationships. We present Robust Deformable Detector (RDD), a novel
and robust keypoint detector/descriptor leveraging the deformable transformer,
which captures global context and geometric invariance through deformable
self-attention mechanisms. Specifically, we observed that deformable attention
focuses on key locations, effectively reducing the search space complexity and
modeling the geometric invariance. Furthermore, we collected an Air-to-Ground
dataset for training in addition to the standard MegaDepth dataset. Our
proposed method outperforms all state-of-the-art keypoint detection/description
methods in sparse matching tasks and is also capable of semi-dense matching. To
ensure comprehensive evaluation, we introduce two challenging benchmarks: one
emphasizing large viewpoint and scale variations, and the other being an
Air-to-Ground benchmark -- an evaluation setting that has recently gaining
popularity for 3D reconstruction across different altitudes.

</details>

### [70] [Visually Interpretable Subtask Reasoning for Visual Question Answering](https://arxiv.org/abs/2505.08084)
*Yu Cheng,Arushi Goel,Hakan Bilen*

Main category: cs.CV

TLDR: VISTAR是一种基于子任务驱动的训练框架，通过生成文本和视觉解释提升多模态大语言模型（MLLMs）的可解释性和推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在复杂视觉问题推理中计算成本高且准确性低的问题。

Method: 通过微调MLLMs生成结构化的“子任务思维”理性（逐步推理序列），无需依赖外部模型。

Result: 在两个基准测试中，VISTAR显著提高了推理准确性并保持可解释性。

Conclusion: VISTAR为复杂视觉问题的多步推理提供了一种高效且可解释的解决方案。

Abstract: Answering complex visual questions like `Which red furniture can be used for
sitting?' requires multi-step reasoning, including object recognition,
attribute filtering, and relational understanding. Recent work improves
interpretability in multimodal large language models (MLLMs) by decomposing
tasks into sub-task programs, but these methods are computationally expensive
and less accurate due to poor adaptation to target data. To address this, we
introduce VISTAR (Visually Interpretable Subtask-Aware Reasoning Model), a
subtask-driven training framework that enhances both interpretability and
reasoning by generating textual and visual explanations within MLLMs. Instead
of relying on external models, VISTAR fine-tunes MLLMs to produce structured
Subtask-of-Thought rationales (step-by-step reasoning sequences). Experiments
on two benchmarks show that VISTAR consistently improves reasoning accuracy
while maintaining interpretability. Our code and dataset will be available at
https://github.com/ChengJade/VISTAR.

</details>

### [71] [Multi-modal wound classification using wound image and location by Xception and Gaussian Mixture Recurrent Neural Network (GMRNN)](https://arxiv.org/abs/2505.08086)
*Ramin Mousa,Ehsan Matbooe,Hakimeh Khojasteh,Amirali Bengari,Mohammadmahdi Vahediahmar*

Main category: cs.CV

TLDR: 论文提出了一种基于迁移学习的多模态AI模型，结合Xception和GMRNN架构，用于伤口分类，显著提高了诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 急性及难愈合伤口的有效诊断对临床护理至关重要，传统方法常因感染、血管疾病等因素导致效果不佳，AI工具可加速医学图像解读并改善早期检测。

Method: 通过迁移学习算法提取特征并结合位置特征，构建多模态网络，分类糖尿病、压力性、手术性和静脉性溃疡。

Result: 实验结果显示伤口分类准确率在78.77%至100%之间，显著优于传统深度神经网络。

Conclusion: 该方法在常见伤口类型的分类中表现出卓越的准确性，为临床诊断提供了高效工具。

Abstract: The effective diagnosis of acute and hard-to-heal wounds is crucial for wound
care practitioners to provide effective patient care. Poor clinical outcomes
are often linked to infection, peripheral vascular disease, and increasing
wound depth, which collectively exacerbate these comorbidities. However,
diagnostic tools based on Artificial Intelligence (AI) speed up the
interpretation of medical images and improve early detection of disease. In
this article, we propose a multi-modal AI model based on transfer learning
(TL), which combines two state-of-the-art architectures, Xception and GMRNN,
for wound classification. The multi-modal network is developed by concatenating
the features extracted by a transfer learning algorithm and location features
to classify the wound types of diabetic, pressure, surgical, and venous ulcers.
The proposed method is comprehensively compared with deep neural networks (DNN)
for medical image analysis. The experimental results demonstrate a notable
wound-class classifications (containing only diabetic, pressure, surgical, and
venous) vary from 78.77 to 100\% in various experiments. The results presented
in this study showcase the exceptional accuracy of the proposed methodology in
accurately classifying the most commonly occurring wound types using wound
images and their corresponding locations.

</details>

### [72] [Topology-Guided Knowledge Distillation for Efficient Point Cloud Processing](https://arxiv.org/abs/2505.08101)
*Luu Tung Hai,Thinh D. Le,Zhicheng Ding,Qing Tian,Truong-Son Hy*

Main category: cs.CV

TLDR: 提出了一种新颖的蒸馏框架，通过拓扑感知表示和梯度引导知识蒸馏，将高性能点云模型的知识迁移到轻量级学生模型中，显著减少了模型大小和推理时间。


<details>
  <summary>Details</summary>
Motivation: 点云处理在自动驾驶和3D物体识别中至关重要，但高性能模型在资源受限环境中的部署面临计算和内存需求高的挑战。

Method: 利用拓扑感知表示和梯度引导知识蒸馏，从高容量教师模型向轻量级学生模型迁移知识，同时捕捉点云的几何结构。

Result: 在Nuscenes、SemanticKITTI和Waymo数据集上表现优异，模型大小减少约16倍，推理时间降低近1.9倍，在NuScenes上达到知识蒸馏技术的SOTA性能。

Conclusion: 该方法在保持高性能的同时显著降低了模型复杂度，适用于资源受限环境中的点云处理。

Abstract: Point cloud processing has gained significant attention due to its critical
role in applications such as autonomous driving and 3D object recognition.
However, deploying high-performance models like Point Transformer V3 in
resource-constrained environments remains challenging due to their high
computational and memory demands. This work introduces a novel distillation
framework that leverages topology-aware representations and gradient-guided
knowledge distillation to effectively transfer knowledge from a high-capacity
teacher to a lightweight student model. Our approach captures the underlying
geometric structures of point clouds while selectively guiding the student
model's learning process through gradient-based feature alignment. Experimental
results in the Nuscenes, SemanticKITTI, and Waymo datasets demonstrate that the
proposed method achieves competitive performance, with an approximately 16x
reduction in model size and a nearly 1.9x decrease in inference time compared
to its teacher model. Notably, on NuScenes, our method achieves
state-of-the-art performance among knowledge distillation techniques trained
solely on LiDAR data, surpassing prior knowledge distillation baselines in
segmentation performance. Our implementation is available publicly at:
  https://github.com/HySonLab/PointDistill

</details>

### [73] [Sleep Position Classification using Transfer Learning for Bed-based Pressure Sensors](https://arxiv.org/abs/2505.08111)
*Olivier Papillon,Rafik Goubran,James Green,Julien Larivière-Chartier,Caitlin Higginson,Frank Knoefel,Rébecca Robillard*

Main category: cs.CV

TLDR: 论文提出了一种基于压力敏感垫（PSM）的非侵入式睡眠监测方法，利用迁移学习解决临床数据标注不足的问题，并通过预训练的Vision Transformer模型（ViTMAE和ViTPose）实现了优于传统方法的睡眠姿势分类。


<details>
  <summary>Details</summary>
Motivation: 睡眠姿势影响睡眠质量和睡眠障碍（如呼吸暂停）的发生率，但临床环境中标注数据不足限制了深度学习模型的应用。

Method: 采用迁移学习，利用预训练的ViTMAE和ViTPose模型对低分辨率PSM数据进行睡眠姿势分类。

Result: 在112晚患者记录和13名患者的高分辨率数据集上验证，模型性能优于传统方法（如TCN、SVM、XGBoost和Random Forest）。

Conclusion: 尽管低分辨率数据带来挑战，该方法在临床环境中具有实际应用潜力。

Abstract: Bed-based pressure-sensitive mats (PSMs) offer a non-intrusive way of
monitoring patients during sleep. We focus on four-way sleep position
classification using data collected from a PSM placed under a mattress in a
sleep clinic. Sleep positions can affect sleep quality and the prevalence of
sleep disorders, such as apnea. Measurements were performed on patients with
suspected sleep disorders referred for assessments at a sleep clinic. Training
deep learning models can be challenging in clinical settings due to the need
for large amounts of labeled data. To overcome the shortage of labeled training
data, we utilize transfer learning to adapt pre-trained deep learning models to
accurately estimate sleep positions from a low-resolution PSM dataset collected
in a polysomnography sleep lab. Our approach leverages Vision Transformer
models pre-trained on ImageNet using masked autoencoding (ViTMAE) and a
pre-trained model for human pose estimation (ViTPose). These approaches
outperform previous work from PSM-based sleep pose classification using deep
learning (TCN) as well as traditional machine learning models (SVM, XGBoost,
Random Forest) that use engineered features. We evaluate the performance of
sleep position classification from 112 nights of patient recordings and
validate it on a higher resolution 13-patient dataset. Despite the challenges
of differentiating between sleep positions from low-resolution PSM data, our
approach shows promise for real-world deployment in clinical settings

</details>

### [74] [Now you see it, Now you don't: Damage Label Agreement in Drone & Satellite Post-Disaster Imagery](https://arxiv.org/abs/2505.08117)
*Thomas Manzini,Priyankari Perali,Jayesh Tripathi,Robin Murphy*

Main category: cs.CV

TLDR: 该论文分析了卫星和无人机图像在飓风灾害中对15,814栋建筑的损坏标签，发现29.02%的标签不一致，且两种来源的分布差异显著，可能对机器学习损害评估系统的部署带来风险和潜在危害。


<details>
  <summary>Details</summary>
Motivation: 目前尚无关于无人机和卫星图像在建筑损坏评估中标签一致性的研究，现有研究因标签模式、建筑位置不一致和数据量不足而受限。

Method: 通过比较三种飓风下相同标签模式和建筑位置的损坏标签，克服了现有研究的局限性，数据量是之前研究的19.05倍。

Result: 卫星标签比无人机标签至少低估20.43%的损坏（p<1.2x10^-117），且两种标签分布显著不同（p<5.1x10^-175）。

Conclusion: 这种不一致可能导致计算机视觉和机器学习模型在实际应用中误判，带来伦理风险和社会危害。论文提出四项建议以提高可靠性和透明度。

Abstract: This paper audits damage labels derived from coincident satellite and drone
aerial imagery for 15,814 buildings across Hurricanes Ian, Michael, and Harvey,
finding 29.02% label disagreement and significantly different distributions
between the two sources, which presents risks and potential harms during the
deployment of machine learning damage assessment systems. Currently, there is
no known study of label agreement between drone and satellite imagery for
building damage assessment. The only prior work that could be used to infer if
such imagery-derived labels agree is limited by differing damage label schemas,
misaligned building locations, and low data quantities. This work overcomes
these limitations by comparing damage labels using the same damage label
schemas and building locations from three hurricanes, with the 15,814 buildings
representing 19.05 times more buildings considered than the most relevant prior
work. The analysis finds satellite-derived labels significantly under-report
damage by at least 20.43% compared to drone-derived labels (p<1.2x10^-117), and
satellite- and drone-derived labels represent significantly different
distributions (p<5.1x10^-175). This indicates that computer vision and machine
learning (CV/ML) models trained on at least one of these distributions will
misrepresent actual conditions, as the differing satellite and drone-derived
distributions cannot simultaneously represent the distribution of actual
conditions in a scene. This potential misrepresentation poses ethical risks and
potential societal harm if not managed. To reduce the risk of future societal
harms, this paper offers four recommendations to improve reliability and
transparency to decisio-makers when deploying CV/ML damage assessment systems
in practice

</details>

### [75] [JSover: Joint Spectrum Estimation and Multi-Material Decomposition from Single-Energy CT Projections](https://arxiv.org/abs/2505.08123)
*Qing Wu,Hongjiang Wei,Jingyi Yu,S. Kevin Zhou,Yuyao Zhang*

Main category: cs.CV

TLDR: JSover是一种新型单能CT多材料分解框架，通过联合重建和能量谱估计，显著提高了分解的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统多材料分解方法依赖光谱CT和预测量能量谱，临床适用性受限。现有单能CT方法存在两步分解问题，导致非线性伪影和噪声。

Method: 提出JSover框架，一步联合重建多材料组成并估计能量谱，结合物理先验和隐式神经表示（INR）优化求解。

Result: 实验表明，JSover在模拟和真实CT数据上优于现有方法，提高了分解准确性和计算效率。

Conclusion: JSover通过一步分解和INR优化，显著提升了单能CT多材料分解的可靠性和实用性。

Abstract: Multi-material decomposition (MMD) enables quantitative reconstruction of
tissue compositions in the human body, supporting a wide range of clinical
applications. However, traditional MMD typically requires spectral CT scanners
and pre-measured X-ray energy spectra, significantly limiting clinical
applicability. To this end, various methods have been developed to perform MMD
using conventional (i.e., single-energy, SE) CT systems, commonly referred to
as SEMMD. Despite promising progress, most SEMMD methods follow a two-step
image decomposition pipeline, which first reconstructs monochromatic CT images
using algorithms such as FBP, and then performs decomposition on these images.
The initial reconstruction step, however, neglects the energy-dependent
attenuation of human tissues, introducing severe nonlinear beam hardening
artifacts and noise into the subsequent decomposition. This paper proposes
JSover, a fundamentally reformulated one-step SEMMD framework that jointly
reconstructs multi-material compositions and estimates the energy spectrum
directly from SECT projections. By explicitly incorporating physics-informed
spectral priors into the SEMMD process, JSover accurately simulates a virtual
spectral CT system from SE acquisitions, thereby improving the reliability and
accuracy of decomposition. Furthermore, we introduce implicit neural
representation (INR) as an unsupervised deep learning solver for representing
the underlying material maps. The inductive bias of INR toward continuous image
patterns constrains the solution space and further enhances estimation quality.
Extensive experiments on both simulated and real CT datasets show that JSover
outperforms state-of-the-art SEMMD methods in accuracy and computational
efficiency.

</details>

### [76] [SLAG: Scalable Language-Augmented Gaussian Splatting](https://arxiv.org/abs/2505.08124)
*Laszlo Szilagyi,Francis Engelmann,Jeannette Bohg*

Main category: cs.CV

TLDR: SLAG是一种多GPU框架，用于语言增强的高斯泼溅，提升大规模场景嵌入的速度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决时间敏感和大数据场景下机器人有限计算资源的挑战。

Method: 集成2D视觉语言模型特征到3D场景中，通过归一化加权平均计算语言嵌入，无需损失函数。

Result: 在16-GPU设置下，嵌入计算速度提升18倍，同时保持嵌入质量。

Conclusion: SLAG为大规模机器人应用提供了高效、可扩展的解决方案。

Abstract: Language-augmented scene representations hold great promise for large-scale
robotics applications such as search-and-rescue, smart cities, and mining. Many
of these scenarios are time-sensitive, requiring rapid scene encoding while
also being data-intensive, necessitating scalable solutions. Deploying these
representations on robots with limited computational resources further adds to
the challenge. To address this, we introduce SLAG, a multi-GPU framework for
language-augmented Gaussian splatting that enhances the speed and scalability
of embedding large scenes. Our method integrates 2D visual-language model
features into 3D scenes using SAM and CLIP. Unlike prior approaches, SLAG
eliminates the need for a loss function to compute per-Gaussian language
embeddings. Instead, it derives embeddings from 3D Gaussian scene parameters
via a normalized weighted average, enabling highly parallelized scene encoding.
Additionally, we introduce a vector database for efficient embedding storage
and retrieval. Our experiments show that SLAG achieves an 18 times speedup in
embedding computation on a 16-GPU setup compared to OpenGaussian, while
preserving embedding quality on the ScanNet and LERF datasets. For more
details, visit our project website: https://slag-project.github.io/.

</details>

### [77] [Asynchronous Multi-Object Tracking with an Event Camera](https://arxiv.org/abs/2505.08126)
*Angus Apps,Ziwei Wang,Vladimir Perejogin,Timothy Molloy,Robert Mahony*

Main category: cs.CV

TLDR: AEMOT算法通过异步处理事件数据，检测和跟踪多目标，性能优于其他事件算法37%以上。


<details>
  <summary>Details</summary>
Motivation: 事件相机在动态环境中具有低延迟、高时间分辨率和高动态范围的优势，适合多目标跟踪。

Method: 使用新颖的Field of Active Flow Directions检测特征，结合AEB跟踪器构建候选对象，并通过学习验证阶段筛选对象。

Result: 在Bee Swarm数据集上，AEMOT跟踪蜜蜂的性能优于其他算法37%。

Conclusion: AEMOT算法高效且准确，适用于动态环境中的多目标跟踪。

Abstract: Events cameras are ideal sensors for enabling robots to detect and track
objects in highly dynamic environments due to their low latency output, high
temporal resolution, and high dynamic range. In this paper, we present the
Asynchronous Event Multi-Object Tracking (AEMOT) algorithm for detecting and
tracking multiple objects by processing individual raw events asynchronously.
AEMOT detects salient event blob features by identifying regions of consistent
optical flow using a novel Field of Active Flow Directions built from the
Surface of Active Events. Detected features are tracked as candidate objects
using the recently proposed Asynchronous Event Blob (AEB) tracker in order to
construct small intensity patches of each candidate object. A novel learnt
validation stage promotes or discards candidate objects based on classification
of their intensity patches, with promoted objects having their position,
velocity, size, and orientation estimated at their event rate. We evaluate
AEMOT on a new Bee Swarm Dataset, where it tracks dozens of small bees with
precision and recall performance exceeding that of alternative event-based
detection and tracking algorithms by over 37%. Source code and the labelled
event Bee Swarm Dataset will be open sourced

</details>

### [78] [MoKD: Multi-Task Optimization for Knowledge Distillation](https://arxiv.org/abs/2505.08170)
*Zeeshan Hayder,Ali Cheraghian,Lars Petersson,Mehrtash Harandi*

Main category: cs.CV

TLDR: MoKD通过多任务优化解决知识蒸馏中的梯度冲突和梯度主导问题，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决知识蒸馏中任务目标和教师指导的平衡问题，以及教师与学生模型知识表示的差异。

Method: 将知识蒸馏重新定义为多目标优化问题，并引入子空间学习框架。

Result: 在ImageNet-1K和COCO数据集上表现优于现有方法，达到SOTA性能。

Conclusion: MoKD在知识蒸馏中实现了更高效的性能提升，优于从头训练的模型。

Abstract: Compact models can be effectively trained through Knowledge Distillation
(KD), a technique that transfers knowledge from larger, high-performing teacher
models. Two key challenges in Knowledge Distillation (KD) are: 1) balancing
learning from the teacher's guidance and the task objective, and 2) handling
the disparity in knowledge representation between teacher and student models.
To address these, we propose Multi-Task Optimization for Knowledge Distillation
(MoKD). MoKD tackles two main gradient issues: a) Gradient Conflicts, where
task-specific and distillation gradients are misaligned, and b) Gradient
Dominance, where one objective's gradient dominates, causing imbalance. MoKD
reformulates KD as a multi-objective optimization problem, enabling better
balance between objectives. Additionally, it introduces a subspace learning
framework to project feature representations into a high-dimensional space,
improving knowledge transfer. Our MoKD is demonstrated to outperform existing
methods through extensive experiments on image classification using the
ImageNet-1K dataset and object detection using the COCO dataset, achieving
state-of-the-art performance with greater efficiency. To the best of our
knowledge, MoKD models also achieve state-of-the-art performance compared to
models trained from scratch.

</details>

### [79] [Empowering Vision Transformers with Multi-Scale Causal Intervention for Long-Tailed Image Classification](https://arxiv.org/abs/2505.08173)
*Xiaoshuo Yan,Zhaochuan Li,Lei Meng,Zhuang Qi,Wei Wu,Zixuan Li,Xiangxu Meng*

Main category: cs.CV

TLDR: 论文提出TSCNet，一种两阶段因果建模方法，通过多尺度因果干预解决ViT在长尾分类中的性能问题。


<details>
  <summary>Details</summary>
Motivation: 研究现有因果模型在CNNs和ViT变体上的表现差异，发现ViT的全局特征表示导致因果方法难以建模细粒度特征与预测的关联，影响尾部类别的分类。

Method: TSCNet分为两阶段：1) HCRL阶段，通过多尺度干预解耦背景与对象；2) CLBC阶段，通过反事实平衡数据分布优化决策边界。

Result: 在多个长尾基准测试中，TSCNet显著优于现有方法，有效消除数据不平衡引入的偏差。

Conclusion: TSCNet通过细粒度因果建模和多尺度干预，显著提升了ViT在长尾分类中的性能。

Abstract: Causal inference has emerged as a promising approach to mitigate long-tail
classification by handling the biases introduced by class imbalance. However,
along with the change of advanced backbone models from Convolutional Neural
Networks (CNNs) to Visual Transformers (ViT), existing causal models may not
achieve an expected performance gain. This paper investigates the influence of
existing causal models on CNNs and ViT variants, highlighting that ViT's global
feature representation makes it hard for causal methods to model associations
between fine-grained features and predictions, which leads to difficulties in
classifying tail classes with similar visual appearance. To address these
issues, this paper proposes TSCNet, a two-stage causal modeling method to
discover fine-grained causal associations through multi-scale causal
interventions. Specifically, in the hierarchical causal representation learning
stage (HCRL), it decouples the background and objects, applying backdoor
interventions at both the patch and feature level to prevent model from using
class-irrelevant areas to infer labels which enhances fine-grained causal
representation. In the counterfactual logits bias calibration stage (CLBC), it
refines the optimization of model's decision boundary by adaptive constructing
counterfactual balanced data distribution to remove the spurious associations
in the logits caused by data distribution. Extensive experiments conducted on
various long-tail benchmarks demonstrate that the proposed TSCNet can eliminate
multiple biases introduced by data imbalance, which outperforms existing
methods.

</details>

### [80] [Monocular Depth Guided Occlusion-Aware Disparity Refinement via Semi-supervised Learning in Laparoscopic Images](https://arxiv.org/abs/2505.08178)
*Ziteng Liu,Dongdong He,Chenghong Zhang,Wenpeng Gao,Yili Fu*

Main category: cs.CV

TLDR: 本文提出了一种深度引导的遮挡感知视差细化网络（DGORNet），利用单目深度信息解决腹腔镜图像中的遮挡和标记数据稀缺问题，并通过位置嵌入模块和光流差异损失提升性能。


<details>
  <summary>Details</summary>
Motivation: 腹腔镜图像中的遮挡和标记数据稀缺是视差估计的主要挑战，需要一种能够利用未标记数据并提升时空一致性的方法。

Method: 提出DGORNet网络，结合单目深度信息、位置嵌入模块和光流差异损失，优化视差图并利用视频帧的时序连续性。

Result: 在SCARED数据集上，DGORNet在EPE和RMSE指标上优于现有方法，尤其在遮挡和无纹理区域表现突出。

Conclusion: DGORNet通过位置嵌入和光流差异损失有效提升了腹腔镜手术中的视差估计性能，为数据限制和遮挡问题提供了实用解决方案。

Abstract: Occlusion and the scarcity of labeled surgical data are significant
challenges in disparity estimation for stereo laparoscopic images. To address
these issues, this study proposes a Depth Guided Occlusion-Aware Disparity
Refinement Network (DGORNet), which refines disparity maps by leveraging
monocular depth information unaffected by occlusion. A Position Embedding (PE)
module is introduced to provide explicit spatial context, enhancing the
network's ability to localize and refine features. Furthermore, we introduce an
Optical Flow Difference Loss (OFDLoss) for unlabeled data, leveraging temporal
continuity across video frames to improve robustness in dynamic surgical
scenes. Experiments on the SCARED dataset demonstrate that DGORNet outperforms
state-of-the-art methods in terms of End-Point Error (EPE) and Root Mean
Squared Error (RMSE), particularly in occlusion and texture-less regions.
Ablation studies confirm the contributions of the Position Embedding and
Optical Flow Difference Loss, highlighting their roles in improving spatial and
temporal consistency. These results underscore DGORNet's effectiveness in
enhancing disparity estimation for laparoscopic surgery, offering a practical
solution to challenges in disparity estimation and data limitations.

</details>

### [81] [Unsupervised Raindrop Removal from a Single Image using Conditional Diffusion Models](https://arxiv.org/abs/2505.08190)
*Lhuqita Fazry,Valentino Vito*

Main category: cs.CV

TLDR: 提出了一种基于扩散模型的单图像雨滴去除新方法。


<details>
  <summary>Details</summary>
Motivation: 单图像雨滴去除任务具有挑战性，传统方法依赖GAN，而扩散模型在图像修复中表现出色。

Method: 采用扩散模型进行图像修复，结合雨滴区域检测。

Result: 实现了基于扩散模型的雨滴去除，效果优于传统方法。

Conclusion: 扩散模型为单图像雨滴去除提供了新的有效解决方案。

Abstract: Raindrop removal is a challenging task in image processing. Removing
raindrops while relying solely on a single image further increases the
difficulty of the task. Common approaches include the detection of raindrop
regions in the image, followed by performing a background restoration process
conditioned on those regions. While various methods can be applied for the
detection step, the most common architecture used for background restoration is
the Generative Adversarial Network (GAN). Recent advances in the use of
diffusion models have led to state-of-the-art image inpainting techniques. In
this paper, we introduce a novel technique for raindrop removal from a single
image using diffusion-based image inpainting.

</details>

### [82] [ADC-GS: Anchor-Driven Deformable and Compressed Gaussian Splatting for Dynamic Scene Reconstruction](https://arxiv.org/abs/2505.08196)
*He Huang,Qi Yang,Mufan Liu,Yiling Xu,Zhu Li*

Main category: cs.CV

TLDR: ADC-GS提出了一种基于锚点的动态场景重建方法，通过层次化运动和速率失真优化提升效率和存储性能。


<details>
  <summary>Details</summary>
Motivation: 现有4D高斯泼溅方法忽略了相邻高斯基元的冗余性，导致性能不佳。

Method: ADC-GS采用锚点结构和层次化运动捕捉，结合速率失真优化。

Result: 渲染速度提升300%-800%，存储效率达到最优，且不影响质量。

Conclusion: ADC-GS在动态场景重建中表现出色，优于现有方法。

Abstract: Existing 4D Gaussian Splatting methods rely on per-Gaussian deformation from
a canonical space to target frames, which overlooks redundancy among adjacent
Gaussian primitives and results in suboptimal performance. To address this
limitation, we propose Anchor-Driven Deformable and Compressed Gaussian
Splatting (ADC-GS), a compact and efficient representation for dynamic scene
reconstruction. Specifically, ADC-GS organizes Gaussian primitives into an
anchor-based structure within the canonical space, enhanced by a temporal
significance-based anchor refinement strategy. To reduce deformation
redundancy, ADC-GS introduces a hierarchical coarse-to-fine pipeline that
captures motions at varying granularities. Moreover, a rate-distortion
optimization is adopted to achieve an optimal balance between bitrate
consumption and representation fidelity. Experimental results demonstrate that
ADC-GS outperforms the per-Gaussian deformation approaches in rendering speed
by 300%-800% while achieving state-of-the-art storage efficiency without
compromising rendering quality. The code is released at
https://github.com/H-Huang774/ADC-GS.git.

</details>

### [83] [Visual Watermarking in the Era of Diffusion Models: Advances and Challenges](https://arxiv.org/abs/2505.08197)
*Junxian Duan,Jiyang Guang,Wenkui Yang,Ran He*

Main category: cs.CV

TLDR: 论文探讨了在生成式AI时代，利用扩散模型嵌入水印技术保护数字内容版权的方法及其挑战。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的进步，视觉内容易被滥用，传统被动检测方法难以应对复杂篡改，需要更有效的水印技术保护版权。

Method: 通过扩散模型学习特征，嵌入不可察觉且鲁棒的水印，提升检测准确性。

Result: 扩散模型能有效增强水印的鲁棒性，对抗伪造威胁。

Conclusion: 开发创新的水印解决方案对保护数字内容版权至关重要，扩散模型为此提供了新方向。

Abstract: As generative artificial intelligence technologies like Stable Diffusion
advance, visual content becomes more vulnerable to misuse, raising concerns
about copyright infringement. Visual watermarks serve as effective protection
mechanisms, asserting ownership and deterring unauthorized use. Traditional
deepfake detection methods often rely on passive techniques that struggle with
sophisticated manipulations. In contrast, diffusion models enhance detection
accuracy by allowing for the effective learning of features, enabling the
embedding of imperceptible and robust watermarks. We analyze the strengths and
challenges of watermark techniques related to diffusion models, focusing on
their robustness and application in watermark generation. By exploring the
integration of advanced diffusion models and watermarking security, we aim to
advance the discourse on preserving watermark robustness against evolving
forgery threats. It emphasizes the critical importance of developing innovative
solutions to protect digital content and ensure the preservation of ownership
rights in the era of generative AI.

</details>

### [84] [Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix](https://arxiv.org/abs/2505.08228)
*Unai Gurbindo,Axel Brando,Jaume Abella,Caroline König*

Main category: cs.CV

TLDR: 该研究提出了一种利用扩散模型Instruct Pix2Pix生成天气增强数据集的方法，以提升目标检测模型在恶劣天气下的鲁棒性，并在模拟和真实环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 恶劣天气条件下目标检测系统的鲁棒性对自动驾驶技术发展至关重要，但现有模型在此类环境中的性能存在显著差距。

Method: 使用Instruct Pix2Pix扩散模型生成天气增强数据集，并在CARLA模拟器及真实数据集BDD100K和ACDC上进行实验验证。

Result: 实验表明，定制化的数据增强策略能显著提升目标检测模型在恶劣天气下的性能。

Conclusion: 该研究为提升自动驾驶感知系统的可靠性提供了有效方法，并为未来技术发展奠定了基础。

Abstract: Enhancing the robustness of object detection systems under adverse weather
conditions is crucial for the advancement of autonomous driving technology.
This study presents a novel approach leveraging the diffusion model Instruct
Pix2Pix to develop prompting methodologies that generate realistic datasets
with weather-based augmentations aiming to mitigate the impact of adverse
weather on the perception capabilities of state-of-the-art object detection
models, including Faster R-CNN and YOLOv10. Experiments were conducted in two
environments, in the CARLA simulator where an initial evaluation of the
proposed data augmentation was provided, and then on the real-world image data
sets BDD100K and ACDC demonstrating the effectiveness of the approach in real
environments.
  The key contributions of this work are twofold: (1) identifying and
quantifying the performance gap in object detection models under challenging
weather conditions, and (2) demonstrating how tailored data augmentation
strategies can significantly enhance the robustness of these models. This
research establishes a solid foundation for improving the reliability of
perception systems in demanding environmental scenarios, and provides a pathway
for future advancements in autonomous driving.

</details>

### [85] [HMPNet: A Feature Aggregation Architecture for Maritime Object Detection from a Shipborne Perspective](https://arxiv.org/abs/2505.08231)
*Yu Zhang,Fengyuan Liu,Juan Lyu,Yi Wei,Changdong Yu*

Main category: cs.CV

TLDR: 论文介绍了Navigation12数据集和HMPNet模型，用于解决船舶视角下目标检测的数据稀缺问题，并在精度和计算效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏针对海事环境的专用数据集，限制了高级视觉感知技术在船舶导航中的应用。

Method: 提出Navigation12数据集，并设计HMPNet模型，采用分层动态调制主干、矩阵级联多尺度颈部和聚合权重共享检测器。

Result: HMPNet在平均精度上比YOLOv11n提高3.3%，参数减少23%。

Conclusion: Navigation12和HMPNet为海事目标检测提供了有效解决方案，显著提升了性能。

Abstract: In the realm of intelligent maritime navigation, object detection from a
shipborne perspective is paramount. Despite the criticality, the paucity of
maritime-specific data impedes the deployment of sophisticated visual
perception techniques, akin to those utilized in autonomous vehicular systems,
within the maritime context. To bridge this gap, we introduce Navigation12, a
novel dataset annotated for 12 object categories under diverse maritime
environments and weather conditions. Based upon this dataset, we propose
HMPNet, a lightweight architecture tailored for shipborne object detection.
HMPNet incorporates a hierarchical dynamic modulation backbone to bolster
feature aggregation and expression, complemented by a matrix cascading
poly-scale neck and a polymerization weight sharing detector, facilitating
efficient multi-scale feature aggregation. Empirical evaluations indicate that
HMPNet surpasses current state-of-the-art methods in terms of both accuracy and
computational efficiency, realizing a 3.3% improvement in mean Average
Precision over YOLOv11n, the prevailing model, and reducing parameters by 23%.

</details>

### [86] [G-MSGINet: A Grouped Multi-Scale Graph-Involution Network for Contactless Fingerprint Recognition](https://arxiv.org/abs/2505.08233)
*Santhoshkumar Peddi,Soham Bandyopadhyay,Debasis Samanta*

Main category: cs.CV

TLDR: G-MSGINet是一种高效的无接触指纹识别框架，结合了局部特征定位和身份嵌入，无需复杂预处理，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖多分支架构或复杂预处理，限制了实际应用中的扩展性和泛化能力。

Method: 提出GMSGI层，整合像素级卷积、动态多尺度核生成和图关系建模，通过端到端优化逐步细化特征。

Result: 在三个基准数据集上，F1分数达0.83±0.02，Rank-1准确率97.0%-99.1%，EER低至0.5%，参数和计算量显著减少。

Conclusion: G-MSGINet在无接触生物识别中表现出高效性和可扩展性，优于现有方法。

Abstract: This paper presents G-MSGINet, a unified and efficient framework for robust
contactless fingerprint recognition that jointly performs minutiae localization
and identity embedding directly from raw input images. Existing approaches rely
on multi-branch architectures, orientation labels, or complex preprocessing
steps, which limit scalability and generalization across real-world acquisition
scenarios. In contrast, the proposed architecture introduces the GMSGI layer, a
novel computational module that integrates grouped pixel-level involution,
dynamic multi-scale kernel generation, and graph-based relational modelling
into a single processing unit. Stacked GMSGI layers progressively refine both
local minutiae-sensitive features and global topological representations
through end-to-end optimization. The architecture eliminates explicit
orientation supervision and adapts graph connectivity directly from learned
kernel descriptors, thereby capturing meaningful structural relationships among
fingerprint regions without fixed heuristics. Extensive experiments on three
benchmark datasets, namely PolyU, CFPose, and Benchmark 2D/3D, demonstrate that
G-MSGINet consistently achieves minutiae F1-scores in the range of
$0.83\pm0.02$ and Rank-1 identification accuracies between 97.0% and 99.1%,
while maintaining an Equal Error Rate (EER) as low as 0.5%. These results
correspond to improvements of up to 4.8% in F1-score and 1.4% in Rank-1
accuracy when compared to prior methods, using only 0.38 million parameters and
6.63 giga floating-point operations, which represents up to ten times fewer
parameters than competitive baselines. This highlights the scalability and
effectiveness of G-MSGINet in real-world contactless biometric recognition
scenarios.

</details>

### [87] [Removing Watermarks with Partial Regeneration using Semantic Information](https://arxiv.org/abs/2505.08234)
*Krti Tallam,John Kevin Cava,Caleb Geniesse,N. Benjamin Erichson,Michael W. Mahoney*

Main category: cs.CV

TLDR: 论文揭露了当前语义水印的漏洞，提出了一种名为SemanticRegen的三阶段攻击方法，能够有效擦除水印且保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成图像的普及，水印技术成为版权保护的重要手段，但其对抗适应性攻击的鲁棒性尚未充分研究。

Method: SemanticRegen攻击分为三阶段：(1) 使用视觉语言模型生成细粒度描述，(2) 零样本分割提取前景掩码，(3) 基于LLM引导的扩散模型修复背景。

Result: 在四种水印系统（TreeRing、StegaStamp、StableSig、DWT/DCT）上测试，SemanticRegen成功擦除TreeRing水印，并将其他水印的比特准确率降至0.75以下，同时保持高感知质量（mSSIM=0.94）。

Conclusion: 研究揭示了当前水印防御与语义感知攻击能力之间的差距，呼吁开发更具鲁棒性的水印算法。

Abstract: As AI-generated imagery becomes ubiquitous, invisible watermarks have emerged
as a primary line of defense for copyright and provenance. The newest
watermarking schemes embed semantic signals - content-aware patterns that are
designed to survive common image manipulations - yet their true robustness
against adaptive adversaries remains under-explored. We expose a previously
unreported vulnerability and introduce SemanticRegen, a three-stage, label-free
attack that erases state-of-the-art semantic and invisible watermarks while
leaving an image's apparent meaning intact. Our pipeline (i) uses a
vision-language model to obtain fine-grained captions, (ii) extracts foreground
masks with zero-shot segmentation, and (iii) inpaints only the background via
an LLM-guided diffusion model, thereby preserving salient objects and style
cues. Evaluated on 1,000 prompts across four watermarking systems - TreeRing,
StegaStamp, StableSig, and DWT/DCT - SemanticRegen is the only method to defeat
the semantic TreeRing watermark (p = 0.10 > 0.05) and reduces bit-accuracy
below 0.75 for the remaining schemes, all while maintaining high perceptual
quality (masked SSIM = 0.94 +/- 0.01). We further introduce masked SSIM (mSSIM)
to quantify fidelity within foreground regions, showing that our attack
achieves up to 12 percent higher mSSIM than prior diffusion-based attackers.
These results highlight an urgent gap between current watermark defenses and
the capabilities of adaptive, semantics-aware adversaries, underscoring the
need for watermarking algorithms that are resilient to content-preserving
regenerative attacks.

</details>

### [88] [EventDiff: A Unified and Efficient Diffusion Model Framework for Event-based Video Frame Interpolation](https://arxiv.org/abs/2505.08235)
*Hanle Zheng,Xujie Han,Zegang Peng,Shangbin Zhang,Guangxun Du,Zhuo Zou,Xilin Wang,Jibin Wu,Hao Guo,Lei Deng*

Main category: cs.CV

TLDR: EventDiff是一种基于事件的扩散模型框架，用于视频帧插值（VFI），通过去噪过程直接在潜在空间进行插值，避免了显式运动建模，并在多个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决视频帧插值在复杂运动、遮挡和光照变化下的挑战，同时避免传统方法在细微运动场景下高保真图像重建的不足。

Method: 提出EventDiff框架，包含事件-帧混合自动编码器（HAE）和轻量级时空交叉注意力模块（STCA），通过两阶段训练策略（预训练HAE后与扩散模型联合优化）实现插值。

Result: 在Vimeo90K-Triplet上PSNR提升1.98dB，在SNU-FILM多难度任务中表现优异，比现有扩散方法快4.24倍且PSNR提升5.72dB。

Conclusion: EventDiff通过潜在空间去噪插值和高效的事件-帧融合，显著提升了视频帧插值的鲁棒性和性能。

Abstract: Video Frame Interpolation (VFI) is a fundamental yet challenging task in
computer vision, particularly under conditions involving large motion,
occlusion, and lighting variation. Recent advancements in event cameras have
opened up new opportunities for addressing these challenges. While existing
event-based VFI methods have succeeded in recovering large and complex motions
by leveraging handcrafted intermediate representations such as optical flow,
these designs often compromise high-fidelity image reconstruction under subtle
motion scenarios due to their reliance on explicit motion modeling. Meanwhile,
diffusion models provide a promising alternative for VFI by reconstructing
frames through a denoising process, eliminating the need for explicit motion
estimation or warping operations. In this work, we propose EventDiff, a unified
and efficient event-based diffusion model framework for VFI. EventDiff features
a novel Event-Frame Hybrid AutoEncoder (HAE) equipped with a lightweight
Spatial-Temporal Cross Attention (STCA) module that effectively fuses dynamic
event streams with static frames. Unlike previous event-based VFI methods,
EventDiff performs interpolation directly in the latent space via a denoising
diffusion process, making it more robust across diverse and challenging VFI
scenarios. Through a two-stage training strategy that first pretrains the HAE
and then jointly optimizes it with the diffusion model, our method achieves
state-of-the-art performance across multiple synthetic and real-world event VFI
datasets. The proposed method outperforms existing state-of-the-art event-based
VFI methods by up to 1.98dB in PSNR on Vimeo90K-Triplet and shows superior
performance in SNU-FILM tasks with multiple difficulty levels. Compared to the
emerging diffusion-based VFI approach, our method achieves up to 5.72dB PSNR
gain on Vimeo90K-Triplet and 4.24X faster inference.

</details>

### [89] [Congenital Heart Disease recognition using Deep Learning/Transformer models](https://arxiv.org/abs/2505.08242)
*Aidar Amangeldi,Vladislav Yarovenko,Angsar Taigonyrov*

Main category: cs.CV

TLDR: 研究探讨了双模态（声音和图像）深度学习方法在先天性心脏病（CHD）诊断中的应用，取得了73.9%和80.72%的准确率。


<details>
  <summary>Details</summary>
Motivation: CHD是婴儿发病和死亡的主要原因，但现有非侵入性筛查方法存在假阴性问题。

Method: 采用双模态（声音和图像）深度学习方法。

Result: 在ZCHSound数据集上达到73.9%准确率，在DICOM胸部X光数据集上达到80.72%准确率。

Conclusion: 双模态深度学习方法在CHD诊断中具有潜力。

Abstract: Congenital Heart Disease (CHD) remains a leading cause of infant morbidity
and mortality, yet non-invasive screening methods often yield false negatives.
Deep learning models, with their ability to automatically extract features, can
assist doctors in detecting CHD more effectively. In this work, we investigate
the use of dual-modality (sound and image) deep learning methods for CHD
diagnosis. We achieve 73.9% accuracy on the ZCHSound dataset and 80.72%
accuracy on the DICOM Chest X-ray dataset.

</details>

### [90] [Identifying Memorization of Diffusion Models through p-Laplace Analysis](https://arxiv.org/abs/2505.08246)
*Jonathan Brokman,Amit Giloni,Omer Hofman,Roman Vainshtein,Hisashi Kojima,Guy Gilboa*

Main category: cs.CV

TLDR: 该论文研究了扩散模型中的得分函数是否可以用于计算高阶微分（p-Laplace算子），并展示了其在识别记忆训练数据中的有效性。


<details>
  <summary>Details</summary>
Motivation: 探索扩散模型中得分函数的进一步应用，特别是高阶微分的计算及其在识别记忆数据中的作用。

Method: 提出了一种基于学习得分函数的数值p-Laplace近似方法，并在高斯混合模型和图像生成模型中进行了验证。

Result: p-Laplace算子能有效识别概率分布的关键特征，首次在图像生成模型中实现了记忆数据的识别。

Conclusion: 得分函数的高阶微分（p-Laplace算子）可用于识别记忆数据，为生成模型的分析提供了新工具。

Abstract: Diffusion models, today's leading image generative models, estimate the score
function, i.e. the gradient of the log probability of (perturbed) data samples,
without direct access to the underlying probability distribution. This work
investigates whether the estimated score function can be leveraged to compute
higher-order differentials, namely p-Laplace operators. We show here these
operators can be employed to identify memorized training data. We propose a
numerical p-Laplace approximation based on the learned score functions, showing
its effectiveness in identifying key features of the probability landscape. We
analyze the structured case of Gaussian mixture models, and demonstrate the
results carry-over to image generative models, where memorization
identification based on the p-Laplace operator is performed for the first time.

</details>

### [91] [CNN and ViT Efficiency Study on Tiny ImageNet and DermaMNIST Datasets](https://arxiv.org/abs/2505.08259)
*Aidar Amangeldi,Angsar Taigonyrov,Muhammad Huzaid Jawad,Chinedu Emmanuel Mbonu*

Main category: cs.CV

TLDR: 研究评估了卷积和Transformer架构在医学和通用图像分类任务中的权衡，通过微调策略在DermatologyMNIST和TinyImageNet上测试，证明Vision Transformers在性能、推理速度和参数效率上优于基线ResNet-18。


<details>
  <summary>Details</summary>
Motivation: 探索在资源受限环境中部署高效图像分类模型的可行性，比较卷积和Transformer架构的优劣。

Method: 以ResNet-18为基线，对四种Vision Transformer变体（Tiny、Small、Base、Large）进行微调，并通过系统超参数调整优化性能。

Result: 微调后的Vision Transformers性能匹配或超越基线，推理更快且参数更少。

Conclusion: Vision Transformers在资源受限环境中具有部署潜力，平衡了性能和效率。

Abstract: This study evaluates the trade-offs between convolutional and
transformer-based architectures on both medical and general-purpose image
classification benchmarks. We use ResNet-18 as our baseline and introduce a
fine-tuning strategy applied to four Vision Transformer variants (Tiny, Small,
Base, Large) on DermatologyMNIST and TinyImageNet. Our goal is to reduce
inference latency and model complexity with acceptable accuracy degradation.
Through systematic hyperparameter variations, we demonstrate that appropriately
fine-tuned Vision Transformers can match or exceed the baseline's performance,
achieve faster inference, and operate with fewer parameters, highlighting their
viability for deployment in resource-constrained environments.

</details>

### [92] [Few-shot Novel Category Discovery](https://arxiv.org/abs/2505.08260)
*Chunming Li,Shidong Wang,Haofeng Zhang*

Main category: cs.CV

TLDR: 论文提出了一种新设置Few-Shot Novel Category Discovery (FSNCD)，通过结合少量支持样本的知识，灵活切换已知类识别和新类聚类任务，并提出了SHC和UKC方法验证模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有NCD的转导学习范式限制了其在真实场景中的应用，少量新类标签数据可以缓解这一问题。

Method: 提出了FSNCD框架，结合少量支持样本知识，采用SHC和UKC方法进行模型推理。

Result: 在五个常用数据集上的实验表明，该方法在不同任务设置和场景中均表现领先。

Conclusion: FSNCD框架通过少量支持样本实现了灵活的任务切换，验证了其在实际场景中的有效性。

Abstract: The recently proposed Novel Category Discovery (NCD) adapt paradigm of
transductive learning hinders its application in more real-world scenarios. In
fact, few labeled data in part of new categories can well alleviate this
burden, which coincides with the ease that people can label few of new category
data. Therefore, this paper presents a new setting in which a trained agent is
able to flexibly switch between the tasks of identifying examples of known
(labelled) classes and clustering novel (completely unlabeled) classes as the
number of query examples increases by leveraging knowledge learned from only a
few (handful) support examples. Drawing inspiration from the discovery of novel
categories using prior-based clustering algorithms, we introduce a novel
framework that further relaxes its assumptions to the real-world open set level
by unifying the concept of model adaptability in few-shot learning. We refer to
this setting as Few-Shot Novel Category Discovery (FSNCD) and propose
Semi-supervised Hierarchical Clustering (SHC) and Uncertainty-aware K-means
Clustering (UKC) to examine the model's reasoning capabilities. Extensive
experiments and detailed analysis on five commonly used datasets demonstrate
that our methods can achieve leading performance levels across different task
settings and scenarios.

</details>

### [93] [Open the Eyes of MPNN: Vision Enhances MPNN in Link Prediction](https://arxiv.org/abs/2505.08266)
*Yanbin Wei,Xuehao Wang,Zhan Zhuang,Yang Chen,Shuhao Chen,Yulong Zhang,Yu Zhang,James Kwok*

Main category: cs.CV

TLDR: GVN首次将视觉感知引入MPNN，提出Graph Vision Network（GVN）及其高效变体E-GVN，显著提升链接预测性能，并在多个数据集上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 视觉感知在MPNN中未被充分利用，GVN旨在填补这一空白，增强链接预测能力。

Method: 提出GVN和E-GVN框架，将视觉结构意识融入MPNN。

Result: 在七个链接预测数据集上表现优异，包括大规模图，兼容现有SOTA方法并取得新SOTA。

Conclusion: GVN为链接预测开辟了新方向，展示了视觉增强的潜力。

Abstract: Message-passing graph neural networks (MPNNs) and structural features (SFs)
are cornerstones for the link prediction task. However, as a common and
intuitive mode of understanding, the potential of visual perception has been
overlooked in the MPNN community. For the first time, we equip MPNNs with
vision structural awareness by proposing an effective framework called Graph
Vision Network (GVN), along with a more efficient variant (E-GVN). Extensive
empirical results demonstrate that with the proposed frameworks, GVN
consistently benefits from the vision enhancement across seven link prediction
datasets, including challenging large-scale graphs. Such improvements are
compatible with existing state-of-the-art (SOTA) methods and GVNs achieve new
SOTA results, thereby underscoring a promising novel direction for link
prediction.

</details>

### [94] [IrrMap: A Large-Scale Comprehensive Dataset for Irrigation Method Mapping](https://arxiv.org/abs/2505.08273)
*Nibir Chandra Mandal,Oishee Bintey Hoque,Abhijin Adiga,Samarth Swarup,Mandy Wilson,Lu Feng,Yangfeng Ji,Miaomiao Zhang,Geoffrey Fox,Madhav Marathe*

Main category: cs.CV

TLDR: IrrMap是一个用于灌溉方法映射的大规模数据集（110万块），包含多分辨率卫星图像和辅助数据，覆盖美国西部多个州的农田。数据集支持深度学习训练，并提供完整的数据生成流程和分析结果。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模的灌溉方法数据集，限制了灌溉分析和农业研究的进展。IrrMap旨在填补这一空白，提供高质量、多样化的数据支持。

Method: 利用Landsat和Sentinel卫星图像，结合作物类型、土地利用和植被指数等辅助数据，构建标准化224x224 GeoTIFF图像块，并提供数据加载器和训练-测试分割。

Result: 数据集覆盖168万农场和1410万英亩土地，分析了灌溉方法分布、空间模式和面积变化，揭示了区域和分辨率差异。

Conclusion: IrrMap为灌溉研究提供了丰富资源，并开源数据集、模型和代码，促进进一步探索和应用。

Abstract: We introduce IrrMap, the first large-scale dataset (1.1 million patches) for
irrigation method mapping across regions. IrrMap consists of multi-resolution
satellite imagery from LandSat and Sentinel, along with key auxiliary data such
as crop type, land use, and vegetation indices. The dataset spans 1,687,899
farms and 14,117,330 acres across multiple western U.S. states from 2013 to
2023, providing a rich and diverse foundation for irrigation analysis and
ensuring geospatial alignment and quality control. The dataset is ML-ready,
with standardized 224x224 GeoTIFF patches, the multiple input modalities,
carefully chosen train-test-split data, and accompanying dataloaders for
seamless deep learning model training andbenchmarking in irrigation mapping.
The dataset is also accompanied by a complete pipeline for dataset generation,
enabling researchers to extend IrrMap to new regions for irrigation data
collection or adapt it with minimal effort for other similar applications in
agricultural and geospatial analysis. We also analyze the irrigation method
distribution across crop groups, spatial irrigation patterns (using Shannon
diversity indices), and irrigated area variations for both LandSat and
Sentinel, providing insights into regional and resolution-based differences. To
promote further exploration, we openly release IrrMap, along with the derived
datasets, benchmark models, and pipeline code, through a GitHub repository:
https://github.com/Nibir088/IrrMap and Data repository:
https://huggingface.co/Nibir/IrrMap, providing comprehensive documentation and
implementation details.

</details>

### [95] [Ultra Lowrate Image Compression with Semantic Residual Coding and Compression-aware Diffusion](https://arxiv.org/abs/2505.08281)
*Anle Ke,Xu Zhang,Tong Chen,Ming Lu,Chao Zhou,Jiawen Gu,Zhan Ma*

Main category: cs.CV

TLDR: ResULIC是一种基于残差引导的超低码率图像压缩方法，通过语义残差编码和压缩感知扩散模型提升重建质量和编码效率。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型图像压缩框架在重建保真度和编码效率上表现不佳，需改进。

Method: 引入语义残差编码（SRC）捕捉原始图像与压缩表示的语义差异，结合压缩感知扩散模型（CDM）优化码率与扩散步长的对齐。

Result: 实验表明ResULIC在LPIPS和FID指标上分别节省80.7%和66.3%的BD-rate，优于现有方法。

Conclusion: ResULIC通过残差信号和扩散模型的协同优化，显著提升了图像压缩性能。

Abstract: Existing multimodal large model-based image compression frameworks often rely
on a fragmented integration of semantic retrieval, latent compression, and
generative models, resulting in suboptimal performance in both reconstruction
fidelity and coding efficiency. To address these challenges, we propose a
residual-guided ultra lowrate image compression named ResULIC, which
incorporates residual signals into both semantic retrieval and the
diffusion-based generation process. Specifically, we introduce Semantic
Residual Coding (SRC) to capture the semantic disparity between the original
image and its compressed latent representation. A perceptual fidelity optimizer
is further applied for superior reconstruction quality. Additionally, we
present the Compression-aware Diffusion Model (CDM), which establishes an
optimal alignment between bitrates and diffusion time steps, improving
compression-reconstruction synergy. Extensive experiments demonstrate the
effectiveness of ResULIC, achieving superior objective and subjective
performance compared to state-of-the-art diffusion-based methods with - 80.7%,
-66.3% BD-rate saving in terms of LPIPS and FID. Project page is available at
https: //njuvision.github.io/ResULIC/.

</details>

### [96] [Disruptive Transformation of Artworks in Master-Disciple Relationships: The Case of Ukiyo-e Artworks](https://arxiv.org/abs/2505.08284)
*Honna Shinichi,Akira Matsui*

Main category: cs.CV

TLDR: 论文利用机器学习对日本浮世绘进行定量分析，发现整体创造力随文化成熟下降，但风格创造力保持高水平。


<details>
  <summary>Details</summary>
Motivation: 传统艺术研究依赖主观判断，机器学习为东方绘画（如浮世绘）提供定量分析新视角。

Method: 基于11,000张高分辨率浮世绘图像，利用网络计算创造力概念分析作品和艺术家创造力。

Result: 浮世绘整体创造力随文化成熟下降，但风格创造力保持高水平并更加细分。

Conclusion: 研究为浮世绘和东方艺术分析提供新见解，揭示其在文化历史中的演变和重要性。

Abstract: Artwork research has long relied on human sensibility and subjective
judgment, but recent developments in machine learning have enabled the
quantitative assessment of features that humans could not discover. In Western
paintings, comprehensive analyses have been conducted from various perspectives
in conjunction with large databases, but such extensive analysis has not been
sufficiently conducted for Eastern paintings. Then, we focus on Ukiyo-e, a
traditional Japanese art form, as a case study of Eastern paintings, and
conduct a quantitative analysis of creativity in works of art using 11,000
high-resolution images. This involves using the concept of calculating
creativity from networks to analyze both the creativity of the artwork and that
of the artists. As a result, In terms of Ukiyo-e as a whole, it was found that
the creativity of its appearance has declined with the maturation of culture,
but in terms of style, it has become more segmented with the maturation of
culture and has maintained a high level of creativity. This not only provides
new insights into the study of Ukiyo-e but also shows how Ukiyo-e has evolved
within the ongoing cultural history, playing a culturally significant role in
the analysis of Eastern art.

</details>

### [97] [FauForensics: Boosting Audio-Visual Deepfake Detection with Facial Action Units](https://arxiv.org/abs/2505.08294)
*Jian Wang,Baoyuan Wu,Li Liu,Qingshan Liu*

Main category: cs.CV

TLDR: 论文提出了一种名为FauForensics的新框架，通过引入生物不变的面部动作单元（FAUs）来检测多模态深度伪造内容，解决了现有方法在跨模态特征处理和泛化能力上的不足。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的快速发展导致音频-视觉深度伪造威胁增加，现有方法主要针对单模态伪造，难以应对多模态伪造问题。

Method: 提出FauForensics框架，利用生物不变的面部动作单元（FAUs）作为伪造抵抗特征，并通过专用融合模块计算帧级视听相似度。

Result: 在FakeAVCeleb和LAV-DF数据集上实现了最优性能，平均比现有方法提升4.83%。

Conclusion: FauForensics在多模态深度伪造检测中表现出色，具有更强的跨数据集泛化能力。

Abstract: The rapid evolution of generative AI has increased the threat of realistic
audio-visual deepfakes, demanding robust detection methods. Existing solutions
primarily address unimodal (audio or visual) forgeries but struggle with
multimodal manipulations due to inadequate handling of heterogeneous modality
features and poor generalization across datasets. To this end, we propose a
novel framework called FauForensics by introducing biologically invariant
facial action units (FAUs), which is a quantitative descriptor of facial muscle
activity linked to emotion physiology. It serves as forgery-resistant
representations that reduce domain dependency while capturing subtle dynamics
often disrupted in synthetic content. Besides, instead of comparing entire
video clips as in prior works, our method computes fine-grained frame-wise
audiovisual similarities via a dedicated fusion module augmented with learnable
cross-modal queries. It dynamically aligns temporal-spatial lip-audio
relationships while mitigating multi-modal feature heterogeneity issues.
Experiments on FakeAVCeleb and LAV-DF show state-of-the-art (SOTA) performance
and superior cross-dataset generalizability with up to an average of 4.83\%
than existing methods.

</details>

### [98] [Knowledge-Informed Deep Learning for Irrigation Type Mapping from Remote Sensing](https://arxiv.org/abs/2505.08302)
*Oishee Bintey Hoque,Nibir Chandra Mandal,Abhijin Adiga,Samarth Swarup,Sayjro Kossi Nouwakpo,Amanda Wilson,Madhav Marathe*

Main category: cs.CV

TLDR: KIIM是一种基于Swin-Transformer的新方法，通过多模态信息和加权集成显著提高了灌溉分类的准确性，特别是在滴灌分类上表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有模型仅依赖卫星图像的光谱特征，难以应对农业景观的复杂性和训练数据的不足。

Method: KIIM结合了作物到灌溉概率的编码、空间注意力图、双向交叉注意力和加权集成。

Result: 在五个美国州的实验中，KIIM比基线提高了22.9%的IoU，滴灌分类提高了71.4%。

Conclusion: KIIM通过两阶段迁移学习减少了对大量标注数据的依赖，为大规模自动化灌溉制图提供了高效且经济的解决方案。

Abstract: Accurate mapping of irrigation methods is crucial for sustainable
agricultural practices and food systems. However, existing models that rely
solely on spectral features from satellite imagery are ineffective due to the
complexity of agricultural landscapes and limited training data, making this a
challenging problem. We present Knowledge-Informed Irrigation Mapping (KIIM), a
novel Swin-Transformer based approach that uses (i) a specialized projection
matrix to encode crop to irrigation probability, (ii) a spatial attention map
to identify agricultural lands from non-agricultural lands, (iii)
bi-directional cross-attention to focus complementary information from
different modalities, and (iv) a weighted ensemble for combining predictions
from images and crop information. Our experimentation on five states in the US
shows up to 22.9\% (IoU) improvement over baseline with a 71.4% (IoU)
improvement for hard-to-classify drip irrigation. In addition, we propose a
two-phase transfer learning approach to enhance cross-state irrigation mapping,
achieving a 51% IoU boost in a state with limited labeled data. The ability to
achieve baseline performance with only 40% of the training data highlights its
efficiency, reducing the dependency on extensive manual labeling efforts and
making large-scale, automated irrigation mapping more feasible and
cost-effective.

</details>

### [99] [An incremental algorithm for non-convex AI-enhanced medical image processing](https://arxiv.org/abs/2505.08324)
*Elena Morotti*

Main category: cs.CV

TLDR: 论文提出了一种结合深度学习和增量优化的混合框架incDG，用于高效解决非凸正则化逆问题，尤其在医学影像中表现优异。


<details>
  <summary>Details</summary>
Motivation: 非凸正则化逆问题因其复杂的优化空间和多局部极小值而难以解决，但其能提供高质量的任务导向解，尤其在医学影像中需要增强临床相关特征。

Method: incDG框架结合深度学习与增量模型优化，利用深度神经网络生成初始解，再通过非凸变分解算器进行正则化迭代优化。

Result: 在多种数据集上验证，incDG在医学影像去模糊和断层重建中表现优于传统迭代解算器和深度学习方法，且无需真实数据训练也能保持性能。

Conclusion: incDG是一种高效、稳健的工具，适用于解决影像及其他领域的非凸逆问题。

Abstract: Solving non-convex regularized inverse problems is challenging due to their
complex optimization landscapes and multiple local minima. However, these
models remain widely studied as they often yield high-quality, task-oriented
solutions, particularly in medical imaging, where the goal is to enhance
clinically relevant features rather than merely minimizing global error. We
propose incDG, a hybrid framework that integrates deep learning with
incremental model-based optimization to efficiently approximate the
$\ell_0$-optimal solution of imaging inverse problems. Built on the Deep Guess
strategy, incDG exploits a deep neural network to generate effective
initializations for a non-convex variational solver, which refines the
reconstruction through regularized incremental iterations. This design combines
the efficiency of Artificial Intelligence (AI) tools with the theoretical
guarantees of model-based optimization, ensuring robustness and stability. We
validate incDG on TpV-regularized optimization tasks, demonstrating its
effectiveness in medical image deblurring and tomographic reconstruction across
diverse datasets, including synthetic images, brain CT slices, and
chest-abdomen scans. Results show that incDG outperforms both conventional
iterative solvers and deep learning-based methods, achieving superior accuracy
and stability. Moreover, we confirm that training incDG without ground truth
does not significantly degrade performance, making it a practical and powerful
tool for solving non-convex inverse problems in imaging and beyond.

</details>

### [100] [A computer vision-based model for occupancy detection using low-resolution thermal images](https://arxiv.org/abs/2505.08336)
*Xue Cui,Vincent Gbouna Zakka,Minhyun Lee*

Main category: cs.CV

TLDR: 该研究提出了一种基于低分辨率热成像和计算机视觉技术的占用检测模型，解决了传统RGB图像带来的隐私问题，并优化了计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 传统HVAC系统基于固定时间表运行，不考虑实际占用情况，而基于RGB图像的占用检测存在隐私问题。低分辨率热成像提供了一种非侵入式解决方案。

Method: 研究采用低分辨率热成像和计算机视觉技术，通过迁移学习微调YOLOv5模型，开发占用检测模型。

Result: 模型性能优异，精确度、召回率和mAP50值接近1.000。

Conclusion: 该模型不仅解决了隐私问题，还降低了计算资源需求，为HVAC系统的占用检测提供了高效解决方案。

Abstract: Occupancy plays an essential role in influencing the energy consumption and
operation of heating, ventilation, and air conditioning (HVAC) systems.
Traditional HVAC typically operate on fixed schedules without considering
occupancy. Advanced occupant-centric control (OCC) adopted occupancy status in
regulating HVAC operations. RGB images combined with computer vision (CV)
techniques are widely used for occupancy detection, however, the detailed
facial and body features they capture raise significant privacy concerns.
Low-resolution thermal images offer a non-invasive solution that mitigates
privacy issues. The study developed an occupancy detection model utilizing
low-resolution thermal images and CV techniques, where transfer learning was
applied to fine-tune the You Only Look Once version 5 (YOLOv5) model. The
developed model ultimately achieved satisfactory performance, with precision,
recall, mAP50, and mAP50 values approaching 1.000. The contributions of this
model lie not only in mitigating privacy concerns but also in reducing
computing resource demands.

</details>

### [101] [FAD: Frequency Adaptation and Diversion for Cross-domain Few-shot Learning](https://arxiv.org/abs/2505.08349)
*Ruixiao Shi,Fu Feng,Yucheng Xie,Jing Wang,Xin Geng*

Main category: cs.CV

TLDR: 论文提出了一种频率感知框架FAD，通过频域建模和调制提升跨域小样本学习的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注空间域，忽略了频域变化对跨域泛化的重要性。

Method: FAD框架将特征转换到频域，分频段适配并重构，针对不同频段使用专用卷积分支。

Result: 在Meta-Dataset基准测试中，FAD显著优于现有方法。

Conclusion: 频域表示和分频段适配能有效提升跨域小样本学习的泛化性能。

Abstract: Cross-domain few-shot learning (CD-FSL) requires models to generalize from
limited labeled samples under significant distribution shifts. While recent
methods enhance adaptability through lightweight task-specific modules, they
operate solely in the spatial domain and overlook frequency-specific variations
that are often critical for robust transfer. We observe that spatially similar
images across domains can differ substantially in their spectral
representations, with low and high frequencies capturing complementary semantic
information at coarse and fine levels. This indicates that uniform spatial
adaptation may overlook these spectral distinctions, thus constraining
generalization. To address this, we introduce Frequency Adaptation and
Diversion (FAD), a frequency-aware framework that explicitly models and
modulates spectral components. At its core is the Frequency Diversion Adapter,
which transforms intermediate features into the frequency domain using the
discrete Fourier transform (DFT), partitions them into low, mid, and
high-frequency bands via radial masks, and reconstructs each band using inverse
DFT (IDFT). Each frequency band is then adapted using a dedicated convolutional
branch with a kernel size tailored to its spectral scale, enabling targeted and
disentangled adaptation across frequencies. Extensive experiments on the
Meta-Dataset benchmark demonstrate that FAD consistently outperforms
state-of-the-art methods on both seen and unseen domains, validating the
utility of frequency-domain representations and band-wise adaptation for
improving generalization in CD-FSL.

</details>

### [102] [STORYANCHORS: Generating Consistent Multi-Scene Story Frames for Long-Form Narratives](https://arxiv.org/abs/2505.08350)
*Bo Wang,Haoyang Huang,Zhiyin Lu,Fengyuan Liu,Guoqing Ma,Jianlong Yuan,Yuan Zhang,Nan Duan*

Main category: cs.CV

TLDR: StoryAnchors是一个统一框架，用于生成高质量、多场景且具有强时序一致性的故事帧。它通过双向故事生成器和特定条件提升生成质量，支持手动编辑和扩展。实验表明其在一致性和叙事丰富性上优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决多场景故事帧生成中的时序一致性和叙事连贯性问题，同时提升场景多样性和生成质量。

Method: 采用双向故事生成器整合过去和未来上下文，引入特定条件区分故事帧生成与标准视频合成，并结合多事件标签和渐进式训练。

Result: 在一致性、叙事连贯性和场景多样性上优于现有开源模型，与GPT-4o在叙事一致性上表现相当。

Conclusion: StoryAnchors为故事驱动帧生成提供了可扩展、灵活且高度可编辑的基础，推动了该领域的研究边界。

Abstract: This paper introduces StoryAnchors, a unified framework for generating
high-quality, multi-scene story frames with strong temporal consistency. The
framework employs a bidirectional story generator that integrates both past and
future contexts to ensure temporal consistency, character continuity, and
smooth scene transitions throughout the narrative. Specific conditions are
introduced to distinguish story frame generation from standard video synthesis,
facilitating greater scene diversity and enhancing narrative richness. To
further improve generation quality, StoryAnchors integrates Multi-Event Story
Frame Labeling and Progressive Story Frame Training, enabling the model to
capture both overarching narrative flow and event-level dynamics. This approach
supports the creation of editable and expandable story frames, allowing for
manual modifications and the generation of longer, more complex sequences.
Extensive experiments show that StoryAnchors outperforms existing open-source
models in key areas such as consistency, narrative coherence, and scene
diversity. Its performance in narrative consistency and story richness is also
on par with GPT-4o. Ultimately, StoryAnchors pushes the boundaries of
story-driven frame generation, offering a scalable, flexible, and highly
editable foundation for future research.

</details>

### [103] [DArFace: Deformation Aware Robustness for Low Quality Face Recognition](https://arxiv.org/abs/2505.08423)
*Sadaf Gulshad,Abdullah Aldahlawi Thakaa*

Main category: cs.CV

TLDR: DArFace提出了一种针对低质量面部图像的鲁棒人脸识别框架，通过模拟全局和局部变形增强模型性能。


<details>
  <summary>Details</summary>
Motivation: 现实场景中低质量面部图像（如低分辨率、运动模糊）导致识别性能下降，现有方法常忽略局部非刚性变形。

Method: DArFace通过对抗性训练模拟全局变换和局部弹性变形，并引入对比目标保持身份一致性。

Result: 在TinyFace、IJB-B和IJB-C等低质量基准测试中，DArFace显著优于现有方法。

Conclusion: DArFace通过建模局部变形显著提升了低质量面部图像的识别鲁棒性。

Abstract: Facial recognition systems have achieved remarkable success by leveraging
deep neural networks, advanced loss functions, and large-scale datasets.
However, their performance often deteriorates in real-world scenarios involving
low-quality facial images. Such degradations, common in surveillance footage or
standoff imaging include low resolution, motion blur, and various distortions,
resulting in a substantial domain gap from the high-quality data typically used
during training. While existing approaches attempt to address robustness by
modifying network architectures or modeling global spatial transformations,
they frequently overlook local, non-rigid deformations that are inherently
present in real-world settings. In this work, we introduce DArFace, a
Deformation-Aware robust Face recognition framework that enhances robustness to
such degradations without requiring paired high- and low-quality training
samples. Our method adversarially integrates both global transformations (e.g.,
rotation, translation) and local elastic deformations during training to
simulate realistic low-quality conditions. Moreover, we introduce a contrastive
objective to enforce identity consistency across different deformed views.
Extensive evaluations on low-quality benchmarks including TinyFace, IJB-B, and
IJB-C demonstrate that DArFace surpasses state-of-the-art methods, with
significant gains attributed to the inclusion of local deformation modeling.

</details>

### [104] [DHECA-SuperGaze: Dual Head-Eye Cross-Attention and Super-Resolution for Unconstrained Gaze Estimation](https://arxiv.org/abs/2505.08426)
*Franko Šikić,Donik Vršnak,Sven Lončarić*

Main category: cs.CV

TLDR: DHECA-SuperGaze是一种基于深度学习的方法，通过超分辨率和双头眼交叉注意力模块改进无约束视线估计，显著降低了角度误差。


<details>
  <summary>Details</summary>
Motivation: 无约束视线估计在现实场景中面临图像分辨率低和头眼交互建模不足的挑战，需要更鲁棒的方法。

Method: 提出双分支卷积主干处理眼部和多尺度超分辨率头部图像，并引入双头眼交叉注意力模块进行特征优化。

Result: 在Gaze360和GFIE数据集上，静态和时序配置中的角度误差分别降低了0.48°-3.00°，跨数据集测试也表现优异。

Conclusion: DHECA-SuperGaze在视线估计任务中表现出卓越的性能和泛化能力。

Abstract: Unconstrained gaze estimation is the process of determining where a subject
is directing their visual attention in uncontrolled environments. Gaze
estimation systems are important for a myriad of tasks such as driver
distraction monitoring, exam proctoring, accessibility features in modern
software, etc. However, these systems face challenges in real-world scenarios,
partially due to the low resolution of in-the-wild images and partially due to
insufficient modeling of head-eye interactions in current state-of-the-art
(SOTA) methods. This paper introduces DHECA-SuperGaze, a deep learning-based
method that advances gaze prediction through super-resolution (SR) and a dual
head-eye cross-attention (DHECA) module. Our dual-branch convolutional backbone
processes eye and multiscale SR head images, while the proposed DHECA module
enables bidirectional feature refinement between the extracted visual features
through cross-attention mechanisms. Furthermore, we identified critical
annotation errors in one of the most diverse and widely used gaze estimation
datasets, Gaze360, and rectified the mislabeled data. Performance evaluation on
Gaze360 and GFIE datasets demonstrates superior within-dataset performance of
the proposed method, reducing angular error (AE) by 0.48{\deg} (Gaze360) and
2.95{\deg} (GFIE) in static configurations, and 0.59{\deg} (Gaze360) and
3.00{\deg} (GFIE) in temporal settings compared to prior SOTA methods.
Cross-dataset testing shows improvements in AE of more than 1.53{\deg}
(Gaze360) and 3.99{\deg} (GFIE) in both static and temporal settings,
validating the robust generalization properties of our approach.

</details>

### [105] [Visual Image Reconstruction from Brain Activity via Latent Representation](https://arxiv.org/abs/2505.08429)
*Yukiyasu Kamitani,Misato Tanaka,Ken Shirakawa*

Main category: cs.CV

TLDR: 本文回顾了视觉图像重建领域的进展，从早期分类方法到利用深度神经网络和生成模型的复杂重建技术，强调了分层潜在表示、组合策略和模块化架构的作用。尽管取得显著进展，但仍面临零样本泛化和主观感知建模等挑战。


<details>
  <summary>Details</summary>
Motivation: 探索如何从大脑活动中解码视觉内容，以深入了解神经编码并推动临床应用。

Method: 整合深度神经网络和生成模型，利用分层潜在表示、组合策略和模块化架构。

Result: 实现了更详细的视觉体验重建，但仍需解决零样本泛化和主观感知建模问题。

Conclusion: 视觉图像重建为神经编码研究提供了新视角，但需关注伦理问题和模型泛化能力的提升。

Abstract: Visual image reconstruction, the decoding of perceptual content from brain
activity into images, has advanced significantly with the integration of deep
neural networks (DNNs) and generative models. This review traces the field's
evolution from early classification approaches to sophisticated reconstructions
that capture detailed, subjective visual experiences, emphasizing the roles of
hierarchical latent representations, compositional strategies, and modular
architectures. Despite notable progress, challenges remain, such as achieving
true zero-shot generalization for unseen images and accurately modeling the
complex, subjective aspects of perception. We discuss the need for diverse
datasets, refined evaluation metrics aligned with human perceptual judgments,
and compositional representations that strengthen model robustness and
generalizability. Ethical issues, including privacy, consent, and potential
misuse, are underscored as critical considerations for responsible development.
Visual image reconstruction offers promising insights into neural coding and
enables new psychological measurements of visual experiences, with applications
spanning clinical diagnostics and brain-machine interfaces.

</details>

### [106] [TT-DF: A Large-Scale Diffusion-Based Dataset and Benchmark for Human Body Forgery Detection](https://arxiv.org/abs/2505.08437)
*Wenkui Yang,Zhida Zhang,Xiaoqiang Zhou,Junxian Duan,Jie Cao*

Main category: cs.CV

TLDR: 论文介绍了TikTok-DeepFake（TT-DF）数据集，专注于人体伪造检测，并提出了一种新的检测模型TOF-Net，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于人体伪造检测缺乏数据集和方法，作者旨在填补这一空白，提供全面的数据集和高效的检测模型。

Method: 构建了TT-DF数据集，包含多种伪造方法和配置；提出TOF-Net模型，利用时空不一致性和光流分布差异检测伪造。

Result: TOF-Net在TT-DF上表现优异，优于现有面部伪造检测模型。

Conclusion: TT-DF和TOF-Net为人体伪造检测提供了重要资源和方法，推动了该领域的发展。

Abstract: The emergence and popularity of facial deepfake methods spur the vigorous
development of deepfake datasets and facial forgery detection, which to some
extent alleviates the security concerns about facial-related artificial
intelligence technologies. However, when it comes to human body forgery, there
has been a persistent lack of datasets and detection methods, due to the later
inception and complexity of human body generation methods. To mitigate this
issue, we introduce TikTok-DeepFake (TT-DF), a novel large-scale
diffusion-based dataset containing 6,120 forged videos with 1,378,857 synthetic
frames, specifically tailored for body forgery detection. TT-DF offers a wide
variety of forgery methods, involving multiple advanced human image animation
models utilized for manipulation, two generative configurations based on the
disentanglement of identity and pose information, as well as different
compressed versions. The aim is to simulate any potential unseen forged data in
the wild as comprehensively as possible, and we also furnish a benchmark on
TT-DF. Additionally, we propose an adapted body forgery detection model,
Temporal Optical Flow Network (TOF-Net), which exploits the spatiotemporal
inconsistencies and optical flow distribution differences between natural data
and forged data. Our experiments demonstrate that TOF-Net achieves favorable
performance on TT-DF, outperforming current state-of-the-art extendable facial
forgery detection models. For our TT-DF dataset, please refer to
https://github.com/HashTAG00002/TT-DF.

</details>

### [107] [A Survey of 3D Reconstruction with Event Cameras: From Event-based Geometry to Neural 3D Rendering](https://arxiv.org/abs/2505.08438)
*Chuanzhi Xu,Haoxian Zhou,Langyi Chen,Haodong Chen,Ying Zhou,Vera Chung,Qiang Qu*

Main category: cs.CV

TLDR: 本文综述了事件相机在3D重建中的应用，分类了现有方法并总结了相关数据集，同时指出了当前研究的局限性和未来方向。


<details>
  <summary>Details</summary>
Motivation: 事件相机因其异步捕捉像素亮度变化的能力，在3D重建中表现出色，尤其是在极端环境下。本文旨在为事件驱动的3D重建提供全面参考。

Method: 将现有工作按输入模态（立体、单目、多模态）和重建方法（几何、深度学习、神经渲染）分类，并总结相关数据集。

Result: 分类了现有方法，总结了数据集，并指出了数据可用性、评估、表示和动态场景处理等局限性。

Conclusion: 本文为事件相机在3D重建中的研究提供了全面综述和未来发展方向。

Abstract: Event cameras have emerged as promising sensors for 3D reconstruction due to
their ability to capture per-pixel brightness changes asynchronously. Unlike
conventional frame-based cameras, they produce sparse and temporally rich data
streams, which enable more accurate 3D reconstruction and open up the
possibility of performing reconstruction in extreme environments such as
high-speed motion, low light, or high dynamic range scenes. In this survey, we
provide the first comprehensive review focused exclusively on 3D reconstruction
using event cameras. The survey categorises existing works into three major
types based on input modality - stereo, monocular, and multimodal systems, and
further classifies them by reconstruction approach, including geometry-based,
deep learning-based, and recent neural rendering techniques such as Neural
Radiance Fields and 3D Gaussian Splatting. Methods with a similar research
focus were organised chronologically into the most subdivided groups. We also
summarise public datasets relevant to event-based 3D reconstruction. Finally,
we highlight current research limitations in data availability, evaluation,
representation, and dynamic scene handling, and outline promising future
research directions. This survey aims to serve as a comprehensive reference and
a roadmap for future developments in event-driven 3D reconstruction.

</details>

### [108] [VCRBench: Exploring Long-form Causal Reasoning Capabilities of Large Video Language Models](https://arxiv.org/abs/2505.08455)
*Pritam Sarkar,Ali Etemad*

Main category: cs.CV

TLDR: 论文提出了一个名为VCRBench的新基准，用于评估大型视频语言模型（LVLM）在视频因果推理中的表现，并发现现有模型在此任务上表现不佳。作者提出了一种模块化方法RRD，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门用于评估视频因果推理的基准，限制了大型视频语言模型在此领域的研究进展。

Method: 通过创建VCRBench基准，使用日常活动视频测试LVLM的因果推理能力，并提出RRD方法将任务分解为视频识别和因果推理两部分。

Result: 实验表明，现有LVLM在视频因果推理上表现不佳，而RRD方法能显著提升性能（最高提升25.2%）。

Conclusion: LVLM在复杂视频因果推理任务中主要依赖语言知识，RRD方法为解决这一问题提供了有效途径。

Abstract: Despite recent advances in video understanding, the capabilities of Large
Video Language Models (LVLMs) to perform video-based causal reasoning remains
underexplored, largely due to the absence of relevant and dedicated benchmarks
for evaluating causal reasoning in visually grounded and goal-driven settings.
To fill this gap, we introduce a novel benchmark named Video-based long-form
Causal Reasoning (VCRBench). We create VCRBench using procedural videos of
simple everyday activities, where the steps are deliberately shuffled with each
clip capturing a key causal event, to test whether LVLMs can identify, reason
about, and correctly sequence the events needed to accomplish a specific goal.
Moreover, the benchmark is carefully designed to prevent LVLMs from exploiting
linguistic shortcuts, as seen in multiple-choice or binary QA formats, while
also avoiding the challenges associated with evaluating open-ended QA. Our
evaluation of state-of-the-art LVLMs on VCRBench suggests that these models
struggle with video-based long-form causal reasoning, primarily due to their
difficulty in modeling long-range causal dependencies directly from visual
observations. As a simple step toward enabling such capabilities, we propose
Recognition-Reasoning Decomposition (RRD), a modular approach that breaks
video-based causal reasoning into two sub-tasks of video recognition and causal
reasoning. Our experiments on VCRBench show that RRD significantly boosts
accuracy on VCRBench, with gains of up to 25.2%. Finally, our thorough analysis
reveals interesting insights, for instance, that LVLMs primarily rely on
language knowledge for complex video-based long-form causal reasoning tasks.

</details>

### [109] [A Deep Learning-Driven Framework for Inhalation Injury Grading Using Bronchoscopy Images](https://arxiv.org/abs/2505.08517)
*Yifan Li,Alan W Pang,Jo Woon Chong*

Main category: cs.CV

TLDR: 提出了一种基于深度学习的框架，利用支气管镜图像和机械通气时长作为客观指标，改进了吸入性损伤的分级方法。通过增强的StarGAN生成高质量合成图像，显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如AIS）依赖主观评估且与临床结果相关性弱，限制了吸入性损伤的诊断和分级。

Method: 提出增强的StarGAN，结合Patch Loss和SSIM Loss生成高质量合成图像，并用Swin Transformer进行分类评估。

Result: 增强StarGAN生成的数据集使分类准确率提升11.11%，达到77.78%，FID得分最低（30.06）。生成的图像被烧伤外科医生认可为真实且临床相关。

Conclusion: 增强StarGAN能有效解决医学影像数据稀缺问题，提升吸入性损伤分级的分类准确性。

Abstract: Inhalation injuries face a challenge in clinical diagnosis and grading due to
the limitations of traditional methods, such as Abbreviated Injury Score (AIS),
which rely on subjective assessments and show weak correlations with clinical
outcomes. This study introduces a novel deep learning-based framework for
grading inhalation injuries using bronchoscopy images with the duration of
mechanical ventilation as an objective metric. To address the scarcity of
medical imaging data, we propose enhanced StarGAN, a generative model that
integrates Patch Loss and SSIM Loss to improve synthetic images' quality and
clinical relevance. The augmented dataset generated by enhanced StarGAN
significantly improved classification performance when evaluated using the Swin
Transformer, achieving an accuracy of 77.78%, an 11.11% improvement over the
original dataset. Image quality was assessed using the Fr\'echet Inception
Distance (FID), where Enhanced StarGAN achieved the lowest FID of 30.06,
outperforming baseline models. Burn surgeons confirmed the realism and clinical
relevance of the generated images, particularly the preservation of bronchial
structures and color distribution. These results highlight the potential of
enhanced StarGAN in addressing data limitations and improving classification
accuracy for inhalation injury grading.

</details>

### [110] [Attention-based Generative Latent Replay: A Continual Learning Approach for WSI Analysis](https://arxiv.org/abs/2505.08524)
*Pratibha Kumari,Daniel Reisenbüchler,Afshin Bozorgpour,Nadine S. Schaadt,Friedrich Feuerhake,Dorit Merhof*

Main category: cs.CV

TLDR: 提出了一种基于注意力的生成潜在重放持续学习框架（AGLR-CL），用于解决全切片图像（WSI）分类中的领域偏移问题。


<details>
  <summary>Details</summary>
Motivation: WSI分类在计算病理学中应用广泛，但受限于不同器官、疾病或机构间的领域偏移。

Method: 采用高斯混合模型（GMMs）合成WSI表示和补丁分布，结合注意力机制过滤关键补丁嵌入，避免存储原始数据。

Result: 在多个公共数据集上验证，AGLR-CL在保留历史知识的同时适应新领域，性能优于无缓冲方法，与有缓冲方法相当。

Conclusion: AGLR-CL为WSI分类提供了一种隐私保护且高效的持续学习方案。

Abstract: Whole slide image (WSI) classification has emerged as a powerful tool in
computational pathology, but remains constrained by domain shifts, e.g., due to
different organs, diseases, or institution-specific variations. To address this
challenge, we propose an Attention-based Generative Latent Replay Continual
Learning framework (AGLR-CL), in a multiple instance learning (MIL) setup for
domain incremental WSI classification. Our method employs Gaussian Mixture
Models (GMMs) to synthesize WSI representations and patch count distributions,
preserving knowledge of past domains without explicitly storing original data.
A novel attention-based filtering step focuses on the most salient patch
embeddings, ensuring high-quality synthetic samples. This privacy-aware
strategy obviates the need for replay buffers and outperforms other buffer-free
counterparts while matching the performance of buffer-based solutions. We
validate AGLR-CL on clinically relevant biomarker detection and molecular
status prediction across multiple public datasets with diverse centers, organs,
and patient cohorts. Experimental results confirm its ability to retain prior
knowledge and adapt to new domains, offering an effective, privacy-preserving
avenue for domain incremental continual learning in WSI classification.

</details>

### [111] [Dynamic Snake Upsampling Operater and Boundary-Skeleton Weighted Loss for Tubular Structure Segmentation](https://arxiv.org/abs/2505.08525)
*Yiqi Chen,Ganghai Huang,Sheng Zhang,Jianglin Dai*

Main category: cs.CV

TLDR: 论文提出动态蛇形上采样操作和边界-骨架加权损失，用于提升管状拓扑结构的分割精度。


<details>
  <summary>Details</summary>
Motivation: 传统上采样操作难以处理管状结构的细长性和形态曲率，影响分割精度。

Method: 设计动态蛇形上采样操作，自适应调整采样步长；提出边界-骨架加权损失，平衡主体与边界权重。

Result: 实验表明，该方法提升了像素级分割精度和拓扑一致性。

Conclusion: 动态蛇形上采样和加权损失有效改善了管状结构的分割效果。

Abstract: Accurate segmentation of tubular topological structures (e.g., fissures and
vasculature) is critical in various fields to guarantee dependable downstream
quantitative analysis and modeling. However, in dense prediction tasks such as
semantic segmentation and super-resolution, conventional upsampling operators
cannot accommodate the slenderness of tubular structures and the curvature of
morphology. This paper introduces a dynamic snake upsampling operators and a
boundary-skeleton weighted loss tailored for topological tubular structures.
Specifically, we design a snake upsampling operators based on an adaptive
sampling domain, which dynamically adjusts the sampling stride according to the
feature map and selects a set of subpixel sampling points along the serpentine
path, enabling more accurate subpixel-level feature recovery for tubular
structures. Meanwhile, we propose a skeleton-to-boundary increasing weighted
loss that trades off main body and boundary weight allocation based on mask
class ratio and distance field, preserving main body overlap while enhancing
focus on target topological continuity and boundary alignment precision.
Experiments across various domain datasets and backbone networks show that this
plug-and-play dynamic snake upsampling operator and boundary-skeleton weighted
loss boost both pixel-wise segmentation accuracy and topological consistency of
results.

</details>

### [112] [Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting](https://arxiv.org/abs/2505.08527)
*Zheang Huai,Hui Tang,Yi Li,Zhuangzhuang Chen,Xiaomeng Li*

Main category: cs.CV

TLDR: 该论文提出了一种基于Segment Anything Model（SAM）的双特征引导（DFG）自动提示方法，用于解决源自由域适应（SFDA）分割任务中的域差距问题。


<details>
  <summary>Details</summary>
Motivation: 源自由域适应（SFDA）分割任务中，现有方法生成的边界框提示因域差距而不准确，影响了模型在目标域的表现。

Method: 通过双特征引导（DFG）方法，分两阶段搜索边界框提示：特征聚合阶段初步适应目标域，第二阶段利用目标模型特征和SAM特征逐步扩展边界框提示。

Result: 在3D和2D数据集上的实验表明，该方法性能优于传统方法。

Conclusion: DFG方法通过自动搜索准确的边界框提示，显著提升了SFDA分割任务的性能。

Abstract: Source-free domain adaptation (SFDA) for segmentation aims at adapting a
model trained in the source domain to perform well in the target domain with
only the source model and unlabeled target data.Inspired by the recent success
of Segment Anything Model (SAM) which exhibits the generality of segmenting
images of various modalities and in different domains given human-annotated
prompts like bounding boxes or points, we for the first time explore the
potentials of Segment Anything Model for SFDA via automatedly finding an
accurate bounding box prompt. We find that the bounding boxes directly
generated with existing SFDA approaches are defective due to the domain gap.To
tackle this issue, we propose a novel Dual Feature Guided (DFG) auto-prompting
approach to search for the box prompt. Specifically, the source model is first
trained in a feature aggregation phase, which not only preliminarily adapts the
source model to the target domain but also builds a feature distribution
well-prepared for box prompt search. In the second phase, based on two feature
distribution observations, we gradually expand the box prompt with the guidance
of the target model feature and the SAM feature to handle the class-wise
clustered target features and the class-wise dispersed target features,
respectively. To remove the potentially enlarged false positive regions caused
by the over-confident prediction of the target model, the refined pseudo-labels
produced by SAM are further postprocessed based on connectivity analysis.
Experiments on 3D and 2D datasets indicate that our approach yields superior
performance compared to conventional methods. Code is available at
https://github.com/zheangh/DFG.

</details>

### [113] [The RaspGrade Dataset: Towards Automatic Raspberry Ripeness Grading with Deep Learning](https://arxiv.org/abs/2505.08537)
*Mohamed Lamine Mekhalfi,Paul Chippendale,Fabio Poiesi,Samuele Bonecher,Gilberto Osler,Nicola Zancanella*

Main category: cs.CV

TLDR: 研究探讨了计算机视觉在快速、准确、非侵入式食品质量评估中的应用，专注于工业环境中实时将覆盆子分为五个等级的新挑战。


<details>
  <summary>Details</summary>
Motivation: 解决工业环境中覆盆子实时分级的难题，提高食品质量评估的效率和准确性。

Method: 通过采集并标注RaspGrade数据集，进行实例分割实验以获取水果级别的掩码。

Result: 实验显示某些覆盆子等级因颜色相似和遮挡难以分类，而其他等级则基于颜色更易区分。

Conclusion: RaspGrade数据集公开可用，为覆盆子分级研究提供了资源，但某些分类挑战仍需解决。

Abstract: This research investigates the application of computer vision for rapid,
accurate, and non-invasive food quality assessment, focusing on the novel
challenge of real-time raspberry grading into five distinct classes within an
industrial environment as the fruits move along a conveyor belt. To address
this, a dedicated dataset of raspberries, namely RaspGrade, was acquired and
meticulously annotated. Instance segmentation experiments revealed that
accurate fruit-level masks can be obtained; however, the classification of
certain raspberry grades presents challenges due to color similarities and
occlusion, while others are more readily distinguishable based on color. The
acquired and annotated RaspGrade dataset is accessible on HuggingFace at:
https://huggingface.co/datasets/FBK-TeV/RaspGrade.

</details>

### [114] [DFA-CON: A Contrastive Learning Approach for Detecting Copyright Infringement in DeepFake Art](https://arxiv.org/abs/2505.08552)
*Haroon Wahab,Hassan Ugail,Irfan Mehmood*

Main category: cs.CV

TLDR: 本文提出了一种名为DFA-CON的对比学习框架，用于检测侵犯版权或伪造的AI生成艺术作品，并在多种攻击类型下表现出色。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具在视觉内容创作中的广泛应用引发了版权侵权和伪造的严重问题，现有模型容易因记忆训练模式而侵犯版权。

Method: DFA-CON通过对比学习框架学习判别性表示空间，区分原始艺术作品及其伪造版本，并在多种攻击类型（如修复、风格迁移、对抗扰动和cutmix）上进行训练。

Result: 评估结果显示，DFA-CON在大多数攻击类型下表现出鲁棒的检测性能，优于现有的预训练基础模型。

Conclusion: DFA-CON为解决AI生成艺术作品的版权侵权和伪造问题提供了有效工具，代码和模型将在接受后公开。

Abstract: Recent proliferation of generative AI tools for visual content
creation-particularly in the context of visual artworks-has raised serious
concerns about copyright infringement and forgery. The large-scale datasets
used to train these models often contain a mixture of copyrighted and
non-copyrighted artworks. Given the tendency of generative models to memorize
training patterns, they are susceptible to varying degrees of copyright
violation. Building on the recently proposed DeepfakeArt Challenge benchmark,
this work introduces DFA-CON, a contrastive learning framework designed to
detect copyright-infringing or forged AI-generated art. DFA-CON learns a
discriminative representation space, posing affinity among original artworks
and their forged counterparts within a contrastive learning framework. The
model is trained across multiple attack types, including inpainting, style
transfer, adversarial perturbation, and cutmix. Evaluation results demonstrate
robust detection performance across most attack types, outperforming recent
pretrained foundation models. Code and model checkpoints will be released
publicly upon acceptance.

</details>

### [115] [Reinforcement Learning meets Masked Video Modeling : Trajectory-Guided Adaptive Token Selection](https://arxiv.org/abs/2505.08561)
*Ayush K. Rai,Kyle Min,Tarun Krishna,Feiyan Hu,Alan F. Smeaton,Noel E. O'Connor*

Main category: cs.CV

TLDR: 提出了一种轨迹感知自适应令牌采样器（TATS），用于视频建模中的动态令牌选择，结合MAE框架和PPO优化策略，实现高效预训练。


<details>
  <summary>Details</summary>
Motivation: 现有视频建模中的掩码策略选择存在挑战，需更动态和高效的方法。

Method: 提出TATS建模令牌运动动态，结合MAE框架和PPO联合优化。

Result: 在四个基准测试中表现优异，支持高掩码率且不影响下游任务性能。

Conclusion: TATS方法在效率、泛化性和迁移性上优于现有技术。

Abstract: Masked video modeling~(MVM) has emerged as a highly effective pre-training
strategy for visual foundation models, whereby the model reconstructs masked
spatiotemporal tokens using information from visible tokens. However, a key
challenge in such approaches lies in selecting an appropriate masking strategy.
Previous studies have explored predefined masking techniques, including random
and tube-based masking, as well as approaches that leverage key motion priors,
optical flow and semantic cues from externally pre-trained models. In this
work, we introduce a novel and generalizable Trajectory-Aware Adaptive Token
Sampler (TATS), which models the motion dynamics of tokens and can be
seamlessly integrated into the masked autoencoder (MAE) framework to select
motion-centric tokens in videos. Additionally, we propose a unified training
strategy that enables joint optimization of both MAE and TATS from scratch
using Proximal Policy Optimization (PPO). We show that our model allows for
aggressive masking without compromising performance on the downstream task of
action recognition while also ensuring that the pre-training remains memory
efficient. Extensive experiments of the proposed approach across four
benchmarks, including Something-Something v2, Kinetics-400, UCF101, and HMDB51,
demonstrate the effectiveness, transferability, generalization, and efficiency
of our work compared to other state-of-the-art methods.

</details>

### [116] [Thermal Detection of People with Mobility Restrictions for Barrier Reduction at Traffic Lights Controlled Intersections](https://arxiv.org/abs/2505.08568)
*Xiao Ni,Carsten Kuehnel,Xiaoyi Jiang*

Main category: cs.CV

TLDR: 提出了一种基于热成像的交通信号系统，动态调整信号时长以服务行动不便者，并开发了YOLO-Thermal检测器以提高热成像检测精度。


<details>
  <summary>Details</summary>
Motivation: 现有RGB摄像头系统忽视行动不便者需求，且存在恶劣天气下性能不足和隐私问题。

Method: 构建TD4PWMR热成像数据集，开发YOLO-Thermal检测器，结合特征提取和注意力机制。

Result: YOLO-Thermal优于现有检测器，系统有效提升无障碍交叉路口体验。

Conclusion: 热成像系统解决了RGB系统的局限性，为所有用户提供更包容的交通解决方案。

Abstract: Rapid advances in deep learning for computer vision have driven the adoption
of RGB camera-based adaptive traffic light systems to improve traffic safety
and pedestrian comfort. However, these systems often overlook the needs of
people with mobility restrictions. Moreover, the use of RGB cameras presents
significant challenges, including limited detection performance under adverse
weather or low-visibility conditions, as well as heightened privacy concerns.
To address these issues, we propose a fully automated, thermal detector-based
traffic light system that dynamically adjusts signal durations for individuals
with walking impairments or mobility burden and triggers the auditory signal
for visually impaired individuals, thereby advancing towards barrier-free
intersection for all users. To this end, we build the thermal dataset for
people with mobility restrictions (TD4PWMR), designed to capture diverse
pedestrian scenarios, particularly focusing on individuals with mobility aids
or mobility burden under varying environmental conditions, such as different
lighting, weather, and crowded urban settings. While thermal imaging offers
advantages in terms of privacy and robustness to adverse conditions, it also
introduces inherent hurdles for object detection due to its lack of color and
fine texture details and generally lower resolution of thermal images. To
overcome these limitations, we develop YOLO-Thermal, a novel variant of the
YOLO architecture that integrates advanced feature extraction and attention
mechanisms for enhanced detection accuracy and robustness in thermal imaging.
Experiments demonstrate that the proposed thermal detector outperforms existing
detectors, while the proposed traffic light system effectively enhances
barrier-free intersection. The source codes and dataset are available at
https://github.com/leon2014dresden/YOLO-THERMAL.

</details>

### [117] [ReSurgSAM2: Referring Segment Anything in Surgical Video via Credible Long-term Tracking](https://arxiv.org/abs/2505.08581)
*Haofeng Liu,Mingqi Gao,Xuxiao Luo,Ziyue Wang,Guanyi Qin,Junde Wu,Yueming Jin*

Main category: cs.CV

TLDR: ReSurgSAM2是一种两阶段的手术场景分割框架，结合了Segment Anything Model 2和多样性驱动的长期记忆机制，显著提升了分割效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有手术场景分割方法效率低且跟踪时间短，限制了其在复杂手术场景中的应用。

Method: 采用两阶段框架：文本引导的目标检测和分割，以及基于可靠初始帧选择和多样性驱动的长期跟踪。

Result: ReSurgSAM2在准确性和效率上显著优于现有方法，实时运行速度为61.2 FPS。

Conclusion: ReSurgSAM2为手术场景分割提供了高效且可靠的解决方案，适用于复杂手术环境。

Abstract: Surgical scene segmentation is critical in computer-assisted surgery and is
vital for enhancing surgical quality and patient outcomes. Recently, referring
surgical segmentation is emerging, given its advantage of providing surgeons
with an interactive experience to segment the target object. However, existing
methods are limited by low efficiency and short-term tracking, hindering their
applicability in complex real-world surgical scenarios. In this paper, we
introduce ReSurgSAM2, a two-stage surgical referring segmentation framework
that leverages Segment Anything Model 2 to perform text-referred target
detection, followed by tracking with reliable initial frame identification and
diversity-driven long-term memory. For the detection stage, we propose a
cross-modal spatial-temporal Mamba to generate precise detection and
segmentation results. Based on these results, our credible initial frame
selection strategy identifies the reliable frame for the subsequent tracking.
Upon selecting the initial frame, our method transitions to the tracking stage,
where it incorporates a diversity-driven memory mechanism that maintains a
credible and diverse memory bank, ensuring consistent long-term tracking.
Extensive experiments demonstrate that ReSurgSAM2 achieves substantial
improvements in accuracy and efficiency compared to existing methods, operating
in real-time at 61.2 FPS. Our code and datasets will be available at
https://github.com/jinlab-imvr/ReSurgSAM2.

</details>

### [118] [A Large-scale Benchmark on Geological Fault Delineation Models: Domain Shift, Training Dynamics, Generalizability, Evaluation and Inferential Behavior](https://arxiv.org/abs/2505.08585)
*Jorge Quesada,Chen Zhou,Prithwijit Chowdhury,Mohammad Alotaibi,Ahmad Mustafa,Yusufjon Kumamnov,Mohit Prabhushankar,Ghassan AlRegib*

Main category: cs.CV

TLDR: 论文通过大规模基准测试研究，探讨了机器学习模型在地震解释中的泛化性问题，并提出了针对领域转移的策略指南。


<details>
  <summary>Details</summary>
Motivation: 地震解释中机器学习模型的泛化性不足，尤其是在不同地质、采集和处理设置下的数据中表现不稳定。

Method: 研究训练和评估了200多个模型，涵盖三种异构数据集（合成和真实数据），系统评估了预训练、微调和联合训练策略。

Result: 揭示了当前微调实践的脆弱性、灾难性遗忘现象，并建立了实验基线以分析性能权衡。

Conclusion: 为开发更具泛化性、可解释性和有效性的地震解释模型提供了方向，并提出了部署指南。

Abstract: Machine learning has taken a critical role in seismic interpretation
workflows, especially in fault delineation tasks. However, despite the recent
proliferation of pretrained models and synthetic datasets, the field still
lacks a systematic understanding of the generalizability limits of these models
across seismic data representing a variety of geologic, acquisition and
processing settings. Distributional shifts between different data sources,
limitations in fine-tuning strategies and labeled data accessibility, and
inconsistent evaluation protocols all represent major roadblocks in the
deployment of reliable and robust models in real-world exploration settings. In
this paper, we present the first large-scale benchmarking study explicitly
designed to provide answers and guidelines for domain shift strategies in
seismic interpretation. Our benchmark encompasses over $200$ models trained and
evaluated on three heterogeneous datasets (synthetic and real data) including
FaultSeg3D, CRACKS, and Thebe. We systematically assess pretraining,
fine-tuning, and joint training strategies under varying degrees of domain
shift. Our analysis highlights the fragility of current fine-tuning practices,
the emergence of catastrophic forgetting, and the challenges of interpreting
performance in a systematic manner. We establish a robust experimental baseline
to provide insights into the tradeoffs inherent to current fault delineation
workflows, and shed light on directions for developing more generalizable,
interpretable and effective machine learning models for seismic interpretation.
The insights and analyses reported provide a set of guidelines on the
deployment of fault delineation models within seismic interpretation workflows.

</details>

### [119] [PrePrompt: Predictive prompting for class incremental learning](https://arxiv.org/abs/2505.08586)
*Libo Huang,Zhulin An,Chuanguang Yang,Boyu Diao,Fei Wang,Yan Zeng,Zhifeng Hao,Yongjun Xu*

Main category: cs.CV

TLDR: 论文提出了一种名为PrePrompt的新框架，通过预测任务特定的提示来改进基于预训练模型的类增量学习，避免了相关性方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于相关性的方法难以用少量可训练提示拟合所有任务的特征空间。

Method: PrePrompt将类增量学习分解为两阶段预测框架：任务特定提示预测和标签预测，并通过特征翻译平衡稳定性和可塑性。

Result: 实验表明，PrePrompt在多个基准测试中优于现有的基于提示的类增量学习方法。

Conclusion: PrePrompt通过预测任务特定提示和动态平衡，显著提升了类增量学习的性能。

Abstract: Class Incremental Learning (CIL) based on pre-trained models offers a
promising direction for open-world continual learning. Existing methods
typically rely on correlation-based strategies, where an image's classification
feature is used as a query to retrieve the most related key prompts and select
the corresponding value prompts for training. However, these approaches face an
inherent limitation: fitting the entire feature space of all tasks with only a
few trainable prompts is fundamentally challenging. We propose Predictive
Prompting (PrePrompt), a novel CIL framework that circumvents correlation-based
limitations by leveraging pre-trained models' natural classification ability to
predict task-specific prompts. Specifically, PrePrompt decomposes CIL into a
two-stage prediction framework: task-specific prompt prediction followed by
label prediction. While theoretically appealing, this framework risks bias
toward recent classes due to missing historical data for older classifier
calibration. PrePrompt then mitigates this by incorporating feature
translation, dynamically balancing stability and plasticity. Experiments across
multiple benchmarks demonstrate PrePrompt's superiority over state-of-the-art
prompt-based CIL methods. The code will be released upon acceptance.

</details>

### [120] [MESSI: A Multi-Elevation Semantic Segmentation Image Dataset of an Urban Environment](https://arxiv.org/abs/2505.08589)
*Barak Pinkovich,Boaz Matalon,Ehud Rivlin,Hector Rotstein*

Main category: cs.CV

TLDR: MESSI数据集包含2525张无人机拍摄的密集城市环境图像，支持多高度语义分割研究，并提供丰富标注。


<details>
  <summary>Details</summary>
Motivation: 研究深度对语义分割的影响，并覆盖无人机3D飞行中的视觉多样性。

Method: 使用多种神经网络模型进行语义分割，并提供数据集标注细节。

Result: MESSI数据集可作为无人机图像语义分割的评估基准。

Conclusion: MESSI数据集公开，支持语义分割及其他应用研究。

Abstract: This paper presents a Multi-Elevation Semantic Segmentation Image (MESSI)
dataset comprising 2525 images taken by a drone flying over dense urban
environments. MESSI is unique in two main features. First, it contains images
from various altitudes, allowing us to investigate the effect of depth on
semantic segmentation. Second, it includes images taken from several different
urban regions (at different altitudes). This is important since the variety
covers the visual richness captured by a drone's 3D flight, performing
horizontal and vertical maneuvers. MESSI contains images annotated with
location, orientation, and the camera's intrinsic parameters and can be used to
train a deep neural network for semantic segmentation or other applications of
interest (e.g., localization, navigation, and tracking). This paper describes
the dataset and provides annotation details. It also explains how semantic
segmentation was performed using several neural network models and shows
several relevant statistics. MESSI will be published in the public domain to
serve as an evaluation benchmark for semantic segmentation using images
captured by a drone or similar vehicle flying over a dense urban environment.

</details>

### [121] [Rejoining fragmented ancient bamboo slips with physics-driven deep learning](https://arxiv.org/abs/2505.08601)
*Jinchi Zhu,Zhou Zhao,Hailong Lei,Xiaoguang Wang,Jialiang Lu,Jing Li,Qianqian Tang,Jiachen Shen,Gui-Song Xia,Bo Du,Yongchao Xu*

Main category: cs.CV

TLDR: WisePanda是一种基于物理原理的深度学习框架，用于拼接破碎的竹简，显著提高了匹配准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 竹简是记录东亚古代文明的重要媒介，但许多出土竹简已破碎成不规则碎片，拼接困难。

Method: WisePanda利用断裂和材料劣化的物理原理，自动生成合成训练数据，训练匹配网络，无需手动配对样本。

Result: Top-50匹配准确率从36%提升至52%，拼接效率提高约20倍。

Conclusion: 结合物理原理的深度学习显著提升模型性能，为古代文物修复提供了新范式。

Abstract: Bamboo slips are a crucial medium for recording ancient civilizations in East
Asia, and offers invaluable archaeological insights for reconstructing the Silk
Road, studying material culture exchanges, and global history. However, many
excavated bamboo slips have been fragmented into thousands of irregular pieces,
making their rejoining a vital yet challenging step for understanding their
content. Here we introduce WisePanda, a physics-driven deep learning framework
designed to rejoin fragmented bamboo slips. Based on the physics of fracture
and material deterioration, WisePanda automatically generates synthetic
training data that captures the physical properties of bamboo fragmentations.
This approach enables the training of a matching network without requiring
manually paired samples, providing ranked suggestions to facilitate the
rejoining process. Compared to the leading curve matching method, WisePanda
increases Top-50 matching accuracy from 36\% to 52\%. Archaeologists using
WisePanda have experienced substantial efficiency improvements (approximately
20 times faster) when rejoining fragmented bamboo slips. This research
demonstrates that incorporating physical principles into deep learning models
can significantly enhance their performance, transforming how archaeologists
restore and study fragmented artifacts. WisePanda provides a new paradigm for
addressing data scarcity in ancient artifact restoration through physics-driven
machine learning.

</details>

### [122] [Unsupervised Out-of-Distribution Detection in Medical Imaging Using Multi-Exit Class Activation Maps and Feature Masking](https://arxiv.org/abs/2505.08604)
*Yu-Jen Chen,Xueyang Li,Yiyu Shi,Tsung-Yi Ho*

Main category: cs.CV

TLDR: 论文提出了一种基于多出口类激活图（MECAM）的无监督OOD检测框架，通过特征掩码和多分辨率CAM提升医学影像中OOD检测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 医学影像中OOD检测的可靠性至关重要。研究发现ID数据的CAM通常聚焦于预测相关区域，而OOD数据缺乏此类激活，这为区分提供了依据。

Method: 提出MECAM框架，利用多出口网络生成不同分辨率和深度的CAM，结合特征掩码技术，增强OOD检测的鲁棒性。

Result: 在多个ID和OOD数据集上验证了MECAM的有效性，优于现有OOD检测方法。

Conclusion: 多出口网络和特征掩码技术为医学影像中的OOD检测提供了可靠且可解释的解决方案，具有临床应用的潜力。

Abstract: Out-of-distribution (OOD) detection is essential for ensuring the reliability
of deep learning models in medical imaging applications. This work is motivated
by the observation that class activation maps (CAMs) for in-distribution (ID)
data typically emphasize regions that are highly relevant to the model's
predictions, whereas OOD data often lacks such focused activations. By masking
input images with inverted CAMs, the feature representations of ID data undergo
more substantial changes compared to those of OOD data, offering a robust
criterion for differentiation. In this paper, we introduce a novel unsupervised
OOD detection framework, Multi-Exit Class Activation Map (MECAM), which
leverages multi-exit CAMs and feature masking. By utilizing mult-exit networks
that combine CAMs from varying resolutions and depths, our method captures both
global and local feature representations, thereby enhancing the robustness of
OOD detection. We evaluate MECAM on multiple ID datasets, including ISIC19 and
PathMNIST, and test its performance against three medical OOD datasets, RSNA
Pneumonia, COVID-19, and HeadCT, and one natural image OOD dataset, iSUN.
Comprehensive comparisons with state-of-the-art OOD detection methods validate
the effectiveness of our approach. Our findings emphasize the potential of
multi-exit networks and feature masking for advancing unsupervised OOD
detection in medical imaging, paving the way for more reliable and
interpretable models in clinical practice.

</details>

### [123] [Leveraging Multi-Modal Information to Enhance Dataset Distillation](https://arxiv.org/abs/2505.08605)
*Zhe Li,Hadrien Reynaud,Bernhard Kainz*

Main category: cs.CV

TLDR: 论文提出两种改进数据集蒸馏的方法：基于文本的监督和对象中心掩码，通过结合文本信息和对象级优化提升蒸馏数据集质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注视觉表示优化，而结合多模态信息和细化对象级信息可以显著提升蒸馏数据集的质量。

Method: 提出两种策略：1) 文本特征融合和文本匹配，用于结合文本信息；2) 对象中心掩码，通过分割掩码隔离目标对象并设计两种损失函数。

Result: 综合评估表明，结合文本指导和对象中心掩码能显著提升数据集蒸馏效果，生成的数据集在下游任务中表现更优。

Conclusion: 通过引入文本监督和对象级优化，论文显著提升了数据集蒸馏的质量和实用性。

Abstract: Dataset distillation aims to create a compact and highly representative
synthetic dataset that preserves the knowledge of a larger real dataset. While
existing methods primarily focus on optimizing visual representations,
incorporating additional modalities and refining object-level information can
significantly improve the quality of distilled datasets. In this work, we
introduce two key enhancements to dataset distillation: caption-guided
supervision and object-centric masking. To integrate textual information, we
propose two strategies for leveraging caption features: the feature
concatenation, where caption embeddings are fused with visual features at the
classification stage, and caption matching, which introduces a caption-based
alignment loss during training to ensure semantic coherence between real and
synthetic data. Additionally, we apply segmentation masks to isolate target
objects and remove background distractions, introducing two loss functions
designed for object-centric learning: masked feature alignment loss and masked
gradient matching loss. Comprehensive evaluations demonstrate that integrating
caption-based guidance and object-centric masking enhances dataset
distillation, leading to synthetic datasets that achieve superior performance
on downstream tasks.

</details>

### [124] [Boosting Zero-shot Stereo Matching using Large-scale Mixed Images Sources in the Real World](https://arxiv.org/abs/2505.08607)
*Yuran Wang,Yingping Liang,Ying Fu*

Main category: cs.CV

TLDR: 论文提出BooSTer框架，结合视觉基础模型和大规模混合图像数据（合成、真实和单视图图像），解决立体匹配中标注数据稀缺和领域差异问题。


<details>
  <summary>Details</summary>
Motivation: 立体匹配方法依赖密集像素级标注数据，但真实数据标注成本高，且合成与真实图像间存在领域差异。

Method: 1. 设计数据生成策略，结合单目深度估计和扩散模型，从单视图图像生成密集立体匹配数据；2. 利用单目深度估计模型的伪标签和动态尺度不变损失解决真实数据稀疏标注问题；3. 引入视觉基础模型作为编码器提取鲁棒特征。

Result: 在基准数据集上验证了方法的有效性，显著提升了精度，尤其在标注数据有限和领域差异场景下。

Conclusion: BooSTer框架通过混合数据源和视觉基础模型，有效解决了立体匹配中的数据稀缺和领域适应问题。

Abstract: Stereo matching methods rely on dense pixel-wise ground truth labels, which
are laborious to obtain, especially for real-world datasets. The scarcity of
labeled data and domain gaps between synthetic and real-world images also pose
notable challenges. In this paper, we propose a novel framework,
\textbf{BooSTer}, that leverages both vision foundation models and large-scale
mixed image sources, including synthetic, real, and single-view images. First,
to fully unleash the potential of large-scale single-view images, we design a
data generation strategy combining monocular depth estimation and diffusion
models to generate dense stereo matching data from single-view images. Second,
to tackle sparse labels in real-world datasets, we transfer knowledge from
monocular depth estimation models, using pseudo-mono depth labels and a dynamic
scale- and shift-invariant loss for additional supervision. Furthermore, we
incorporate vision foundation model as an encoder to extract robust and
transferable features, boosting accuracy and generalization. Extensive
experiments on benchmark datasets demonstrate the effectiveness of our
approach, achieving significant improvements in accuracy over existing methods,
particularly in scenarios with limited labeled data and domain shifts.

</details>

### [125] [WaveGuard: Robust Deepfake Detection and Source Tracing via Dual-Tree Complex Wavelet and Graph Neural Networks](https://arxiv.org/abs/2505.08614)
*Ziyuan He,Zhiqing Guo,Liejun Wang,Gaobo Yang,Yunfeng Diao,Dan Ma*

Main category: cs.CV

TLDR: WaveGuard是一种主动水印框架，通过频域嵌入和图结构一致性增强鲁棒性和不可感知性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 应对Deepfake技术带来的隐私侵犯和身份盗窃风险。

Method: 使用DT-CWT在高频子带嵌入水印，结合SC-GNN保持视觉质量，并设计注意力模块优化嵌入精度。

Result: 在人脸替换和重演任务中，WaveGuard在鲁棒性和视觉质量上优于现有方法。

Conclusion: WaveGuard为Deepfake防御提供了高效解决方案。

Abstract: Deepfake technology poses increasing risks such as privacy invasion and
identity theft. To address these threats, we propose WaveGuard, a proactive
watermarking framework that enhances robustness and imperceptibility via
frequency-domain embedding and graph-based structural consistency.
Specifically, we embed watermarks into high-frequency sub-bands using Dual-Tree
Complex Wavelet Transform (DT-CWT) and employ a Structural Consistency Graph
Neural Network (SC-GNN) to preserve visual quality. We also design an attention
module to refine embedding precision. Experimental results on face swap and
reenactment tasks demonstrate that WaveGuard outperforms state-of-the-art
methods in both robustness and visual quality. Code is available at
https://github.com/vpsg-research/WaveGuard.

</details>

### [126] [OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning](https://arxiv.org/abs/2505.08617)
*Zhaochen Su,Linjie Li,Mingyang Song,Yunzhuo Hao,Zhengyuan Yang,Jun Zhang,Guanjie Chen,Jiawei Gu,Juntao Li,Xiaoye Qu,Yu Cheng*

Main category: cs.CV

TLDR: OpenThinkIMG是一个开源框架，用于增强大型视觉语言模型（LVLMs）的动态视觉工具调用能力，通过强化学习（V-ToolRL）显著提升了任务表现。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏标准化基础设施，限制了LVLMs整合多样化视觉工具、生成交互数据及训练鲁棒代理的能力。

Method: 提出OpenThinkIMG框架，包括标准化视觉工具接口、可扩展轨迹生成和灵活训练环境，并引入V-ToolRL强化学习框架优化工具调用策略。

Result: 在图表推理任务中，V-ToolRL训练的模型显著优于监督微调（SFT）和现有基线（如Taco、CogCom），甚至超过GPT-4.1。

Conclusion: OpenThinkIMG为动态视觉推理提供了基础框架，推动开发能真正“用图像思考”的AI代理。

Abstract: While humans can flexibly leverage interactive visual cognition for complex
problem-solving, enabling Large Vision-Language Models (LVLMs) to learn
similarly adaptive behaviors with visual tools remains challenging. A
significant hurdle is the current lack of standardized infrastructure, which
hinders integrating diverse tools, generating rich interaction data, and
training robust agents effectively. To address these gaps, we introduce
OpenThinkIMG, the first open-source, comprehensive end-to-end framework for
tool-augmented LVLMs. It features standardized vision tool interfaces, scalable
trajectory generation for policy initialization, and a flexible training
environment. Furthermore, considering supervised fine-tuning (SFT) on static
demonstrations offers limited policy generalization for dynamic tool
invocation, we propose a novel reinforcement learning (RL) framework V-ToolRL
to train LVLMs to learn adaptive policies for invoking external vision tools.
V-ToolRL enables LVLMs to autonomously discover optimal tool-usage strategies
by directly optimizing for task success using feedback from tool interactions.
We empirically validate V-ToolRL on challenging chart reasoning tasks. Our
RL-trained agent, built upon a Qwen2-VL-2B, significantly outperforms its
SFT-initialized counterpart (+28.83 points) and surpasses established
supervised tool-learning baselines like Taco and CogCom by an average of +12.7
points. Notably, it also surpasses prominent closed-source models like GPT-4.1
by +8.68 accuracy points. We hope OpenThinkIMG can serve as a foundational
framework for advancing dynamic, tool-augmented visual reasoning, helping the
community develop AI agents that can genuinely "think with images".

</details>

### [127] [DLO-Splatting: Tracking Deformable Linear Objects Using 3D Gaussian Splatting](https://arxiv.org/abs/2505.08644)
*Holly Dinkel,Marcel Büsching,Alberta Longhini,Brian Coltin,Trey Smith,Danica Kragic,Mårten Björkman,Timothy Bretl*

Main category: cs.CV

TLDR: DLO-Splatting算法通过多视角RGB图像和夹爪状态信息预测-更新滤波估计可变形线性物体的3D形状，结合动力学模型和渲染损失优化。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉方法在复杂场景（如打结）中难以准确估计可变形线性物体形状的问题。

Method: 使用基于位置的动力学模型和3D高斯渲染损失进行预测-更新滤波，迭代优化形状估计。

Result: 初步实验在打结场景中展示了优于现有视觉方法的效果。

Conclusion: DLO-Splatting为复杂场景下的可变形物体形状估计提供了有效解决方案。

Abstract: This work presents DLO-Splatting, an algorithm for estimating the 3D shape of
Deformable Linear Objects (DLOs) from multi-view RGB images and gripper state
information through prediction-update filtering. The DLO-Splatting algorithm
uses a position-based dynamics model with shape smoothness and rigidity
dampening corrections to predict the object shape. Optimization with a 3D
Gaussian Splatting-based rendering loss iteratively renders and refines the
prediction to align it with the visual observations in the update step. Initial
experiments demonstrate promising results in a knot tying scenario, which is
challenging for existing vision-only methods.

</details>

### [128] [SkillFormer: Unified Multi-View Video Understanding for Proficiency Estimation](https://arxiv.org/abs/2505.08665)
*Edoardo Bianchi,Antonio Liotta*

Main category: cs.CV

TLDR: SkillFormer是一种高效的多视角技能评估架构，通过跨视角融合模块和低秩适应技术，显著减少训练成本，并在EgoExo4D数据集上达到最佳性能。


<details>
  <summary>Details</summary>
Motivation: 评估复杂活动中的人类技能水平是一个具有挑战性的问题，在体育、康复和培训中有广泛应用。

Method: 基于TimeSformer，SkillFormer引入CrossViewFusion模块，结合多头交叉注意力、可学习门控和自适应自校准，并使用低秩适应技术微调少量参数。

Result: 在EgoExo4D数据集上，SkillFormer在多视角设置中达到最佳准确率，参数减少4.5倍，训练轮次减少3.75倍。

Conclusion: 多视角集成对细粒度技能评估具有重要价值，SkillFormer展示了高效性和性能优势。

Abstract: Assessing human skill levels in complex activities is a challenging problem
with applications in sports, rehabilitation, and training. In this work, we
present SkillFormer, a parameter-efficient architecture for unified multi-view
proficiency estimation from egocentric and exocentric videos. Building on the
TimeSformer backbone, SkillFormer introduces a CrossViewFusion module that
fuses view-specific features using multi-head cross-attention, learnable
gating, and adaptive self-calibration. We leverage Low-Rank Adaptation to
fine-tune only a small subset of parameters, significantly reducing training
costs. In fact, when evaluated on the EgoExo4D dataset, SkillFormer achieves
state-of-the-art accuracy in multi-view settings while demonstrating remarkable
computational efficiency, using 4.5x fewer parameters and requiring 3.75x fewer
training epochs than prior baselines. It excels in multiple structured tasks,
confirming the value of multi-view integration for fine-grained skill
assessment.

</details>

### [129] [Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS) challenge results](https://arxiv.org/abs/2505.08685)
*Meritxell Riera-Marin,Sikha O K,Julia Rodriguez-Comas,Matthias Stefan May,Zhaohong Pan,Xiang Zhou,Xiaokun Liang,Franciskus Xaverius Erick,Andrea Prenner,Cedric Hemon,Valentin Boussot,Jean-Louis Dillenseger,Jean-Claude Nunes,Abdul Qayyum,Moona Mazher,Steven A Niederer,Kaisar Kushibar,Carlos Martin-Isla,Petia Radeva,Karim Lekadir,Theodore Barfoot,Luis C. Garcia Peraza Herrera,Ben Glocker,Tom Vercauteren,Lucas Gago,Justin Englemann,Joy-Marie Kleiss,Anton Aubanell,Andreu Antolin,Javier Garcia-Lopez,Miguel A. Gonzalez Ballester,Adrian Galdran*

Main category: cs.CV

TLDR: CURVAS挑战赛通过多标注者数据评估深度学习模型在医学图像分割中的校准和不确定性，强调模型校准与结果质量的相关性。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中标注变异性、校准和不确定性估计的挑战，提升模型的可靠性和临床适用性。

Method: 七支团队提交DL模型，使用DSC、ECE和CRPS等指标评估，结合共识与非共识标注数据。

Result: 校准良好的模型表现更优，预训练知识增强的模型对异常结构更具鲁棒性。

Conclusion: 多标注者标注、校准评估和不确定性感知是开发可靠医学图像分割模型的关键。

Abstract: Deep learning (DL) has become the dominant approach for medical image
segmentation, yet ensuring the reliability and clinical applicability of these
models requires addressing key challenges such as annotation variability,
calibration, and uncertainty estimation. This is why we created the Calibration
and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation
(CURVAS), which highlights the critical role of multiple annotators in
establishing a more comprehensive ground truth, emphasizing that segmentation
is inherently subjective and that leveraging inter-annotator variability is
essential for robust model evaluation. Seven teams participated in the
challenge, submitting a variety of DL models evaluated using metrics such as
Dice Similarity Coefficient (DSC), Expected Calibration Error (ECE), and
Continuous Ranked Probability Score (CRPS). By incorporating consensus and
dissensus ground truth, we assess how DL models handle uncertainty and whether
their confidence estimates align with true segmentation performance. Our
findings reinforce the importance of well-calibrated models, as better
calibration is strongly correlated with the quality of the results.
Furthermore, we demonstrate that segmentation models trained on diverse
datasets and enriched with pre-trained knowledge exhibit greater robustness,
particularly in cases deviating from standard anatomical structures. Notably,
the best-performing models achieved high DSC and well-calibrated uncertainty
estimates. This work underscores the need for multi-annotator ground truth,
thorough calibration assessments, and uncertainty-aware evaluations to develop
trustworthy and clinically reliable DL-based medical image segmentation models.

</details>

### [130] [SPAST: Arbitrary Style Transfer with Style Priors via Pre-trained Large-scale Model](https://arxiv.org/abs/2505.08695)
*Zhanjie Zhang,Quanwei Zhang,Junsheng Luan,Mengyuan Yang,Yun Wang,Lei Zhao*

Main category: cs.CV

TLDR: 提出了一种名为SPAST的新框架，用于生成高质量风格化图像并减少推理时间。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么生成低质量图像，要么推理时间长且难以保留内容结构。

Method: 设计了局部-全局窗口大小风格化模块（LGWSSM）和风格先验损失。

Result: 实验证明SPAST能生成高质量图像且推理时间短。

Conclusion: SPAST在风格迁移任务中表现优于现有方法。

Abstract: Given an arbitrary content and style image, arbitrary style transfer aims to
render a new stylized
  image which preserves the content image's structure and possesses the style
image's style. Existing
  arbitrary style transfer methods are based on either small models or
pre-trained large-scale models.
  The small model-based methods fail to generate high-quality stylized images,
bringing artifacts and
  disharmonious patterns. The pre-trained large-scale model-based methods can
generate high-quality
  stylized images but struggle to preserve the content structure and cost long
inference time. To this
  end, we propose a new framework, called SPAST, to generate high-quality
stylized images with
  less inference time. Specifically, we design a novel Local-global Window Size
Stylization Module
  (LGWSSM)tofuse style features into content features. Besides, we introduce a
novel style prior loss,
  which can dig out the style priors from a pre-trained large-scale model into
the SPAST and motivate
  the SPAST to generate high-quality stylized images with short inference
time.We conduct abundant
  experiments to verify that our proposed method can generate high-quality
stylized images and less
  inference time compared with the SOTA arbitrary style transfer methods.

</details>

### [131] [Controllable Image Colorization with Instance-aware Texts and Masks](https://arxiv.org/abs/2505.08705)
*Yanru An,Ling Gui,Qiang Hu,Chunlei Cai,Tianxiao Ye,Xiaoyun Zhang,Yanfeng Wang*

Main category: cs.CV

TLDR: 提出了一种基于扩散模型的实例感知图像着色方法MT-Color，通过像素级掩码注意力机制和实例掩码文本引导模块解决了颜色溢出和绑定错误问题，并构建了专用数据集GPT-color。


<details>
  <summary>Details</summary>
Motivation: 当前主流图像着色模型存在颜色溢出和绑定错误问题，且无法实现实例级着色。

Method: 设计了像素级掩码注意力机制和实例掩码文本引导模块，采用多实例采样策略，并构建了数据集GPT-color。

Result: 定性和定量实验表明，模型和数据集优于先前方法。

Conclusion: MT-Color实现了精确的实例感知着色，解决了现有问题。

Abstract: Recently, the application of deep learning in image colorization has received
widespread attention. The maturation of diffusion models has further advanced
the development of image colorization models. However, current mainstream image
colorization models still face issues such as color bleeding and color binding
errors, and cannot colorize images at the instance level. In this paper, we
propose a diffusion-based colorization method MT-Color to achieve precise
instance-aware colorization with use-provided guidance. To tackle color
bleeding issue, we design a pixel-level mask attention mechanism that
integrates latent features and conditional gray image features through
cross-attention. We use segmentation masks to construct cross-attention masks,
preventing pixel information from exchanging between different instances. We
also introduce an instance mask and text guidance module that extracts instance
masks and text representations of each instance, which are then fused with
latent features through self-attention, utilizing instance masks to form
self-attention masks to prevent instance texts from guiding the colorization of
other areas, thus mitigating color binding errors. Furthermore, we apply a
multi-instance sampling strategy, which involves sampling each instance region
separately and then fusing the results. Additionally, we have created a
specialized dataset for instance-level colorization tasks, GPT-color, by
leveraging large visual language models on existing image datasets. Qualitative
and quantitative experiments show that our model and dataset outperform
previous methods and datasets.

</details>

### [132] [TiMo: Spatiotemporal Foundation Model for Satellite Image Time Series](https://arxiv.org/abs/2505.08723)
*Xiaolei Qin,Di Wang,Jing Zhang,Fengxiang Wang,Xin Su,Bo Du,Liangpei Zhang*

Main category: cs.CV

TLDR: TiMo是一种新型的分层视觉Transformer基础模型，专为卫星图像时间序列（SITS）分析设计，通过动态捕捉多尺度时空关系，显著提升了任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有时空基础模型依赖普通视觉Transformer，未能显式捕捉多尺度时空关系，限制了其在下游任务中的效果。

Method: 提出TiMo模型，引入时空陀螺注意力机制，动态捕捉多尺度时空模式，并利用MillionST数据集进行预训练。

Result: 在多项时空任务中，TiMo表现优于现有方法，包括森林砍伐监测、土地覆盖分割等。

Conclusion: TiMo通过显式建模多尺度时空关系，显著提升了SITS分析的性能，为相关应用提供了有效工具。

Abstract: Satellite image time series (SITS) provide continuous observations of the
Earth's surface, making them essential for applications such as environmental
management and disaster assessment. However, existing spatiotemporal foundation
models rely on plain vision transformers, which encode entire temporal
sequences without explicitly capturing multiscale spatiotemporal relationships
between land objects. This limitation hinders their effectiveness in downstream
tasks. To overcome this challenge, we propose TiMo, a novel hierarchical vision
transformer foundation model tailored for SITS analysis. At its core, we
introduce a spatiotemporal gyroscope attention mechanism that dynamically
captures evolving multiscale patterns across both time and space. For
pre-training, we curate MillionST, a large-scale dataset of one million images
from 100,000 geographic locations, each captured across 10 temporal phases over
five years, encompassing diverse geospatial changes and seasonal variations.
Leveraging this dataset, we adapt masked image modeling to pre-train TiMo,
enabling it to effectively learn and encode generalizable spatiotemporal
representations.Extensive experiments across multiple spatiotemporal
tasks-including deforestation monitoring, land cover segmentation, crop type
classification, and flood detection-demonstrate TiMo's superiority over
state-of-the-art methods. Code, model, and dataset will be released at
https://github.com/MiliLab/TiMo.

</details>

### [133] [Extending Large Vision-Language Model for Diverse Interactive Tasks in Autonomous Driving](https://arxiv.org/abs/2505.08725)
*Zongchuang Zhao,Haoyu Fu,Dingkang Liang,Xin Zhou,Dingyuan Zhang,Hongwei Xie,Bing Wang,Xiang Bai*

Main category: cs.CV

TLDR: 论文提出NuInteract数据集和DriveMonkey框架，解决LVLMs在3D场景理解中的不足，显著提升3D视觉定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有LVLMs在自动驾驶场景中缺乏对多视角和3D对象的全面理解，且2D与3D映射关系不足。

Method: 引入NuInteract数据集（1.5M多视角图像语言对）和DriveMonkey框架，结合空间处理器提升3D感知。

Result: DriveMonkey在3D视觉定位任务中表现优于通用LVLMs，提升9.86%。

Conclusion: NuInteract和DriveMonkey为LVLMs在自动驾驶中的3D场景理解提供了有效解决方案。

Abstract: The Large Visual-Language Models (LVLMs) have significantly advanced image
understanding. Their comprehension and reasoning capabilities enable promising
applications in autonomous driving scenarios. However, existing research
typically focuses on front-view perspectives and partial objects within scenes,
struggling to achieve comprehensive scene understanding. Meanwhile, existing
LVLMs suffer from the lack of mapping relationship between 2D and 3D and
insufficient integration of 3D object localization and instruction
understanding. To tackle these limitations, we first introduce NuInteract, a
large-scale dataset with over 1.5M multi-view image language pairs spanning
dense scene captions and diverse interactive tasks. Furthermore, we propose
DriveMonkey, a simple yet effective framework that seamlessly integrates LVLMs
with a spatial processor using a series of learnable queries. The spatial
processor, designed as a plug-and-play component, can be initialized with
pre-trained 3D detectors to improve 3D perception. Our experiments show that
DriveMonkey outperforms general LVLMs, especially achieving a 9.86% notable
improvement on the 3D visual grounding task. The dataset and code will be
released at https://github.com/zc-zhao/DriveMonkey.

</details>

### [134] [Advancing Food Nutrition Estimation via Visual-Ingredient Feature Fusion](https://arxiv.org/abs/2505.08747)
*Huiyan Qi,Bin Zhu,Chong-Wah Ngo,Jingjing Chen,Ee-Peng Lim*

Main category: cs.CV

TLDR: 论文介绍了FastFood数据集和VIF²方法，通过融合视觉和食材特征提升营养估计准确性。


<details>
  <summary>Details</summary>
Motivation: 营养估计对健康饮食至关重要，但缺乏带营养标注的数据集限制了进展。

Method: 提出VIF²方法，结合视觉和食材特征，并通过同义词替换和重采样增强食材鲁棒性。

Result: 在FastFood和Nutrition5k数据集上验证了方法的有效性，支持不同骨干网络。

Conclusion: 食材信息对营养估计至关重要，VIF²方法显著提升了准确性。

Abstract: Nutrition estimation is an important component of promoting healthy eating
and mitigating diet-related health risks. Despite advances in tasks such as
food classification and ingredient recognition, progress in nutrition
estimation is limited due to the lack of datasets with nutritional annotations.
To address this issue, we introduce FastFood, a dataset with 84,446 images
across 908 fast food categories, featuring ingredient and nutritional
annotations. In addition, we propose a new model-agnostic Visual-Ingredient
Feature Fusion (VIF$^2$) method to enhance nutrition estimation by integrating
visual and ingredient features. Ingredient robustness is improved through
synonym replacement and resampling strategies during training. The
ingredient-aware visual feature fusion module combines ingredient features and
visual representation to achieve accurate nutritional prediction. During
testing, ingredient predictions are refined using large multimodal models by
data augmentation and majority voting. Our experiments on both FastFood and
Nutrition5k datasets validate the effectiveness of our proposed method built in
different backbones (e.g., Resnet, InceptionV3 and ViT), which demonstrates the
importance of ingredient information in nutrition estimation.
https://huiyanqi.github.io/fastfood-nutrition-estimation/.

</details>

### [135] [Towards Autonomous UAV Visual Object Search in City Space: Benchmark and Agentic Methodology](https://arxiv.org/abs/2505.08765)
*Yatai Ji,Zhengqiu Zhu,Yong Zhao,Beidan Liu,Chen Gao,Yihao Zhao,Sihang Qiu,Yue Hu,Quanjun Yin,Yong Li*

Main category: cs.CV

TLDR: 论文提出CityAVOS数据集和PRPSearcher方法，用于无人机在复杂城市环境中自主搜索目标物体，通过多模态大语言模型模拟人类认知，显著提升搜索效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂城市环境中表现不佳，需解决语义冗余、相似物体区分和探索-利用困境等问题。

Method: 提出PRPSearcher方法，构建三种专用地图（动态语义地图、3D认知地图、3D不确定性地图），结合去噪机制和IPT提示机制。

Result: 在CityAVOS数据集上，PRPSearcher在成功率和搜索效率上显著优于基线方法（平均提升37.69% SR和28.96% SPL）。

Conclusion: PRPSearcher为自主目标搜索奠定基础，但与人类表现仍有差距，需进一步改进语义推理和空间探索能力。

Abstract: Aerial Visual Object Search (AVOS) tasks in urban environments require
Unmanned Aerial Vehicles (UAVs) to autonomously search for and identify target
objects using visual and textual cues without external guidance. Existing
approaches struggle in complex urban environments due to redundant semantic
processing, similar object distinction, and the exploration-exploitation
dilemma. To bridge this gap and support the AVOS task, we introduce CityAVOS,
the first benchmark dataset for autonomous search of common urban objects. This
dataset comprises 2,420 tasks across six object categories with varying
difficulty levels, enabling comprehensive evaluation of UAV agents' search
capabilities. To solve the AVOS tasks, we also propose PRPSearcher
(Perception-Reasoning-Planning Searcher), a novel agentic method powered by
multi-modal large language models (MLLMs) that mimics human three-tier
cognition. Specifically, PRPSearcher constructs three specialized maps: an
object-centric dynamic semantic map enhancing spatial perception, a 3D
cognitive map based on semantic attraction values for target reasoning, and a
3D uncertainty map for balanced exploration-exploitation search. Also, our
approach incorporates a denoising mechanism to mitigate interference from
similar objects and utilizes an Inspiration Promote Thought (IPT) prompting
mechanism for adaptive action planning. Experimental results on CityAVOS
demonstrate that PRPSearcher surpasses existing baselines in both success rate
and search efficiency (on average: +37.69% SR, +28.96% SPL, -30.69% MSS, and
-46.40% NE). While promising, the performance gap compared to humans highlights
the need for better semantic reasoning and spatial exploration capabilities in
AVOS tasks. This work establishes a foundation for future advances in embodied
target search. Dataset and source code are available at
https://anonymous.4open.science/r/CityAVOS-3DF8.

</details>

<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [136] [Monocular Online Reconstruction with Enhanced Detail Preservation](https://arxiv.org/abs/2505.07887)
*Songyin Wu,Zhaoyang Lv,Yufeng Zhu,Duncan Frost,Zhengqin Li,Ling-Qi Yan,Carl Ren,Richard Newcombe,Zhao Dong*

Main category: cs.GR

TLDR: 提出了一种基于3D高斯的在线密集映射框架，用于从单目图像流中重建逼真细节。


<details>
  <summary>Details</summary>
Motivation: 解决单目在线重建中的两个关键挑战：无需依赖深度图的高斯分布，以及确保重建地图的局部和全局一致性。

Method: 引入分层高斯管理模块和全局一致性优化模块，并提出多级占用哈希体素（MOHV）结构。

Result: 与现有RGB-only和RGB-D方法相比，实现了更高的重建质量和计算效率。

Conclusion: 该框架具有通用性和可扩展性，可无缝集成到多种跟踪系统中。

Abstract: We propose an online 3D Gaussian-based dense mapping framework for
photorealistic details reconstruction from a monocular image stream. Our
approach addresses two key challenges in monocular online reconstruction:
distributing Gaussians without relying on depth maps and ensuring both local
and global consistency in the reconstructed maps. To achieve this, we introduce
two key modules: the Hierarchical Gaussian Management Module for effective
Gaussian distribution and the Global Consistency Optimization Module for
maintaining alignment and coherence at all scales. In addition, we present the
Multi-level Occupancy Hash Voxels (MOHV), a structure that regularizes
Gaussians for capturing details across multiple levels of granularity. MOHV
ensures accurate reconstruction of both fine and coarse geometries and
textures, preserving intricate details while maintaining overall structural
integrity. Compared to state-of-the-art RGB-only and even RGB-D methods, our
framework achieves superior reconstruction quality with high computational
efficiency. Moreover, it integrates seamlessly with various tracking systems,
ensuring generality and scalability.

</details>

### [137] [ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image](https://arxiv.org/abs/2505.08239)
*Yizhi Wang,Mingrui Zhao,Ali Mahdavi-Amiri,Hao Zhang*

Main category: cs.GR

TLDR: 提出自适应视角规划方法，通过动态相机轨迹优化多视角合成，提升单视角3D重建的遮挡揭示和3D一致性。


<details>
  <summary>Details</summary>
Motivation: 解决传统多视角合成中无序视角生成导致的遮挡问题和3D不一致性。

Method: 计算自适应相机轨迹（ACT），最大化遮挡区域可见性，结合视频扩散模型生成新视角，输入多视角3D重建模型。

Result: 在GSO数据集上显著提升3D重建效果，定量和定性均优于现有方法。

Conclusion: 自适应视角规划高效且无需运行时优化，显著提升遮挡揭示和3D一致性。

Abstract: We introduce adaptive view planning to multi-view synthesis, aiming to
improve both occlusion revelation and 3D consistency for single-view 3D
reconstruction. Instead of generating an unordered set of views independently
or simultaneously, we generate a sequence of views, leveraging temporal
consistency to enhance 3D coherence. Most importantly, our view sequence is not
determined by a pre-determined camera setup. Instead, we compute an adaptive
camera trajectory (ACT), specifically, an orbit of camera views, which
maximizes the visibility of occluded regions of the 3D object to be
reconstructed. Once the best orbit is found, we feed it to a video diffusion
model to generate novel views around the orbit, which in turn, are passed to a
multi-view 3D reconstruction model to obtain the final reconstruction. Our
multi-view synthesis pipeline is quite efficient since it involves no run-time
training/optimization, only forward inferences by applying the pre-trained
models for occlusion analysis and multi-view synthesis. Our method predicts
camera trajectories that reveal occlusions effectively and produce consistent
novel views, significantly improving 3D reconstruction over SOTA on the unseen
GSO dataset, both quantitatively and qualitatively.

</details>

### [138] [M3G: Multi-Granular Gesture Generator for Audio-Driven Full-Body Human Motion Synthesis](https://arxiv.org/abs/2505.08293)
*Zhizhuo Yin,Yuk Hang Tsui,Pan Hui*

Main category: cs.GR

TLDR: 提出了一种名为M3G的新框架，用于从音频生成全身手势，解决了现有方法因固定粒度无法建模不同手势模式的问题。


<details>
  <summary>Details</summary>
Motivation: 现有系统因固定粒度的手势标记无法适应不同手势模式的多样性，限制了自然和表达性手势的生成。

Method: 提出多粒度VQ-VAE（MGVQ-VAE）标记运动模式，并设计多粒度标记预测器从音频中提取信息，预测运动标记。

Result: 实验表明，M3G在生成自然和表达性全身手势方面优于现有方法。

Conclusion: M3G通过多粒度建模显著提升了音频驱动手势生成的质量。

Abstract: Generating full-body human gestures encompassing face, body, hands, and
global movements from audio is a valuable yet challenging task in virtual
avatar creation. Previous systems focused on tokenizing the human gestures
framewisely and predicting the tokens of each frame from the input audio.
However, one observation is that the number of frames required for a complete
expressive human gesture, defined as granularity, varies among different human
gesture patterns. Existing systems fail to model these gesture patterns due to
the fixed granularity of their gesture tokens. To solve this problem, we
propose a novel framework named Multi-Granular Gesture Generator (M3G) for
audio-driven holistic gesture generation. In M3G, we propose a novel
Multi-Granular VQ-VAE (MGVQ-VAE) to tokenize motion patterns and reconstruct
motion sequences from different temporal granularities. Subsequently, we
proposed a multi-granular token predictor that extracts multi-granular
information from audio and predicts the corresponding motion tokens. Then M3G
reconstructs the human gestures from the predicted tokens using the MGVQ-VAE.
Both objective and subjective experiments demonstrate that our proposed M3G
framework outperforms the state-of-the-art methods in terms of generating
natural and expressive full-body human gestures.

</details>

### [139] [Claycode: Stylable and Deformable 2D Scannable Codes](https://arxiv.org/abs/2505.08666)
*Marco Maida,Alberto Crescini,Marco Perronet,Elena Camuffo*

Main category: cs.GR

TLDR: Claycode是一种新型2D可扫描码，支持高度风格化和变形，优于传统二维码。


<details>
  <summary>Details</summary>
Motivation: 传统矩阵式二维码（如QR码）在风格化和变形方面受限，Claycode旨在解决这一问题。

Method: 通过树结构编码信息，将比特映射到拓扑树中，并以目标多边形边界内的嵌套彩色区域呈现。

Result: Claycode在高度变形场景下表现优异，功能不受影响。

Conclusion: Claycode为2D可扫描码提供了更高的灵活性和适应性。

Abstract: This paper introduces Claycode, a novel 2D scannable code designed for
extensive stylization and deformation. Unlike traditional matrix-based codes
(e.g., QR codes), Claycodes encode their message in a tree structure. During
the encoding process, bits are mapped into a topology tree, which is then
depicted as a nesting of color regions drawn within the boundaries of a target
polygon shape. When decoding, Claycodes are extracted and interpreted in
real-time from a camera stream. We detail the end-to-end pipeline and show that
Claycodes allow for extensive stylization without compromising their
functionality. We then empirically demonstrate Claycode's high tolerance to
heavy deformations, outperforming traditional 2D scannable codes in scenarios
where they typically fail.

</details>

### [140] [CAD-Coder:Text-Guided CAD Files Code Generation](https://arxiv.org/abs/2505.08686)
*Changqi He,Shuhan Zhang,Liguo Zhang,Jiajun Miao*

Main category: cs.GR

TLDR: CAD-Coder是一个将自然语言指令转换为CAD脚本代码的框架，生成可编辑的CAD文件，解决了现有生成方法缺乏交互性和几何标注的问题。


<details>
  <summary>Details</summary>
Motivation: 传统CAD依赖专家手工绘制或修改现有库文件，无法快速个性化。生成式AI虽能实现高效个性化CAD生成，但现有方法缺乏交互性和几何标注，限制了实际应用。

Method: 提出CAD-Coder框架，将自然语言指令转换为CAD脚本代码，生成可编辑的.Dxf文件。构建了包含29,130个Dxf文件及其脚本代码的数据集，确保编辑性和几何标注。

Result: 在多种2D/3D CAD生成任务中，CAD-Coder表现优于现有方法，具备更强的交互能力，并能生成带几何标注的可编辑草图。

Conclusion: CAD-Coder为交互式生成CAD提供了有效解决方案，填补了现有生成方法在交互性和几何标注方面的不足。

Abstract: Computer-aided design (CAD) is a way to digitally create 2D drawings and 3D
models of real-world products. Traditional CAD typically relies on hand-drawing
by experts or modifications of existing library files, which doesn't allow for
rapid personalization. With the emergence of generative artificial
intelligence, convenient and efficient personalized CAD generation has become
possible. However, existing generative methods typically produce outputs that
lack interactive editability and geometric annotations, limiting their
practical applications in manufacturing. To enable interactive generative CAD,
we propose CAD-Coder, a framework that transforms natural language instructions
into CAD script codes, which can be executed in Python environments to generate
human-editable CAD files (.Dxf). To facilitate the generation of editable CAD
sketches with annotation information, we construct a comprehensive dataset
comprising 29,130 Dxf files with their corresponding script codes, where each
sketch preserves both editability and geometric annotations. We evaluate
CAD-Coder on various 2D/3D CAD generation tasks against existing methods,
demonstrating superior interactive capabilities while uniquely providing
editable sketches with geometric annotations.

</details>

<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [141] [Not that Groove: Zero-Shot Symbolic Music Editing](https://arxiv.org/abs/2505.08203)
*Li Zhang*

Main category: cs.SD

TLDR: 论文提出了一种基于零样本提示的LLM方法，用于符号音乐编辑，解决了缺乏标注数据的问题，并通过设计创新的格式和提供评估数据集来验证效果。


<details>
  <summary>Details</summary>
Motivation: AI音乐生成主要集中在音频领域，但其在音乐制作行业中的应用受限。为了在仅依赖文本指令的情况下实现最大灵活性，研究者首次尝试符号音乐编辑。

Method: 利用零样本提示的LLM方法编辑鼓点节奏，设计了一种创新的格式以连接LLM和音乐，并提供了与音乐家判断高度一致的评估数据集。

Result: 证明了零样本提示的LLM可以有效编辑鼓点节奏，且评估数据集验证了方法的有效性。

Conclusion: 该方法为符号音乐编辑提供了新的解决方案，展示了LLM在音乐生成领域的潜力。

Abstract: Most work in AI music generation focused on audio, which has seen limited use
in the music production industry due to its rigidity. To maximize flexibility
while assuming only textual instructions from producers, we are among the first
to tackle symbolic music editing. We circumvent the known challenge of lack of
labeled data by proving that LLMs with zero-shot prompting can effectively edit
drum grooves. The recipe of success is a creatively designed format that
interfaces LLMs and music, while we facilitate evaluation by providing an
evaluation dataset with annotated unit tests that highly aligns with musicians'
judgment.

</details>

<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [142] [Improving Unsupervised Task-driven Models of Ventral Visual Stream via Relative Position Predictivity](https://arxiv.org/abs/2505.08316)
*Dazhong Rong,Hao Dong,Xing Gao,Jiyu Wei,Di Hong,Yaoyao Hao,Qinming He,Yueming Wang*

Main category: cs.CE

TLDR: 论文提出了一种新的无监督任务驱动方法，结合相对位置预测和对比学习，以更符合生物现实的方式建模腹侧视觉流（VVS）。实验表明该方法在物体识别和RP预测中表现优异，并提高了模型与大脑的相似性。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅通过对比学习建模VVS，忽略了其可能参与的其他功能（如相对位置预测）。本文旨在探索VVS在位置感知中的作用。

Method: 提出结合相对位置（RP）预测与对比学习的无监督任务驱动方法，以更全面地建模VVS。

Result: 实验显示，新方法显著提升了物体识别性能，同时增强了RP预测能力，并提高了模型与大脑的相似性。

Conclusion: 研究从计算角度证实了VVS在位置感知（尤其是RP预测）中的作用，为理解其多功能性提供了新证据。

Abstract: Based on the concept that ventral visual stream (VVS) mainly functions for
object recognition, current unsupervised task-driven methods model VVS by
contrastive learning, and have achieved good brain similarity. However, we
believe functions of VVS extend beyond just object recognition. In this paper,
we introduce an additional function involving VVS, named relative position (RP)
prediction. We first theoretically explain contrastive learning may be unable
to yield the model capability of RP prediction. Motivated by this, we
subsequently integrate RP learning with contrastive learning, and propose a new
unsupervised task-driven method to model VVS, which is more inline with
biological reality. We conduct extensive experiments, demonstrating that: (i)
our method significantly improves downstream performance of object recognition
while enhancing RP predictivity; (ii) RP predictivity generally improves the
model brain similarity. Our results provide strong evidence for the involvement
of VVS in location perception (especially RP prediction) from a computational
perspective.

</details>

<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [143] [OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval](https://arxiv.org/abs/2505.07879)
*Wei Yang,Jingjing Fu,Rui Wang,Jinyu Wang,Lei Song,Jiang Bian*

Main category: cs.IR

TLDR: 本文提出了一种多模态检索增强生成系统，通过粗到细的多步检索方法提升知识库视觉问答（KB-VQA）的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言检索增强生成方法未能充分利用查询和知识库中多模态和多粒度信息的交互潜力。

Method: 系统采用粗到细的多步检索策略，包括初始粗粒度跨模态检索、多模态融合重排序和细粒度文本重排序。

Result: 在InfoSeek和Encyclopedic-VQA基准测试中，该方法实现了最先进的检索性能和高度竞争力的回答结果。

Conclusion: 该方法通过协调多粒度和多模态信息，显著提升了KB-VQA系统的效果。

Abstract: Vision-language retrieval-augmented generation (RAG) has become an effective
approach for tackling Knowledge-Based Visual Question Answering (KB-VQA), which
requires external knowledge beyond the visual content presented in images. The
effectiveness of Vision-language RAG systems hinges on multimodal retrieval,
which is inherently challenging due to the diverse modalities and knowledge
granularities in both queries and knowledge bases. Existing methods have not
fully tapped into the potential interplay between these elements. We propose a
multimodal RAG system featuring a coarse-to-fine, multi-step retrieval that
harmonizes multiple granularities and modalities to enhance efficacy. Our
system begins with a broad initial search aligning knowledge granularity for
cross-modal retrieval, followed by a multimodal fusion reranking to capture the
nuanced multimodal information for top entity selection. A text reranker then
filters out the most relevant fine-grained section for augmented generation.
Extensive experiments on the InfoSeek and Encyclopedic-VQA benchmarks show our
method achieves state-of-the-art retrieval performance and highly competitive
answering results, underscoring its effectiveness in advancing KB-VQA systems.

</details>

<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [144] [UniSkill: Imitating Human Videos via Cross-Embodiment Skill Representations](https://arxiv.org/abs/2505.08787)
*Hanjung Kim,Jaehyun Kang,Hyolim Kang,Meedeum Cho,Seon Joo Kim,Youngwoon Lee*

Main category: cs.RO

TLDR: UniSkill框架通过学习跨具身视频数据的无标签技能表示，实现从人类视频到机器人策略的有效迁移。


<details>
  <summary>Details</summary>
Motivation: 模仿是人类学习新任务的基本机制，但机器人由于具身差异难以直接应用。现有方法依赖对齐数据，但大规模收集困难。

Method: 提出UniSkill框架，从大规模跨具身视频数据中学习无标签技能表示，实现人类视频技能到机器人策略的迁移。

Result: 实验表明，UniSkill能成功指导机器人选择合适动作，即使面对未见过的视频提示。

Conclusion: UniSkill为解决跨具身技能迁移问题提供了一种有效方法。

Abstract: Mimicry is a fundamental learning mechanism in humans, enabling individuals
to learn new tasks by observing and imitating experts. However, applying this
ability to robots presents significant challenges due to the inherent
differences between human and robot embodiments in both their visual appearance
and physical capabilities. While previous methods bridge this gap using
cross-embodiment datasets with shared scenes and tasks, collecting such aligned
data between humans and robots at scale is not trivial. In this paper, we
propose UniSkill, a novel framework that learns embodiment-agnostic skill
representations from large-scale cross-embodiment video data without any
labels, enabling skills extracted from human video prompts to effectively
transfer to robot policies trained only on robot data. Our experiments in both
simulation and real-world environments show that our cross-embodiment skills
successfully guide robots in selecting appropriate actions, even with unseen
video prompts. The project website can be found at:
https://kimhanjung.github.io/UniSkill.

</details>

<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [145] [Multimodal Assessment of Classroom Discourse Quality: A Text-Centered Attention-Based Multi-Task Learning Approach](https://arxiv.org/abs/2505.07902)
*Ruikun Hou,Babette Bühler,Tim Fütterer,Efe Bozkir,Peter Gerjets,Ulrich Trautwein,Enkelejda Kasneci*

Main category: cs.CY

TLDR: 该研究提出了一种基于多模态融合的架构，用于评估课堂话语质量，结合文本、音频和视频数据，并通过多任务学习和序数分类方法提升效果。


<details>
  <summary>Details</summary>
Motivation: 传统课堂话语评估依赖人工编码，耗时且成本高，而现有AI研究多局限于单一句子层面，缺乏对整个课程段话语质量的评估。

Method: 采用注意力机制捕捉多模态交互，多任务学习预测三个话语组件的质量分数，并将任务建模为序数分类问题。

Result: 在GTI德国数据集上验证了模型有效性，文本模态起主导作用，结合音频特征后模型与人类评分一致性提高，总体Quadratic Weighted Kappa得分为0.384。

Conclusion: 该研究为自动化话语质量评估奠定了基础，支持通过多维反馈促进教师专业发展。

Abstract: Classroom discourse is an essential vehicle through which teaching and
learning take place. Assessing different characteristics of discursive
practices and linking them to student learning achievement enhances the
understanding of teaching quality. Traditional assessments rely on manual
coding of classroom observation protocols, which is time-consuming and costly.
Despite many studies utilizing AI techniques to analyze classroom discourse at
the utterance level, investigations into the evaluation of discursive practices
throughout an entire lesson segment remain limited. To address this gap, our
study proposes a novel text-centered multimodal fusion architecture to assess
the quality of three discourse components grounded in the Global Teaching
InSights (GTI) observation protocol: Nature of Discourse, Questioning, and
Explanations. First, we employ attention mechanisms to capture inter- and
intra-modal interactions from transcript, audio, and video streams. Second, a
multi-task learning approach is adopted to jointly predict the quality scores
of the three components. Third, we formulate the task as an ordinal
classification problem to account for rating level order. The effectiveness of
these designed elements is demonstrated through an ablation study on the GTI
Germany dataset containing 92 videotaped math lessons. Our results highlight
the dominant role of text modality in approaching this task. Integrating
acoustic features enhances the model's consistency with human ratings,
achieving an overall Quadratic Weighted Kappa score of 0.384, comparable to
human inter-rater reliability (0.326). Our study lays the groundwork for the
future development of automated discourse quality assessment to support teacher
professional development through timely feedback on multidimensional discourse
practices.

</details>

<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [146] [Image-Guided Microstructure Optimization using Diffusion Models: Validated with Li-Mn-rich Cathode Precursors](https://arxiv.org/abs/2505.07906)
*Geunho Choi,Changhwan Lee,Jieun Kim,Insoo Ye,Keeyoung Jung,Inchul Park*

Main category: cond-mat.mtrl-sci

TLDR: 论文提出了一种基于AI的图像驱动闭环框架，用于锂离子电池正极前驱体的微结构预测与优化设计。


<details>
  <summary>Details</summary>
Motivation: 微结构对材料性能至关重要，但因其难以量化、预测和优化，很少被作为显式设计变量。本研究旨在解决这一问题。

Method: 框架结合了扩散图像生成模型、定量图像分析流程和粒子群优化算法，通过SEM图像提取形态特征并预测合成条件。

Result: 平台能准确预测特定合成条件下的SEM形态，并通过实验验证了预测与合成结构的高度一致性。

Conclusion: 该框架为数据驱动的材料设计提供了实用策略，支持正向预测和逆向设计，推动图像引导的微结构工程自动化。

Abstract: Microstructure often dictates materials performance, yet it is rarely treated
as an explicit design variable because microstructure is hard to quantify,
predict, and optimize. Here, we introduce an image centric, closed-loop
framework that makes microstructural morphology into a controllable objective
and demonstrate its use case with Li- and Mn-rich layered oxide cathode
precursors. This work presents an integrated, AI driven framework for the
predictive design and optimization of lithium-ion battery cathode precursor
synthesis. This framework integrates a diffusion-based image generation model,
a quantitative image analysis pipeline, and a particle swarm optimization (PSO)
algorithm. By extracting key morphological descriptors such as texture,
sphericity, and median particle size (D50) from SEM images, the platform
accurately predicts SEM like morphologies resulting from specific
coprecipitation conditions, including reaction time-, solution concentration-,
and pH-dependent structural changes. Optimization then pinpoints synthesis
parameters that yield user defined target morphologies, as experimentally
validated by the close agreement between predicted and synthesized structures.
This framework offers a practical strategy for data driven materials design,
enabling both forward prediction and inverse design of synthesis conditions and
paving the way toward autonomous, image guided microstructure engineering.

</details>

<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [147] [CellVerse: Do Large Language Models Really Understand Cell Biology?](https://arxiv.org/abs/2505.07865)
*Fan Zhang,Tianyu Liu,Zhihong Zhu,Hao Wu,Haixin Wang,Donghao Zhou,Yefeng Zheng,Kun Wang,Xian Wu,Pheng-Ann Heng*

Main category: q-bio.QM

TLDR: CellVerse是一个语言驱动的单细胞分析基准，评估了14种LLM在单细胞多组学数据任务中的表现，发现现有模型在细胞生物学应用中仍有显著挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究未全面评估LLM在语言驱动的单细胞分析任务中的表现，CellVerse旨在填补这一空白。

Method: 引入CellVerse基准，整合四种单细胞多组学数据，涵盖细胞类型注释、药物反应预测和扰动分析三个层次任务，并系统评估14种LLM的性能。

Result: 现有专业模型表现不佳，通用模型（如Qwen、Llama等）初步展现理解能力，但整体性能仍有较大提升空间，尤其在药物反应预测任务中表现不佳。

Conclusion: CellVerse揭示了LLM在细胞生物学应用中的挑战，为通过自然语言推进单细胞分析奠定了基础。

Abstract: Recent studies have demonstrated the feasibility of modeling single-cell data
as natural languages and the potential of leveraging powerful large language
models (LLMs) for understanding cell biology. However, a comprehensive
evaluation of LLMs' performance on language-driven single-cell analysis tasks
still remains unexplored. Motivated by this challenge, we introduce CellVerse,
a unified language-centric question-answering benchmark that integrates four
types of single-cell multi-omics data and encompasses three hierarchical levels
of single-cell analysis tasks: cell type annotation (cell-level), drug response
prediction (drug-level), and perturbation analysis (gene-level). Going beyond
this, we systematically evaluate the performance across 14 open-source and
closed-source LLMs ranging from 160M to 671B on CellVerse. Remarkably, the
experimental results reveal: (1) Existing specialist models (C2S-Pythia) fail
to make reasonable decisions across all sub-tasks within CellVerse, while
generalist models such as Qwen, Llama, GPT, and DeepSeek family models exhibit
preliminary understanding capabilities within the realm of cell biology. (2)
The performance of current LLMs falls short of expectations and has substantial
room for improvement. Notably, in the widely studied drug response prediction
task, none of the evaluated LLMs demonstrate significant performance
improvement over random guessing. CellVerse offers the first large-scale
empirical demonstration that significant challenges still remain in applying
LLMs to cell biology. By introducing CellVerse, we lay the foundation for
advancing cell biology through natural languages and hope this paradigm could
facilitate next-generation single-cell analysis.

</details>

<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [148] [NAZM: Network Analysis of Zonal Metrics in Persian Poetic Tradition](https://arxiv.org/abs/2505.08052)
*Kourosh Shahnazari,Seyed Moein Ayyoubzadeh*

Main category: cs.SI

TLDR: 该研究通过构建多维相似性网络，模拟古典波斯诗人的影响力动态，结合语义、词汇、风格、主题和韵律特征，识别关键诗人、风格中心和桥梁诗人，并通过社区检测算法揭示文学流派。


<details>
  <summary>Details</summary>
Motivation: 旨在通过计算模型揭示波斯诗人之间的相互影响，区分经典重要性与互文影响，突出结构上重要但知名度较低的诗人。

Method: 使用Ganjoor语料库的严格数据集，构建加权相似性矩阵和聚合图，计算多种中心性指标，并应用Louvain社区检测算法。

Result: 发现波斯文学中诗人之间的结构关系，识别出与已知文学流派（如Sabk-e Hindi、Sabk-e Khorasani）对应的诗人集群。

Conclusion: 结合计算语言学与文学研究，提出了一个可解释且可扩展的诗歌传统模型，为数字人文研究提供了新视角。

Abstract: This study formalizes a computational model to simulate classical Persian
poets' dynamics of influence through constructing a multi-dimensional
similarity network. Using a rigorously curated dataset based on Ganjoor's
corpus, we draw upon semantic, lexical, stylistic, thematic, and metrical
features to demarcate each poet's corpus. Each is contained within weighted
similarity matrices, which are then appended to generate an aggregate graph
showing poet-to-poet influence. Further network investigation is carried out to
identify key poets, style hubs, and bridging poets by calculating degree,
closeness, betweenness, eigenvector, and Katz centrality measures. Further, for
typological insight, we use the Louvain community detection algorithm to
demarcate clusters of poets sharing both style and theme coherence, which
correspond closely to acknowledged schools of literature like Sabk-e Hindi,
Sabk-e Khorasani, and the Bazgasht-e Adabi phenomenon. Our findings provide a
new data-driven view of Persian literature distinguished between canonical
significance and interextual influence, thus highlighting relatively
lesser-known figures who hold great structural significance. Combining
computational linguistics with literary study, this paper produces an
interpretable and scalable model for poetic tradition, enabling retrospective
reflection as well as forward-looking research within digital humanities.

</details>

<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [149] [SpNeRF: Memory Efficient Sparse Volumetric Neural Rendering Accelerator for Edge Devices](https://arxiv.org/abs/2505.08191)
*Yipu Zhang,Jiawei Liang,Jian Peng,Jiang Xu,Wei Zhang*

Main category: cs.AR

TLDR: SpNeRF是一种软硬件协同设计方法，针对稀疏体素神经渲染优化内存和性能，显著减少内存占用并提升效率。


<details>
  <summary>Details</summary>
Motivation: 神经渲染在AR/VR中应用广泛，但其大体积素网格数据和不规则访问模式限制了边缘设备的实时处理能力。现有方法未充分解决大体积素网格导致的内存问题。

Method: 提出预处理和在线解码步骤，使用哈希映射减少内存占用，并通过位图掩码降低哈希冲突的PSNR损失。设计专用硬件架构支持稀疏体素处理。

Result: 实验显示，SpNeRF平均减少21.07倍内存占用，保持PSNR水平，并在速度和能效上显著优于现有方案。

Conclusion: SpNeRF通过软硬件协同设计有效解决了神经渲染中的内存和性能瓶颈，适用于边缘设备。

Abstract: Neural rendering has gained prominence for its high-quality output, which is
crucial for AR/VR applications. However, its large voxel grid data size and
irregular access patterns challenge real-time processing on edge devices. While
previous works have focused on improving data locality, they have not
adequately addressed the issue of large voxel grid sizes, which necessitate
frequent off-chip memory access and substantial on-chip memory. This paper
introduces SpNeRF, a software-hardware co-design solution tailored for sparse
volumetric neural rendering. We first identify memory-bound rendering
inefficiencies and analyze the inherent sparsity in the voxel grid data of
neural rendering. To enhance efficiency, we propose novel preprocessing and
online decoding steps, reducing the memory size for voxel grid. The
preprocessing step employs hash mapping to support irregular data access while
maintaining a minimal memory size. The online decoding step enables efficient
on-chip sparse voxel grid processing, incorporating bitmap masking to mitigate
PSNR loss caused by hash collisions. To further optimize performance, we design
a dedicated hardware architecture supporting our sparse voxel grid processing
technique. Experimental results demonstrate that SpNeRF achieves an average
21.07$\times$ reduction in memory size while maintaining comparable PSNR
levels. When benchmarked against Jetson XNX, Jetson ONX, RT-NeRF.Edge and
NeuRex.Edge, our design achieves speedups of 95.1$\times$, 63.5$\times$,
1.5$\times$ and 10.3$\times$, and improves energy efficiency by 625.6$\times$,
529.1$\times$, 4$\times$, and 4.4$\times$, respectively.

</details>

<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [150] [Evaluation of UAV-Based RGB and Multispectral Vegetation Indices for Precision Agriculture in Palm Tree Cultivation](https://arxiv.org/abs/2505.07840)
*Alavikunhu Panthakkan,S M Anzar,K. Sherin,Saeed Al Mansoori,Hussain Al-Ahmad*

Main category: eess.IV

TLDR: 该研究评估了无人机多光谱和RGB成像在棕榈树种植区的植被健康监测效果，发现RGB指数与多光谱指数性能相当，为大规模农业监测提供了低成本方案。


<details>
  <summary>Details</summary>
Motivation: 精准农业需要高效的植被监测技术以提高作物产量和可持续性。研究旨在验证RGB成像在多光谱监测中的替代潜力。

Method: 使用配备多光谱传感器的无人机，计算NDVI和SAVI指数，同时评估RGB指数（如VARI和MGRVI）的分类效果。

Result: RGB指数在植被分类和胁迫检测中表现与多光谱指数相似，验证了其成本效益优势。

Conclusion: RGB成像可作为精准农业的经济高效工具，推动数据驱动的作物管理广泛应用。

Abstract: Precision farming relies on accurate vegetation monitoring to enhance crop
productivity and promote sustainable agricultural practices. This study
presents a comprehensive evaluation of UAV-based imaging for vegetation health
assessment in a palm tree cultivation region in Dubai. By comparing
multispectral and RGB image data, we demonstrate that RGBbased vegetation
indices offer performance comparable to more expensive multispectral indices,
providing a cost-effective alternative for large-scale agricultural monitoring.
Using UAVs equipped with multispectral sensors, indices such as NDVI and SAVI
were computed to categorize vegetation into healthy, moderate, and stressed
conditions. Simultaneously, RGB-based indices like VARI and MGRVI delivered
similar results in vegetation classification and stress detection. Our findings
highlight the practical benefits of integrating RGB imagery into precision
farming, reducing operational costs while maintaining accuracy in plant health
monitoring. This research underscores the potential of UAVbased RGB imaging as
a powerful tool for precision agriculture, enabling broader adoption of
data-driven decision-making in crop management. By leveraging the strengths of
both multispectral and RGB imaging, this work advances the state of UAV
applications in agriculture, paving the way for more efficient and scalable
farming solutions.

</details>

### [151] [Pose Estimation for Intra-cardiac Echocardiography Catheter via AI-Based Anatomical Understanding](https://arxiv.org/abs/2505.07851)
*Jaeyoung Huh,Ankur Kapoor,Young-Ho Kim*

Main category: eess.IV

TLDR: 提出了一种基于Vision Transformer的解剖感知姿态估计系统，用于从ICE图像中确定导管位置和方向，无需外部跟踪传感器。


<details>
  <summary>Details</summary>
Motivation: 现有导航方法依赖电磁跟踪或手动调整，易受干扰且依赖操作者经验，需改进。

Method: 使用ViT模型处理ICE图像，通过16x16嵌入和Transformer网络预测位置和方向，优化采用MSE损失函数。

Result: 平均位置误差9.48 mm，方向误差(16.13°, 8.98°, 10.47°)，验证了模型准确性。

Conclusion: 该系统提高了手术效率，减少操作负担，支持无跟踪实时定位，可独立或补充现有系统。

Abstract: Intra-cardiac Echocardiography (ICE) plays a crucial role in
Electrophysiology (EP) and Structural Heart Disease (SHD) interventions by
providing high-resolution, real-time imaging of cardiac structures. However,
existing navigation methods rely on electromagnetic (EM) tracking, which is
susceptible to interference and position drift, or require manual adjustments
based on operator expertise. To overcome these limitations, we propose a novel
anatomy-aware pose estimation system that determines the ICE catheter position
and orientation solely from ICE images, eliminating the need for external
tracking sensors. Our approach leverages a Vision Transformer (ViT)-based deep
learning model, which captures spatial relationships between ICE images and
anatomical structures. The model is trained on a clinically acquired dataset of
851 subjects, including ICE images paired with position and orientation labels
normalized to the left atrium (LA) mesh. ICE images are patchified into 16x16
embeddings and processed through a transformer network, where a [CLS] token
independently predicts position and orientation via separate linear layers. The
model is optimized using a Mean Squared Error (MSE) loss function, balancing
positional and orientational accuracy. Experimental results demonstrate an
average positional error of 9.48 mm and orientation errors of (16.13 deg, 8.98
deg, 10.47 deg) across x, y, and z axes, confirming the model accuracy.
Qualitative assessments further validate alignment between predicted and target
views within 3D cardiac meshes. This AI-driven system enhances procedural
efficiency, reduces operator workload, and enables real-time ICE catheter
localization for tracking-free procedures. The proposed method can function
independently or complement existing mapping systems like CARTO, offering a
transformative approach to ICE-guided interventions.

</details>

### [152] [Computationally Efficient Diffusion Models in Medical Imaging: A Comprehensive Review](https://arxiv.org/abs/2505.07866)
*Abdullah,Tao Huang,Ickjai Lee,Euijoon Ahn*

Main category: eess.IV

TLDR: 该论文探讨了扩散模型在计算机视觉中的高效性和推理时间，重点分析了DDPM、LDM和WDM三种模型在自然和医学成像中的应用及其挑战。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成高质量合成图像方面表现出色，但高计算成本限制了其应用。研究旨在解决这一问题，并探索其在医学成像中的潜力。

Method: 论文分类分析了三种扩散模型（DDPM、LDM和WDM），讨论了它们在自然和医学成像中的计算效率和应用。

Result: 扩散模型在医学成像中具有快速、可靠和高质量生成图像的潜力，但仍存在计算复杂性和局限性。

Conclusion: 研究为扩散模型在医学成像中的应用提供了方向，并指出了未来研究的机会和挑战。

Abstract: The diffusion model has recently emerged as a potent approach in computer
vision, demonstrating remarkable performances in the field of generative
artificial intelligence. Capable of producing high-quality synthetic images,
diffusion models have been successfully applied across a range of applications.
However, a significant challenge remains with the high computational cost
associated with training and generating these models. This study focuses on the
efficiency and inference time of diffusion-based generative models,
highlighting their applications in both natural and medical imaging. We present
the most recent advances in diffusion models by categorizing them into three
key models: the Denoising Diffusion Probabilistic Model (DDPM), the Latent
Diffusion Model (LDM), and the Wavelet Diffusion Model (WDM). These models play
a crucial role in medical imaging, where producing fast, reliable, and
high-quality medical images is essential for accurate analysis of abnormalities
and disease diagnosis. We first investigate the general framework of DDPM, LDM,
and WDM and discuss the computational complexity gap filled by these models in
natural and medical imaging. We then discuss the current limitations of these
models as well as the opportunities and future research directions in medical
imaging.

</details>

### [153] [Skeleton-Guided Diffusion Model for Accurate Foot X-ray Synthesis in Hallux Valgus Diagnosis](https://arxiv.org/abs/2505.08247)
*Midi Wan,Pengfei Li,Yizhuo Liang,Di Wu,Yushan Pan,Guangzhen Zhu,Hao Wang*

Main category: eess.IV

TLDR: 论文提出了一种骨骼约束条件扩散模型（SCCDM）和足部评估方法KCC，用于提高医学图像合成的准确性和临床适用性。


<details>
  <summary>Details</summary>
Motivation: 针对现有X射线模型在图像保真度、骨骼一致性和物理约束方面的不足，特别是缺乏骨骼引导的扩散方法，研究旨在改善这一问题。

Method: SCCDM结合多尺度特征提取和注意力机制，并引入KCC方法利用骨骼标志点进行评估。

Result: 模型在SSIM和PSNR上分别提高了5.72%和18.34%，结合KCC后平均得分达0.85，显示强临床适用性。

Conclusion: SCCDM和KCC的组合显著提升了医学图像合成的质量，具有实际应用价值。

Abstract: Medical image synthesis plays a crucial role in providing anatomically
accurate images for diagnosis and treatment. Hallux valgus, which affects
approximately 19% of the global population, requires frequent weight-bearing
X-rays for assessment, placing additional strain on both patients and
healthcare providers. Existing X-ray models often struggle to balance image
fidelity, skeletal consistency, and physical constraints, particularly in
diffusion-based methods that lack skeletal guidance. We propose the
Skeletal-Constrained Conditional Diffusion Model (SCCDM) and introduce KCC, a
foot evaluation method utilizing skeletal landmarks. SCCDM incorporates
multi-scale feature extraction and attention mechanisms, improving the
Structural Similarity Index (SSIM) by 5.72% (0.794) and Peak Signal-to-Noise
Ratio (PSNR) by 18.34% (21.40 dB). When combined with KCC, the model achieves
an average score of 0.85, demonstrating strong clinical applicability. The code
is available at https://github.com/midisec/SCCDM.

</details>

### [154] [An integrated language-vision foundation model for conversational diagnostics and triaging in primary eye care](https://arxiv.org/abs/2505.08414)
*Zhi Da Soh,Yang Bai,Kai Yu,Yang Zhou,Xiaofeng Lei,Sahil Thakur,Zann Lee,Lee Ching Linette Phang,Qingsheng Peng,Can Can Xue,Rachel Shujuan Chong,Quan V. Hoang,Lavanya Raghavan,Yih Chung Tham,Charumathi Sabanayagam,Wei-Chi Wu,Ming-Chih Ho,Jiangnan He,Preeti Gupta,Ecosse Lamoureux,Seang Mei Saw,Vinay Nangia,Songhomitra Panda-Jonas,Jie Xu,Ya Xing Wang,Xinxing Xu,Jost B. Jonas,Tien Yin Wong,Rick Siow Mong Goh,Yong Liu,Ching-Yu Cheng*

Main category: eess.IV

TLDR: Meta-EyeFM是一个结合大型语言模型（LLM）和视觉基础模型（VFM）的多功能基础模型，用于眼部疾病评估，通过路由机制实现高精度任务分析。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型多为任务专用且缺乏用户友好接口，Meta-EyeFM旨在提供一种多功能、高精度的眼部疾病评估工具。

Method: 利用低秩适应（Low Rank Adaptation）微调视觉基础模型，结合路由机制实现任务特异性分析。

Result: 模型在路由任务中达到100%准确率，疾病检测准确率≥82.2%，严重程度区分≥89%，体征识别≥76%，优于Gemini-1.5-flash和ChatGPT-4o LMMs。

Conclusion: Meta-EyeFM在诊断性能和可用性上表现优异，可作为初级眼科护理的决策支持工具或在线LLM用于眼底评估。

Abstract: Current deep learning models are mostly task specific and lack a
user-friendly interface to operate. We present Meta-EyeFM, a multi-function
foundation model that integrates a large language model (LLM) with vision
foundation models (VFMs) for ocular disease assessment. Meta-EyeFM leverages a
routing mechanism to enable accurate task-specific analysis based on text
queries. Using Low Rank Adaptation, we fine-tuned our VFMs to detect ocular and
systemic diseases, differentiate ocular disease severity, and identify common
ocular signs. The model achieved 100% accuracy in routing fundus images to
appropriate VFMs, which achieved $\ge$ 82.2% accuracy in disease detection,
$\ge$ 89% in severity differentiation, $\ge$ 76% in sign identification.
Meta-EyeFM was 11% to 43% more accurate than Gemini-1.5-flash and ChatGPT-4o
LMMs in detecting various eye diseases and comparable to an ophthalmologist.
This system offers enhanced usability and diagnostic performance, making it a
valuable decision support tool for primary eye care or an online LLM for fundus
evaluation.

</details>

### [155] [GNCAF: A GNN-based Neighboring Context Aggregation Framework for Tertiary Lymphoid Structures Semantic Segmentation in WSI](https://arxiv.org/abs/2505.08430)
*Lei Su*

Main category: eess.IV

TLDR: 本文提出了一种基于图神经网络（GNN）的邻近上下文聚合框架（GNCAF），用于端到端地分割全切片图像（WSI）中的三级淋巴结构（TLS）区域和成熟阶段。该方法通过多跳邻近上下文聚合和自注意力机制，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖细胞代理任务并需要额外后处理步骤，无法充分利用邻近上下文信息。本文旨在直接分割TLS区域和成熟阶段，并解决WSI中广泛尺度和邻近上下文利用不足的问题。

Method: 提出GNCAF框架，通过多跳邻近上下文聚合和自注意力机制增强目标补丁的分割能力。该方法可与多种分割模型结合，提升上下文感知能力。

Result: 在两个TLS-SS数据集（TCGA-COAD和INHOUSE-PAAD）上，GNCAF在mF1和mIoU指标上分别最高提升22.08%和26.57%。此外，该方法在淋巴结转移分割任务中也表现出良好的扩展性。

Conclusion: GNCAF通过有效整合邻近上下文信息，显著提升了TLS语义分割性能，并展示了任务扩展潜力。

Abstract: Tertiary lymphoid structures (TLS) are organized clusters of immune cells,
whose maturity and area can be quantified in whole slide image (WSI) for
various prognostic tasks. Existing methods for assessing these characteristics
typically rely on cell proxy tasks and require additional post-processing
steps. In this work, We focus on a novel task-TLS Semantic Segmentation
(TLS-SS)-which segments both the regions and maturation stages of TLS in WSI in
an end-to-end manner. Due to the extensive scale of WSI and patch-based
segmentation strategies, TLS-SS necessitates integrating from neighboring
patches to guide target patch (target) segmentation. Previous techniques often
employ on multi-resolution approaches, constraining the capacity to leverage
the broader neighboring context while tend to preserve coarse-grained
information. To address this, we propose a GNN-based Neighboring Context
Aggregation Framework (GNCAF), which progressively aggregates multi-hop
neighboring context from the target and employs a self-attention mechanism to
guide the segmentation of the target. GNCAF can be integrated with various
segmentation models to enhance their ability to perceive contextual information
outside of the patch. We build two TLS-SS datasets, called TCGA-COAD and
INHOUSE-PAAD, and make the former (comprising 225 WSIs and 5041 TLSs) publicly
available. Experiments on these datasets demonstrate the superiority of GNCAF,
achieving a maximum of 22.08% and 26.57% improvement in mF1 and mIoU,
respectively. Additionally, we also validate the task scalability of GNCAF on
segmentation of lymph node metastases.

</details>

### [156] [A portable diagnosis model for Keratoconus using a smartphone](https://arxiv.org/abs/2505.08616)
*Yifan Li,Myeongjun Kim,Yanjing Jin,Peter Ho,Jo Woon Chong*

Main category: eess.IV

TLDR: 提出了一种基于智能手机的便携式圆锥角膜（KC）诊断框架，通过两阶段检测流程实现高精度分类和可视化。


<details>
  <summary>Details</summary>
Motivation: 解决传统Placido盘地形图依赖专业设备的局限性，提高圆锥角膜诊断的可及性。

Method: 使用智能手机屏幕显示Placido盘，通过两阶段检测流程（WSVM分类和彩色地图可视化）分析角膜反射。

Result: 在多种智能手机上实现最高92.93%的准确率，并通过统计验证显示显著区分不同KC阶段的能力。

Conclusion: 智能手机框架为圆锥角膜诊断提供了便携、高精度的解决方案，具有临床潜力。

Abstract: Keratoconus (KC) is a progressive corneal disorder characterized by localized
thinning and protrusion, leading to visual distortion. While Placido disc-based
topography remains a standard in clinical diagnostics, its dependence on
specialized equipment limits accessibility. In this paper, we propose a
portable, smartphone-based diagnostic framework that captures corneal
reflections of a Placido disc displayed on a phone screen and applies a
two-stage detection pipeline, then validate on 3D-printed emulated eyeball
models that simulate normal, moderate, and severe KC stages based on anterior
chamber depth (ACD). The first step of the two-stage detection pipeline is
classifying different stages of KC with features including height and width of
extracted reflections using weighted support vector machine (WSVM). It achieves
a maximum accuracy of 92.93%, and maintains over 90% accuracy across multiple
smartphone models, including the Galaxy Z Flip 3, iPhone 15 Pro, and iPhone 16
Pro. For the second step, we visualize the KC-affected protrusion regions on
the corneas with color maps based on inter-disc distance, that provides an
intuitive representation of disease severity and localization. Moreover, we
validate the ability of the extracted features to differentiate between KC
stages with ANOVA and Omega Squared, with significant p-values (e.g., $p <
10^{-6}$) and large effect sizes ($\\omega^2$ up to 0.8398) among classes.

</details>

### [157] [VIViT: Variable-Input Vision Transformer Framework for 3D MR Image Segmentation](https://arxiv.org/abs/2505.08693)
*Badhan Kumar Das,Ajay Singh,Gengyan Zhao,Han Liu,Thomas J. Re,Dorin Comaniciu,Eli Gibson,Andreas Maier*

Main category: eess.IV

TLDR: 提出了一种基于Transformer的框架VIViT，用于处理多对比度MR数据的自监督预训练和分割微调，解决了现有方法对固定输入模态的限制。


<details>
  <summary>Details</summary>
Motivation: 现实中的MR研究常因采集协议不同而包含不同对比度数据，现有深度学习方法通常需要固定输入模态，难以适应这种多样性。

Method: 设计了VIViT框架，支持自监督预训练和可变对比度的分割微调，最大化数据利用率并适应不同下游任务需求。

Result: 在脑梗死和脑肿瘤分割任务中，VIViT分别取得0.624和0.883的平均Dice分数，优于现有CNN和ViT模型。

Conclusion: VIViT框架在异构MR数据任务中表现出更好的适应性和性能，为实际应用提供了有效解决方案。

Abstract: Self-supervised pretrain techniques have been widely used to improve the
downstream tasks' performance. However, real-world magnetic resonance (MR)
studies usually consist of different sets of contrasts due to different
acquisition protocols, which poses challenges for the current deep learning
methods on large-scale pretrain and different downstream tasks with different
input requirements, since these methods typically require a fixed set of input
modalities or, contrasts. To address this challenge, we propose variable-input
ViT (VIViT), a transformer-based framework designed for self-supervised
pretraining and segmentation finetuning for variable contrasts in each study.
With this ability, our approach can maximize the data availability in pretrain,
and can transfer the learned knowledge from pretrain to downstream tasks
despite variations in input requirements. We validate our method on brain
infarct and brain tumor segmentation, where our method outperforms current CNN
and ViT-based models with a mean Dice score of 0.624 and 0.883 respectively.
These results highlight the efficacy of our design for better adaptability and
performance on tasks with real-world heterogeneous MR data.

</details>

<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [158] [Arrow-Guided VLM: Enhancing Flowchart Understanding via Arrow Direction Encoding](https://arxiv.org/abs/2505.07864)
*Takamitsu Omasa,Ryo Koshihara,Masumi Morishige*

Main category: cs.AI

TLDR: 提出了一种七阶段流程，通过箭头感知检测、OCR提取文本和结构化提示，显著提高了流程图识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在解释流程图的方向箭头和拓扑结构时表现不佳，需要改进。

Method: 采用七阶段流程，分为箭头感知检测、OCR文本提取和结构化提示构建三部分。

Result: 在90个问题的基准测试中，准确率从80%提升至89%，尤其在下一步查询中表现显著。

Conclusion: 方法有效但依赖检测器和OCR精度，未来将扩展评估集并应用于BPMN和UML。

Abstract: Flowcharts are indispensable tools in software design and business-process
analysis, yet current vision-language models (VLMs) frequently misinterpret the
directional arrows and graph topology that set these diagrams apart from
natural images. We introduce a seven-stage pipeline grouped into three broader
processes: (1) arrow-aware detection of nodes and arrow endpoints; (2) optical
character recognition (OCR) to extract node text; and (3) construction of a
structured prompt that guides the VLMs. Tested on a 90-question benchmark
distilled from 30 annotated flowcharts, the method raises overall accuracy from
80 % to 89 % (+9 percentage points) without any task-specific fine-tuning. The
gain is most pronounced for next-step queries (25/30 -> 30/30; 100 %, +17 pp);
branch-result questions improve more modestly, and before-step questions remain
difficult. A parallel evaluation with an LLM-as-a-Judge protocol shows the same
trends, reinforcing the advantage of explicit arrow encoding. Limitations
include dependence on detector and OCR precision, the small evaluation set, and
residual errors at nodes with multiple incoming edges. Future work will enlarge
the benchmark with synthetic and handwritten flowcharts and assess the approach
on Business Process Model and Notation (BPMN) and Unified Modeling Language
(UML).

</details>

### [159] [Visually Guided Decoding: Gradient-Free Hard Prompt Inversion with Language Models](https://arxiv.org/abs/2505.08622)
*Donghoon Kim,Minji Bae,Kyuhong Shim,Byonghyo Shim*

Main category: cs.AI

TLDR: 提出了一种名为VGD的无梯度方法，利用LLMs和CLIP指导生成连贯且语义对齐的提示，解决了现有提示反转技术的不足。


<details>
  <summary>Details</summary>
Motivation: 现有提示反转技术（如软硬提示）因解释性差和提示生成不连贯而效果不佳，需要改进。

Method: VGD结合LLMs的文本生成能力和CLIP评分，无需额外训练即可生成语义对齐的提示。

Result: 实验表明，VGD在生成可理解和上下文相关的提示上优于现有技术。

Conclusion: VGD提升了提示生成的解释性、泛化性和灵活性，使与文本到图像模型的交互更直观可控。

Abstract: Text-to-image generative models like DALL-E and Stable Diffusion have
revolutionized visual content creation across various applications, including
advertising, personalized media, and design prototyping. However, crafting
effective textual prompts to guide these models remains challenging, often
requiring extensive trial and error. Existing prompt inversion approaches, such
as soft and hard prompt techniques, are not so effective due to the limited
interpretability and incoherent prompt generation. To address these issues, we
propose Visually Guided Decoding (VGD), a gradient-free approach that leverages
large language models (LLMs) and CLIP-based guidance to generate coherent and
semantically aligned prompts. In essence, VGD utilizes the robust text
generation capabilities of LLMs to produce human-readable prompts. Further, by
employing CLIP scores to ensure alignment with user-specified visual concepts,
VGD enhances the interpretability, generalization, and flexibility of prompt
generation without the need for additional training. Our experiments
demonstrate that VGD outperforms existing prompt inversion techniques in
generating understandable and contextually relevant prompts, facilitating more
intuitive and controllable interactions with text-to-image models.

</details>

### [160] [TRAIL: Trace Reasoning and Agentic Issue Localization](https://arxiv.org/abs/2505.08638)
*Darshan Deshpande,Varun Gangal,Hersh Mehta,Jitin Krishnan,Anand Kannappan,Rebecca Qian*

Main category: cs.AI

TLDR: 论文提出了一种动态评估代理工作流痕迹的方法，并引入了错误类型的分类法，同时发布了包含148条人工标注痕迹的数据集TRAIL。


<details>
  <summary>Details</summary>
Motivation: 随着代理工作流的广泛应用，现有评估方法依赖人工分析，无法应对复杂性和规模的增加，亟需一种可扩展的系统化评估方法。

Method: 论文提出了一种动态评估方法，定义了代理系统中的错误类型分类法，并构建了基于真实应用场景的148条人工标注痕迹数据集TRAIL。

Result: 实验表明，现代长上下文LLM在痕迹调试中表现不佳，最佳模型Gemini-2.5-pro在TRAIL上仅得11%。

Conclusion: 论文通过数据集和方法的公开，为未来代理工作流的可扩展评估研究提供了支持。

Abstract: The increasing adoption of agentic workflows across diverse domains brings a
critical need to scalably and systematically evaluate the complex traces these
systems generate. Current evaluation methods depend on manual, domain-specific
human analysis of lengthy workflow traces - an approach that does not scale
with the growing complexity and volume of agentic outputs. Error analysis in
these settings is further complicated by the interplay of external tool outputs
and language model reasoning, making it more challenging than traditional
software debugging. In this work, we (1) articulate the need for robust and
dynamic evaluation methods for agentic workflow traces, (2) introduce a formal
taxonomy of error types encountered in agentic systems, and (3) present a set
of 148 large human-annotated traces (TRAIL) constructed using this taxonomy and
grounded in established agentic benchmarks. To ensure ecological validity, we
curate traces from both single and multi-agent systems, focusing on real-world
applications such as software engineering and open-world information retrieval.
Our evaluations reveal that modern long context LLMs perform poorly at trace
debugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our
dataset and code are made publicly available to support and accelerate future
research in scalable evaluation for agentic workflows.

</details>

### [161] [LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs](https://arxiv.org/abs/2505.08704)
*K M Sajjadul Islam,Ayesha Siddika Nipu,Jiawei Wu,Praveen Madiraju*

Main category: cs.AI

TLDR: 论文探讨了基于提示的大型语言模型（如GPT-4o和DeepSeek-R1）在电子健康记录（EHRs）中识别医疗实体的效果，其中GPT-4o结合提示集成方法表现最佳。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录中的非结构化临床文本需要有效提取关键医疗实体（如问题、测试和治疗），以支持下游临床应用。

Method: 研究采用提示工程方法（零样本、少样本和集成方法），利用GPT-4o和DeepSeek-R1进行医疗实体识别。

Result: GPT-4o结合提示集成方法取得了最高性能（F1分数0.95，召回率0.98），优于DeepSeek-R1。

Conclusion: 提示集成方法通过嵌入相似性和多数投票提高了可靠性，GPT-4o在医疗实体识别任务中表现最佳。

Abstract: Electronic Health Records (EHRs) are digital records of patient information,
often containing unstructured clinical text. Named Entity Recognition (NER) is
essential in EHRs for extracting key medical entities like problems, tests, and
treatments to support downstream clinical applications. This paper explores
prompt-based medical entity recognition using large language models (LLMs),
specifically GPT-4o and DeepSeek-R1, guided by various prompt engineering
techniques, including zero-shot, few-shot, and an ensemble approach. Among all
strategies, GPT-4o with prompt ensemble achieved the highest classification
performance with an F1-score of 0.95 and recall of 0.98, outperforming
DeepSeek-R1 on the task. The ensemble method improved reliability by
aggregating outputs through embedding-based similarity and majority voting.

</details>

### [162] [Decoding Neighborhood Environments with Large Language Models](https://arxiv.org/abs/2505.08163)
*Andrew Cart,Shaohu Zhang,Melanie Escue,Xugui Zhou,Haitao Zhao,Prashanth BusiReddyGari,Beiyu Lin,Shuang Li*

Main category: cs.AI

TLDR: 研究探讨了使用大型语言模型（LLMs）如ChatGPT和Gemini解码邻里环境的可行性，结合YOLOv11模型实现高精度检测，并通过多数投票策略提升LLMs的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统邻里环境评估方法资源密集且难以规模化，机器学习虽具潜力但数据标注和模型可及性受限。

Method: 训练YOLOv11模型检测六种环境指标，评估四种LLMs的可行性和鲁棒性，采用多数投票策略。

Result: YOLOv11模型平均准确率达99.13%，LLMs通过多数投票实现超88%的准确率。

Conclusion: LLMs无需训练即可成为解码邻里环境的有效工具，结合YOLOv11模型效果更佳。

Abstract: Neighborhood environments include physical and environmental conditions such
as housing quality, roads, and sidewalks, which significantly influence human
health and well-being. Traditional methods for assessing these environments,
including field surveys and geographic information systems (GIS), are
resource-intensive and challenging to evaluate neighborhood environments at
scale. Although machine learning offers potential for automated analysis, the
laborious process of labeling training data and the lack of accessible models
hinder scalability. This study explores the feasibility of large language
models (LLMs) such as ChatGPT and Gemini as tools for decoding neighborhood
environments (e.g., sidewalk and powerline) at scale. We train a robust
YOLOv11-based model, which achieves an average accuracy of 99.13% in detecting
six environmental indicators, including streetlight, sidewalk, powerline,
apartment, single-lane road, and multilane road. We then evaluate four LLMs,
including ChatGPT, Gemini, Claude, and Grok, to assess their feasibility,
robustness, and limitations in identifying these indicators, with a focus on
the impact of prompting strategies and fine-tuning. We apply majority voting
with the top three LLMs to achieve over 88% accuracy, which demonstrates LLMs
could be a useful tool to decode the neighborhood environment without any
training effort.

</details>

<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [163] [SciCom Wiki: Fact-Checking and FAIR Knowledge Distribution for Scientific Videos and Podcasts](https://arxiv.org/abs/2505.07912)
*Tim Wittenborg,Constantin Sebastian Tremel,Niklas Stehr,Oliver Karras,Markus Stocker,Sören Auer*

Main category: cs.DL

TLDR: 本文提出SciCom Wiki平台，支持科学传播知识基础设施（SciCom KI），通过FAIR媒体表示和神经符号计算事实核查工具应对视频和播客中的错误信息。


<details>
  <summary>Details</summary>
Motivation: 民主社会需要可靠信息，但视频和播客作为传播媒介易传播错误信息，现有SciCom KI缺乏规模化应对能力。

Method: 基于Wikibase构建开源平台，通过53名利益相关者调查、11次访谈和14名参与者评估需求，开发神经符号计算事实核查工具。

Result: 平台满足需求，工具通过10次专家访谈和43名用户调查验证必要性及可用性。

Conclusion: SciCom Wiki可作为FAIR数字图书馆核心节点，但需协作应对信息洪流。

Abstract: Democratic societies need accessible, reliable information. Videos and
Podcasts have established themselves as the medium of choice for civic
dissemination, but also as carriers of misinformation. The emerging Science
Communication Knowledge Infrastructure (SciCom KI) curating non-textual media
is still fragmented and not adequately equipped to scale against the content
flood. Our work sets out to support the SciCom KI with a central, collaborative
platform, the SciCom Wiki, to facilitate FAIR (findable, accessible,
interoperable, reusable) media representation and the fact-checking of their
content, particularly for videos and podcasts. Building an open-source service
system centered around Wikibase, we survey requirements from 53 stakeholders,
refine these in 11 interviews, and evaluate our prototype based on these
requirements with another 14 participants. To address the most requested
feature, fact-checking, we developed a neurosymbolic computational
fact-checking approach, converting heterogenous media into knowledge graphs.
This increases machine-readability and allows comparing statements against
equally represented ground-truth. Our computational fact-checking tool was
iteratively evaluated through 10 expert interviews, a public user survey with
43 participants verified the necessity and usability of our tool. Overall, our
findings identified several needs to systematically support the SciCom KI. The
SciCom Wiki, as a FAIR digital library complementing our neurosymbolic
computational fact-checking framework, was found suitable to address the raised
requirements. Further, we identified that the SciCom KI is severely
underdeveloped regarding FAIR knowledge and related systems facilitating its
collaborative creation and curation. Our system can provide a central knowledge
node, yet a collaborative effort is required to scale against the imminent
(mis-)information flood.

</details>

<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [164] [A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem](https://arxiv.org/abs/2505.08148)
*Sunday Oyinlola Ogundoyin,Muhammad Ikram,Hassan Jameel Asghar,Benjamin Zi Hao Zhao,Dali Kaafar*

Main category: cs.CR

TLDR: 研究分析了14,904个定制GPT模型，发现95%以上存在安全漏洞，主要包括角色扮演攻击、系统提示泄漏和钓鱼内容生成。


<details>
  <summary>Details</summary>
Motivation: 随着定制GPT模型的广泛应用，其安全漏洞问题日益突出，但现有研究缺乏大规模实证分析。

Method: 通过分析14,904个定制GPT模型，评估其对七种可被利用威胁的易感性，并引入多指标排名系统。

Result: 95%以上的定制GPT缺乏足够安全保护，最常见漏洞包括角色扮演攻击（96.51%）、系统提示泄漏（92.20%）和钓鱼（91.22%）。

Conclusion: 研究呼吁加强安全措施和内容审核，以确保GPT应用的安全部署。

Abstract: Millions of users leverage generative pretrained transformer (GPT)-based
language models developed by leading model providers for a wide range of tasks.
To support enhanced user interaction and customization, many platforms-such as
OpenAI-now enable developers to create and publish tailored model instances,
known as custom GPTs, via dedicated repositories or application stores. These
custom GPTs empower users to browse and interact with specialized applications
designed to meet specific needs. However, as custom GPTs see growing adoption,
concerns regarding their security vulnerabilities have intensified. Existing
research on these vulnerabilities remains largely theoretical, often lacking
empirical, large-scale, and statistically rigorous assessments of associated
risks.
  In this study, we analyze 14,904 custom GPTs to assess their susceptibility
to seven exploitable threats, such as roleplay-based attacks, system prompt
leakage, phishing content generation, and malicious code synthesis, across
various categories and popularity tiers within the OpenAI marketplace. We
introduce a multi-metric ranking system to examine the relationship between a
custom GPT's popularity and its associated security risks.
  Our findings reveal that over 95% of custom GPTs lack adequate security
protections. The most prevalent vulnerabilities include roleplay-based
vulnerabilities (96.51%), system prompt leakage (92.20%), and phishing
(91.22%). Furthermore, we demonstrate that OpenAI's foundational models exhibit
inherent security weaknesses, which are often inherited or amplified in custom
GPTs. These results highlight the urgent need for enhanced security measures
and stricter content moderation to ensure the safe deployment of GPT-based
applications.

</details>

### [165] [Where the Devil Hides: Deepfake Detectors Can No Longer Be Trusted](https://arxiv.org/abs/2505.08255)
*Shuaiwei Yuan,Junyu Dong,Yuezun Li*

Main category: cs.CR

TLDR: 论文探讨了Deepfake检测器因使用第三方数据集而面临的安全风险，并提出了一种生成隐蔽触发器的解决方案，通过两种投毒场景验证了方法的有效性和隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成技术的发展，Deepfake检测器依赖第三方数据集训练可能被恶意植入后门，导致检测失效，亟需研究其安全风险及解决方案。

Method: 开发了一种触发器生成器，生成隐蔽且有效的触发器，并通过脏标签和干净标签两种投毒场景植入后门。

Result: 实验证明该方法在隐蔽性和有效性上优于基线方法，能够成功操纵检测器行为。

Conclusion: 研究揭示了Deepfake检测器的安全漏洞，并提出了一种隐蔽的后门植入方法，为未来防御措施提供了参考。

Abstract: With the advancement of AI generative techniques, Deepfake faces have become
incredibly realistic and nearly indistinguishable to the human eye. To counter
this, Deepfake detectors have been developed as reliable tools for assessing
face authenticity. These detectors are typically developed on Deep Neural
Networks (DNNs) and trained using third-party datasets. However, this protocol
raises a new security risk that can seriously undermine the trustfulness of
Deepfake detectors: Once the third-party data providers insert poisoned
(corrupted) data maliciously, Deepfake detectors trained on these datasets will
be injected ``backdoors'' that cause abnormal behavior when presented with
samples containing specific triggers. This is a practical concern, as
third-party providers may distribute or sell these triggers to malicious users,
allowing them to manipulate detector performance and escape accountability.
  This paper investigates this risk in depth and describes a solution to
stealthily infect Deepfake detectors. Specifically, we develop a trigger
generator, that can synthesize passcode-controlled, semantic-suppression,
adaptive, and invisible trigger patterns, ensuring both the stealthiness and
effectiveness of these triggers. Then we discuss two poisoning scenarios,
dirty-label poisoning and clean-label poisoning, to accomplish the injection of
backdoors. Extensive experiments demonstrate the effectiveness, stealthiness,
and practicality of our method compared to several baselines.

</details>

<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [166] [A Reproduction Study: The Kernel PCA Interpretation of Self-Attention Fails Under Scrutiny](https://arxiv.org/abs/2505.07908)
*Karahan Sarıtaş,Çağatay Yıldız*

Main category: cs.LG

TLDR: 本研究重新检验了自注意力机制实现核主成分分析（KPCA）的论点，发现其与实验数据不符，缺乏实证支持。


<details>
  <summary>Details</summary>
Motivation: 验证自注意力机制是否如近期研究所述实现了KPCA，并分析其理论依据与实验数据的一致性。

Method: 通过比较自注意力机制中的值向量与KPCA理论预测的特征向量，评估相似性指标（如余弦相似性和CKA），并分析重构损失和Gram矩阵特征值统计。

Result: 实验显示自注意力机制与KPCA理论预测无显著对应关系，相似性指标低，重构损失差异大，特征值统计不可复现。

Conclusion: 自注意力机制的KPCA解释缺乏实证支持，现有理论主张与实验结果不一致。

Abstract: In this reproduction study, we revisit recent claims that self-attention
implements kernel principal component analysis (KPCA) (Teo et al., 2024),
positing that (i) value vectors $V$ capture the eigenvectors of the Gram matrix
of the keys, and (ii) that self-attention projects queries onto the principal
component axes of the key matrix $K$ in a feature space. Our analysis reveals
three critical inconsistencies: (1) No alignment exists between learned
self-attention value vectors and what is proposed in the KPCA perspective, with
average similarity metrics (optimal cosine similarity $\leq 0.32$, linear CKA
(Centered Kernel Alignment) $\leq 0.11$, kernel CKA $\leq 0.32$) indicating
negligible correspondence; (2) Reported decreases in reconstruction loss
$J_\text{proj}$, arguably justifying the claim that the self-attention
minimizes the projection error of KPCA, are misinterpreted, as the quantities
involved differ by orders of magnitude ($\sim\!10^3$); (3) Gram matrix
eigenvalue statistics, introduced to justify that $V$ captures the eigenvector
of the gram matrix, are irreproducible without undocumented
implementation-specific adjustments. Across 10 transformer architectures, we
conclude that the KPCA interpretation of self-attention lacks empirical
support.

</details>

### [167] [Beyond Input Activations: Identifying Influential Latents by Gradient Sparse Autoencoders](https://arxiv.org/abs/2505.08080)
*Dong Shu,Xuansheng Wu,Haiyan Zhao,Mengnan Du,Ninghao Liu*

Main category: cs.LG

TLDR: 论文提出了一种名为GradSAE的方法，通过结合输出端梯度信息，识别稀疏自编码器中对模型输出最具因果影响的潜在特征。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅依赖输入端激活分析稀疏自编码器，忽略了潜在特征对模型输出的因果影响。本文假设只有高因果影响的潜在特征对模型控制有效。

Method: 提出Gradient Sparse Autoencoder (GradSAE)，利用输出端梯度信息识别最具影响力的潜在特征。

Result: 验证了假设，即高因果影响的潜在特征对模型控制更有效。

Conclusion: GradSAE为稀疏自编码器的分析和控制提供了更有效的方法。

Abstract: Sparse Autoencoders (SAEs) have recently emerged as powerful tools for
interpreting and steering the internal representations of large language models
(LLMs). However, conventional approaches to analyzing SAEs typically rely
solely on input-side activations, without considering the causal influence
between each latent feature and the model's output. This work is built on two
key hypotheses: (1) activated latents do not contribute equally to the
construction of the model's output, and (2) only latents with high causal
influence are effective for model steering. To validate these hypotheses, we
propose Gradient Sparse Autoencoder (GradSAE), a simple yet effective method
that identifies the most influential latents by incorporating output-side
gradient information.

</details>

### [168] [Large Language Models for Computer-Aided Design: A Survey](https://arxiv.org/abs/2505.08137)
*Licheng Zhang,Bach Le,Naveed Akhtar,Siew-Kei Lam,Tuan Ngo*

Main category: cs.LG

TLDR: 本文首次系统综述了大型语言模型（LLMs）与计算机辅助设计（CAD）的结合，填补了该领域的研究空白。


<details>
  <summary>Details</summary>
Motivation: 随着现代设计复杂度的提升，LLMs在优化CAD流程中展现出巨大潜力，但目前缺乏相关综述研究。

Method: 文章首先概述CAD的工业重要性及AI驱动的创新需求，随后详细介绍LLMs的基础知识，包括闭源和开源模型，并重点分析LLMs在CAD中的六大应用领域。

Result: 提出了LLMs在CAD中的六类关键应用，并展示了其显著影响。

Conclusion: 文章提出了未来研究方向，为CAD技术的创新和未来发展提供了广阔机遇。

Abstract: Large Language Models (LLMs) have seen rapid advancements in recent years,
with models like ChatGPT and DeepSeek, showcasing their remarkable capabilities
across diverse domains. While substantial research has been conducted on LLMs
in various fields, a comprehensive review focusing on their integration with
Computer-Aided Design (CAD) remains notably absent. CAD is the industry
standard for 3D modeling and plays a vital role in the design and development
of products across different industries. As the complexity of modern designs
increases, the potential for LLMs to enhance and streamline CAD workflows
presents an exciting frontier. This article presents the first systematic
survey exploring the intersection of LLMs and CAD. We begin by outlining the
industrial significance of CAD, highlighting the need for AI-driven innovation.
Next, we provide a detailed overview of the foundation of LLMs. We also examine
both closed-source LLMs as well as publicly available models. The core of this
review focuses on the various applications of LLMs in CAD, providing a taxonomy
of six key areas where these models are making considerable impact. Finally, we
propose several promising future directions for further advancements, which
offer vast opportunities for innovation and are poised to shape the future of
CAD technology. Github:
https://github.com/lichengzhanguom/LLMs-CAD-Survey-Taxonomy

</details>

### [169] [Optimizing Retrieval-Augmented Generation: Analysis of Hyperparameter Impact on Performance and Efficiency](https://arxiv.org/abs/2505.08445)
*Adel Ammar,Anis Koubaa,Omer Nacar,Wadii Boulila*

Main category: cs.LG

TLDR: 论文研究了检索增强生成（RAG）系统的超参数对速度和性能的影响，发现Chroma速度更快，Faiss检索精度更高，同时固定长度分块和重排策略对性能有不同影响。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型中的幻觉和知识过时问题，通过RAG系统结合外部检索提升生成质量。

Method: 分析Chroma和Faiss向量存储、分块策略、重排和温度等超参数，评估六项指标。

Result: Chroma查询速度快13%，Faiss检索精度更高；固定长度分块表现最佳；重排提升质量但增加运行时。

Conclusion: RAG系统可通过优化超参数实现高检索精度，对下游任务如医疗决策支持有重要意义。

Abstract: Large language models achieve high task performance yet often hallucinate or
rely on outdated knowledge. Retrieval-augmented generation (RAG) addresses
these gaps by coupling generation with external search. We analyse how
hyperparameters influence speed and quality in RAG systems, covering Chroma and
Faiss vector stores, chunking policies, cross-encoder re-ranking, and
temperature, and we evaluate six metrics: faithfulness, answer correctness,
answer relevancy, context precision, context recall, and answer similarity.
Chroma processes queries 13% faster, whereas Faiss yields higher retrieval
precision, revealing a clear speed-accuracy trade-off. Naive fixed-length
chunking with small windows and minimal overlap outperforms semantic
segmentation while remaining the quickest option. Re-ranking provides modest
gains in retrieval quality yet increases runtime by roughly a factor of 5, so
its usefulness depends on latency constraints. These results help practitioners
balance computational cost and accuracy when tuning RAG systems for
transparent, up-to-date responses. Finally, we re-evaluate the top
configurations with a corrective RAG workflow and show that their advantages
persist when the model can iteratively request additional evidence. We obtain a
near-perfect context precision (99%), which demonstrates that RAG systems can
achieve extremely high retrieval accuracy with the right combination of
hyperparameters, with significant implications for applications where retrieval
quality directly impacts downstream task performance, such as clinical decision
support in healthcare.

</details>

### [170] [Memorization-Compression Cycles Improve Generalization](https://arxiv.org/abs/2505.08727)
*Fangyuan Yu*

Main category: cs.LG

TLDR: 论文提出通过压缩内部表示提升泛化能力，引入IBLM目标，提出GAPT算法，实验显示显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索数据扩展和表示压缩对泛化的影响，并模拟生物学习与睡眠交替机制。

Method: 提出IBLM目标，设计GAPT算法动态切换记忆与压缩阶段。

Result: GAPT在GPT-2预训练中降低MBE 50%，提升交叉熵4.8%，OOD泛化提升35%。

Conclusion: GAPT通过模拟睡眠机制有效提升模型泛化能力，减少干扰。

Abstract: We prove theoretically that generalization improves not only through data
scaling but also by compressing internal representations. To operationalize
this insight, we introduce the Information Bottleneck Language Modeling (IBLM)
objective, which reframes language modeling as a constrained optimization
problem: minimizing representation entropy subject to optimal prediction
performance. Empirically, we observe an emergent memorization-compression cycle
during LLM pretraining, evidenced by oscillation positive/negative gradient
alignment between cross-entropy and Matrix-Based Entropy (MBE), a measure of
representation entropy. This pattern closely mirrors the predictive-compressive
trade-off prescribed by IBLM and also parallels the biological alternation
between awake learning and sleep consolidation. Motivated by this observation,
we propose Gated Phase Transition (GAPT), a training algorithm that adaptively
switches between memorization and compression phases. When applied to GPT-2
pretraining on FineWeb dataset, GAPT reduces MBE by 50% and improves
cross-entropy by 4.8%. GAPT improves OOD generalizatino by 35% in a pretraining
task on arithmetic multiplication. In a setting designed to simulate
catastrophic forgetting, GAPT reduces interference by compressing and
separating representations, achieving a 97% improvement in separation -
paralleling the functional role of sleep consolidation.

</details>

### [171] [Fréchet Power-Scenario Distance: A Metric for Evaluating Generative AI Models across Multiple Time-Scales in Smart Grids](https://arxiv.org/abs/2505.08082)
*Yuting Cai,Shaohuai Liu,Chao Tian,Le Xie*

Main category: cs.LG

TLDR: 提出了一种基于Fréchet距离的新指标，用于评估生成模型在智能电网中产生的合成数据质量。


<details>
  <summary>Details</summary>
Motivation: 传统欧氏距离指标无法有效评估合成数据集之间的质量差异，需从分布角度提出新方法。

Method: 基于Fréchet距离，在学习的特征空间中估计两个数据集之间的距离。

Result: 实证结果表明，该指标在不同时间尺度和模型中表现优越，提升了智能电网数据驱动决策的可靠性。

Conclusion: 新指标从分布角度有效评估合成数据质量，为智能电网应用提供了更可靠的评估工具。

Abstract: Generative artificial intelligence (AI) models in smart grids have advanced
significantly in recent years due to their ability to generate large amounts of
synthetic data, which would otherwise be difficult to obtain in the real world
due to confidentiality constraints. A key challenge in utilizing such synthetic
data is how to assess the data quality produced from such generative models.
Traditional Euclidean distance-based metrics only reflect pair-wise relations
between two individual samples, and could fail in evaluating quality
differences between groups of synthetic datasets. In this work, we propose a
novel metric based on the Fr\'{e}chet Distance (FD) estimated between two
datasets in a learned feature space. The proposed method evaluates the quality
of generation from a distributional perspective. Empirical results demonstrate
the superiority of the proposed metric across timescales and models, enhancing
the reliability of data-driven decision-making in smart grid operations.

</details>

### [172] [CodePDE: An Inference Framework for LLM-driven PDE Solver Generation](https://arxiv.org/abs/2505.08783)
*Shanda Li,Tanya Marwah,Junhong Shen,Weiwei Sun,Andrej Risteski,Yiming Yang,Ameet Talwalkar*

Main category: cs.LG

TLDR: CodePDE利用大型语言模型生成PDE求解器，无需任务特定调优，实现超人类性能。


<details>
  <summary>Details</summary>
Motivation: 传统PDE求解方法依赖专家知识且计算成本高，神经网络求解器需大量数据且缺乏可解释性。

Method: 将PDE求解视为代码生成任务，利用LLM的推理、调试和自优化能力。

Result: CodePDE在多种PDE问题上表现超人类，并分析了生成求解器的精度、效率和数值方案选择。

Conclusion: LLM在PDE求解中展现出潜力，但也存在局限性，为未来模型设计提供了新视角。

Abstract: Partial differential equations (PDEs) are fundamental to modeling physical
systems, yet solving them remains a complex challenge. Traditional numerical
solvers rely on expert knowledge to implement and are computationally
expensive, while neural-network-based solvers require large training datasets
and often lack interpretability. In this work, we frame PDE solving as a code
generation task and introduce CodePDE, the first inference framework for
generating PDE solvers using large language models (LLMs). Leveraging advanced
inference-time algorithms and scaling strategies, CodePDE unlocks critical
capacities of LLM for PDE solving: reasoning, debugging, selfrefinement, and
test-time scaling -- all without task-specific tuning. CodePDE achieves
superhuman performance across a range of representative PDE problems. We also
present a systematic empirical analysis of LLM generated solvers, analyzing
their accuracy, efficiency, and numerical scheme choices. Our findings
highlight the promise and the current limitations of LLMs in PDE solving,
offering a new perspective on solver design and opportunities for future model
development. Our code is available at https://github.com/LithiumDA/CodePDE.

</details>

### [173] [Decoupled Multimodal Prototypes for Visual Recognition with Missing Modalities](https://arxiv.org/abs/2505.08283)
*Jueqing Lu,Yuanyuan Qi,Xiaohao Yang,Shujie Zhou,Lan Du*

Main category: cs.LG

TLDR: 提出了一种基于解耦原型的新型输出头，用于处理多模态学习中的缺失模态问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设所有模态可用，但现实中常缺失某些模态，导致性能下降。

Method: 设计了缺失感知的类原型输出头，动态适应不同缺失场景，并与现有提示方法兼容。

Result: 实验表明，该方法在多种缺失场景和缺失率下显著提升性能。

Conclusion: 提出的输出头有效解决了多模态学习中的缺失模态问题，具有广泛适用性。

Abstract: Multimodal learning enhances deep learning models by enabling them to
perceive and understand information from multiple data modalities, such as
visual and textual inputs. However, most existing approaches assume the
availability of all modalities, an assumption that often fails in real-world
applications. Recent works have introduced learnable missing-case-aware prompts
to mitigate performance degradation caused by missing modalities while reducing
the need for extensive model fine-tuning. Building upon the effectiveness of
missing-case-aware handling for missing modalities, we propose a novel
decoupled prototype-based output head, which leverages missing-case-aware
class-wise prototypes tailored for each individual modality. This approach
dynamically adapts to different missing modality scenarios and can be
seamlessly integrated with existing prompt-based methods. Extensive experiments
demonstrate that our proposed output head significantly improves performance
across a wide range of missing-modality scenarios and varying missing rates.

</details>

### [174] [Efficient Unstructured Pruning of Mamba State-Space Models for Resource-Constrained Environments](https://arxiv.org/abs/2505.08299)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.LG

TLDR: 提出了一种针对Mamba模型的无结构化剪枝框架，减少70%参数同时保留95%性能。


<details>
  <summary>Details</summary>
Motivation: Mamba模型参数过多，难以在资源受限环境中部署。

Method: 结合梯度感知的幅度剪枝、迭代剪枝计划和全局剪枝策略。

Result: 在多个基准测试中显著提升效率，性能损失极小。

Conclusion: 揭示了Mamba架构的冗余性和鲁棒性，拓宽了其应用范围。

Abstract: State-space models (SSMs), particularly the Mamba architecture, have emerged
as powerful alternatives to Transformers for sequence modeling, offering
linear-time complexity and competitive performance across diverse tasks.
However, their large parameter counts pose significant challenges for
deployment in resource-constrained environments. We propose a novel
unstructured pruning framework tailored for Mamba models that achieves up to
70\% parameter reduction while retaining over 95\% of the original performance.
Our approach integrates three key innovations: (1) a gradient-aware magnitude
pruning technique that combines weight magnitude and gradient information to
identify less critical parameters, (2) an iterative pruning schedule that
gradually increases sparsity to maintain model stability, and (3) a global
pruning strategy that optimizes parameter allocation across the entire model.
Through extensive experiments on WikiText-103, Long Range Arena, and ETT
time-series benchmarks, we demonstrate significant efficiency gains with
minimal performance degradation. Our analysis of pruning effects on Mamba's
components reveals critical insights into the architecture's redundancy and
robustness, enabling practical deployment in resource-constrained settings
while broadening Mamba's applicability.

</details>

### [175] [GradMix: Gradient-based Selective Mixup for Robust Data Augmentation in Class-Incremental Learning](https://arxiv.org/abs/2505.08528)
*Minsu Kim,Seong-Hyeon Hwang,Steven Euijong Whang*

Main category: cs.LG

TLDR: 论文提出GradMix，一种针对类增量学习中灾难性遗忘问题的数据增强方法，通过梯度选择性混合样本，显著减少遗忘。


<details>
  <summary>Details</summary>
Motivation: 持续学习中，如何在获取新知识的同时保留旧知识是一个挑战。现有方法如经验回放虽有效，但随机混合样本可能损害旧知识。

Method: 提出GradMix，基于梯度的选择性混合方法，仅混合有益类对的样本，避免有害类对的影响。

Result: 实验表明，GradMix在多个数据集上优于基线方法，显著减少了灾难性遗忘。

Conclusion: GradMix为持续学习中的数据增强提供了更优策略，有效平衡新旧知识的学习。

Abstract: In the context of continual learning, acquiring new knowledge while
maintaining previous knowledge presents a significant challenge. Existing
methods often use experience replay techniques that store a small portion of
previous task data for training. In experience replay approaches, data
augmentation has emerged as a promising strategy to further improve the model
performance by mixing limited previous task data with sufficient current task
data. However, we theoretically and empirically analyze that training with
mixed samples from random sample pairs may harm the knowledge of previous tasks
and cause greater catastrophic forgetting. We then propose GradMix, a robust
data augmentation method specifically designed for mitigating catastrophic
forgetting in class-incremental learning. GradMix performs gradient-based
selective mixup using a class-based criterion that mixes only samples from
helpful class pairs and not from detrimental class pairs for reducing
catastrophic forgetting. Our experiments on various real datasets show that
GradMix outperforms data augmentation baselines in accuracy by minimizing the
forgetting of previous knowledge.

</details>