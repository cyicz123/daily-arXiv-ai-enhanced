<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 22]
- [cs.CV](#cs.CV) [Total: 68]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.SD](#cs.SD) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.CY](#cs.CY) [Total: 3]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]
- [eess.IV](#eess.IV) [Total: 5]
- [cs.RO](#cs.RO) [Total: 3]
- [cs.LG](#cs.LG) [Total: 8]
- [cs.AI](#cs.AI) [Total: 3]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [math.OC](#math.OC) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Calibrating Uncertainty Quantification of Multi-Modal LLMs using Grounding](https://arxiv.org/abs/2505.03788)
*Trilok Padhi,Ramneet Kaur,Adam D. Cobb,Manoj Acharya,Anirban Roy,Colin Samplawski,Brian Matejek,Alexander M. Berenbeim,Nathaniel D. Bastian,Susmit Jha*

Main category: cs.CL

TLDR: 提出了一种针对多模态大语言模型（LLM）的校准不确定性量化（UQ）的新方法，通过结合跨模态一致性和自一致性来改进校准效果。


<details>
  <summary>Details</summary>
Motivation: 现有UQ方法在多模态LLM中常因模型在错误场景下表现一致而高估置信度，导致校准效果不佳。

Method: 利用视觉输入对文本响应进行基础校准，并通过温度缩放技术校准基础模型的置信度。

Result: 在医疗问答（Slake）和视觉问答（VQAv2）任务中，新框架显著提升了校准效果。

Conclusion: 该方法在多模态任务中有效改进了置信度校准，提升了模型的可靠性。

Abstract: We introduce a novel approach for calibrating uncertainty quantification (UQ)
tailored for multi-modal large language models (LLMs). Existing
state-of-the-art UQ methods rely on consistency among multiple responses
generated by the LLM on an input query under diverse settings. However, these
approaches often report higher confidence in scenarios where the LLM is
consistently incorrect. This leads to a poorly calibrated confidence with
respect to accuracy. To address this, we leverage cross-modal consistency in
addition to self-consistency to improve the calibration of the multi-modal
models. Specifically, we ground the textual responses to the visual inputs. The
confidence from the grounding model is used to calibrate the overall
confidence. Given that using a grounding model adds its own uncertainty in the
pipeline, we apply temperature scaling - a widely accepted parametric
calibration technique - to calibrate the grounding model's confidence in the
accuracy of generated responses. We evaluate the proposed approach across
multiple multi-modal tasks, such as medical question answering (Slake) and
visual question answering (VQAv2), considering multi-modal models such as
LLaVA-Med and LLaVA. The experiments demonstrate that the proposed framework
achieves significantly improved calibration on both tasks.

</details>

### [2] [Hesitation is defeat? Connecting Linguistic and Predictive Uncertainty](https://arxiv.org/abs/2505.03910)
*Gianluca Manzo,Julia Ive*

Main category: cs.CL

TLDR: 该论文探讨了深度学习模型在胸片解读中的预测不确定性，并与人类语言不确定性进行比较，发现两者相关性有限，需进一步优化。


<details>
  <summary>Details</summary>
Motivation: 提升胸片解读的自动化水平，同时关注预测不确定性的量化，以改进临床决策。

Method: 使用BERT模型，比较蒙特卡洛Dropout和深度集成方法，评估预测不确定性与语言不确定性的关系。

Result: 模型表现良好，但预测不确定性与语言不确定性相关性较低。

Conclusion: 贝叶斯方法提供有用不确定性估计，但需进一步优化以更好地匹配人类不确定性。

Abstract: Automating chest radiograph interpretation using Deep Learning (DL) models
has the potential to significantly improve clinical workflows, decision-making,
and large-scale health screening. However, in medical settings, merely
optimising predictive performance is insufficient, as the quantification of
uncertainty is equally crucial. This paper investigates the relationship
between predictive uncertainty, derived from Bayesian Deep Learning
approximations, and human/linguistic uncertainty, as estimated from free-text
radiology reports labelled by rule-based labellers. Utilising BERT as the model
of choice, this study evaluates different binarisation methods for uncertainty
labels and explores the efficacy of Monte Carlo Dropout and Deep Ensembles in
estimating predictive uncertainty. The results demonstrate good model
performance, but also a modest correlation between predictive and linguistic
uncertainty, highlighting the challenges in aligning machine uncertainty with
human interpretation nuances. Our findings suggest that while Bayesian
approximations provide valuable uncertainty estimates, further refinement is
necessary to fully capture and utilise the subtleties of human uncertainty in
clinical applications.

</details>

### [3] [A Reasoning-Focused Legal Retrieval Benchmark](https://arxiv.org/abs/2505.03970)
*Lucia Zheng,Neel Guha,Javokhir Arifov,Sarah Zhang,Michal Skreta,Christopher D. Manning,Peter Henderson,Daniel E. Ho*

Main category: cs.CL

TLDR: 论文介绍了两个新的法律RAG基准测试：Bar Exam QA和Housing Statute QA，以解决法律RAG系统开发中缺乏真实基准的问题。


<details>
  <summary>Details</summary>
Motivation: 法律AI开发者使用RAG系统提升性能，但缺乏能捕捉法律检索和问答复杂性的基准。

Method: 通过类似法律研究的标注过程，构建了两个真实法律研究任务的基准。

Result: 现有检索管线的表现表明，法律RAG仍具挑战性。

Conclusion: 研究为未来法律RAG系统的改进提供了动力。

Abstract: As the legal community increasingly examines the use of large language models
(LLMs) for various legal applications, legal AI developers have turned to
retrieval-augmented LLMs ("RAG" systems) to improve system performance and
robustness. An obstacle to the development of specialized RAG systems is the
lack of realistic legal RAG benchmarks which capture the complexity of both
legal retrieval and downstream legal question-answering. To address this, we
introduce two novel legal RAG benchmarks: Bar Exam QA and Housing Statute QA.
Our tasks correspond to real-world legal research tasks, and were produced
through annotation processes which resemble legal research. We describe the
construction of these benchmarks and the performance of existing retriever
pipelines. Our results suggest that legal RAG remains a challenging
application, thus motivating future research.

</details>

### [4] [Divide, Optimize, Merge: Fine-Grained LLM Agent Optimization at Scale](https://arxiv.org/abs/2505.03973)
*Jiale Liu,Yifan Zeng,Shaokun Zhang,Chi Zhang,Malte Højmark-Bertelsen,Marie Normann Gadeberg,Huazheng Wang,Qingyun Wu*

Main category: cs.CL

TLDR: 论文提出了一种细粒度优化（FGO）框架，通过将大型优化任务分解为可管理的子集，解决了传统LLM优化方法因数据集增长导致的上下文窗口溢出和模式识别退化问题。


<details>
  <summary>Details</summary>
Motivation: 传统LLM优化方法在处理大规模数据集时存在上下文窗口溢出和模式识别退化的问题，亟需一种可扩展的解决方案。

Method: FGO框架将大型优化任务分解为子集，进行针对性优化，并通过渐进式合并系统化组合优化后的组件。

Result: 在ALFWorld、LogisticsQA和GAIA基准测试中，FGO性能优于现有方法1.6-8.6%，同时平均提示令牌消耗减少56.3%。

Conclusion: FGO为扩展LLM优化提供了实用解决方案，展示了其在各种数据集规模下的可扩展性和高效性。

Abstract: LLM-based optimization has shown remarkable potential in enhancing agentic
systems. However, the conventional approach of prompting LLM optimizer with the
whole training trajectories on training dataset in a single pass becomes
untenable as datasets grow, leading to context window overflow and degraded
pattern recognition. To address these challenges, we propose Fine-Grained
Optimization (FGO), a scalable framework that divides large optimization tasks
into manageable subsets, performs targeted optimizations, and systematically
combines optimized components through progressive merging. Evaluation across
ALFWorld, LogisticsQA, and GAIA benchmarks demonstrate that FGO outperforms
existing approaches by 1.6-8.6% while reducing average prompt token consumption
by 56.3%. Our framework provides a practical solution for scaling up LLM-based
optimization of increasingly sophisticated agent systems. Further analysis
demonstrates that FGO achieves the most consistent performance gain in all
training dataset sizes, showcasing its scalability and efficiency.

</details>

### [5] [X-Reasoner: Towards Generalizable Reasoning Across Modalities and Domains](https://arxiv.org/abs/2505.03981)
*Qianchu Liu,Sheng Zhang,Guanghui Qin,Timothy Ossowski,Yu Gu,Ying Jin,Sid Kiblawi,Sam Preston,Mu Wei,Paul Vozila,Tristan Naumann,Hoifung Poon*

Main category: cs.CL

TLDR: X-Reasoner通过通用领域文本后训练实现跨模态和跨领域的推理能力，并通过两阶段方法（监督微调和强化学习）提升性能。X-Reasoner-Med是其医学专用变体，表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索推理能力是否可跨模态和领域泛化，填补开源研究中多模态推理的空白。

Method: 两阶段方法：监督微调（长链思维蒸馏）和强化学习（可验证奖励）。

Result: X-Reasoner在跨模态和领域任务中表现优于现有模型，X-Reasoner-Med在医学领域达到新SOTA。

Conclusion: 通用文本后训练可实现跨模态和领域推理，领域专用数据可进一步提升性能。

Abstract: Recent proprietary models (e.g., o3) have begun to demonstrate strong
multimodal reasoning capabilities. Yet, most existing open-source research
concentrates on training text-only reasoning models, with evaluations limited
to mainly mathematical and general-domain tasks. Therefore, it remains unclear
how to effectively extend reasoning capabilities beyond text input and general
domains. This paper explores a fundamental research question: Is reasoning
generalizable across modalities and domains? Our findings support an
affirmative answer: General-domain text-based post-training can enable such
strong generalizable reasoning. Leveraging this finding, we introduce
X-Reasoner, a vision-language model post-trained solely on general-domain text
for generalizable reasoning, using a two-stage approach: an initial supervised
fine-tuning phase with distilled long chain-of-thoughts, followed by
reinforcement learning with verifiable rewards. Experiments show that
X-Reasoner successfully transfers reasoning capabilities to both multimodal and
out-of-domain settings, outperforming existing state-of-the-art models trained
with in-domain and multimodal data across various general and medical
benchmarks (Figure 1). Additionally, we find that X-Reasoner's performance in
specialized domains can be further enhanced through continued training on
domain-specific text-only data. Building upon this, we introduce
X-Reasoner-Med, a medical-specialized variant that achieves new state of the
art on numerous text-only and multimodal medical benchmarks.

</details>

### [6] [SLOT: Structuring the Output of Large Language Models](https://arxiv.org/abs/2505.04016)
*Darren Yow-Bang Wang,Zhengyuan Shen,Soumya Smruti Mishra,Zhichao Xu,Yifei Teng,Haibo Ding*

Main category: cs.CL

TLDR: SLOT是一种模型无关的方法，通过微调轻量级语言模型将LLM的非结构化输出转换为精确的结构化格式，显著提升模式准确性和内容保真度。


<details>
  <summary>Details</summary>
Motivation: 在关键应用中，LLM的非结构化输出常偏离预定义模式，影响可靠性。SLOT旨在解决这一问题。

Method: SLOT采用微调的轻量级语言模型作为后处理层，支持多种LLM和模式规范，并通过数据合成和评估方法验证效果。

Result: 微调的Mistral-7B模型在模式准确性和内容相似性上表现优异（99.5%和94.0%），优于Claude-3.5-Sonnet。

Conclusion: SLOT使小型模型也能生成可靠的结构化输出，适用于资源受限环境。

Abstract: Structured outputs are essential for large language models (LLMs) in critical
applications like agents and information extraction. Despite their
capabilities, LLMs often generate outputs that deviate from predefined schemas,
significantly hampering reliable application development. We present SLOT
(Structured LLM Output Transformer), a model-agnostic approach that transforms
unstructured LLM outputs into precise structured formats. While existing
solutions predominantly rely on constrained decoding techniques or are tightly
coupled with specific models, SLOT employs a fine-tuned lightweight language
model as a post-processing layer, achieving flexibility across various LLMs and
schema specifications. We introduce a systematic pipeline for data curation and
synthesis alongside a formal evaluation methodology that quantifies both schema
accuracy and content fidelity. Our results demonstrate that fine-tuned
Mistral-7B model with constrained decoding achieves near perfect schema
accuracy (99.5%) and content similarity (94.0%), outperforming
Claude-3.5-Sonnet by substantial margins (+25 and +20 percentage points,
respectively). Notably, even compact models like Llama-3.2-1B can match or
exceed the structured output capabilities of much larger proprietary models
when equipped with SLOT, enabling reliable structured generation in
resource-constrained environments.

</details>

### [7] [Advancing and Benchmarking Personalized Tool Invocation for LLMs](https://arxiv.org/abs/2505.04072)
*Xu Huang,Yuefeng Huang,Weiwen Liu,Xingshan Zeng,Yasheng Wang,Ruiming Tang,Hong Xie,Defu Lian*

Main category: cs.CL

TLDR: 论文提出了个性化工具调用（Personalized Tool Invocation）的概念，并定义了工具偏好和基于用户档案的查询两个任务。作者开发了PTool框架和PTBench基准，验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs调用工具的基本能力，忽略了工具调用中的个性化约束。

Method: 提出了PTool数据合成框架，并构建了PTBench基准，对开源模型进行微调。

Result: 验证了PTool框架的有效性，并提供了有价值的见解。

Conclusion: PTool和PTBench为个性化工具调用提供了新的研究方向和实践工具。

Abstract: Tool invocation is a crucial mechanism for extending the capabilities of
Large Language Models (LLMs) and has recently garnered significant attention.
It enables LLMs to solve complex problems through tool calls while accessing
up-to-date world knowledge. However, existing work primarily focuses on the
fundamental ability of LLMs to invoke tools for problem-solving, without
considering personalized constraints in tool invocation. In this work, we
introduce the concept of Personalized Tool Invocation and define two key tasks:
Tool Preference and Profile-dependent Query. Tool Preference addresses user
preferences when selecting among functionally similar tools, while
Profile-dependent Query considers cases where a user query lacks certain tool
parameters, requiring the model to infer them from the user profile. To tackle
these challenges, we propose PTool, a data synthesis framework designed for
personalized tool invocation. Additionally, we construct \textbf{PTBench}, the
first benchmark for evaluating personalized tool invocation. We then fine-tune
various open-source models, demonstrating the effectiveness of our framework
and providing valuable insights. Our benchmark is public at
https://github.com/hyfshadow/PTBench.

</details>

### [8] [Natural Language Generation in Healthcare: A Review of Methods and Applications](https://arxiv.org/abs/2505.04073)
*Mengxian Lyu,Xiaohan Li,Ziyi Chen,Jinqian Pan,Cheng Peng,Sankalp Talankar,Yonghui Wu*

Main category: cs.CL

TLDR: 本文综述了自然语言生成（NLG）在医疗领域的应用，分析了113篇相关文献，涵盖数据模态、模型架构、临床应用及评估方法，并总结了关键技术和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的突破，NLG在医疗领域的应用潜力巨大，但缺乏全面综述。本文旨在填补这一空白。

Method: 通过文献检索筛选出113篇相关文章，遵循PRISMA指南，系统分析数据模态、模型架构、临床应用及评估方法。

Result: 总结了NLG在医疗领域的关键方法、应用场景及其能力与局限性，并指出新兴挑战。

Conclusion: 本文为未来研究提供了有价值的见解，有助于利用NLG推动医疗发现和健康护理的变革。

Abstract: Natural language generation (NLG) is the key technology to achieve generative
artificial intelligence (AI). With the breakthroughs in large language models
(LLMs), NLG has been widely used in various medical applications, demonstrating
the potential to enhance clinical workflows, support clinical decision-making,
and improve clinical documentation. Heterogeneous and diverse medical data
modalities, such as medical text, images, and knowledge bases, are utilized in
NLG. Researchers have proposed many generative models and applied them in a
number of healthcare applications. There is a need for a comprehensive review
of NLG methods and applications in the medical domain. In this study, we
systematically reviewed 113 scientific publications from a total of 3,988
NLG-related articles identified using a literature search, focusing on data
modality, model architecture, clinical applications, and evaluation methods.
Following PRISMA (Preferred Reporting Items for Systematic reviews and
Meta-Analyses) guidelines, we categorize key methods, identify clinical
applications, and assess their capabilities, limitations, and emerging
challenges. This timely review covers the key NLG technologies and medical
applications and provides valuable insights for future studies to leverage NLG
to transform medical discovery and healthcare.

</details>

### [9] [Bringing legal knowledge to the public by constructing a legal question bank using large-scale pre-trained language model](https://arxiv.org/abs/2505.04132)
*Mingruo Yuan,Ben Kao,Tien-Hsuan Wu,Michael M. K. Cheung,Henry W. H. Chan,Anne S. Y. Cheung,Felix W. H. Chan,Yongxi Chen*

Main category: cs.CL

TLDR: 论文提出了一种三步法，将复杂的法律信息转化为易于公众理解的形式，包括创建法律知识片段（CLIC-pages）、构建法律问题库（LQB）和设计交互式推荐系统（CRec）。重点探讨了利用GPT-3等模型生成法律问题的技术。


<details>
  <summary>Details</summary>
Motivation: 法律文件通常技术性强，公众难以理解。研究旨在解决法律信息的可导航性和可理解性问题，帮助非专业人士获取法律知识。

Method: 1. 将法律条文转化为易于理解的CLIC-pages；2. 构建法律问题库（LQB）；3. 设计交互式推荐系统（CRec）。重点研究了利用GPT-3生成法律问题的技术。

Result: 机器生成的问题（MGQs）更具扩展性和多样性，成本更低；人工编写的问题（HCQs）更精确。CRec原型展示了三步法的有效性。

Conclusion: 三步法能有效提升法律信息的可访问性，GPT-3在生成法律问题方面具有潜力，但需结合人工精确性。

Abstract: Access to legal information is fundamental to access to justice. Yet
accessibility refers not only to making legal documents available to the
public, but also rendering legal information comprehensible to them. A vexing
problem in bringing legal information to the public is how to turn formal legal
documents such as legislation and judgments, which are often highly technical,
to easily navigable and comprehensible knowledge to those without legal
education. In this study, we formulate a three-step approach for bringing legal
knowledge to laypersons, tackling the issues of navigability and
comprehensibility. First, we translate selected sections of the law into
snippets (called CLIC-pages), each being a small piece of article that focuses
on explaining certain technical legal concept in layperson's terms. Second, we
construct a Legal Question Bank (LQB), which is a collection of legal questions
whose answers can be found in the CLIC-pages. Third, we design an interactive
CLIC Recommender (CRec). Given a user's verbal description of a legal situation
that requires a legal solution, CRec interprets the user's input and shortlists
questions from the question bank that are most likely relevant to the given
legal situation and recommends their corresponding CLIC pages where relevant
legal knowledge can be found. In this paper we focus on the technical aspects
of creating an LQB. We show how large-scale pre-trained language models, such
as GPT-3, can be used to generate legal questions. We compare machine-generated
questions (MGQs) against human-composed questions (HCQs) and find that MGQs are
more scalable, cost-effective, and more diversified, while HCQs are more
precise. We also show a prototype of CRec and illustrate through an example how
our 3-step approach effectively brings relevant legal knowledge to the public.

</details>

### [10] [Enhancing Granular Sentiment Classification with Chain-of-Thought Prompting in Large Language Models](https://arxiv.org/abs/2505.04135)
*Vihaan Miriyala,Smrithi Bukkapatnam,Lavanya Prahallad*

Main category: cs.CL

TLDR: 使用Chain-of-Thought (CoT)提示方法显著提升了应用商店评论中细粒度情感分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的数值和极性评分无法捕捉用户反馈中的细微情感差异。

Method: 在2000条亚马逊应用评论上比较了CoT提示与简单提示的效果，并与人工判断进行对比。

Result: CoT提示将分类准确率从84%提升至93%。

Conclusion: 显式推理能显著提升情感分析性能。

Abstract: We explore the use of Chain-of-Thought (CoT) prompting with large language
models (LLMs) to improve the accuracy of granular sentiment categorization in
app store reviews. Traditional numeric and polarity-based ratings often fail to
capture the nuanced sentiment embedded in user feedback. We evaluated the
effectiveness of CoT prompting versus simple prompting on 2000 Amazon app
reviews by comparing each method's predictions to human judgements. CoT
prompting improved classification accuracy from 84% to 93% highlighting the
benefit of explicit reasoning in enhancing sentiment analysis performance.

</details>

### [11] [Unmasking the Canvas: A Dynamic Benchmark for Image Generation Jailbreaking and LLM Content Safety](https://arxiv.org/abs/2505.04146)
*Variath Madhupal Gautham Nair,Vishal Varma Dantuluri*

Main category: cs.CL

TLDR: 论文提出了一种动态可扩展的基准数据集UTCB，用于评估大语言模型在图像生成中的漏洞，并通过多语言混淆和结构化提示工程测试模型安全性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在图像生成任务中表现优异，但其内容安全检查易受提示攻击，导致生成不当内容。

Method: 结合结构化提示工程、多语言混淆（如祖鲁语、盖尔语、Base64）和Groq托管的LLaMA-3评估，支持零样本和回退提示策略、风险评分和自动标记。

Result: UTCB数据集分为青铜（未验证）、白银（LLM辅助验证）和黄金（人工验证）三个层级，支持动态扩展。

Conclusion: UTCB为模型安全性评估提供了动态且可扩展的工具，未来将纳入更多数据源和模型行为。

Abstract: Existing large language models (LLMs) are advancing rapidly and produce
outstanding results in image generation tasks, yet their content safety checks
remain vulnerable to prompt-based jailbreaks. Through preliminary testing on
platforms such as ChatGPT, MetaAI, and Grok, we observed that even short,
natural prompts could lead to the generation of compromising images ranging
from realistic depictions of forged documents to manipulated images of public
figures.
  We introduce Unmasking the Canvas (UTC Benchmark; UTCB), a dynamic and
scalable benchmark dataset to evaluate LLM vulnerability in image generation.
Our methodology combines structured prompt engineering, multilingual
obfuscation (e.g., Zulu, Gaelic, Base64), and evaluation using Groq-hosted
LLaMA-3. The pipeline supports both zero-shot and fallback prompting
strategies, risk scoring, and automated tagging. All generations are stored
with rich metadata and curated into Bronze (non-verified), Silver (LLM-aided
verification), and Gold (manually verified) tiers. UTCB is designed to evolve
over time with new data sources, prompt templates, and model behaviors.
  Warning: This paper includes visual examples of adversarial inputs designed
to test model safety. All outputs have been redacted to ensure responsible
disclosure.

</details>

### [12] [Can Language Models Understand Social Behavior in Clinical Conversations?](https://arxiv.org/abs/2505.04152)
*Manas Satish Bedmutha,Feng Chen,Andrea Hartzler,Trevor Cohen,Nadir Weibel*

Main category: cs.CL

TLDR: 论文探讨了利用大型语言模型（LLMs）自动分析临床对话中的社交信号，以提升医患沟通效果。


<details>
  <summary>Details</summary>
Motivation: 医患沟通的效果不仅依赖于临床信息交换，还受社交信号（如非语言行为）影响。随着LLMs的发展，自动分析这些信号成为可能。

Method: 设计了任务特定的提示，并在包含20种社交信号的标注数据集上评估了多种LLM架构和提示风格。

Result: 开发了首个能追踪20种社交信号的系统，并揭示了LLM的行为模式。

Conclusion: 研究为提升LLM在医疗社交信号处理任务中的性能提供了见解。

Abstract: Effective communication between providers and their patients influences
health and care outcomes. The effectiveness of such conversations has been
linked not only to the exchange of clinical information, but also to a range of
interpersonal behaviors; commonly referred to as social signals, which are
often conveyed through non-verbal cues and shape the quality of the
patient-provider relationship. Recent advances in large language models (LLMs)
have demonstrated an increasing ability to infer emotional and social behaviors
even when analyzing only textual information. As automation increases also in
clinical settings, such as for transcription of patient-provider conversations,
there is growing potential for LLMs to automatically analyze and extract social
behaviors from these interactions. To explore the foundational capabilities of
LLMs in tracking social signals in clinical dialogue, we designed task-specific
prompts and evaluated model performance across multiple architectures and
prompting styles using a highly imbalanced, annotated dataset spanning 20
distinct social signals such as provider dominance, patient warmth, etc. We
present the first system capable of tracking all these 20 coded signals, and
uncover patterns in LLM behavior. Further analysis of model configurations and
clinical context provides insights for enhancing LLM performance on social
signal processing tasks in healthcare settings.

</details>

### [13] [LLM-Independent Adaptive RAG: Let the Question Speak for Itself](https://arxiv.org/abs/2505.04253)
*Maria Marina,Nikolay Ivanov,Sergey Pletenev,Mikhail Salnikov,Daria Galimzianova,Nikita Krayko,Vasily Konovalov,Alexander Panchenko,Viktor Moskvoretskii*

Main category: cs.CL

TLDR: 本文提出了一种轻量级、不依赖LLM的自适应检索方法，通过外部信息实现高效检索，性能与复杂LLM方法相当。


<details>
  <summary>Details</summary>
Motivation: LLM容易产生幻觉，RAG虽能缓解但计算成本高且可能传播错误信息，现有自适应检索方法依赖LLM且效率低。

Method: 研究了27个特征，分为7组及其混合组合，基于外部信息设计轻量级自适应检索方法。

Result: 在6个QA数据集上评估，性能与复杂LLM方法相当，效率显著提升。

Conclusion: 外部信息在自适应检索中具有潜力，轻量级方法可实现高效且高性能的检索。

Abstract: Large Language Models~(LLMs) are prone to hallucinations, and
Retrieval-Augmented Generation (RAG) helps mitigate this, but at a high
computational cost while risking misinformation. Adaptive retrieval aims to
retrieve only when necessary, but existing approaches rely on LLM-based
uncertainty estimation, which remain inefficient and impractical. In this
study, we introduce lightweight LLM-independent adaptive retrieval methods
based on external information. We investigated 27 features, organized into 7
groups, and their hybrid combinations. We evaluated these methods on 6 QA
datasets, assessing the QA performance and efficiency. The results show that
our approach matches the performance of complex LLM-based methods while
achieving significant efficiency gains, demonstrating the potential of external
information for adaptive retrieval.

</details>

### [14] [GASCADE: Grouped Summarization of Adverse Drug Event for Enhanced Cancer Pharmacovigilance](https://arxiv.org/abs/2505.04284)
*Sofia Jamil,Aryan Dabad,Bollampalli Areen Reddy,Sriparna Saha,Rajiv Misra,Adil A. Shakur*

Main category: cs.CL

TLDR: 论文提出了一种针对癌症治疗中药物不良事件（ADEs）的分组摘要任务，并发布了MCADRS数据集和GASCADE框架，结合LLMs和T5模型，提升了摘要性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注一般疾病，缺乏针对癌症药物不良事件的摘要方法，资源有限且需求迫切。

Method: 提出GASCADE框架，结合LLMs的信息提取能力和T5模型的摘要能力，首次在摘要任务中应用对齐技术。

Result: GASCADE在多种指标上表现优异，通过自动和人工评估验证。

Conclusion: 该框架提升了药物决策效率，为个性化癌症护理提供了新途径，代码和数据集已公开。

Abstract: In the realm of cancer treatment, summarizing adverse drug events (ADEs)
reported by patients using prescribed drugs is crucial for enhancing
pharmacovigilance practices and improving drug-related decision-making. While
the volume and complexity of pharmacovigilance data have increased, existing
research in this field has predominantly focused on general diseases rather
than specifically addressing cancer. This work introduces the task of grouped
summarization of adverse drug events reported by multiple patients using the
same drug for cancer treatment. To address the challenge of limited resources
in cancer pharmacovigilance, we present the MultiLabeled Cancer Adverse Drug
Reaction and Summarization (MCADRS) dataset. This dataset includes
pharmacovigilance posts detailing patient concerns regarding drug efficacy and
adverse effects, along with extracted labels for drug names, adverse drug
events, severity, and adversity of reactions, as well as summaries of ADEs for
each drug. Additionally, we propose the Grouping and Abstractive Summarization
of Cancer Adverse Drug events (GASCADE) framework, a novel pipeline that
combines the information extraction capabilities of Large Language Models
(LLMs) with the summarization power of the encoder-decoder T5 model. Our work
is the first to apply alignment techniques, including advanced algorithms like
Direct Preference Optimization, to encoder-decoder models using synthetic
datasets for summarization tasks. Through extensive experiments, we demonstrate
the superior performance of GASCADE across various metrics, validated through
both automated assessments and human evaluations. This multitasking approach
enhances drug-related decision-making and fosters a deeper understanding of
patient concerns, paving the way for advancements in personalized and
responsive cancer care. The code and dataset used in this work are publicly
available.

</details>

### [15] [The Aloe Family Recipe for Open and Specialized Healthcare LLMs](https://arxiv.org/abs/2505.04388)
*Dario Garcia-Gasulla,Jordi Bayarri-Planas,Ashwin Kumar Gururajan,Enrique Lopez-Cuena,Adrian Tormos,Daniel Hinjos,Pablo Bernabeu-Perez,Anna Arias-Duart,Pablo Agustin Martin-Torres,Marta Gonzalez-Mallo,Sergio Alvarez-Napagao,Eduard Ayguadé-Parra,Ulises Cortés*

Main category: cs.CL

TLDR: 该论文提出了一种开源医疗大语言模型Aloe Beta，通过优化数据预处理和训练阶段，结合DPO和RAG提升模型安全性和效能，并定义了新的评估标准。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在医疗领域的应用增加，需要开源模型以保护公共利益。

Method: 基于Llama 3.1和Qwen 2.5，使用自定义数据集和DPO对齐，通过四种测试评估模型。

Result: Aloe Beta在医疗基准测试中表现优异，安全性显著提升，并附有详细风险评估。

Conclusion: Aloe Beta为开源医疗LLM领域树立了新标准，兼具高性能和伦理要求。

Abstract: Purpose: With advancements in Large Language Models (LLMs) for healthcare,
the need arises for competitive open-source models to protect the public
interest. This work contributes to the field of open medical LLMs by optimizing
key stages of data preprocessing and training, while showing how to improve
model safety (through DPO) and efficacy (through RAG). The evaluation
methodology used, which includes four different types of tests, defines a new
standard for the field. The resultant models, shown to be competitive with the
best private alternatives, are released with a permisive license.
  Methods: Building on top of strong base models like Llama 3.1 and Qwen 2.5,
Aloe Beta uses a custom dataset to enhance public data with synthetic Chain of
Thought examples. The models undergo alignment with Direct Preference
Optimization, emphasizing ethical and policy-aligned performance in the
presence of jailbreaking attacks. Evaluation includes close-ended, open-ended,
safety and human assessments, to maximize the reliability of results.
  Results: Recommendations are made across the entire pipeline, backed by the
solid performance of the Aloe Family. These models deliver competitive
performance across healthcare benchmarks and medical fields, and are often
preferred by healthcare professionals. On bias and toxicity, the Aloe Beta
models significantly improve safety, showing resilience to unseen jailbreaking
attacks. For a responsible release, a detailed risk assessment specific to
healthcare is attached to the Aloe Family models.
  Conclusion: The Aloe Beta models, and the recipe that leads to them, are a
significant contribution to the open-source medical LLM field, offering
top-of-the-line performance while maintaining high ethical requirements. This
work sets a new standard for developing and reporting aligned LLMs in
healthcare.

</details>

### [16] [Large Means Left: Political Bias in Large Language Models Increases with Their Number of Parameters](https://arxiv.org/abs/2505.04393)
*David Exler,Mark Schutera,Markus Reischl,Luca Rettenberger*

Main category: cs.CL

TLDR: 论文研究了大型语言模型（LLMs）在德国联邦议院投票背景下的政治偏见，发现其倾向于左翼政党，并探讨了语言、模型来源和发布时间对偏见的影响。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的普及，评估和减轻LLMs中的偏见对防止用户受到误导至关重要。

Method: 使用Wahl-O-Mat评分量化LLMs的政治偏见，比较模型对齐分数以识别影响因素。

Result: 发现LLMs倾向于左翼政党，语言沟通方式、模型来源和发布时间影响其政治观点。

Conclusion: LLMs易表现政治偏见，开发公司需承担责任以减少偏见对公众意见的影响。

Abstract: With the increasing prevalence of artificial intelligence, careful evaluation
of inherent biases needs to be conducted to form the basis for alleviating the
effects these predispositions can have on users. Large language models (LLMs)
are predominantly used by many as a primary source of information for various
topics. LLMs frequently make factual errors, fabricate data (hallucinations),
or present biases, exposing users to misinformation and influencing opinions.
Educating users on their risks is key to responsible use, as bias, unlike
hallucinations, cannot be caught through data verification. We quantify the
political bias of popular LLMs in the context of the recent vote of the German
Bundestag using the score produced by the Wahl-O-Mat. This metric measures the
alignment between an individual's political views and the positions of German
political parties. We compare the models' alignment scores to identify factors
influencing their political preferences. Doing so, we discover a bias toward
left-leaning parties, most dominant in larger LLMs. Also, we find that the
language we use to communicate with the models affects their political views.
Additionally, we analyze the influence of a model's origin and release date and
compare the results to the outcome of the recent vote of the Bundestag. Our
results imply that LLMs are prone to exhibiting political bias. Large
corporations with the necessary means to develop LLMs, thus, knowingly or
unknowingly, have a responsibility to contain these biases, as they can
influence each voter's decision-making process and inform public opinion in
general and at scale.

</details>

### [17] [YABLoCo: Yet Another Benchmark for Long Context Code Generation](https://arxiv.org/abs/2505.04406)
*Aidar Valeev,Roman Garaev,Vadim Lomshakov,Irina Piontkovskaya,Vladimir Ivanov,Israel Adewuyi*

Main category: cs.CL

TLDR: 论文提出YABLoCo基准，用于评估大语言模型在C/C++大型代码库中的函数生成能力，填补了现有基准的空白。


<details>
  <summary>Details</summary>
Motivation: 现有基准多针对小型代码库，而实际项目可能包含数百万行代码，需评估模型在大型代码库中的表现。

Method: 构建包含215个函数的测试集，涵盖不同依赖级别的函数上下文、文档、函数体和调用图，并提供可扩展的评估管道和可视化工具。

Result: YABLoCo基准支持C/C++语言，覆盖200K至2,000K行代码的大型代码库，为代码生成评估提供新标准。

Conclusion: 该基准为评估大语言模型在大型C/C++代码库中的代码生成能力提供了有效工具。

Abstract: Large Language Models demonstrate the ability to solve various programming
tasks, including code generation. Typically, the performance of LLMs is
measured on benchmarks with small or medium-sized context windows of thousands
of lines of code. At the same time, in real-world software projects,
repositories can span up to millions of LoC. This paper closes this gap by
contributing to the long context code generation benchmark (YABLoCo). The
benchmark featured a test set of 215 functions selected from four large
repositories with thousands of functions. The dataset contained metadata of
functions, contexts of the functions with different levels of dependencies,
docstrings, functions bodies, and call graphs for each repository. This paper
presents three key aspects of the contribution. First, the benchmark aims at
function body generation in large repositories in C and C++, two languages not
covered by previous benchmarks. Second, the benchmark contains large
repositories from 200K to 2,000K LoC. Third, we contribute a scalable
evaluation pipeline for efficient computing of the target metrics and a tool
for visual analysis of generated code. Overall, these three aspects allow for
evaluating code generation in large repositories in C and C++.

</details>

### [18] [OBLIVIATE: Robust and Practical Machine Unlearning for Large Language Models](https://arxiv.org/abs/2505.04416)
*Xiaoyu Xu,Minxin Du,Qingqing Ye,Haibo Hu*

Main category: cs.CL

TLDR: OBLIVIATE是一种高效的遗忘框架，用于从大型语言模型中移除敏感数据，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs可能记忆敏感、受版权保护或有毒内容的问题。

Method: 通过提取目标标记、构建保留集和使用定制损失函数（掩码、蒸馏和世界事实）进行微调，结合LoRA技术提高效率。

Result: 实验表明，OBLIVIATE能有效抵抗成员推理攻击，最小化对保留数据的影响，并在多种场景下保持鲁棒性。

Conclusion: OBLIVIATE为LLMs的安全性和实用性提供了可行的解决方案。

Abstract: Large language models (LLMs) trained over extensive corpora risk memorizing
sensitive, copyrighted, or toxic content. To address this, we propose
OBLIVIATE, a robust unlearning framework that removes targeted data while
preserving model utility. The framework follows a structured process:
extracting target tokens, building retain sets, and fine-tuning with a tailored
loss function comprising three components -- masking, distillation, and world
fact. Using low-rank adapters (LoRA), it ensures efficiency without
compromising unlearning quality. We conduct experiments on multiple datasets,
including the Harry Potter series, WMDP, and TOFU, using a comprehensive suite
of metrics: forget quality (new document-level memorization score), model
utility, and fluency. Results demonstrate its effectiveness in resisting
membership inference attacks, minimizing the impact on retained data, and
maintaining robustness across diverse scenarios.

</details>

### [19] [Detecting Spelling and Grammatical Anomalies in Russian Poetry Texts](https://arxiv.org/abs/2505.04507)
*Ilya Koziev*

Main category: cs.CL

TLDR: 论文提出通过自动语言异常检测提升生成模型训练数据的质量，特别是在诗歌生成等创意任务中。


<details>
  <summary>Details</summary>
Motivation: 互联网来源的训练文本缺乏质量控制，影响生成诗歌的流畅性和价值。

Method: 比较无监督和有监督的文本异常检测方法，并引入RUPOR数据集用于跨句语法错误检测。

Result: 提供了工具和见解，帮助提升创意领域生成模型的训练数据质量。

Conclusion: 自动化异常检测能有效改善训练数据集，提升生成模型的性能。

Abstract: The quality of natural language texts in fine-tuning datasets plays a
critical role in the performance of generative models, particularly in
computational creativity tasks such as poem or song lyric generation. Fluency
defects in generated poems significantly reduce their value. However, training
texts are often sourced from internet-based platforms without stringent quality
control, posing a challenge for data engineers to manage defect levels
effectively.
  To address this issue, we propose the use of automated linguistic anomaly
detection to identify and filter out low-quality texts from training datasets
for creative models. In this paper, we present a comprehensive comparison of
unsupervised and supervised text anomaly detection approaches, utilizing both
synthetic and human-labeled datasets. We also introduce the RUPOR dataset, a
collection of Russian-language human-labeled poems designed for cross-sentence
grammatical error detection, and provide the full evaluation code. Our work
aims to empower the community with tools and insights to improve the quality of
training datasets for generative models in creative domains.

</details>

### [20] [Pangu Ultra MoE: How to Train Your Big MoE on Ascend NPUs](https://arxiv.org/abs/2505.04519)
*Yehui Tang,Yichun Yin,Yaoyuan Wang,Hang Zhou,Yu Pan,Wei Guo,Ziyang Zhang,Miao Rang,Fangcheng Liu,Naifu Zhang,Binghan Li,Yonghan Dong,Xiaojun Meng,Yasheng Wang,Dong Li,Yin Li,Dandan Tu,Can Chen,Youliang Yan,Fisher Yu,Ruiming Tang,Yunhe Wang,Botian Huang,Bo Wang,Boxiao Liu,Changzheng Zhang,Da Kuang,Fei Liu,Gang Huang,Jiansheng Wei,Jiarui Qin,Jie Ran,Jinpeng Li,Jun Zhao,Liang Dai,Lin Li,Liqun Deng,Peifeng Qin,Pengyuan Zeng,Qiang Gu,Shaohua Tang,Shengjun Cheng,Tao Gao,Tao Yu,Tianshu Li,Tianyu Bi,Wei He,Weikai Mao,Wenyong Huang,Wulong Liu,Xiabing Li,Xianzhi Yu,Xueyu Wu,Xu He,Yangkai Du,Yan Xu,Ye Tian,Yimeng Wu,Yongbing Huang,Yong Tian,Yong Zhu,Yue Li,Yufei Wang,Yuhang Gai,Yujun Li,Yu Luo,Yunsheng Ni,Yusen Sun,Zelin Chen,Zhe Liu,Zhicheng Liu,Zhipeng Tu,Zilin Ding,Zongyuan Zhan*

Main category: cs.CL

TLDR: 论文探讨了如何在Ascend NPUs上高效训练稀疏大语言模型（LLMs），提出了Pangu Ultra MoE模型，并通过实验验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 稀疏大语言模型（如MoE）在万亿参数规模下面临软件和硬件系统的挑战，研究旨在优化Ascend NPUs上的资源利用和性能表现。

Method: 利用模拟比较模型超参数，优化专家并行性以减少通信开销，并提升设备内存效率。

Result: 训练Pangu Ultra MoE时实现了30.0%的MFU，性能与DeepSeek R1相当，验证了Ascend系统的能力。

Conclusion: 研究证明了在Ascend NPUs上高效训练大规模稀疏语言模型的可行性，并探讨了未来研究方向。

Abstract: Sparse large language models (LLMs) with Mixture of Experts (MoE) and close
to a trillion parameters are dominating the realm of most capable language
models. However, the massive model scale poses significant challenges for the
underlying software and hardware systems. In this paper, we aim to uncover a
recipe to harness such scale on Ascend NPUs. The key goals are better usage of
the computing resources under the dynamic sparse model structures and
materializing the expected performance gain on the actual hardware. To select
model configurations suitable for Ascend NPUs without repeatedly running the
expensive experiments, we leverage simulation to compare the trade-off of
various model hyperparameters. This study led to Pangu Ultra MoE, a sparse LLM
with 718 billion parameters, and we conducted experiments on the model to
verify the simulation results. On the system side, we dig into Expert
Parallelism to optimize the communication between NPU devices to reduce the
synchronization overhead. We also optimize the memory efficiency within the
devices to further reduce the parameter and activation management overhead. In
the end, we achieve an MFU of 30.0% when training Pangu Ultra MoE, with
performance comparable to that of DeepSeek R1, on 6K Ascend NPUs, and
demonstrate that the Ascend system is capable of harnessing all the training
stages of the state-of-the-art language models. Extensive experiments indicate
that our recipe can lead to efficient training of large-scale sparse language
models with MoE. We also study the behaviors of such models for future
reference.

</details>

### [21] [Overcoming Data Scarcity in Generative Language Modelling for Low-Resource Languages: A Systematic Review](https://arxiv.org/abs/2505.04531)
*Josh McGiff,Nikola S. Nikolov*

Main category: cs.CL

TLDR: 本文系统综述了针对低资源语言（LRL）生成式语言建模中数据稀缺问题的解决策略，总结了技术方法、架构选择及评估趋势，并提出了扩展应用和未来挑战的建议。


<details>
  <summary>Details</summary>
Motivation: 生成式语言模型（如ChatGPT）主要服务于高资源语言（如英语），加剧了NLP领域的语言不平等问题。本文旨在填补低资源语言生成式建模的研究空白。

Method: 基于54项研究，系统分类和评估了数据增强、反向翻译、多语言训练和提示工程等技术方法，并分析了模型架构、语言覆盖和评估方法。

Result: 研究发现过度依赖Transformer模型、LRL覆盖范围有限以及评估方法不一致等问题。

Conclusion: 建议扩展方法至更多LRL，并解决评估一致性等问题，以推动包容性AI工具的开发，支持语言多样性保护。

Abstract: Generative language modelling has surged in popularity with the emergence of
services such as ChatGPT and Google Gemini. While these models have
demonstrated transformative potential in productivity and communication, they
overwhelmingly cater to high-resource languages like English. This has
amplified concerns over linguistic inequality in natural language processing
(NLP). This paper presents the first systematic review focused specifically on
strategies to address data scarcity in generative language modelling for
low-resource languages (LRL). Drawing from 54 studies, we identify, categorise
and evaluate technical approaches, including monolingual data augmentation,
back-translation, multilingual training, and prompt engineering, across
generative tasks. We also analyse trends in architecture choices, language
family representation, and evaluation methods. Our findings highlight a strong
reliance on transformer-based models, a concentration on a small subset of
LRLs, and a lack of consistent evaluation across studies. We conclude with
recommendations for extending these methods to a wider range of LRLs and
outline open challenges in building equitable generative language systems.
Ultimately, this review aims to support researchers and developers in building
inclusive AI tools for underrepresented languages, a necessary step toward
empowering LRL speakers and the preservation of linguistic diversity in a world
increasingly shaped by large-scale language technologies.

</details>

### [22] [ZeroSearch: Incentivize the Search Capability of LLMs without Searching](https://arxiv.org/abs/2505.04588)
*Hao Sun,Zile Qiao,Jiayan Guo,Xuanbo Fan,Yingyan Hou,Yong Jiang,Pengjun Xie,Fei Huang,Yan Zhang*

Main category: cs.CL

TLDR: ZeroSearch是一种强化学习框架，通过避免与真实搜索引擎交互，激励大型语言模型（LLM）的搜索能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法中因搜索引擎返回文档质量不可控和API成本过高的问题。

Method: 采用轻量级监督微调将LLM转化为检索模块，并结合基于课程的策略逐步降低生成文档质量。

Result: 实验表明，ZeroSearch能有效激励LLM的搜索能力，甚至在某些情况下超越真实搜索引擎。

Conclusion: ZeroSearch是一种高效且可扩展的解决方案，适用于不同规模的LLM和多种RL算法。

Abstract: Effective information searching is essential for enhancing the reasoning and
generation capabilities of large language models (LLMs). Recent research has
explored using reinforcement learning (RL) to improve LLMs' search capabilities
by interacting with live search engines in real-world environments. While these
approaches show promising results, they face two major challenges: (1)
Uncontrolled Document Quality: The quality of documents returned by search
engines is often unpredictable, introducing noise and instability into the
training process. (2) Prohibitively High API Costs: RL training requires
frequent rollouts, potentially involving hundreds of thousands of search
requests, which incur substantial API expenses and severely constrain
scalability. To address these challenges, we introduce ZeroSearch, a
reinforcement learning framework that incentivizes the search capabilities of
LLMs without interacting with real search engines. Our approach begins with
lightweight supervised fine-tuning to transform the LLM into a retrieval module
capable of generating both relevant and noisy documents in response to a query.
During RL training, we employ a curriculum-based rollout strategy that
incrementally degrades the quality of generated documents, progressively
eliciting the model's reasoning ability by exposing it to increasingly
challenging retrieval scenarios. Extensive experiments demonstrate that
ZeroSearch effectively incentivizes the search capabilities of LLMs using a 3B
LLM as the retrieval module. Remarkably, a 7B retrieval module achieves
comparable performance to the real search engine, while a 14B retrieval module
even surpasses it. Furthermore, it generalizes well across both base and
instruction-tuned models of various parameter sizes and is compatible with a
wide range of RL algorithms.

</details>

<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [23] [Beyond Recognition: Evaluating Visual Perspective Taking in Vision Language Models](https://arxiv.org/abs/2505.03821)
*Gracjan Góral,Alicja Ziarko,Piotr Miłoś,Michał Nauman,Maciej Wołczyk,Michał Kosiński*

Main category: cs.CV

TLDR: 研究了视觉语言模型（VLMs）在视觉视角任务中的表现，发现其在场景理解上表现良好，但在空间推理和视角任务上表现较差。


<details>
  <summary>Details</summary>
Motivation: 探索VLMs在复杂视觉任务中的能力，尤其是视觉视角任务，以填补当前模型在空间和视角推理上的不足。

Method: 通过设计144个视觉任务，系统性地改变空间配置和视角，评估多个先进模型的表现。

Result: 模型在场景理解上表现优异，但在空间推理和视角任务上表现显著下降。

Conclusion: 未来VLM开发需整合显式几何表示和针对性训练，以提升复杂视觉任务的能力。

Abstract: We investigate the ability of Vision Language Models (VLMs) to perform visual
perspective taking using a novel set of visual tasks inspired by established
human tests. Our approach leverages carefully controlled scenes, in which a
single humanoid minifigure is paired with a single object. By systematically
varying spatial configurations - such as object position relative to the
humanoid minifigure and the humanoid minifigure's orientation - and using both
bird's-eye and surface-level views, we created 144 unique visual tasks. Each
visual task is paired with a series of 7 diagnostic questions designed to
assess three levels of visual cognition: scene understanding, spatial
reasoning, and visual perspective taking. Our evaluation of several
state-of-the-art models, including GPT-4-Turbo, GPT-4o,
Llama-3.2-11B-Vision-Instruct, and variants of Claude Sonnet, reveals that
while they excel in scene understanding, the performance declines significantly
on spatial reasoning and further deteriorates on perspective-taking. Our
analysis suggests a gap between surface-level object recognition and the deeper
spatial and perspective reasoning required for complex visual tasks, pointing
to the need for integrating explicit geometric representations and tailored
training protocols in future VLM development.

</details>

### [24] [In-situ and Non-contact Etch Depth Prediction in Plasma Etching via Machine Learning (ANN & BNN) and Digital Image Colorimetry](https://arxiv.org/abs/2505.03826)
*Minji Kang,Seongho Kim,Eunseo Go,Donghyeon Paek,Geon Lim,Muyoung Kim,Soyeun Kim,Sung Kyu Jang,Min Sup Choi,Woo Seok Kang,Jaehyun Kim,Jaekwang Kim,Hyeong-U Kim*

Main category: cs.CV

TLDR: 论文提出了一种基于机器学习的非接触式原位蚀刻深度预测框架，用于半导体制造中的绝缘材料厚度监测，通过人工神经网络和贝叶斯神经网络优化预测精度，并验证了数字图像比色法的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统的外部分析方法存在时间延迟和污染风险，需要一种实时、非侵入的监测方法以提高半导体制造的效率和稳定性。

Method: 研究采用人工神经网络（ANN）和贝叶斯神经网络（BNN）预测蚀刻深度，并探索了数字图像比色法（DIC）作为输入数据的可行性。

Result: ANN显著降低了均方误差，BNN能可靠估计不确定性；DIC数据在无明确工艺参数时仍表现良好。

Conclusion: 结合DIC和ML的方法为等离子蚀刻过程提供了一种经济高效的原位监测方案，提升了制造效率和工艺稳定性。

Abstract: Precise monitoring of etch depth and the thickness of insulating materials,
such as Silicon dioxide and silicon nitride, is critical to ensuring device
performance and yield in semiconductor manufacturing. While conventional
ex-situ analysis methods are accurate, they are constrained by time delays and
contamination risks. To address these limitations, this study proposes a
non-contact, in-situ etch depth prediction framework based on machine learning
(ML) techniques. Two scenarios are explored. In the first scenario, an
artificial neural network (ANN) is trained to predict average etch depth from
process parameters, achieving a significantly lower mean squared error (MSE)
compared to a linear baseline model. The approach is then extended to
incorporate variability from repeated measurements using a Bayesian Neural
Network (BNN) to capture both aleatoric and epistemic uncertainty. Coverage
analysis confirms the BNN's capability to provide reliable uncertainty
estimates. In the second scenario, we demonstrate the feasibility of using RGB
data from digital image colorimetry (DIC) as input for etch depth prediction,
achieving strong performance even in the absence of explicit process
parameters. These results suggest that the integration of DIC and ML offers a
viable, cost-effective alternative for real-time, in-situ, and non-invasive
monitoring in plasma etching processes, contributing to enhanced process
stability, and manufacturing efficiency.

</details>

### [25] [VideoLLM Benchmarks and Evaluation: A Survey](https://arxiv.org/abs/2505.03829)
*Yogesh Kumar*

Main category: cs.CV

TLDR: 本文综述了视频大语言模型（VideoLLMs）的评测基准和方法，分析了现有基准的特点、评测协议及局限性，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，视频理解技术取得显著进展，但缺乏系统性的评测框架。本文旨在填补这一空白，帮助研究者更有效地评估VideoLLMs。

Method: 通过分析现有视频理解基准和评测方法（如闭集、开集和时空任务评测），总结性能趋势和挑战。

Result: 揭示了当前评测框架的局限性，并提出了改进方向，如多样化、多模态和可解释性更强的基准设计。

Conclusion: 本文为研究者提供了评估VideoLLMs的结构化指南，并指出了推动视频理解领域发展的未来方向。

Abstract: The rapid development of Large Language Models (LLMs) has catalyzed
significant advancements in video understanding technologies. This survey
provides a comprehensive analysis of benchmarks and evaluation methodologies
specifically designed or used for Video Large Language Models (VideoLLMs). We
examine the current landscape of video understanding benchmarks, discussing
their characteristics, evaluation protocols, and limitations. The paper
analyzes various evaluation methodologies, including closed-set, open-set, and
specialized evaluations for temporal and spatiotemporal understanding tasks. We
highlight the performance trends of state-of-the-art VideoLLMs across these
benchmarks and identify key challenges in current evaluation frameworks.
Additionally, we propose future research directions to enhance benchmark
design, evaluation metrics, and protocols, including the need for more diverse,
multimodal, and interpretability-focused benchmarks. This survey aims to equip
researchers with a structured understanding of how to effectively evaluate
VideoLLMs and identify promising avenues for advancing the field of video
understanding with large language models.

</details>

### [26] [Video Forgery Detection for Surveillance Cameras: A Review](https://arxiv.org/abs/2505.03832)
*Noor B. Tayfor,Tarik A. Rashid,Shko M. Qader,Bryar A. Hassan,Mohammed H. Abdalla,Jafar Majidpour,Aram M. Ahmed,Hussein M. Ali,Aso M. Aladdin,Abdulhady A. Abdullah,Ahmed S. Shamsaldin,Haval M. Sidqi,Abdulrahman Salih,Zaher M. Yaseen,Azad A. Ameen,Janmenjoy Nayak,Mahmood Yashar Hamza*

Main category: cs.CV

TLDR: 本文综述了用于检测视频伪造的现有法证技术，重点探讨了其在验证监控录像真实性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着视频编辑工具的普及，监控录像的篡改问题日益严重，可能引发错误信息并影响司法公正，因此确保视频完整性至关重要。

Method: 研究了多种方法，包括基于压缩的分析、帧重复检测和基于机器学习的方法。

Result: 研究发现，需要更强大的法证技术以应对不断演变的伪造手段。

Conclusion: 加强视频法证能力将确保监控录像的可靠性和法律证据的可接受性。

Abstract: The widespread availability of video recording through smartphones and
digital devices has made video-based evidence more accessible than ever.
Surveillance footage plays a crucial role in security, law enforcement, and
judicial processes. However, with the rise of advanced video editing tools,
tampering with digital recordings has become increasingly easy, raising
concerns about their authenticity. Ensuring the integrity of surveillance
videos is essential, as manipulated footage can lead to misinformation and
undermine judicial decisions. This paper provides a comprehensive review of
existing forensic techniques used to detect video forgery, focusing on their
effectiveness in verifying the authenticity of surveillance recordings. Various
methods, including compression-based analysis, frame duplication detection, and
machine learning-based approaches, are explored. The findings highlight the
growing necessity for more robust forensic techniques to counteract evolving
forgery methods. Strengthening video forensic capabilities will ensure that
surveillance recordings remain credible and admissible as legal evidence.

</details>

### [27] [PointExplainer: Towards Transparent Parkinson's Disease Diagnosis](https://arxiv.org/abs/2505.03833)
*Xuechao Wang,Sven Nomm,Junqing Huang,Kadri Medijainen,Aaro Toomela,Michael Ruzhansky*

Main category: cs.CV

TLDR: PointExplainer是一种可解释的诊断策略，用于识别手绘区域对帕金森病早期诊断的贡献。


<details>
  <summary>Details</summary>
Motivation: 现有诊断方法缺乏清晰的可解释性，影响了临床信任。

Method: PointExplainer通过离散归因值量化手绘段的贡献，包括诊断模块和解释模块，并引入一致性度量。

Result: 在两个基准数据集和新构建的数据集上，PointExplainer提供了直观解释且未降低诊断性能。

Conclusion: PointExplainer能够提供直观且可信的解释，适用于帕金森病的早期诊断。

Abstract: Deep neural networks have shown potential in analyzing digitized hand-drawn
signals for early diagnosis of Parkinson's disease. However, the lack of clear
interpretability in existing diagnostic methods presents a challenge to
clinical trust. In this paper, we propose PointExplainer, an explainable
diagnostic strategy to identify hand-drawn regions that drive model diagnosis.
Specifically, PointExplainer assigns discrete attribution values to hand-drawn
segments, explicitly quantifying their relative contributions to the model's
decision. Its key components include: (i) a diagnosis module, which encodes
hand-drawn signals into 3D point clouds to represent hand-drawn trajectories,
and (ii) an explanation module, which trains an interpretable surrogate model
to approximate the local behavior of the black-box diagnostic model. We also
introduce consistency measures to further address the issue of faithfulness in
explanations. Extensive experiments on two benchmark datasets and a newly
constructed dataset show that PointExplainer can provide intuitive explanations
with no diagnostic performance degradation. The source code is available at
https://github.com/chaoxuewang/PointExplainer.

</details>

### [28] [Explainable Face Recognition via Improved Localization](https://arxiv.org/abs/2505.03837)
*Rashik Shadman,Daqing Hou,Faraz Hussain,M G Sarwar Murshed*

Main category: cs.CV

TLDR: 论文提出了一种基于Scaled Directed Divergence (SDD)的可解释人脸识别方法，通过精细定位相关面部特征，提高系统透明度和用户信任度。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习人脸识别系统缺乏解释性，用户难以信任其决策。

Method: 采用SDD类激活映射技术，精细定位与模型决策相关的面部特征。

Result: SDD CAM比传统CAM更精确地突出相关特征，提供更透明的视觉解释。

Conclusion: SDD方法显著提升了人脸识别系统的可解释性和用户信任度。

Abstract: Biometric authentication has become one of the most widely used tools in the
current technological era to authenticate users and to distinguish between
genuine users and imposters. Face is the most common form of biometric modality
that has proven effective. Deep learning-based face recognition systems are now
commonly used across different domains. However, these systems usually operate
like black-box models that do not provide necessary explanations or
justifications for their decisions. This is a major disadvantage because users
cannot trust such artificial intelligence-based biometric systems and may not
feel comfortable using them when clear explanations or justifications are not
provided. This paper addresses this problem by applying an efficient method for
explainable face recognition systems. We use a Class Activation Mapping
(CAM)-based discriminative localization (very narrow/specific localization)
technique called Scaled Directed Divergence (SDD) to visually explain the
results of deep learning-based face recognition systems. We perform fine
localization of the face features relevant to the deep learning model for its
prediction/decision. Our experiments show that the SDD Class Activation Map
(CAM) highlights the relevant face features very specifically compared to the
traditional CAM and very accurately. The provided visual explanations with
narrow localization of relevant features can ensure much-needed transparency
and trust for deep learning-based face recognition systems.

</details>

### [29] [GAME: Learning Multimodal Interactions via Graph Structures for Personality Trait Estimation](https://arxiv.org/abs/2505.03846)
*Kangsheng Wang,Yuhang Li,Chengwei Ye,Yufei Lin,Huanzhen Zhang,Bohan Hu,Linuo Xu,Shuyan Liu*

Main category: cs.CV

TLDR: GAME是一个图增强多模态编码器，用于从短视频中预测人格特质，通过融合视觉、听觉和文本特征，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 短视频中的人格分析因多源特征的复杂交互而具有挑战性，需要一种鲁棒的多模态融合方法。

Method: GAME结合了图卷积网络（GCN）和卷积神经网络（CNN）的双分支Geo Two-Stream Network，提取面部结构特征；同时使用ResNet18和VGGFace提取全局特征，BiGRU处理时序动态，VGGish提取音频特征，XLM-Roberta提取文本语义，并通过通道注意力融合模块整合多模态特征。

Result: GAME在多个基准测试中表现优于现有方法，验证了其有效性和泛化能力。

Conclusion: GAME通过多模态特征的有效融合，显著提升了人格预测的准确性。

Abstract: Apparent personality analysis from short videos poses significant chal-lenges
due to the complex interplay of visual, auditory, and textual cues. In this
paper, we propose GAME, a Graph-Augmented Multimodal Encoder designed to
robustly model and fuse multi-source features for automatic personality
prediction. For the visual stream, we construct a facial graph and introduce a
dual-branch Geo Two-Stream Network, which combines Graph Convolutional Networks
(GCNs) and Convolutional Neural Net-works (CNNs) with attention mechanisms to
capture both structural and appearance-based facial cues. Complementing this,
global context and iden-tity features are extracted using pretrained ResNet18
and VGGFace back-bones. To capture temporal dynamics, frame-level features are
processed by a BiGRU enhanced with temporal attention modules. Meanwhile, audio
representations are derived from the VGGish network, and linguistic se-mantics
are captured via the XLM-Roberta transformer. To achieve effective multimodal
integration, we propose a Channel Attention-based Fusion module, followed by a
Multi-Layer Perceptron (MLP) regression head for predicting personality traits.
Extensive experiments show that GAME con-sistently outperforms existing methods
across multiple benchmarks, vali-dating its effectiveness and generalizability.

</details>

### [30] [Advanced Clustering Framework for Semiconductor Image Analytics Integrating Deep TDA with Self-Supervised and Transfer Learning Techniques](https://arxiv.org/abs/2505.03848)
*Janhavi Giri,Attila Lengyel,Don Kent,Edward Kibardin*

Main category: cs.CV

TLDR: 论文提出了一种结合深度拓扑数据分析（TDA）、自监督学习和迁移学习的先进聚类框架，用于半导体制造中的图像数据聚类，解决了传统方法在高维无标签数据中的局限性。


<details>
  <summary>Details</summary>
Motivation: 半导体制造产生大量图像数据，传统聚类方法难以处理高维无标签数据，无法捕捉细微模式。

Method: 结合TDA提取拓扑特征，自监督学习从无标签数据中提取有意义的表示，迁移学习增强框架的适应性和可扩展性。

Result: 在合成和开源半导体图像数据集上验证，成功识别出与缺陷模式和工艺变化相关的聚类。

Conclusion: 该框架为半导体制造等领域的大规模图像数据提供了可扩展的解决方案，具有主动过程监控和质量控制的潜力。

Abstract: Semiconductor manufacturing generates vast amounts of image data, crucial for
defect identification and yield optimization, yet often exceeds manual
inspection capabilities. Traditional clustering techniques struggle with
high-dimensional, unlabeled data, limiting their effectiveness in capturing
nuanced patterns. This paper introduces an advanced clustering framework that
integrates deep Topological Data Analysis (TDA) with self-supervised and
transfer learning techniques, offering a novel approach to unsupervised image
clustering. TDA captures intrinsic topological features, while self-supervised
learning extracts meaningful representations from unlabeled data, reducing
reliance on labeled datasets. Transfer learning enhances the framework's
adaptability and scalability, allowing fine-tuning to new datasets without
retraining from scratch. Validated on synthetic and open-source semiconductor
image datasets, the framework successfully identifies clusters aligned with
defect patterns and process variations. This study highlights the
transformative potential of combining TDA, self-supervised learning, and
transfer learning, providing a scalable solution for proactive process
monitoring and quality control in semiconductor manufacturing and other domains
with large-scale image datasets.

</details>

### [31] [An Active Inference Model of Covert and Overt Visual Attention](https://arxiv.org/abs/2505.03856)
*Tin Mišić,Karlo Koledić,Fabio Bonsignorio,Ivan Petrović,Ivan Marković*

Main category: cs.CV

TLDR: 该论文提出了一种基于主动推理的视觉注意力模型，通过动态优化感官精度来最小化自由能，研究了外源性和内源性注意力的交互作用及其在Posner提示任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 研究如何在复杂感官输入中选择性关注相关刺激并过滤干扰，为智能体提供高效的注意力机制。

Method: 利用主动推理框架动态优化感官精度，测试模型在Posner提示任务和目标聚焦任务中的行为，测量反应时间。

Result: 外源性和有效提示通常导致更快的反应时间；模型表现出类似抑制返回的行为；反射性眼动比有意眼动更快但适应性较差。

Conclusion: 模型成功模拟了注意力的动态特性，为理解外源性和内源性注意力机制提供了新视角。

Abstract: The ability to selectively attend to relevant stimuli while filtering out
distractions is essential for agents that process complex, high-dimensional
sensory input. This paper introduces a model of covert and overt visual
attention through the framework of active inference, utilizing dynamic
optimization of sensory precisions to minimize free-energy. The model
determines visual sensory precisions based on both current environmental
beliefs and sensory input, influencing attentional allocation in both covert
and overt modalities. To test the effectiveness of the model, we analyze its
behavior in the Posner cueing task and a simple target focus task using
two-dimensional(2D) visual data. Reaction times are measured to investigate the
interplay between exogenous and endogenous attention, as well as valid and
invalid cueing. The results show that exogenous and valid cues generally lead
to faster reaction times compared to endogenous and invalid cues. Furthermore,
the model exhibits behavior similar to inhibition of return, where previously
attended locations become suppressed after a specific cue-target onset
asynchrony interval. Lastly, we investigate different aspects of overt
attention and show that involuntary, reflexive saccades occur faster than
intentional ones, but at the expense of adaptability.

</details>

### [32] [Novel Extraction of Discriminative Fine-Grained Feature to Improve Retinal Vessel Segmentation](https://arxiv.org/abs/2505.03896)
*Shuang Zeng,Chee Hong Lee,Micky C Nnamdi,Wenqi Shi,J Ben Tamo,Lei Zhu,Hangzhou He,Xinliang Zhang,Qian Chen,May D. Wang,Yanye Lu,Qiushi Ren*

Main category: cs.CV

TLDR: 提出了一种名为AttUKAN的新型注意力U形Kolmogorov-Arnold网络及标签引导的像素级对比损失，用于视网膜血管分割，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分利用编码器的细粒度特征表示，导致视网膜血管分割的判别性特征提取不足。

Method: 在Kolmogorov-Arnold网络中引入注意力门，并设计标签引导的像素级对比损失，以增强特征提取能力。

Result: 在多个数据集上取得最高F1和MIoU分数，优于11种现有网络。

Conclusion: AttUKAN在视网膜血管分割任务中表现最优，代码已开源。

Abstract: Retinal vessel segmentation is a vital early detection method for several
severe ocular diseases. Despite significant progress in retinal vessel
segmentation with the advancement of Neural Networks, there are still
challenges to overcome. Specifically, retinal vessel segmentation aims to
predict the class label for every pixel within a fundus image, with a primary
focus on intra-image discrimination, making it vital for models to extract more
discriminative features. Nevertheless, existing methods primarily focus on
minimizing the difference between the output from the decoder and the label,
but ignore fully using feature-level fine-grained representations from the
encoder. To address these issues, we propose a novel Attention U-shaped
Kolmogorov-Arnold Network named AttUKAN along with a novel Label-guided
Pixel-wise Contrastive Loss for retinal vessel segmentation. Specifically, we
implement Attention Gates into Kolmogorov-Arnold Networks to enhance model
sensitivity by suppressing irrelevant feature activations and model
interpretability by non-linear modeling of KAN blocks. Additionally, we also
design a novel Label-guided Pixel-wise Contrastive Loss to supervise our
proposed AttUKAN to extract more discriminative features by distinguishing
between foreground vessel-pixel pairs and background pairs. Experiments are
conducted across four public datasets including DRIVE, STARE, CHASE_DB1, HRF
and our private dataset. AttUKAN achieves F1 scores of 82.50%, 81.14%, 81.34%,
80.21% and 80.09%, along with MIoU scores of 70.24%, 68.64%, 68.59%, 67.21% and
66.94% in the above datasets, which are the highest compared to 11 networks for
retinal vessel segmentation. Quantitative and qualitative results show that our
AttUKAN achieves state-of-the-art performance and outperforms existing retinal
vessel segmentation methods. Our code will be available at
https://github.com/stevezs315/AttUKAN.

</details>

### [33] [Deep Learning Framework for Infrastructure Maintenance: Crack Detection and High-Resolution Imaging of Infrastructure Surfaces](https://arxiv.org/abs/2505.03974)
*Nikhil M. Pawar,Jorge A. Prozzi,Feng Hong,Surya Sarat Chandra Congress*

Main category: cs.CV

TLDR: 本文提出了一种结合CNN和ESPCNN的框架，用于高效超分辨率和减少误报，以提升基础设施图像中的损伤检测精度。


<details>
  <summary>Details</summary>
Motivation: 现有超分辨率技术因处理所有图像（包括无损伤图像）导致计算成本高和误报多，需要一种更高效的方法。

Method: 使用CNN分类图像（有/无损伤），再用轻量级ESPCNN对有损伤图像进行超分辨率处理。

Result: ESPCNN在超分辨率指标上优于双三次插值，且框架能减少计算成本和误报。

Conclusion: 该框架可帮助高速公路机构高效检测损伤，优化资产管理。

Abstract: Recently, there has been an impetus for the application of cutting-edge data
collection platforms such as drones mounted with camera sensors for
infrastructure asset management. However, the sensor characteristics, proximity
to the structure, hard-to-reach access, and environmental conditions often
limit the resolution of the datasets. A few studies used super-resolution
techniques to address the problem of low-resolution images. Nevertheless, these
techniques were observed to increase computational cost and false alarms of
distress detection due to the consideration of all the infrastructure images
i.e., positive and negative distress classes. In order to address the
pre-processing of false alarm and achieve efficient super-resolution, this
study developed a framework consisting of convolutional neural network (CNN)
and efficient sub-pixel convolutional neural network (ESPCNN). CNN accurately
classified both the classes. ESPCNN, which is the lightweight super-resolution
technique, generated high-resolution infrastructure image of positive distress
obtained from CNN. The ESPCNN outperformed bicubic interpolation in all the
evaluation metrics for super-resolution. Based on the performance metrics, the
combination of CNN and ESPCNN was observed to be effective in preprocessing the
infrastructure images with negative distress, reducing the computational cost
and false alarms in the next step of super-resolution. The visual inspection
showed that EPSCNN is able to capture crack propagation, complex geometry of
even minor cracks. The proposed framework is expected to help the highway
agencies in accurately performing distress detection and assist in efficient
asset management practices.

</details>

### [34] [Action Spotting and Precise Event Detection in Sports: Datasets, Methods, and Challenges](https://arxiv.org/abs/2505.03991)
*Hao Xu,Arbind Agrahari Baniya,Sam Well,Mohamed Reda Bouadjenek,Richard Dazeley,Sunil Aryal*

Main category: cs.CV

TLDR: 该论文综述了视频事件检测在体育分析中的重要性，重点介绍了TAL、AS和PES三大任务，并分析了相关数据集、评估方法和最新技术。


<details>
  <summary>Details</summary>
Motivation: 视频事件检测对体育分析至关重要，能够自动化识别关键时刻，提升表现分析、观众参与和转播效率。

Method: 综述了TAL、AS和PES三大任务的方法论演变，包括多模态方法、自监督学习和知识蒸馏技术。

Result: 总结了现有数据集和评估指标的优缺点，并分析了最先进技术的应用和局限性。

Conclusion: 提出了未来研究方向，旨在开发更通用、高效和鲁棒的事件检测框架。

Abstract: Video event detection has become an essential component of sports analytics,
enabling automated identification of key moments and enhancing performance
analysis, viewer engagement, and broadcast efficiency. Recent advancements in
deep learning, particularly Convolutional Neural Networks (CNNs) and
Transformers, have significantly improved accuracy and efficiency in Temporal
Action Localization (TAL), Action Spotting (AS), and Precise Event Spotting
(PES). This survey provides a comprehensive overview of these three key tasks,
emphasizing their differences, applications, and the evolution of
methodological approaches. We thoroughly review and categorize existing
datasets and evaluation metrics specifically tailored for sports contexts,
highlighting the strengths and limitations of each. Furthermore, we analyze
state-of-the-art techniques, including multi-modal approaches that integrate
audio and visual information, methods utilizing self-supervised learning and
knowledge distillation, and approaches aimed at generalizing across multiple
sports. Finally, we discuss critical open challenges and outline promising
research directions toward developing more generalized, efficient, and robust
event detection frameworks applicable to diverse sports. This survey serves as
a foundation for future research on efficient, generalizable, and multi-modal
sports event detection.

</details>

### [35] [The Eye as a Window to Systemic Health: A Survey of Retinal Imaging from Classical Techniques to Oculomics](https://arxiv.org/abs/2505.04006)
*Inamullah,Imran Razzak,Shoaib Jameel*

Main category: cs.CV

TLDR: 视网膜成像技术结合人工智能分析，为眼部及全身疾病提供早期检测和干预的新途径。


<details>
  <summary>Details</summary>
Motivation: 利用视网膜独特的血管化结构作为健康监测窗口，推动眼部与非眼部疾病的早期发现与干预。

Method: 综述视网膜成像技术的演变，探讨AI驱动分析的整合需求，以及从传统技术向眼组学的转变。

Result: 揭示了眼组学在眼科和全身疾病中的应用潜力，并指出研究中的挑战与未来方向。

Conclusion: 眼组学为疾病监测提供了非侵入性标记，但仍需克服技术障碍以推动其发展。

Abstract: The unique vascularized anatomy of the human eye, encased in the retina,
provides an opportunity to act as a window for human health. The retinal
structure assists in assessing the early detection, monitoring of disease
progression and intervention for both ocular and non-ocular diseases. The
advancement in imaging technology leveraging Artificial Intelligence has seized
this opportunity to bridge the gap between the eye and human health. This track
paves the way for unveiling systemic health insight from the ocular system and
surrogating non-invasive markers for timely intervention and identification.
The new frontiers of oculomics in ophthalmology cover both ocular and systemic
diseases, and getting more attention to explore them. In this survey paper, we
explore the evolution of retinal imaging techniques, the dire need for the
integration of AI-driven analysis, and the shift of retinal imaging from
classical techniques to oculomics. We also discuss some hurdles that may be
faced in the progression of oculomics, highlighting the research gaps and
future directions.

</details>

### [36] [FoodTrack: Estimating Handheld Food Portions with Egocentric Video](https://arxiv.org/abs/2505.04055)
*Ervin Wang,Yuhao Chen*

Main category: cs.CV

TLDR: FoodTrack框架通过第一视角视频直接测量手持食物体积，克服了传统方法的限制，提高了食物摄入跟踪的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统食物摄入跟踪方法依赖特定相机角度、无遮挡图像或手势识别，且假设咬合大小，无法直接测量食物体积。

Method: 提出FoodTrack框架，利用第一视角视频直接估计食物体积，无需依赖手势或固定咬合假设。

Result: 在手持食物对象上，绝对百分比损失约为7.01%，优于之前方法在最佳情况下的16.40%误差。

Conclusion: FoodTrack提供了一种更准确、适应性更强的食物摄入跟踪解决方案。

Abstract: Accurately tracking food consumption is crucial for nutrition and health
monitoring. Traditional approaches typically require specific camera angles,
non-occluded images, or rely on gesture recognition to estimate intake, making
assumptions about bite size rather than directly measuring food volume. We
propose the FoodTrack framework for tracking and measuring the volume of
hand-held food items using egocentric video which is robust to hand occlusions
and flexible with varying camera and object poses. FoodTrack estimates food
volume directly, without relying on intake gestures or fixed assumptions about
bite size, offering a more accurate and adaptable solution for tracking food
consumption. We achieve absolute percentage loss of approximately 7.01% on a
handheld food object, improving upon a previous approach that achieved a 16.40%
mean absolute percentage error in its best case, under less flexible
conditions.

</details>

### [37] [AS3D: 2D-Assisted Cross-Modal Understanding with Semantic-Spatial Scene Graphs for 3D Visual Grounding](https://arxiv.org/abs/2505.04058)
*Feng Xiao,Hongbin Xu,Guocan Zhao,Wenxiong Kang*

Main category: cs.CV

TLDR: 提出了一种基于2D辅助的3D视觉定位框架，通过构建语义-空间场景图提升关系感知能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决3D与语言模态间的显著差异，特别是在区分多个相似物体时，现有方法忽略了被指称物体的感知。

Method: 采用双分支视觉编码器，利用2D预训练属性指导多模态对象编码，并通过图注意力机制实现跨模态交互。

Result: 在主流基准测试中表现优异，尤其在处理多个相似干扰物时效果显著。

Conclusion: 通过增强对象表示和迭代关系学习，实现了3D视觉与指称描述间的有效对齐。

Abstract: 3D visual grounding aims to localize the unique target described by natural
languages in 3D scenes. The significant gap between 3D and language modalities
makes it a notable challenge to distinguish multiple similar objects through
the described spatial relationships. Current methods attempt to achieve
cross-modal understanding in complex scenes via a target-centered learning
mechanism, ignoring the perception of referred objects. We propose a novel
2D-assisted 3D visual grounding framework that constructs semantic-spatial
scene graphs with referred object discrimination for relationship perception.
The framework incorporates a dual-branch visual encoder that utilizes 2D
pre-trained attributes to guide the multi-modal object encoding. Furthermore,
our cross-modal interaction module uses graph attention to facilitate
relationship-oriented information fusion. The enhanced object representation
and iterative relational learning enable the model to establish effective
alignment between 3D vision and referential descriptions. Experimental results
on the popular benchmarks demonstrate our superior performance compared to
state-of-the-art methods, especially in addressing the challenges of multiple
similar distractors.

</details>

### [38] [SEVA: Leveraging Single-Step Ensemble of Vicinal Augmentations for Test-Time Adaptation](https://arxiv.org/abs/2505.04087)
*Zixuan Hu,Yichun Hu,Ling-Yu Duan*

Main category: cs.CV

TLDR: SEVA是一种新型的测试时适应方法，通过单步集成邻近增强技术，在不增加计算负担的情况下提升模型对分布变化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有TTA方法依赖单轮熵训练，无法充分利用可靠样本，且增强策略虽有效但计算成本高。

Method: 提出SEVA，通过理论框架分析多重增强对模型适应的影响，并优化熵损失上界以集成多轮增强训练效果。

Result: SEVA在多种网络架构和测试场景中表现出色，同时满足实时性要求。

Conclusion: SEVA通过高效损失和互补选择策略，显著提升了可靠样本的潜力，并具有广泛适应性。

Abstract: Test-Time adaptation (TTA) aims to enhance model robustness against
distribution shifts through rapid model adaptation during inference. While
existing TTA methods often rely on entropy-based unsupervised training and
achieve promising results, the common practice of a single round of entropy
training is typically unable to adequately utilize reliable samples, hindering
adaptation efficiency. In this paper, we discover augmentation strategies can
effectively unleash the potential of reliable samples, but the rapidly growing
computational cost impedes their real-time application. To address this
limitation, we propose a novel TTA approach named Single-step Ensemble of
Vicinal Augmentations (SEVA), which can take advantage of data augmentations
without increasing the computational burden. Specifically, instead of
explicitly utilizing the augmentation strategy to generate new data, SEVA
develops a theoretical framework to explore the impacts of multiple
augmentations on model adaptation and proposes to optimize an upper bound of
the entropy loss to integrate the effects of multiple rounds of augmentation
training into a single step. Furthermore, we discover and verify that using the
upper bound as the loss is more conducive to the selection mechanism, as it can
effectively filter out harmful samples that confuse the model. Combining these
two key advantages, the proposed efficient loss and a complementary selection
strategy can simultaneously boost the potential of reliable samples and meet
the stringent time requirements of TTA. The comprehensive experiments on
various network architectures across challenging testing scenarios demonstrate
impressive performances and the broad adaptability of SEVA. The code will be
publicly available.

</details>

### [39] [SMMT: Siamese Motion Mamba with Self-attention for Thermal Infrared Target Tracking](https://arxiv.org/abs/2505.04088)
*Shang Zhang,Huanbin Zhang,Dali Feng,Yujie Cui,Ruoyan Xiong,Cen He*

Main category: cs.CV

TLDR: 本文提出了一种新型的Siamese Motion Mamba Tracker (SMMT)，通过双向状态空间模型和自注意力机制解决TIR目标跟踪中的遮挡、运动模糊和背景干扰问题。


<details>
  <summary>Details</summary>
Motivation: TIR目标跟踪常因目标遮挡、运动模糊和背景干扰导致性能下降，需一种更有效的跟踪方法。

Method: 结合双向状态空间模型和自注意力机制，引入Motion Mamba模块提取运动特征，采用Siamese参数共享策略减少计算冗余，并设计运动边缘感知回归损失提升精度。

Result: 在四个TIR跟踪基准测试中，SMMT表现出优越性能。

Conclusion: SMMT通过创新设计和优化策略，显著提升了TIR目标跟踪的准确性和鲁棒性。

Abstract: Thermal infrared (TIR) object tracking often suffers from challenges such as
target occlusion, motion blur, and background clutter, which significantly
degrade the performance of trackers. To address these issues, this paper
pro-poses a novel Siamese Motion Mamba Tracker (SMMT), which integrates a
bidirectional state-space model and a self-attention mechanism. Specifically,
we introduce the Motion Mamba module into the Siamese architecture to ex-tract
motion features and recover overlooked edge details using bidirectional
modeling and self-attention. We propose a Siamese parameter-sharing strate-gy
that allows certain convolutional layers to share weights. This approach
reduces computational redundancy while preserving strong feature
represen-tation. In addition, we design a motion edge-aware regression loss to
improve tracking accuracy, especially for motion-blurred targets. Extensive
experi-ments are conducted on four TIR tracking benchmarks, including
LSOTB-TIR, PTB-TIR, VOT-TIR2015, and VOT-TIR 2017. The results show that SMMT
achieves superior performance in TIR target tracking.

</details>

### [40] [MAISY: Motion-Aware Image SYnthesis for MedicalImage Motion Correction](https://arxiv.org/abs/2505.04105)
*Andrew Zhang,Hao Wang,Shuchang Ye,Michael Fulham,Jinman Kim*

Main category: cs.CV

TLDR: 论文提出MAISY方法，通过动态学习运动特征和引入VS-SSIM损失函数，显著提升医学图像去运动伪影的效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于GAN的方法在去运动伪影时忽略局部特征且SSIM损失函数对像素强度变化敏感，导致效果受限。

Method: MAISY结合Segment Anything Model动态学习运动特征，并引入VS-SSIM损失函数自适应处理高方差区域。

Result: 在胸部和头部CT数据上，PSNR提升40%，SSIM提升10%，Dice提升16%。

Conclusion: MAISY通过改进局部特征学习和损失函数设计，显著优于现有方法。

Abstract: Patient motion during medical image acquisition causes blurring, ghosting,
and distorts organs, which makes image interpretation challenging.Current
state-of-the-art algorithms using Generative Adversarial Network (GAN)-based
methods with their ability to learn the mappings between corrupted images and
their ground truth via Structural Similarity Index Measure (SSIM) loss
effectively generate motion-free images. However, we identified the following
limitations: (i) they mainly focus on global structural characteristics and
therefore overlook localized features that often carry critical pathological
information, and (ii) the SSIM loss function struggles to handle images with
varying pixel intensities, luminance factors, and variance. In this study, we
propose Motion-Aware Image SYnthesis (MAISY) which initially characterize
motion and then uses it for correction by: (a) leveraging the foundation model
Segment Anything Model (SAM), to dynamically learn spatial patterns along
anatomical boundaries where motion artifacts are most pronounced and, (b)
introducing the Variance-Selective SSIM (VS-SSIM) loss which adaptively
emphasizes spatial regions with high pixel variance to preserve essential
anatomical details during artifact correction. Experiments on chest and head CT
datasets demonstrate that our model outperformed the state-of-the-art
counterparts, with Peak Signal-to-Noise Ratio (PSNR) increasing by 40%, SSIM by
10%, and Dice by 16%.

</details>

### [41] [One2Any: One-Reference 6D Pose Estimation for Any Object](https://arxiv.org/abs/2505.04109)
*Mengya Liu,Siyuan Li,Ajad Chhatkuli,Prune Truong,Luc Van Gool,Federico Tombari*

Main category: cs.CV

TLDR: 论文提出了一种名为One2Any的新方法，仅需单张参考-查询RGB-D图像即可估计6D物体姿态，无需3D模型或多视角数据。


<details>
  <summary>Details</summary>
Motivation: 解决现有6D物体姿态估计方法对完整3D模型、多视角图像或特定类别训练的依赖问题，提升对新物体的泛化能力。

Method: 将物体姿态估计视为编码-解码过程，通过单张参考视图生成全面的参考物体姿态嵌入（ROPE），再通过U-Net解码模块生成新视角的参考物体坐标（ROC）。

Result: 在多个基准数据集上表现优异，泛化能力强，精度和鲁棒性达到SOTA，甚至优于需要多视角或CAD输入的方法。

Conclusion: One2Any方法简单高效，支持大规模训练，适用于新物体姿态估计，计算成本低。

Abstract: 6D object pose estimation remains challenging for many applications due to
dependencies on complete 3D models, multi-view images, or training limited to
specific object categories. These requirements make generalization to novel
objects difficult for which neither 3D models nor multi-view images may be
available. To address this, we propose a novel method One2Any that estimates
the relative 6-degrees of freedom (DOF) object pose using only a single
reference-single query RGB-D image, without prior knowledge of its 3D model,
multi-view data, or category constraints. We treat object pose estimation as an
encoding-decoding process, first, we obtain a comprehensive Reference Object
Pose Embedding (ROPE) that encodes an object shape, orientation, and texture
from a single reference view. Using this embedding, a U-Net-based pose decoding
module produces Reference Object Coordinate (ROC) for new views, enabling fast
and accurate pose estimation. This simple encoding-decoding framework allows
our model to be trained on any pair-wise pose data, enabling large-scale
training and demonstrating great scalability. Experiments on multiple benchmark
datasets demonstrate that our model generalizes well to novel objects,
achieving state-of-the-art accuracy and robustness even rivaling methods that
require multi-view or CAD inputs, at a fraction of compute.

</details>

### [42] [GAPrompt: Geometry-Aware Point Cloud Prompt for 3D Vision Model](https://arxiv.org/abs/2505.04119)
*Zixiang Ai,Zichen Liu,Yuanhang Lei,Zhenyu Cui,Xu Zou,Jiahuan Zhou*

Main category: cs.CV

TLDR: 论文提出了一种几何感知的点云提示方法（GAPrompt），通过几何线索增强3D视觉模型的适应性，显著优于现有参数高效微调方法，同时仅需少量可训练参数。


<details>
  <summary>Details</summary>
Motivation: 预训练的3D视觉模型在下游任务中完全微调计算和存储成本高，现有参数高效微调方法因几何信息捕捉能力有限表现不佳。

Method: 提出GAPrompt，包括点提示（Point Prompt）、点位移提示器（Point Shift Prompter）和提示传播机制（Prompt Propagation），以增强几何信息捕捉。

Result: GAPrompt在多个基准测试中显著优于现有方法，性能接近完全微调，仅需2.19%的可训练参数。

Conclusion: GAPrompt为3D视觉模型的参数高效微调提供了有效解决方案，显著提升了性能并降低了资源需求。

Abstract: Pre-trained 3D vision models have gained significant attention for their
promising performance on point cloud data. However, fully fine-tuning these
models for downstream tasks is computationally expensive and storage-intensive.
Existing parameter-efficient fine-tuning (PEFT) approaches, which focus
primarily on input token prompting, struggle to achieve competitive performance
due to their limited ability to capture the geometric information inherent in
point clouds. To address this challenge, we propose a novel Geometry-Aware
Point Cloud Prompt (GAPrompt) that leverages geometric cues to enhance the
adaptability of 3D vision models. First, we introduce a Point Prompt that
serves as an auxiliary input alongside the original point cloud, explicitly
guiding the model to capture fine-grained geometric details. Additionally, we
present a Point Shift Prompter designed to extract global shape information
from the point cloud, enabling instance-specific geometric adjustments at the
input level. Moreover, our proposed Prompt Propagation mechanism incorporates
the shape information into the model's feature extraction process, further
strengthening its ability to capture essential geometric characteristics.
Extensive experiments demonstrate that GAPrompt significantly outperforms
state-of-the-art PEFT methods and achieves competitive results compared to full
fine-tuning on various benchmarks, while utilizing only 2.19% of trainable
parameters. Our code is available at
https://github.com/zhoujiahuan1991/ICML2025-VGP.

</details>

### [43] [Vision Graph Prompting via Semantic Low-Rank Decomposition](https://arxiv.org/abs/2505.04121)
*Zixiang Ai,Zichen Liu,Jiahuan Zhou*

Main category: cs.CV

TLDR: ViG通过图结构表示图像，优于传统网格或序列表示。本文提出VGP框架，针对视觉图结构设计，利用低秩语义特征提升ViG在下游任务中的迁移性能。


<details>
  <summary>Details</summary>
Motivation: 现有提示方法主要针对Transformer模型，忽略了图结构中节点和边的拓扑关系，限制了复杂语义建模能力。

Method: 提出Vision Graph Prompting (VGP)，基于低秩语义特征分解，将语义提示与视觉图拓扑结合。

Result: 实验表明VGP显著提升ViG在下游任务的迁移性能，接近全微调效果且参数高效。

Conclusion: VGP为视觉图结构提供了一种有效的提示方法，平衡了性能和参数效率。

Abstract: Vision GNN (ViG) demonstrates superior performance by representing images as
graph structures, providing a more natural way to capture irregular semantic
patterns beyond traditional grid or sequence-based representations. To
efficiently adapt ViG to downstream tasks, parameter-efficient fine-tuning
techniques like visual prompting become increasingly essential. However,
existing prompting methods are primarily designed for Transformer-based models,
neglecting the rich topological relationships among nodes and edges in
graph-based representations, limiting their capacity to model complex
semantics. In this paper, we propose Vision Graph Prompting (VGP), a novel
framework tailored for vision graph structures. Our core insight reveals that
semantically connected components in the graph exhibit low-rank properties.
Building on this observation, we introduce a semantic low-rank prompting method
that decomposes low-rank semantic features and integrates them with prompts on
vision graph topologies, capturing both global structural patterns and
fine-grained semantic dependencies. Extensive experiments demonstrate our
method significantly improves ViG's transfer performance on diverse downstream
tasks, achieving results comparable to full fine-tuning while maintaining
parameter efficiency. Our code is available at
https://github.com/zhoujiahuan1991/ICML2025-VGP.

</details>

### [44] [R^3-VQA: "Read the Room" by Video Social Reasoning](https://arxiv.org/abs/2505.04147)
*Lixing Niu,Jiapeng Li,Xingping Yu,Shu Wang,Ruining Feng,Bo Wu,Ping Wei,Yisen Wang,Lifeng Fan*

Main category: cs.CV

TLDR: 论文提出了一个高质量视频数据集R^3-VQA，用于复杂社交场景中的社交推理任务，评估了当前视觉语言模型的社交推理能力，发现其与人类水平仍有差距，并提出ToM提示方法提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 现有社交推理任务和数据集过于简单，无法反映真实社交互动的复杂性，因此需要更全面的数据集和任务来评估和改进模型的社交推理能力。

Method: 构建了R^3-VQA数据集，包含复杂社交场景的视频、精细标注的社交事件和心智状态（如信念、意图、欲望、情绪）以及社交因果链，并设计了三个任务：社交事件理解、心智状态估计和社交因果推理。

Result: 实验表明，当前视觉语言模型在复杂社交推理任务中表现远低于人类水平，但ToM提示方法能有效提升其表现。

Conclusion: R^3-VQA为社交推理研究提供了新基准，未来需进一步改进模型以接近人类水平的社交推理能力。

Abstract: "Read the room" is a significant social reasoning capability in human daily
life. Humans can infer others' mental states from subtle social cues. Previous
social reasoning tasks and datasets lack complexity (e.g., simple scenes, basic
interactions, incomplete mental state variables, single-step reasoning, etc.)
and fall far short of the challenges present in real-life social interactions.
In this paper, we contribute a valuable, high-quality, and comprehensive video
dataset named R^3-VQA with precise and fine-grained annotations of social
events and mental states (i.e., belief, intent, desire, and emotion) as well as
corresponding social causal chains in complex social scenarios. Moreover, we
include human-annotated and model-generated QAs. Our task R^3-VQA includes
three aspects: Social Event Understanding, Mental State Estimation, and Social
Causal Reasoning. As a benchmark, we comprehensively evaluate the social
reasoning capabilities and consistencies of current state-of-the-art large
vision-language models (LVLMs). Comprehensive experiments show that (i) LVLMs
are still far from human-level consistent social reasoning in complex social
scenarios; (ii) Theory of Mind (ToM) prompting can help LVLMs perform better on
social reasoning tasks. We provide some of our dataset and codes in
supplementary material and will release our full dataset and codes upon
acceptance.

</details>

### [45] [Learning from Similarity Proportion Loss for Classifying Skeletal Muscle Recovery Stages](https://arxiv.org/abs/2505.04150)
*Yu Yamaoka or Weng Ian Chan,Shigeto Seno,Soichiro Fukada,Hideo Matsuda*

Main category: cs.CV

TLDR: 论文提出了一种名为OSLSP的弱监督学习方法，用于自动化评估肌肉组织再生过程，解决了现有方法无法适应肌肉组织特征和忽略类别序数信息的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统肌肉组织再生评估依赖专家视觉检查，缺乏定量和客观性。现有弱监督学习方法（LLP）无法适应肌肉组织特征且忽略序数信息，需改进。

Method: 提出OSLSP方法，利用相似性比例损失和类别比例注意力机制，更新特征提取器并保留类别序数信息。

Result: OSLSP在骨骼肌恢复阶段分类任务中表现优于大规模预训练和微调模型。

Conclusion: OSLSP为肌肉组织再生评估提供了一种自动化、定量且保留序数信息的解决方案。

Abstract: Evaluating the regeneration process of damaged muscle tissue is a fundamental
analysis in muscle research to measure experimental effect sizes and uncover
mechanisms behind muscle weakness due to aging and disease. The conventional
approach to assessing muscle tissue regeneration involves whole-slide imaging
and expert visual inspection of the recovery stages based on the morphological
information of cells and fibers. There is a need to replace these tasks with
automated methods incorporating machine learning techniques to ensure a
quantitative and objective analysis. Given the limited availability of fully
labeled data, a possible approach is Learning from Label Proportions (LLP), a
weakly supervised learning method using class label proportions. However,
current LLP methods have two limitations: (1) they cannot adapt the feature
extractor for muscle tissues, and (2) they treat the classes representing
recovery stages and cell morphological changes as nominal, resulting in the
loss of ordinal information. To address these issues, we propose Ordinal Scale
Learning from Similarity Proportion (OSLSP), which uses a similarity proportion
loss derived from two bag combinations. OSLSP can update the feature extractor
by using class proportion attention to the ordinal scale of the class. Our
model with OSLSP outperforms large-scale pre-trained and fine-tuning models in
classification tasks of skeletal muscle recovery stages.

</details>

### [46] [DOTA: Deformable Optimized Transformer Architecture for End-to-End Text Recognition with Retrieval-Augmented Generation](https://arxiv.org/abs/2505.04175)
*Naphat Nithisopa,Teerapong Panboonyuen*

Main category: cs.CV

TLDR: 本文提出了一种结合ResNet和Vision Transformer的创新端到端框架，通过Deformable Convolutions、Retrieval-Augmented Generation和CRF提升OCR性能，在多个数据集上达到新SOTA。


<details>
  <summary>Details</summary>
Motivation: 自然图像中的文本识别是一个重要但具有挑战性的任务，广泛应用于计算机视觉和自然语言处理领域。

Method: 框架采用ResNet和Vision Transformer作为主干网络，引入Deformable Convolutions、自适应dropout和CRF，优化特征表示和序列建模。

Result: 在六个基准数据集上验证，平均准确率达77.77%，部分数据集表现优异（如IC13达97.32%）。

Conclusion: 该方法在文本识别任务中表现出色，为多样化和挑战性数据集提供了鲁棒的解决方案。

Abstract: Text recognition in natural images remains a challenging yet essential task,
with broad applications spanning computer vision and natural language
processing. This paper introduces a novel end-to-end framework that combines
ResNet and Vision Transformer backbones with advanced methodologies, including
Deformable Convolutions, Retrieval-Augmented Generation, and Conditional Random
Fields (CRF). These innovations collectively enhance feature representation and
improve Optical Character Recognition (OCR) performance. Specifically, the
framework substitutes standard convolution layers in the third and fourth
blocks with Deformable Convolutions, leverages adaptive dropout for
regularization, and incorporates CRF for more refined sequence modeling.
Extensive experiments conducted on six benchmark datasets IC13, IC15, SVT,
IIIT5K, SVTP, and CUTE80 validate the proposed method's efficacy, achieving
notable accuracies: 97.32% on IC13, 58.26% on IC15, 88.10% on SVT, 74.13% on
IIIT5K, 82.17% on SVTP, and 66.67% on CUTE80, resulting in an average accuracy
of 77.77%. These results establish a new state-of-the-art for text recognition,
demonstrating the robustness of the approach across diverse and challenging
datasets.

</details>

### [47] [S3D: Sketch-Driven 3D Model Generation](https://arxiv.org/abs/2505.04185)
*Hail Song,Wonsik Shin,Naeun Lee,Soomin Chung,Nojun Kwak,Woontack Woo*

Main category: cs.CV

TLDR: S3D框架通过U-Net架构和风格对齐损失，将手绘草图转化为高质量3D模型。


<details>
  <summary>Details</summary>
Motivation: 解决2D草图因模糊和稀疏性导致3D建模困难的问题。

Method: 采用U-Net编码器-解码器架构生成面部分割掩码，结合风格对齐损失和增强技术提升鲁棒性。

Result: 生成高质量3D模型，支持多视角渲染。

Conclusion: S3D框架有效解决了草图到3D模型的转换问题，代码已开源。

Abstract: Generating high-quality 3D models from 2D sketches is a challenging task due
to the inherent ambiguity and sparsity of sketch data. In this paper, we
present S3D, a novel framework that converts simple hand-drawn sketches into
detailed 3D models. Our method utilizes a U-Net-based encoder-decoder
architecture to convert sketches into face segmentation masks, which are then
used to generate a 3D representation that can be rendered from novel views. To
ensure robust consistency between the sketch domain and the 3D output, we
introduce a novel style-alignment loss that aligns the U-Net bottleneck
features with the initial encoder outputs of the 3D generation module,
significantly enhancing reconstruction fidelity. To further enhance the
network's robustness, we apply augmentation techniques to the sketch dataset.
This streamlined framework demonstrates the effectiveness of S3D in generating
high-quality 3D models from sketch inputs. The source code for this project is
publicly available at https://github.com/hailsong/S3D.

</details>

### [48] [VideoPath-LLaVA: Pathology Diagnostic Reasoning Through Video Instruction Tuning](https://arxiv.org/abs/2505.04192)
*Trinh T. L. Vuong,Jin Tae Kwak*

Main category: cs.CV

TLDR: VideoPath-LLaVA是首个结合单张图像、自动提取关键帧视频和手动分割视频的多模态模型，模拟病理学家诊断过程。


<details>
  <summary>Details</summary>
Motivation: 通过整合多种图像场景，模拟病理学家的自然诊断流程，提升AI在病理视频分析中的表现。

Method: 利用VideoPath-Instruct数据集（4278对视频和诊断链式指令），结合单图像指令数据集知识迁移，训练模型。

Result: 在病理视频分析中设立新基准，为临床决策支持系统提供基础。

Conclusion: VideoPath-LLaVA为未来AI系统在病理诊断中的视觉与推理结合提供了可行方案。

Abstract: We present VideoPath-LLaVA, the first large multimodal model (LMM) in
computational pathology that integrates three distinct image scenarios, single
patch images, automatically keyframe-extracted clips, and manually segmented
video pathology images, to mimic the natural diagnostic process of
pathologists. By generating detailed histological descriptions and culminating
in a definitive sign-out diagnosis, VideoPath-LLaVA bridges visual narratives
with diagnostic reasoning.
  Central to our approach is the VideoPath-Instruct dataset, comprising 4278
video and diagnosis-specific chain-of-thought instructional pairs sourced from
educational histopathology videos on YouTube. Although high-quality data is
critical for enhancing diagnostic reasoning, its creation is time-intensive and
limited in volume. To overcome this challenge, we transfer knowledge from
existing single-image instruction datasets to train on weakly annotated,
keyframe-extracted clips, followed by fine-tuning on manually segmented videos.
VideoPath-LLaVA establishes a new benchmark in pathology video analysis and
offers a promising foundation for future AI systems that support clinical
decision-making through integrated visual and diagnostic reasoning. Our code,
data, and model are publicly available at
https://github.com/trinhvg/VideoPath-LLaVA.

</details>

### [49] [SToLa: Self-Adaptive Touch-Language Framework with Tactile Commonsense Reasoning in Open-Ended Scenarios](https://arxiv.org/abs/2505.04201)
*Ning Cheng,Jinan Xu,Jialing Chen,Wenjuan Han*

Main category: cs.CV

TLDR: 论文提出SToLa框架，解决触觉与语言模态整合的挑战，通过Mixture of Experts动态管理多模态，并构建触觉常识推理数据集，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决触觉感知在智能系统中的两大挑战：模态差异和触觉数据稀缺，以实现开放物理世界的常识推理。

Method: 引入SToLa框架，利用Mixture of Experts动态处理触觉与语言模态，并构建触觉常识推理数据集。

Result: SToLa在PhysiCLeAR基准和自建数据集上表现优异，验证了MoE架构在多模态管理中的优势。

Conclusion: SToLa框架有效解决了触觉与语言模态整合问题，为开放场景触觉常识推理提供了性能优势。

Abstract: This paper explores the challenges of integrating tactile sensing into
intelligent systems for multimodal reasoning, particularly in enabling
commonsense reasoning about the open-ended physical world. We identify two key
challenges: modality discrepancy, where existing large touch-language models
often treat touch as a mere sub-modality of language, and open-ended tactile
data scarcity, where current datasets lack the diversity, open-endness and
complexity needed for reasoning. To overcome these challenges, we introduce
SToLa, a Self-Adaptive Touch-Language framework. SToLa utilizes Mixture of
Experts (MoE) to dynamically process, unify, and manage tactile and language
modalities, capturing their unique characteristics. Crucially, we also present
a comprehensive tactile commonsense reasoning dataset and benchmark featuring
free-form questions and responses, 8 physical properties, 4 interactive
characteristics, and diverse commonsense knowledge. Experiments show SToLa
exhibits competitive performance compared to existing models on the PhysiCLeAR
benchmark and self-constructed datasets, proving the effectiveness of the
Mixture of Experts architecture in multimodal management and the performance
advantages for open-scenario tactile commonsense reasoning tasks.

</details>

### [50] [An Enhanced YOLOv8 Model for Real-Time and Accurate Pothole Detection and Measurement](https://arxiv.org/abs/2505.04207)
*Mustafa Yurdakul,Şakir Tasdemir*

Main category: cs.CV

TLDR: 论文提出了一种基于改进YOLOv8的模型，用于坑洞检测及其物理特征分析，通过RGB-D数据集（PothRGBD）和动态蛇形卷积（DSConv）、简单注意力模块（SimAM）等技术提升性能。


<details>
  <summary>Details</summary>
Motivation: 坑洞导致车辆损坏和交通事故，现有方法仅基于2D RGB图像，无法准确分析坑洞物理特征，因此需要更精确的检测方法。

Method: 使用Intel RealSense D415深度相机采集RGB-D数据，构建PothRGBD数据集；改进YOLOv8n-seg模型，引入DSConv、SimAM和GELU。

Result: 改进模型在精度、召回率和mAP@50上分别提升1.96%、6.13%和2.07%，达到93.7%、90.4%和93.8%。

Conclusion: 该模型轻量高效，适用于实时应用，为智能交通提供了深度学习解决方案。

Abstract: Potholes cause vehicle damage and traffic accidents, creating serious safety
and economic problems. Therefore, early and accurate detection of potholes is
crucial. Existing detection methods are usually only based on 2D RGB images and
cannot accurately analyze the physical characteristics of potholes. In this
paper, a publicly available dataset of RGB-D images (PothRGBD) is created and
an improved YOLOv8-based model is proposed for both pothole detection and
pothole physical features analysis. The Intel RealSense D415 depth camera was
used to collect RGB and depth data from the road surfaces, resulting in a
PothRGBD dataset of 1000 images. The data was labeled in YOLO format suitable
for segmentation. A novel YOLO model is proposed based on the YOLOv8n-seg
architecture, which is structurally improved with Dynamic Snake Convolution
(DSConv), Simple Attention Module (SimAM) and Gaussian Error Linear Unit
(GELU). The proposed model segmented potholes with irregular edge structure
more accurately, and performed perimeter and depth measurements on depth maps
with high accuracy. The standard YOLOv8n-seg model achieved 91.9% precision,
85.2% recall and 91.9% mAP@50. With the proposed model, the values increased to
93.7%, 90.4% and 93.8% respectively. Thus, an improvement of 1.96% in
precision, 6.13% in recall and 2.07% in mAP was achieved. The proposed model
performs pothole detection as well as perimeter and depth measurement with high
accuracy and is suitable for real-time applications due to its low model
complexity. In this way, a lightweight and effective model that can be used in
deep learning-based intelligent transportation solutions has been acquired.

</details>

### [51] [CM1 -- A Dataset for Evaluating Few-Shot Information Extraction with Large Vision Language Models](https://arxiv.org/abs/2505.04214)
*Fabian Wolf,Oliver Tüselmann,Arthur Matei,Lukas Hennies,Christoph Rass,Gernot A. Fink*

Main category: cs.CV

TLDR: 该论文提出了一种用于评估大型视觉语言模型（LVLM）少样本能力的新数据集CM1，并展示了LVLM在少量训练数据下优于传统全页提取模型。


<details>
  <summary>Details</summary>
Motivation: 手写文档中关键值信息的自动提取是文档分析的关键挑战，尤其在标注数据稀缺的情况下，LVLM技术具有潜力。

Method: 设计了CM1数据集，包含历史表单的手写条目，并建立了三个基准任务（姓名和出生日期提取），同时考虑了不同训练集规模。

Result: 实验表明，传统全页模型表现优异，但在少量训练样本下，LVLM凭借其规模和预训练优势超越传统方法。

Conclusion: LVLM在少样本场景下具有优势，为文档数字化提供了新思路。

Abstract: The automatic extraction of key-value information from handwritten documents
is a key challenge in document analysis. A reliable extraction is a
prerequisite for the mass digitization efforts of many archives. Large Vision
Language Models (LVLM) are a promising technology to tackle this problem
especially in scenarios where little annotated training data is available. In
this work, we present a novel dataset specifically designed to evaluate the
few-shot capabilities of LVLMs. The CM1 documents are a historic collection of
forms with handwritten entries created in Europe to administer the Care and
Maintenance program after World War Two. The dataset establishes three
benchmarks on extracting name and birthdate information and, furthermore,
considers different training set sizes. We provide baseline results for two
different LVLMs and compare performances to an established full-page extraction
model. While the traditional full-page model achieves highly competitive
performances, our experiments show that when only a few training samples are
available the considered LVLMs benefit from their size and heavy pretraining
and outperform the classical approach.

</details>

### [52] [A Weak Supervision Learning Approach Towards an Equitable Parking Lot Occupancy Estimation](https://arxiv.org/abs/2505.04229)
*Theophilus Aidoo,Till Koebe,Akansh Maurya,Hewan Shrestha,Ingmar Weber*

Main category: cs.CV

TLDR: 提出了一种弱监督框架，利用3米分辨率卫星图像和粗粒度时间标签估计停车场占用率，减少对高分辨率图像的依赖。


<details>
  <summary>Details</summary>
Motivation: 高分辨率标记图像稀缺且昂贵，尤其在低收入地区，限制了遥感应用的发展。

Method: 利用基于时间假设的粗粒度标签（如德国超市和五金店停车场周六满、周日空），训练成对比较模型。

Result: 模型在大型停车场上的AUC达到0.92，展示了良好的性能。

Conclusion: 该方法可扩展用于城市移动性分析，并有望改善脆弱社区的交通模式和资源分配。

Abstract: The scarcity and high cost of labeled high-resolution imagery have long
challenged remote sensing applications, particularly in low-income regions
where high-resolution data are scarce. In this study, we propose a weak
supervision framework that estimates parking lot occupancy using 3m resolution
satellite imagery. By leveraging coarse temporal labels -- based on the
assumption that parking lots of major supermarkets and hardware stores in
Germany are typically full on Saturdays and empty on Sundays -- we train a
pairwise comparison model that achieves an AUC of 0.92 on large parking lots.
The proposed approach minimizes the reliance on expensive high-resolution
images and holds promise for scalable urban mobility analysis. Moreover, the
method can be adapted to assess transit patterns and resource allocation in
vulnerable communities, providing a data-driven basis to improve the well-being
of those most in need.

</details>

### [53] [Bridging Geometry-Coherent Text-to-3D Generation with Multi-View Diffusion Priors and Gaussian Splatting](https://arxiv.org/abs/2505.04262)
*Feng Yang,Wenliang Qian,Wangmeng Zuo,Hui Li*

Main category: cs.CV

TLDR: Score Distillation Sampling (SDS) 在文本到3D生成中忽略了多视角关联，导致几何不一致和多面伪影。本文提出 Coupled Score Distillation (CSD)，通过耦合多视角联合分布先验，实现几何一致的3D生成，并直接优化3D高斯泼溅。


<details>
  <summary>Details</summary>
Motivation: 解决SDS在3D生成中因忽略多视角关联导致的几何不一致和多面伪影问题。

Method: 提出CSD框架，将优化问题重新表述为多视角联合优化，并直接优化3D高斯泼溅。使用可变形四面体网格进一步细化生成的高质量网格。

Result: 实验结果表明，该方法在效率和生成质量上具有竞争力。

Conclusion: CSD通过耦合多视角先验，实现了几何一致的3D生成，并直接优化3D高斯泼溅，生成高质量3D内容。

Abstract: Score Distillation Sampling (SDS) leverages pretrained 2D diffusion models to
advance text-to-3D generation but neglects multi-view correlations, being prone
to geometric inconsistencies and multi-face artifacts in the generated 3D
content. In this work, we propose Coupled Score Distillation (CSD), a framework
that couples multi-view joint distribution priors to ensure geometrically
consistent 3D generation while enabling the stable and direct optimization of
3D Gaussian Splatting. Specifically, by reformulating the optimization as a
multi-view joint optimization problem, we derive an effective optimization rule
that effectively couples multi-view priors to guide optimization across
different viewpoints while preserving the diversity of generated 3D assets.
Additionally, we propose a framework that directly optimizes 3D Gaussian
Splatting (3D-GS) with random initialization to generate geometrically
consistent 3D content. We further employ a deformable tetrahedral grid,
initialized from 3D-GS and refined through CSD, to produce high-quality,
refined meshes. Quantitative and qualitative experimental results demonstrate
the efficiency and competitive quality of our approach.

</details>

### [54] [Object-Shot Enhanced Grounding Network for Egocentric Video](https://arxiv.org/abs/2505.04270)
*Yisen Feng,Haoyu Zhang,Meng Liu,Weili Guan,Liqiang Nie*

Main category: cs.CV

TLDR: OSGNet提出了一种针对自我中心视频的物体-镜头增强定位网络，通过提取物体信息和镜头运动特征，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了自我中心视频的关键特征和细粒度信息，OSGNet旨在解决这一问题。

Method: 提取视频中的物体信息以丰富视频表示，并分析镜头运动特征以增强模态对齐能力。

Result: 在三个数据集上实现了最先进的性能。

Conclusion: OSGNet通过结合物体和镜头特征，有效提升了自我中心视频定位任务的性能。

Abstract: Egocentric video grounding is a crucial task for embodied intelligence
applications, distinct from exocentric video moment localization. Existing
methods primarily focus on the distributional differences between egocentric
and exocentric videos but often neglect key characteristics of egocentric
videos and the fine-grained information emphasized by question-type queries. To
address these limitations, we propose OSGNet, an Object-Shot enhanced Grounding
Network for egocentric video. Specifically, we extract object information from
videos to enrich video representation, particularly for objects highlighted in
the textual query but not directly captured in the video features.
Additionally, we analyze the frequent shot movements inherent to egocentric
videos, leveraging these features to extract the wearer's attention
information, which enhances the model's ability to perform modality alignment.
Experiments conducted on three datasets demonstrate that OSGNet achieves
state-of-the-art performance, validating the effectiveness of our approach. Our
code can be found at https://github.com/Yisen-Feng/OSGNet.

</details>

### [55] [HDiffTG: A Lightweight Hybrid Diffusion-Transformer-GCN Architecture for 3D Human Pose Estimation](https://arxiv.org/abs/2505.04276)
*Yajie Fu,Chaorui Huang,Junwei Li,Hui Kong,Yibin Tian,Huakang Li,Zhiyuan Zhang*

Main category: cs.CV

TLDR: HDiffTG是一种结合Transformer、GCN和扩散模型的新型3D人体姿态估计方法，显著提升了准确性和鲁棒性，同时保持轻量化设计。


<details>
  <summary>Details</summary>
Motivation: 解决3D人体姿态估计中全局与局部特征平衡问题，提升在遮挡和复杂场景下的性能。

Method: 整合Transformer捕获全局时空依赖，GCN建模局部骨骼结构，扩散模型逐步优化，并引入轻量化优化。

Result: 在Human3.6M和MPI-INF-3DHP数据集上达到SOTA性能，尤其在噪声和遮挡环境下表现优异。

Conclusion: HDiffTG通过多技术融合实现了高效、准确的3D姿态估计，适用于复杂场景。

Abstract: We propose HDiffTG, a novel 3D Human Pose Estimation (3DHPE) method that
integrates Transformer, Graph Convolutional Network (GCN), and diffusion model
into a unified framework. HDiffTG leverages the strengths of these techniques
to significantly improve pose estimation accuracy and robustness while
maintaining a lightweight design. The Transformer captures global
spatiotemporal dependencies, the GCN models local skeletal structures, and the
diffusion model provides step-by-step optimization for fine-tuning, achieving a
complementary balance between global and local features. This integration
enhances the model's ability to handle pose estimation under occlusions and in
complex scenarios. Furthermore, we introduce lightweight optimizations to the
integrated model and refine the objective function design to reduce
computational overhead without compromising performance. Evaluation results on
the Human3.6M and MPI-INF-3DHP datasets demonstrate that HDiffTG achieves
state-of-the-art (SOTA) performance on the MPI-INF-3DHP dataset while excelling
in both accuracy and computational efficiency. Additionally, the model exhibits
exceptional robustness in noisy and occluded environments. Source codes and
models are available at https://github.com/CirceJie/HDiffTG

</details>

### [56] [TS-Diff: Two-Stage Diffusion Model for Low-Light RAW Image Enhancement](https://arxiv.org/abs/2505.04281)
*Yi Li,Zhiyuan Zhang,Jiangnan Xia,Jianghan Cheng,Qilong Wu,Junwei Li,Yibin Tian,Hui Kong*

Main category: cs.CV

TLDR: TS-Diff是一种新颖的两阶段扩散模型，用于增强极低光RAW图像。通过虚拟相机和噪声空间合成图像，结合CFI模块学习通用特征，并通过微调适应特定相机噪声。引入颜色校正器和结构重参数化技术，提升效率和一致性。实验证明其在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决极低光条件下RAW图像增强的挑战，包括噪声、颜色偏移和通用性问题。

Method: 两阶段模型：预训练阶段通过虚拟相机合成噪声图像，学习通用特征；对齐阶段微调适应特定相机噪声。引入CFI模块、颜色校正器和结构重参数化技术。

Result: 在QID、SID和ELD数据集上实现最优性能，表现出去噪、通用性和颜色一致性的优势。

Conclusion: TS-Diff是一种鲁棒且通用的低光图像增强解决方案，适用于多种相机和光照条件。

Abstract: This paper presents a novel Two-Stage Diffusion Model (TS-Diff) for enhancing
extremely low-light RAW images. In the pre-training stage, TS-Diff synthesizes
noisy images by constructing multiple virtual cameras based on a noise space.
Camera Feature Integration (CFI) modules are then designed to enable the model
to learn generalizable features across diverse virtual cameras. During the
aligning stage, CFIs are averaged to create a target-specific CFI$^T$, which is
fine-tuned using a small amount of real RAW data to adapt to the noise
characteristics of specific cameras. A structural reparameterization technique
further simplifies CFI$^T$ for efficient deployment. To address color shifts
during the diffusion process, a color corrector is introduced to ensure color
consistency by dynamically adjusting global color distributions. Additionally,
a novel dataset, QID, is constructed, featuring quantifiable illumination
levels and a wide dynamic range, providing a comprehensive benchmark for
training and evaluation under extreme low-light conditions. Experimental
results demonstrate that TS-Diff achieves state-of-the-art performance on
multiple datasets, including QID, SID, and ELD, excelling in denoising,
generalization, and color consistency across various cameras and illumination
levels. These findings highlight the robustness and versatility of TS-Diff,
making it a practical solution for low-light imaging applications. Source codes
and models are available at https://github.com/CircccleK/TS-Diff

</details>

### [57] [MoDE: Mixture of Diffusion Experts for Any Occluded Face Recognition](https://arxiv.org/abs/2505.04306)
*Qiannan Fan,Zhuoyang Li,Jitong Li,Chenyang Cao*

Main category: cs.CV

TLDR: 提出了一种基于扩散专家混合模型（MoDE）的遮挡人脸识别方法，通过身份门控网络自适应整合多重建人脸信息，显著提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 当前遮挡人脸识别算法缺乏对遮挡的先验知识，导致实际应用中性能不佳，影响日常生活便利性。

Method: 采用扩散生成专家估计遮挡人脸的完整图像，并通过身份门控网络评估和整合多重建人脸的身份贡献。

Result: 在三个公开人脸数据集和两个真实场景数据集上验证了方法的优越性能。

Conclusion: MoDE是一种即插即用模块，适用于现有大多数人脸识别模型，显著提升了遮挡人脸识别的效果。

Abstract: With the continuous impact of epidemics, people have become accustomed to
wearing masks. However, most current occluded face recognition (OFR) algorithms
lack prior knowledge of occlusions, resulting in poor performance when dealing
with occluded faces of varying types and severity in reality. Recognizing
occluded faces is still a significant challenge, which greatly affects the
convenience of people's daily lives. In this paper, we propose an
identity-gated mixture of diffusion experts (MoDE) for OFR. Each
diffusion-based generative expert estimates one possible complete image for
occluded faces. Considering the random sampling process of the diffusion model,
which introduces inevitable differences and variations between the inpainted
faces and the real ones. To ensemble effective information from
multi-reconstructed faces, we introduce an identity-gating network to evaluate
the contribution of each reconstructed face to the identity and adaptively
integrate the predictions in the decision space. Moreover, our MoDE is a
plug-and-play module for most existing face recognition models. Extensive
experiments on three public face datasets and two datasets in the wild validate
our advanced performance for various occlusions in comparison with the
competing methods.

</details>

### [58] [Multi-turn Consistent Image Editing](https://arxiv.org/abs/2505.04320)
*Zijun Zhou,Yingying Deng,Xiangyu He,Weiming Dong,Fan Tang*

Main category: cs.CV

TLDR: 提出了一种多轮图像编辑框架，通过迭代优化解决单步编辑的不足，显著提升编辑成功率和视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑方法多为单步操作，难以处理模糊用户意图或复杂变换，导致结果不一致或不符合预期。

Method: 采用流匹配实现精确图像反演，双目标LQR稳定采样，自适应注意力增强方法保持多轮一致性。

Result: 实验表明，框架显著优于现有方法，编辑成功率和视觉保真度大幅提升。

Conclusion: 多轮迭代编辑框架有效解决了单步编辑的局限性，为复杂图像编辑任务提供了更优解决方案。

Abstract: Many real-world applications, such as interactive photo retouching, artistic
content creation, and product design, require flexible and iterative image
editing. However, existing image editing methods primarily focus on achieving
the desired modifications in a single step, which often struggles with
ambiguous user intent, complex transformations, or the need for progressive
refinements. As a result, these methods frequently produce inconsistent
outcomes or fail to meet user expectations. To address these challenges, we
propose a multi-turn image editing framework that enables users to iteratively
refine their edits, progressively achieving more satisfactory results. Our
approach leverages flow matching for accurate image inversion and a
dual-objective Linear Quadratic Regulators (LQR) for stable sampling,
effectively mitigating error accumulation. Additionally, by analyzing the
layer-wise roles of transformers, we introduce a adaptive attention
highlighting method that enhances editability while preserving multi-turn
coherence. Extensive experiments demonstrate that our framework significantly
improves edit success rates and visual fidelity compared to existing methods.

</details>

### [59] [CountDiffusion: Text-to-Image Synthesis with Training-Free Counting-Guidance Diffusion](https://arxiv.org/abs/2505.04347)
*Yanyu Li,Pencheng Wan,Liang Han,Yaowei Wang,Liqiang Nie,Min Zhang*

Main category: cs.CV

TLDR: CountDiffusion是一种无需训练的框架，用于从文本描述生成具有正确对象数量的图像，通过两阶段校正提升T2I模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决Stable Diffusion在生成图像时对象数量不准确的问题，避免高计算成本和抽象概念学习的挑战。

Method: 两阶段框架：首先生成中间去噪结果并计数对象数量，第二阶段通过注意力图校正对象数量。

Result: 实验表明CountDiffusion显著提升了T2I模型生成准确对象数量的能力。

Conclusion: CountDiffusion是一种高效且无需额外训练的解决方案，可轻松集成到现有T2I模型中。

Abstract: Stable Diffusion has advanced text-to-image synthesis, but training models to
generate images with accurate object quantity is still difficult due to the
high computational cost and the challenge of teaching models the abstract
concept of quantity. In this paper, we propose CountDiffusion, a training-free
framework aiming at generating images with correct object quantity from textual
descriptions. CountDiffusion consists of two stages. In the first stage, an
intermediate denoising result is generated by the diffusion model to predict
the final synthesized image with one-step denoising, and a counting model is
used to count the number of objects in this image. In the second stage, a
correction module is used to correct the object quantity by changing the
attention map of the object with universal guidance. The proposed
CountDiffusion can be plugged into any diffusion-based text-to-image (T2I)
generation models without further training. Experiment results demonstrate the
superiority of our proposed CountDiffusion, which improves the accurate object
quantity generation ability of T2I models by a large margin.

</details>

### [60] [WDMamba: When Wavelet Degradation Prior Meets Vision Mamba for Image Dehazing](https://arxiv.org/abs/2505.04369)
*Jie Sun,Heng Liu,Yongzhen Wang,Xiao-Ping Zhang,Mingqiang Wei*

Main category: cs.CV

TLDR: 本文提出了一种基于小波变换的去雾框架WDMamba，通过低频恢复和细节增强两阶段处理，结合Mamba块和自引导对比正则化，显著提升了去雾效果。


<details>
  <summary>Details</summary>
Motivation: 观察到雾霾信息主要存在于低频分量中，因此提出了一种新的去雾方法，以更有效地恢复图像。

Method: 采用两阶段策略：低频恢复阶段使用Mamba块重建全局结构，细节增强阶段补充遗漏的细粒度信息，并引入自引导对比正则化优化训练。

Result: 在公开去雾基准测试中，WDMamba在质量和数量上均优于现有方法。

Conclusion: WDMamba通过小波降解先验和两阶段处理，实现了高效且高质量的去雾效果。

Abstract: In this paper, we reveal a novel haze-specific wavelet degradation prior
observed through wavelet transform analysis, which shows that haze-related
information predominantly resides in low-frequency components. Exploiting this
insight, we propose a novel dehazing framework, WDMamba, which decomposes the
image dehazing task into two sequential stages: low-frequency restoration
followed by detail enhancement. This coarse-to-fine strategy enables WDMamba to
effectively capture features specific to each stage of the dehazing process,
resulting in high-quality restored images. Specifically, in the low-frequency
restoration stage, we integrate Mamba blocks to reconstruct global structures
with linear complexity, efficiently removing overall haze and producing a
coarse restored image. Thereafter, the detail enhancement stage reinstates
fine-grained information that may have been overlooked during the previous
phase, culminating in the final dehazed output. Furthermore, to enhance detail
retention and achieve more natural dehazing, we introduce a self-guided
contrastive regularization during network training. By utilizing the coarse
restored output as a hard negative example, our model learns more
discriminative representations, substantially boosting the overall dehazing
performance. Extensive evaluations on public dehazing benchmarks demonstrate
that our method surpasses state-of-the-art approaches both qualitatively and
quantitatively. Code is available at https://github.com/SunJ000/WDMamba.

</details>

### [61] [Balancing Accuracy, Calibration, and Efficiency in Active Learning with Vision Transformers Under Label Noise](https://arxiv.org/abs/2505.04375)
*Moseli Mots'oehli,Hope Mogale,Kyungim Baek*

Main category: cs.CV

TLDR: 研究探讨了在标签噪声下，不同规模的视觉Transformer（ViT）和Swin Transformer在CIFAR10和CIFAR100数据集上的表现，发现较大的ViT模型（如ViTl32）在准确性和校准性上表现更优，而Swin Transformer的鲁棒性较弱。


<details>
  <summary>Details</summary>
Motivation: 探索在资源受限和标签噪声环境下，视觉Transformer的实用性和性能表现，为实际应用提供指导。

Method: 评估四种ViT配置和三种Swin Transformer配置在CIFAR10和CIFAR100数据集上的表现，分析标签噪声对分类准确性和校准性的影响。

Result: 较大的ViT模型（如ViTl32）在标签噪声下表现更优，而Swin Transformer鲁棒性较弱；基于信息的主动学习策略仅在中等噪声率下有效。

Conclusion: 研究结果为资源受限环境下的视觉Transformer部署提供了实用建议，强调了模型规模、标签噪声和计算效率的平衡。

Abstract: Fine-tuning pre-trained convolutional neural networks on ImageNet for
downstream tasks is well-established. Still, the impact of model size on the
performance of vision transformers in similar scenarios, particularly under
label noise, remains largely unexplored. Given the utility and versatility of
transformer architectures, this study investigates their practicality under
low-budget constraints and noisy labels. We explore how classification accuracy
and calibration are affected by symmetric label noise in active learning
settings, evaluating four vision transformer configurations (Base and Large
with 16x16 and 32x32 patch sizes) and three Swin Transformer configurations
(Tiny, Small, and Base) on CIFAR10 and CIFAR100 datasets, under varying label
noise rates. Our findings show that larger ViT models (ViTl32 in particular)
consistently outperform their smaller counterparts in both accuracy and
calibration, even under moderate to high label noise, while Swin Transformers
exhibit weaker robustness across all noise levels. We find that smaller patch
sizes do not always lead to better performance, as ViTl16 performs consistently
worse than ViTl32 while incurring a higher computational cost. We also find
that information-based Active Learning strategies only provide meaningful
accuracy improvements at moderate label noise rates, but they result in poorer
calibration compared to models trained on randomly acquired labels, especially
at high label noise rates. We hope these insights provide actionable guidance
for practitioners looking to deploy vision transformers in resource-constrained
environments, where balancing model complexity, label noise, and compute
efficiency is critical in model fine-tuning or distillation.

</details>

### [62] [Label-efficient Single Photon Images Classification via Active Learning](https://arxiv.org/abs/2505.04376)
*Zili Zhang,Ziting Wen,Yiheng Qiang,Hongzhou Dong,Wenle Dong,Xinyang Li,Xiaofan Wang,Xiaoqiang Ren*

Main category: cs.CV

TLDR: 本文提出了一种用于单光子图像分类的主动学习框架，通过成像条件感知的采样策略和合成增强技术，显著减少了标注样本需求，并在合成和真实数据集上取得了高分类精度。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注从稀疏光子事件重建3D场景，而单光子图像的语义解释因高标注成本和低效标注策略而未被充分探索。

Method: 提出了一种成像条件感知的采样策略，结合合成增强技术，选择性地标注最具信息量的样本。

Result: 在合成数据上仅需1.5%标注样本即达到97%准确率，真实数据上仅需8%标注样本达到90.63%准确率，优于基线方法。

Conclusion: 主动学习使单光子图像分类性能达到与传统图像相当的水平，为单光子数据的大规模应用铺平道路。

Abstract: Single-photon LiDAR achieves high-precision 3D imaging in extreme
environments through quantum-level photon detection technology. Current
research primarily focuses on reconstructing 3D scenes from sparse photon
events, whereas the semantic interpretation of single-photon images remains
underexplored, due to high annotation costs and inefficient labeling
strategies. This paper presents the first active learning framework for
single-photon image classification. The core contribution is an imaging
condition-aware sampling strategy that integrates synthetic augmentation to
model variability across imaging conditions. By identifying samples where the
model is both uncertain and sensitive to these conditions, the proposed method
selectively annotates only the most informative examples. Experiments on both
synthetic and real-world datasets show that our approach outperforms all
baselines and achieves high classification accuracy with significantly fewer
labeled samples. Specifically, our approach achieves 97% accuracy on synthetic
single-photon data using only 1.5% labeled samples. On real-world data, we
maintain 90.63% accuracy with just 8% labeled samples, which is 4.51% higher
than the best-performing baseline. This illustrates that active learning
enables the same level of classification performance on single-photon images as
on classical images, opening doors to large-scale integration of single-photon
data in real-world applications.

</details>

### [63] [Tetrahedron-Net for Medical Image Registration](https://arxiv.org/abs/2505.04380)
*Jinhai Xiang,Shuai Guo,Qianru Han,Dantong Shi,Xinwei He,Xiang Bai*

Main category: cs.CV

TLDR: 论文提出了一种名为Tetrahedron-Net的新架构，通过增加一个额外的解码器来增强医学图像配准的表示能力。


<details>
  <summary>Details</summary>
Motivation: 现有U-Net类网络在单编码器和单解码器架构中未能充分探索交互，限制了表示能力。

Method: 引入一个额外的解码器，与原始编码器和解码器交互，形成Tetrahedron结构。

Result: 在多个医学图像配准基准测试中表现出优越性能，并能轻松集成到现有U-Net类架构中。

Conclusion: Tetrahedron-Net是一种简洁而通用的方法，显著提升了医学图像配准的质量。

Abstract: Medical image registration plays a vital role in medical image processing.
Extracting expressive representations for medical images is crucial for
improving the registration quality. One common practice for this end is
constructing a convolutional backbone to enable interactions with skip
connections among feature extraction layers. The de facto structure, U-Net-like
networks, has attempted to design skip connections such as nested or full-scale
ones to connect one single encoder and one single decoder to improve its
representation capacity. Despite being effective, it still does not fully
explore interactions with a single encoder and decoder architectures. In this
paper, we embrace this observation and introduce a simple yet effective
alternative strategy to enhance the representations for registrations by
appending one additional decoder. The new decoder is designed to interact with
both the original encoder and decoder. In this way, it not only reuses feature
presentation from corresponding layers in the encoder but also interacts with
the original decoder to corporately give more accurate registration results.
The new architecture is concise yet generalized, with only one encoder and two
decoders forming a ``Tetrahedron'' structure, thereby dubbed Tetrahedron-Net.
Three instantiations of Tetrahedron-Net are further constructed regarding the
different structures of the appended decoder. Our extensive experiments prove
that superior performance can be obtained on several representative benchmarks
of medical image registration. Finally, such a ``Tetrahedron'' design can also
be easily integrated into popular U-Net-like architectures including
VoxelMorph, ViT-V-Net, and TransMorph, leading to consistent performance gains.

</details>

### [64] [DATA: Multi-Disentanglement based Contrastive Learning for Open-World Semi-Supervised Deepfake Attribution](https://arxiv.org/abs/2505.04384)
*Ming-Hui Liu,Xiao-Qian Liu,Xin Luo,Xin-Shun Xu*

Main category: cs.CV

TLDR: 论文提出了一种名为DATA的多解缠对比学习框架，用于提升开放世界半监督深度伪造溯源（OSS-DFA）任务中对新类别的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法过度依赖特定伪造方法线索而忽略共同伪造特征的问题，并提升在开放世界场景中对不确定新类别的区分能力。

Method: 提出'正交深度伪造基'概念，通过解缠方法特定特征减少过拟合；设计增强记忆机制辅助新类别发现和对比学习；使用基对比损失和中心对比损失增强特征标准化和区分性。

Result: 在OSS-DFA基准测试中表现优异，准确率提升2.55% / 5.7%。

Conclusion: DATA框架有效提升了对新类别的泛化能力，并在开放世界场景中取得了显著的性能提升。

Abstract: Deepfake attribution (DFA) aims to perform multiclassification on different
facial manipulation techniques, thereby mitigating the detrimental effects of
forgery content on the social order and personal reputations. However, previous
methods focus only on method-specific clues, which easily lead to overfitting,
while overlooking the crucial role of common forgery features. Additionally,
they struggle to distinguish between uncertain novel classes in more practical
open-world scenarios. To address these issues, in this paper we propose an
innovative multi-DisentAnglement based conTrastive leArning framework, DATA, to
enhance the generalization ability on novel classes for the open-world
semi-supervised deepfake attribution (OSS-DFA) task. Specifically, since all
generation techniques can be abstracted into a similar architecture, DATA
defines the concept of 'Orthonormal Deepfake Basis' for the first time and
utilizes it to disentangle method-specific features, thereby reducing the
overfitting on forgery-irrelevant information. Furthermore, an augmented-memory
mechanism is designed to assist in novel class discovery and contrastive
learning, which aims to obtain clear class boundaries for the novel classes
through instance-level disentanglements. Additionally, to enhance the
standardization and discrimination of features, DATA uses bases contrastive
loss and center contrastive loss as auxiliaries for the aforementioned modules.
Extensive experimental evaluations show that DATA achieves state-of-the-art
performance on the OSS-DFA benchmark, e.g., there are notable accuracy
improvements in 2.55% / 5.7% under different settings, compared with the
existing methods.

</details>

### [65] [Predicting Road Surface Anomalies by Visual Tracking of a Preceding Vehicle](https://arxiv.org/abs/2505.04392)
*Petr Jahoda,Jan Cech*

Main category: cs.CV

TLDR: 提出了一种通过视觉跟踪前车来检测路面异常的新方法，适用于低能见度或交通密集场景，并能提前预测异常。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖直接观察和训练视觉检测器，而新方法通过跟踪前车预测异常，适应性强且能在复杂条件下工作。

Method: 通过迭代稳健估计器补偿相机俯仰旋转，解决相机运动干扰问题，实现实时检测。

Result: 实验表明，即使在复杂路况下，该方法也能可靠地远距离检测路面异常。

Conclusion: 该方法高效、实时，适用于标准消费硬件，为自动驾驶和车辆系统配置提供了实用解决方案。

Abstract: A novel approach to detect road surface anomalies by visual tracking of a
preceding vehicle is proposed. The method is versatile, predicting any kind of
road anomalies, such as potholes, bumps, debris, etc., unlike direct
observation methods that rely on training visual detectors of those cases. The
method operates in low visibility conditions or in dense traffic where the
anomaly is occluded by a preceding vehicle. Anomalies are detected
predictively, i.e., before a vehicle encounters them, which allows to
pre-configure low-level vehicle systems (such as chassis) or to plan an
avoidance maneuver in case of autonomous driving. A challenge is that the
signal coming from camera-based tracking of a preceding vehicle may be weak and
disturbed by camera ego motion due to vibrations affecting the ego vehicle.
Therefore, we propose an efficient method to compensate camera pitch rotation
by an iterative robust estimator. Our experiments on both controlled setup and
normal traffic conditions show that road anomalies can be detected reliably at
a distance even in challenging cases where the ego vehicle traverses imperfect
road surfaces. The method is effective and performs in real time on standard
consumer hardware.

</details>

### [66] [SwinLip: An Efficient Visual Speech Encoder for Lip Reading Using Swin Transformer](https://arxiv.org/abs/2505.04394)
*Young-Hu Park,Rae-Hong Park,Hyung-Min Park*

Main category: cs.CV

TLDR: 提出了一种高效的视觉语音编码器SwinLip，用于唇读任务，通过结合Swin Transformer的层次结构和窗口自注意力机制，显著降低了计算复杂度并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于ResNet的唇读模型计算复杂度高，不适合高效捕获唇读特征，且在多模态研究中引入延迟。

Method: 采用Swin Transformer的层次结构和窗口自注意力机制，结合改进的Conformer时间嵌入和传统空间嵌入，构建轻量级SwinLip编码器。

Result: 在英语LRW和汉语LRW-1000数据集上表现优异，计算量更少，且在汉语LRW-1000上达到SOTA性能。

Conclusion: SwinLip显著提升了唇读网络的性能和推理速度，适用于多种骨干网络，具有高效和轻量化的优势。

Abstract: This paper presents an efficient visual speech encoder for lip reading. While
most recent lip reading studies have been based on the ResNet architecture and
have achieved significant success, they are not sufficiently suitable for
efficiently capturing lip reading features due to high computational complexity
in modeling spatio-temporal information. Additionally, using a complex visual
model not only increases the complexity of lip reading models but also induces
delays in the overall network for multi-modal studies (e.g., audio-visual
speech recognition, speech enhancement, and speech separation). To overcome the
limitations of Convolutional Neural Network (CNN)-based models, we apply the
hierarchical structure and window self-attention of the Swin Transformer to lip
reading. We configure a new lightweight scale of the Swin Transformer suitable
for processing lip reading data and present the SwinLip visual speech encoder,
which efficiently reduces computational load by integrating modified
Convolution-augmented Transformer (Conformer) temporal embeddings with
conventional spatial embeddings in the hierarchical structure. Through
extensive experiments, we have validated that our SwinLip successfully improves
the performance and inference speed of the lip reading network when applied to
various backbones for word and sentence recognition, reducing computational
load. In particular, our SwinLip demonstrated robust performance in both
English LRW and Mandarin LRW-1000 datasets and achieved state-of-the-art
performance on the Mandarin LRW-1000 dataset with less computation compared to
the existing state-of-the-art model.

</details>

### [67] [Deep residual learning with product units](https://arxiv.org/abs/2505.04397)
*Ziyuan Li,Uwe Jaekel,Babette Dellen*

Main category: cs.CV

TLDR: PURe是一种结合乘积单元的深度残差网络，通过乘法特征交互提升表达能力和参数效率，在多个数据集上表现优于传统ResNet，且收敛更快、参数更少。


<details>
  <summary>Details</summary>
Motivation: 传统残差网络主要依赖加法神经元，限制了复杂模式的表达能力。PURe通过引入乘积单元，探索更强大的特征表示方法。

Method: 在残差块的第二层用2D乘积单元替代传统卷积层，并移除非线性激活函数以保留结构信息。

Result: 在Galaxy10 DECaLS、ImageNet和CIFAR-10上，PURe均表现优异，准确率更高、收敛更快、参数更少，且对噪声更鲁棒。

Conclusion: PURe在准确性、效率和鲁棒性之间取得了良好平衡，展示了乘积单元架构在计算机视觉中的潜力。

Abstract: We propose a deep product-unit residual neural network (PURe) that integrates
product units into residual blocks to improve the expressiveness and parameter
efficiency of deep convolutional networks. Unlike standard summation neurons,
product units enable multiplicative feature interactions, potentially offering
a more powerful representation of complex patterns. PURe replaces conventional
convolutional layers with 2D product units in the second layer of each residual
block, eliminating nonlinear activation functions to preserve structural
information. We validate PURe on three benchmark datasets. On Galaxy10 DECaLS,
PURe34 achieves the highest test accuracy of 84.89%, surpassing the much deeper
ResNet152, while converging nearly five times faster and demonstrating strong
robustness to Poisson noise. On ImageNet, PURe architectures outperform
standard ResNet models at similar depths, with PURe34 achieving a top-1
accuracy of 80.27% and top-5 accuracy of 95.78%, surpassing deeper ResNet
variants (ResNet50, ResNet101) while utilizing significantly fewer parameters
and computational resources. On CIFAR-10, PURe consistently outperforms ResNet
variants across varying depths, with PURe272 reaching 95.01% test accuracy,
comparable to ResNet1001 but at less than half the model size. These results
demonstrate that PURe achieves a favorable balance between accuracy,
efficiency, and robustness. Compared to traditional residual networks, PURe not
only achieves competitive classification performance with faster convergence
and fewer parameters, but also demonstrates greater robustness to noise. Its
effectiveness across diverse datasets highlights the potential of
product-unit-based architectures for scalable and reliable deep learning in
computer vision.

</details>

### [68] [MFSeg: Efficient Multi-frame 3D Semantic Segmentation](https://arxiv.org/abs/2505.04408)
*Chengjie Huang,Krzysztof Czarnecki*

Main category: cs.CV

TLDR: MFSeg是一种高效的多帧3D语义分割框架，通过特征级点云序列聚合和正则化，降低计算开销并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 解决多帧3D语义分割中计算开销大和冗余点云上采样的问题。

Method: 采用特征级点云序列聚合和正则化，结合轻量级MLP点解码器。

Result: 在nuScenes和Waymo数据集上表现优于现有方法。

Conclusion: MFSeg在效率和准确性上均表现出色。

Abstract: We propose MFSeg, an efficient multi-frame 3D semantic segmentation
framework. By aggregating point cloud sequences at the feature level and
regularizing the feature extraction and aggregation process, MFSeg reduces
computational overhead while maintaining high accuracy. Moreover, by employing
a lightweight MLP-based point decoder, our method eliminates the need to
upsample redundant points from past frames. Experiments on the nuScenes and
Waymo datasets show that MFSeg outperforms existing methods, demonstrating its
effectiveness and efficiency.

</details>

### [69] [DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception](https://arxiv.org/abs/2505.04410)
*Junjie Wang,Bin Chen,Yulin Li,Bin Kang,Yichi Chen,Zhuotao Tian*

Main category: cs.CV

TLDR: DeCLIP改进CLIP模型，通过解耦自注意力模块提升密集视觉预测任务的性能，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（如CLIP）在密集预测任务中表现不佳，因其局部特征表示能力有限。

Method: 提出DeCLIP框架，解耦自注意力模块为“内容”和“上下文”特征，分别提升局部区分性和空间一致性。

Result: DeCLIP在开放词汇密集预测任务（如目标检测和语义分割）中表现显著优于现有方法。

Conclusion: DeCLIP通过改进局部特征表示，有效解决了CLIP在密集预测任务中的局限性。

Abstract: Dense visual prediction tasks have been constrained by their reliance on
predefined categories, limiting their applicability in real-world scenarios
where visual concepts are unbounded. While Vision-Language Models (VLMs) like
CLIP have shown promise in open-vocabulary tasks, their direct application to
dense prediction often leads to suboptimal performance due to limitations in
local feature representation. In this work, we present our observation that
CLIP's image tokens struggle to effectively aggregate information from
spatially or semantically related regions, resulting in features that lack
local discriminability and spatial consistency. To address this issue, we
propose DeCLIP, a novel framework that enhances CLIP by decoupling the
self-attention module to obtain ``content'' and ``context'' features
respectively. The ``content'' features are aligned with image crop
representations to improve local discriminability, while ``context'' features
learn to retain the spatial correlations under the guidance of vision
foundation models, such as DINO. Extensive experiments demonstrate that DeCLIP
significantly outperforms existing methods across multiple open-vocabulary
dense prediction tasks, including object detection and semantic segmentation.
Code is available at \textcolor{magenta}{https://github.com/xiaomoguhz/DeCLIP}.

</details>

### [70] [RLMiniStyler: Light-weight RL Style Agent for Arbitrary Sequential Neural Style Generation](https://arxiv.org/abs/2505.04424)
*Jing Hu,Chengming Feng,Shu Hu,Ming-Ching Chang,Xin Li,Xi Wu,Xin Wang*

Main category: cs.CV

TLDR: 论文提出了一种基于强化学习的轻量级任意风格迁移框架RLMiniStyler，通过迭代优化生成高质量、多样化的艺术图像序列，同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在生成多样化风格化结果时计算成本高，因此需要一种更高效的解决方案。

Method: 采用强化学习策略迭代指导风格迁移过程，并结合不确定性感知的多任务学习策略动态调整损失权重。

Result: 实验验证了RLMiniStyler在生成高质量、多样化艺术图像序列方面的优势，且计算成本更低。

Conclusion: RLMiniStyler是一种高效、轻量级的任意风格迁移方法，优于现有技术。

Abstract: Arbitrary style transfer aims to apply the style of any given artistic image
to another content image. Still, existing deep learning-based methods often
require significant computational costs to generate diverse stylized results.
Motivated by this, we propose a novel reinforcement learning-based framework
for arbitrary style transfer RLMiniStyler. This framework leverages a unified
reinforcement learning policy to iteratively guide the style transfer process
by exploring and exploiting stylization feedback, generating smooth sequences
of stylized results while achieving model lightweight. Furthermore, we
introduce an uncertainty-aware multi-task learning strategy that automatically
adjusts loss weights to adapt to the content and style balance requirements at
different training stages, thereby accelerating model convergence. Through a
series of experiments across image various resolutions, we have validated the
advantages of RLMiniStyler over other state-of-the-art methods in generating
high-quality, diverse artistic image sequences at a lower cost. Codes are
available at https://github.com/fengxiaoming520/RLMiniStyler.

</details>

### [71] [Learning Real Facial Concepts for Independent Deepfake Detection](https://arxiv.org/abs/2505.04460)
*Ming-Hui Liu,Harry Cheng,Tianyi Wang,Xin Luo,Xin-Shun Xu*

Main category: cs.CV

TLDR: RealID提出了一种新方法，通过独立学习真实和伪造类别的概率，提升深度伪造检测模型的泛化能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度伪造检测模型在未见数据集上泛化能力差，主要原因是过度依赖伪造痕迹和对真实人脸的理解不足。

Method: RealID包含RealC2模块和IDC模块，前者通过MultiReal Memory捕捉真实人脸的全面概念，后者独立决策分类。

Result: 在五个数据集上的实验显示，RealID平均准确率提升1.74%，显著优于现有方法。

Conclusion: RealID通过独立学习真实和伪造类别，有效缓解了伪造无关模式的影响，提升了泛化能力。

Abstract: Deepfake detection models often struggle with generalization to unseen
datasets, manifesting as misclassifying real instances as fake in target
domains. This is primarily due to an overreliance on forgery artifacts and a
limited understanding of real faces. To address this challenge, we propose a
novel approach RealID to enhance generalization by learning a comprehensive
concept of real faces while assessing the probabilities of belonging to the
real and fake classes independently. RealID comprises two key modules: the Real
Concept Capture Module (RealC2) and the Independent Dual-Decision Classifier
(IDC). With the assistance of a MultiReal Memory, RealC2 maintains various
prototypes for real faces, allowing the model to capture a comprehensive
concept of real class. Meanwhile, IDC redefines the classification strategy by
making independent decisions based on the concept of the real class and the
presence of forgery artifacts. Through the combined effect of the above
modules, the influence of forgery-irrelevant patterns is alleviated, and
extensive experiments on five widely used datasets demonstrate that RealID
significantly outperforms existing state-of-the-art methods, achieving a 1.74%
improvement in average accuracy.

</details>

### [72] [CAD-Llama: Leveraging Large Language Models for Computer-Aided Design Parametric 3D Model Generation](https://arxiv.org/abs/2505.04481)
*Jiahao Li,Weijian Ma,Xueyang Li,Yunzhong Lou,Guichun Zhou,Xiangdong Zhou*

Main category: cs.CV

TLDR: 该研究提出了一种名为CAD-Llama的框架，旨在增强预训练大型语言模型（LLMs）生成参数化3D CAD模型的能力。通过引入分层注释管道和类似代码的格式（SPCC），并结合自适应预训练和指令调优，该框架显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是扩展LLMs的生成能力，使其能够处理参数化3D CAD模型的生成任务，填补LLMs在参数化序列和3D结构知识方面的空白。

Method: 方法包括开发分层注释管道和SPCC格式，将参数化3D CAD命令序列转换为结构化代码，并通过自适应预训练和指令调优增强LLMs的空间知识。

Result: 实验结果表明，该框架在生成参数化3D CAD模型方面显著优于现有的自回归方法和LLM基线。

Conclusion: 结论是CAD-Llama框架成功地将LLMs的能力扩展到参数化3D CAD模型生成领域，为未来的研究奠定了基础。

Abstract: Recently, Large Language Models (LLMs) have achieved significant success,
prompting increased interest in expanding their generative capabilities beyond
general text into domain-specific areas. This study investigates the generation
of parametric sequences for computer-aided design (CAD) models using LLMs. This
endeavor represents an initial step towards creating parametric 3D shapes with
LLMs, as CAD model parameters directly correlate with shapes in
three-dimensional space. Despite the formidable generative capacities of LLMs,
this task remains challenging, as these models neither encounter parametric
sequences during their pretraining phase nor possess direct awareness of 3D
structures. To address this, we present CAD-Llama, a framework designed to
enhance pretrained LLMs for generating parametric 3D CAD models. Specifically,
we develop a hierarchical annotation pipeline and a code-like format to
translate parametric 3D CAD command sequences into Structured Parametric CAD
Code (SPCC), incorporating hierarchical semantic descriptions. Furthermore, we
propose an adaptive pretraining approach utilizing SPCC, followed by an
instruction tuning process aligned with CAD-specific guidelines. This
methodology aims to equip LLMs with the spatial knowledge inherent in
parametric sequences. Experimental results demonstrate that our framework
significantly outperforms prior autoregressive methods and existing LLM
baselines.

</details>

### [73] [FA-KPConv: Introducing Euclidean Symmetries to KPConv via Frame Averaging](https://arxiv.org/abs/2505.04485)
*Ali Alawieh,Alexandru P. Condurache*

Main category: cs.CV

TLDR: FA-KPConv是一种基于KPConv的神经网络架构，通过帧平均技术实现点云网络对平移、旋转和反射的精确不变性或等变性，提升分类和配准任务的性能。


<details>
  <summary>Details</summary>
Motivation: KPConv在3D点云分析中广泛应用，但其对欧几里得变换的不变性或等变性仅能通过大数据集或数据增强近似实现，FA-KPConv旨在解决这一问题。

Method: 通过帧平均技术包装现有KPConv网络，嵌入几何先验知识，保持参数数量不变且不损失输入信息。

Result: 在点云分类和配准任务中，尤其在训练数据稀缺或测试数据随机旋转的情况下，FA-KPConv表现出显著优势。

Conclusion: FA-KPConv通过几何先验知识提升了KPConv网络的性能，尤其在数据受限或变换复杂的情况下效果显著。

Abstract: We present Frame-Averaging Kernel-Point Convolution (FA-KPConv), a neural
network architecture built on top of the well-known KPConv, a widely adopted
backbone for 3D point cloud analysis. Even though invariance and/or
equivariance to Euclidean transformations are required for many common tasks,
KPConv-based networks can only approximately achieve such properties when
training on large datasets or with significant data augmentations. Using Frame
Averaging, we allow to flexibly customize point cloud neural networks built
with KPConv layers, by making them exactly invariant and/or equivariant to
translations, rotations and/or reflections of the input point clouds. By simply
wrapping around an existing KPConv-based network, FA-KPConv embeds geometrical
prior knowledge into it while preserving the number of learnable parameters and
not compromising any input information. We showcase the benefit of such an
introduced bias for point cloud classification and point cloud registration,
especially in challenging cases such as scarce training data or randomly
rotated test data.

</details>

### [74] [Efficient Flow Matching using Latent Variables](https://arxiv.org/abs/2505.04486)
*Anirban Samaddar,Yixuan Sun,Viktor Nilsson,Sandeep Madireddy*

Main category: cs.CV

TLDR: Latent-CFM 提出了一种简化的训练和推理策略，利用预训练的深度隐变量模型处理多模态数据，显著减少了训练时间和计算成本，同时提高了生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有流匹配模型在学习从简单源分布到目标数据的流时，未显式建模数据的底层结构或流形，导致学习效率低下，尤其是在高维数据集中。

Method: 提出 Latent-CFM，利用预训练的深度隐变量模型简化多模态数据结构的训练和推理策略。

Result: 实验表明，Latent-CFM 在生成质量和训练效率上优于现有流匹配模型，训练时间减少约 50%，并在物理数据上生成更准确的样本。

Conclusion: Latent-CFM 不仅提高了生成效率和质量，还支持基于隐特征的图像生成，展示了其广泛的应用潜力。

Abstract: Flow matching models have shown great potential in image generation tasks
among probabilistic generative models. Building upon the ideas of continuous
normalizing flows, flow matching models generalize the transport path of the
diffusion models from a simple prior distribution to the data. Most flow
matching models in the literature do not explicitly model the underlying
structure/manifold in the target data when learning the flow from a simple
source distribution like the standard Gaussian. This leads to inefficient
learning, especially for many high-dimensional real-world datasets, which often
reside in a low-dimensional manifold. Existing strategies of incorporating
manifolds, including data with underlying multi-modal distribution, often
require expensive training and hence frequently lead to suboptimal performance.
To this end, we present \texttt{Latent-CFM}, which provides simplified
training/inference strategies to incorporate multi-modal data structures using
pretrained deep latent variable models. Through experiments on multi-modal
synthetic data and widely used image benchmark datasets, we show that
\texttt{Latent-CFM} exhibits improved generation quality with significantly
less training ($\sim 50\%$ less in some cases) and computation than
state-of-the-art flow matching models. Using a 2d Darcy flow dataset, we
demonstrate that our approach generates more physically accurate samples than
competitive approaches. In addition, through latent space analysis, we
demonstrate that our approach can be used for conditional image generation
conditioned on latent features.

</details>

### [75] ["I Can See Forever!": Evaluating Real-time VideoLLMs for Assisting Individuals with Visual Impairments](https://arxiv.org/abs/2505.04488)
*Ziyi Zhang,Zhen Sun,Zongmin Zhang,Zifan Peng,Yuemeng Zhao,Zichun Wang,Zeren Luo,Ruiting Zuo,Xinlei He*

Main category: cs.CV

TLDR: 论文评估了视频语言模型（VideoLLMs）在帮助视障人士方面的有效性，构建了数据集VisAssistDaily和SafeVid，并发现GPT-4o表现最佳。


<details>
  <summary>Details</summary>
Motivation: 视障人士在动态复杂环境中缺乏实时感知支持，现有研究多关注静态内容，需结合先进视觉理解技术。

Method: 构建VisAssistDaily数据集评估模型表现，并通过用户研究测试模型在开放和封闭场景中的实用性。

Result: GPT-4o在任务成功率上表现最佳，但模型在动态环境中感知潜在危险的能力不足。

Conclusion: 提出了SafeVid数据集和轮询机制以提升环境风险感知能力，为未来研究提供参考。

Abstract: The visually impaired population, especially the severely visually impaired,
is currently large in scale, and daily activities pose significant challenges
for them. Although many studies use large language and vision-language models
to assist the blind, most focus on static content and fail to meet real-time
perception needs in dynamic and complex environments, such as daily activities.
To provide them with more effective intelligent assistance, it is imperative to
incorporate advanced visual understanding technologies. Although real-time
vision and speech interaction VideoLLMs demonstrate strong real-time visual
understanding, no prior work has systematically evaluated their effectiveness
in assisting visually impaired individuals. In this work, we conduct the first
such evaluation. First, we construct a benchmark dataset (VisAssistDaily),
covering three categories of assistive tasks for visually impaired individuals:
Basic Skills, Home Life Tasks, and Social Life Tasks. The results show that
GPT-4o achieves the highest task success rate. Next, we conduct a user study to
evaluate the models in both closed-world and open-world scenarios, further
exploring the practical challenges of applying VideoLLMs in assistive contexts.
One key issue we identify is the difficulty current models face in perceiving
potential hazards in dynamic environments. To address this, we build an
environment-awareness dataset named SafeVid and introduce a polling mechanism
that enables the model to proactively detect environmental risks. We hope this
work provides valuable insights and inspiration for future research in this
field.

</details>

### [76] [Defining and Quantifying Creative Behavior in Popular Image Generators](https://arxiv.org/abs/2505.04497)
*Aditi Ramaswamy*

Main category: cs.CV

TLDR: 本文从实践角度研究生成式AI模型的创造力，并引入定量指标帮助用户选择适合任务的模型。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI模型的创造力，解决科学界对此问题的争议。

Method: 提出定量指标，并在多个流行的图像生成模型上评估。

Result: 评估结果表明，提出的指标符合人类直觉。

Conclusion: 定量指标能有效帮助用户选择适合的生成式AI模型。

Abstract: Creativity of generative AI models has been a subject of scientific debate in
the last years, without a conclusive answer. In this paper, we study creativity
from a practical perspective and introduce quantitative measures that help the
user to choose a suitable AI model for a given task. We evaluated our measures
on a number of popular image-to-image generation models, and the results of
this suggest that our measures conform to human intuition.

</details>

### [77] [Leveraging Simultaneous Usage of Edge GPU Hardware Engines for Video Face Detection and Recognition](https://arxiv.org/abs/2505.04502)
*Asma Baobaid,Mahmoud Meribout*

Main category: cs.CV

TLDR: 本文提出了一种利用边缘GPU中多个硬件引擎并发和流水线处理视频人脸检测与识别任务的方法，提高了吞吐量并降低了功耗。


<details>
  <summary>Details</summary>
Motivation: 公共场合的视频人脸检测与识别需求日益增长，但现有方法未能充分利用硬件引擎的并发能力。

Method: 通过并发和流水线技术，同时利用边缘GPU中的多个硬件引擎（包括视频解码），优化任务分配。

Result: 在NVIDIA Orin边缘GPU上实现了更高的吞吐量，功耗降低约5%（300 mW），并满足实时性能要求。

Conclusion: 通过优化硬件引擎的使用，显著提升了性能，并建议进一步改进GPU硬件以提升性能。

Abstract: Video face detection and recognition in public places at the edge is required
in several applications, such as security reinforcement and contactless access
to authorized venues. This paper aims to maximize the simultaneous usage of
hardware engines available in edge GPUs nowadays by leveraging the concurrency
and pipelining of tasks required for face detection and recognition. This also
includes the video decoding task, which is required in most face monitoring
applications as the video streams are usually carried via Gbps Ethernet
network. This constitutes an improvement over previous works where the tasks
are usually allocated to a single engine due to the lack of a unified and
automated framework that simultaneously explores all hardware engines. In
addition, previously, the input faces were usually embedded in still images or
within raw video streams that overlook the burst delay caused by the decoding
stage. The results on real-life video streams suggest that simultaneously using
all the hardware engines available in the recent NVIDIA edge Orin GPU, higher
throughput, and a slight saving of power consumption of around 300 mW,
accounting for around 5%, have been achieved while satisfying the real-time
performance constraint. The performance gets even higher by considering several
video streams simultaneously. Further performance improvement could have been
obtained if the number of shuffle layers that were created by the tensor RT
framework for the face recognition task was lower. Thus, the paper suggests
some hardware improvements to the existing edge GPU processors to enhance their
performance even higher.

</details>

### [78] [HunyuanCustom: A Multimodal-Driven Architecture for Customized Video Generation](https://arxiv.org/abs/2505.04512)
*Teng Hu,Zhentao Yu,Zhengguang Zhou,Sen Liang,Yuan Zhou,Qin Lin,Qinglin Lu*

Main category: cs.CV

TLDR: HunyuanCustom是一个多模态定制视频生成框架，支持图像、音频、视频和文本输入，强调主体一致性和多模态理解。


<details>
  <summary>Details</summary>
Motivation: 现有方法在身份一致性和输入模态多样性方面表现不足，HunyuanCustom旨在解决这些问题。

Method: 基于HunyuanVideo，引入文本-图像融合模块和图像ID增强模块；针对音频和视频输入，提出AudioNet和视频驱动注入模块。

Result: 实验表明HunyuanCustom在ID一致性、真实性和文本-视频对齐方面优于现有方法。

Conclusion: 多模态条件和身份保留策略有效推动了可控视频生成的发展。

Abstract: Customized video generation aims to produce videos featuring specific
subjects under flexible user-defined conditions, yet existing methods often
struggle with identity consistency and limited input modalities. In this paper,
we propose HunyuanCustom, a multi-modal customized video generation framework
that emphasizes subject consistency while supporting image, audio, video, and
text conditions. Built upon HunyuanVideo, our model first addresses the
image-text conditioned generation task by introducing a text-image fusion
module based on LLaVA for enhanced multi-modal understanding, along with an
image ID enhancement module that leverages temporal concatenation to reinforce
identity features across frames. To enable audio- and video-conditioned
generation, we further propose modality-specific condition injection
mechanisms: an AudioNet module that achieves hierarchical alignment via spatial
cross-attention, and a video-driven injection module that integrates
latent-compressed conditional video through a patchify-based feature-alignment
network. Extensive experiments on single- and multi-subject scenarios
demonstrate that HunyuanCustom significantly outperforms state-of-the-art open-
and closed-source methods in terms of ID consistency, realism, and text-video
alignment. Moreover, we validate its robustness across downstream tasks,
including audio and video-driven customized video generation. Our results
highlight the effectiveness of multi-modal conditioning and identity-preserving
strategies in advancing controllable video generation. All the code and models
are available at https://hunyuancustom.github.io.

</details>

### [79] [Text2CT: Towards 3D CT Volume Generation from Free-text Descriptions Using Diffusion Model](https://arxiv.org/abs/2505.04522)
*Pengfei Guo,Can Zhao,Dong Yang,Yufan He,Vishwesh Nath,Ziyue Xu,Pedro R. A. S. Bassi,Zongwei Zhou,Benjamin D. Simon,Stephanie Anne Harmon,Baris Turkbey,Daguang Xu*

Main category: cs.CV

TLDR: Text2CT是一种基于扩散模型的新方法，能够从自由文本描述生成高分辨率3D CT扫描，优于现有方法，并在解剖学保真度和结构细节上表现优异。


<details>
  <summary>Details</summary>
Motivation: 通过自由文本描述生成3D CT扫描，为诊断和研究提供新的可能性，解决了传统方法依赖固定格式文本的局限性。

Method: Text2CT采用扩散模型，将医学文本编码为潜在表示，并解码为3D CT扫描，支持多样化的自由文本输入。

Result: 实验表明，该方法在解剖学保真度和结构细节上表现优异，达到了最先进的水平。

Conclusion: Text2CT在诊断和数据增强方面具有广阔的应用前景。

Abstract: Generating 3D CT volumes from descriptive free-text inputs presents a
transformative opportunity in diagnostics and research. In this paper, we
introduce Text2CT, a novel approach for synthesizing 3D CT volumes from textual
descriptions using the diffusion model. Unlike previous methods that rely on
fixed-format text input, Text2CT employs a novel prompt formulation that
enables generation from diverse, free-text descriptions. The proposed framework
encodes medical text into latent representations and decodes them into
high-resolution 3D CT scans, effectively bridging the gap between semantic text
inputs and detailed volumetric representations in a unified 3D framework. Our
method demonstrates superior performance in preserving anatomical fidelity and
capturing intricate structures as described in the input text. Extensive
evaluations show that our approach achieves state-of-the-art results, offering
promising potential applications in diagnostics, and data augmentation.

</details>

### [80] [Edge-GPU Based Face Tracking for Face Detection and Recognition Acceleration](https://arxiv.org/abs/2505.04524)
*Asma Baobaid,Mahmoud Meribout*

Main category: cs.CV

TLDR: 提出了一种结合硬件-软件的优化方法，用于在NVIDIA Jetson AGX Orin边缘GPU上提升人脸检测与识别系统的性能，通过同时利用所有硬件引擎和集成人脸跟踪模块，实现了290 FPS的高吞吐量和800 mW的功耗节省。


<details>
  <summary>Details</summary>
Motivation: 现代应用中，公共场合的实时、准确人脸检测与识别系统至关重要，但现有系统在吞吐量和功耗方面仍有改进空间。

Method: 同时利用NVIDIA Jetson AGX Orin GPU的所有硬件引擎，并集成人脸跟踪模块以减少冗余计算。

Result: 在1920x1080分辨率、平均每帧6张人脸的情况下，系统吞吐量达到290 FPS，功耗节省约800 mW。

Conclusion: 该硬件-软件协同设计方法为高性能边缘机器视觉系统提供了可行方案，特别适用于公共场合的多摄像头监控场景。

Abstract: Cost-effective machine vision systems dedicated to real-time and accurate
face detection and recognition in public places are crucial for many modern
applications. However, despite their high performance, which could be reached
using specialized edge or cloud AI hardware accelerators, there is still room
for improvement in throughput and power consumption. This paper aims to suggest
a combined hardware-software approach that optimizes face detection and
recognition systems on one of the latest edge GPUs, namely NVIDIA Jetson AGX
Orin. First, it leverages the simultaneous usage of all its hardware engines to
improve processing time. This offers an improvement over previous works where
these tasks were mainly allocated automatically and exclusively to the CPU or,
to a higher extent, to the GPU core. Additionally, the paper suggests
integrating a face tracker module to avoid redundantly running the face
recognition algorithm for every frame but only when a new face appears in the
scene. The results of extended experiments suggest that simultaneous usage of
all the hardware engines that are available in the Orin GPU and tracker
integration into the pipeline yield an impressive throughput of 290 FPS (frames
per second) on 1920 x 1080 input size frames containing in average of 6
faces/frame. Additionally, a substantial saving of power consumption of around
800 mW was achieved when compared to running the task on the CPU/GPU engines
only and without integrating a tracker into the Orin GPU\'92s pipeline. This
hardware-codesign approach can pave the way to design high-performance machine
vision systems at the edge, critically needed in video monitoring in public
places where several nearby cameras are usually deployed for a same scene.

</details>

### [81] [DFVO: Learning Darkness-free Visible and Infrared Image Disentanglement and Fusion All at Once](https://arxiv.org/abs/2505.04526)
*Qi Zhou,Yukai Shi,Xiaojun Yang,Xiaoyu Xian,Lunjia Liao,Ruimao Zhang,Liang Lin*

Main category: cs.CV

TLDR: 论文提出了一种名为DFVO的网络，用于在黑暗环境中实现可见光和红外图像的高质量融合，解决了传统方法在光照不足时效果模糊的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图像融合方法在可见光图像光照不足时效果不佳，影响自动驾驶等高级视觉任务。

Method: 采用多任务级联策略，设计潜在共同特征提取器（LCFE）、细节提取模块（DEM）和超交叉注意力模块（HCAM），并通过相关损失函数优化网络。

Result: 在LLVIP数据集上表现最佳，PSNR为63.258 dB，CC为0.724，生成更清晰、信息更丰富的融合图像。

Conclusion: DFVO在黑暗环境中显著提升了图像融合质量，为高级视觉任务提供了更有效的信息。

Abstract: Visible and infrared image fusion is one of the most crucial tasks in the
field of image fusion, aiming to generate fused images with clear structural
information and high-quality texture features for high-level vision tasks.
However, when faced with severe illumination degradation in visible images, the
fusion results of existing image fusion methods often exhibit blurry and dim
visual effects, posing major challenges for autonomous driving. To this end, a
Darkness-Free network is proposed to handle Visible and infrared image
disentanglement and fusion all at Once (DFVO), which employs a cascaded
multi-task approach to replace the traditional two-stage cascaded training
(enhancement and fusion), addressing the issue of information entropy loss
caused by hierarchical data transmission. Specifically, we construct a
latent-common feature extractor (LCFE) to obtain latent features for the
cascaded tasks strategy. Firstly, a details-extraction module (DEM) is devised
to acquire high-frequency semantic information. Secondly, we design a hyper
cross-attention module (HCAM) to extract low-frequency information and preserve
texture features from source images. Finally, a relevant loss function is
designed to guide the holistic network learning, thereby achieving better image
fusion. Extensive experiments demonstrate that our proposed approach
outperforms state-of-the-art alternatives in terms of qualitative and
quantitative evaluations. Particularly, DFVO can generate clearer, more
informative, and more evenly illuminated fusion results in the dark
environments, achieving best performance on the LLVIP dataset with 63.258 dB
PSNR and 0.724 CC, providing more effective information for high-level vision
tasks. Our code is publicly accessible at https://github.com/DaVin-Qi530/DFVO.

</details>

### [82] [RAFT: Robust Augmentation of FeaTures for Image Segmentation](https://arxiv.org/abs/2505.04529)
*Edward Humes,Xiaomin Lin,Uttej Kallakuri,Tinoosh Mohsenin*

Main category: cs.CV

TLDR: RAFT框架通过数据和特征增强以及主动学习，利用少量真实数据提升合成数据训练的模型在真实场景中的表现，并在多个基准测试中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决合成数据训练的模型在真实场景中性能下降的问题（Syn2Real问题）。

Method: 提出RAFT框架，结合数据和特征增强以及主动学习，使用少量真实数据进行模型适应。

Result: 在SYNTHIA->Cityscapes、GTAV->Cityscapes和Cityscapes->ACDC基准测试中，mIoU分别提升2.1%/79.9%、0.4%/78.2%和1.3%/73.2%，超越HALO。

Conclusion: RAFT有效缓解了合成数据与真实数据之间的性能差距，且在不同场景下表现优异。

Abstract: Image segmentation is a powerful computer vision technique for scene
understanding. However, real-world deployment is stymied by the need for
high-quality, meticulously labeled datasets. Synthetic data provides
high-quality labels while reducing the need for manual data collection and
annotation. However, deep neural networks trained on synthetic data often face
the Syn2Real problem, leading to poor performance in real-world deployments.
  To mitigate the aforementioned gap in image segmentation, we propose RAFT, a
novel framework for adapting image segmentation models using minimal labeled
real-world data through data and feature augmentations, as well as active
learning. To validate RAFT, we perform experiments on the synthetic-to-real
"SYNTHIA->Cityscapes" and "GTAV->Cityscapes" benchmarks. We managed to surpass
the previous state of the art, HALO. SYNTHIA->Cityscapes experiences an
improvement in mIoU* upon domain adaptation of 2.1%/79.9%, and GTAV->Cityscapes
experiences a 0.4%/78.2% improvement in mIoU. Furthermore, we test our approach
on the real-to-real benchmark of "Cityscapes->ACDC", and again surpass HALO,
with a gain in mIoU upon adaptation of 1.3%/73.2%. Finally, we examine the
effect of the allocated annotation budget and various components of RAFT upon
the final transfer mIoU.

</details>

### [83] [Registration of 3D Point Sets Using Exponential-based Similarity Matrix](https://arxiv.org/abs/2505.04540)
*Ashutosh Singandhupe,Sanket Lokhande,Hung Manh La*

Main category: cs.CV

TLDR: 论文提出了一种改进的ICP算法（ESM-ICP），通过高斯启发的指数加权方案动态调整相似性矩阵，解决了点云配准中旋转差异大和噪声干扰的问题。


<details>
  <summary>Details</summary>
Motivation: 现有配准技术在大旋转差异或噪声干扰下表现不佳，导致配准不准确或3D重建失真。

Method: 提出ESM-ICP算法，利用指数加权相似性矩阵动态优化旋转和平移估计。

Result: ESM-ICP在大旋转差异和非高斯噪声下优于传统几何方法和部分学习方法。

Conclusion: ESM-ICP在点云配准中表现出更强的鲁棒性，代码已开源。

Abstract: Point cloud registration is a fundamental problem in computer vision and
robotics, involving the alignment of 3D point sets captured from varying
viewpoints using depth sensors such as LiDAR or structured light. In modern
robotic systems, especially those focused on mapping, it is essential to merge
multiple views of the same environment accurately. However, state-of-the-art
registration techniques often struggle when large rotational differences exist
between point sets or when the data is significantly corrupted by sensor noise.
These challenges can lead to misalignments and, consequently, to inaccurate or
distorted 3D reconstructions. In this work, we address both these limitations
by proposing a robust modification to the classic Iterative Closest Point (ICP)
algorithm. Our method, termed Exponential Similarity Matrix ICP (ESM-ICP),
integrates a Gaussian-inspired exponential weighting scheme to construct a
similarity matrix that dynamically adapts across iterations. This matrix
facilitates improved estimation of both rotational and translational components
during alignment. We demonstrate the robustness of ESM-ICP in two challenging
scenarios: (i) large rotational discrepancies between the source and target
point clouds, and (ii) data corrupted by non-Gaussian noise. Our results show
that ESM-ICP outperforms traditional geometric registration techniques as well
as several recent learning-based methods. To encourage reproducibility and
community engagement, our full implementation is made publicly available on
GitHub. https://github.com/aralab-unr/ESM_ICP

</details>

### [84] [Componential Prompt-Knowledge Alignment for Domain Incremental Learning](https://arxiv.org/abs/2505.04575)
*Kunlun Xu,Xu Zou,Gang Hua,Jiahuan Zhou*

Main category: cs.CV

TLDR: KA-Prompt通过组件感知的提示-知识对齐方法，解决了领域增量学习中提示组件间冲突的问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 揭示现有基于提示的领域增量学习方法中，提示组件间的随机定位导致知识冲突和性能下降的问题。

Method: 提出KA-Prompt，分两阶段实现组件对齐：初始组件结构配置和在线对齐保持。

Result: 在领域增量学习基准测试中验证了KA-Prompt的有效性。

Conclusion: KA-Prompt通过组件对齐显著提升了模型的学习和推理能力。

Abstract: Domain Incremental Learning (DIL) aims to learn from non-stationary data
streams across domains while retaining and utilizing past knowledge. Although
prompt-based methods effectively store multi-domain knowledge in prompt
parameters and obtain advanced performance through cross-domain prompt fusion,
we reveal an intrinsic limitation: component-wise misalignment between
domain-specific prompts leads to conflicting knowledge integration and degraded
predictions. This arises from the random positioning of knowledge components
within prompts, where irrelevant component fusion introduces interference.To
address this, we propose Componential Prompt-Knowledge Alignment (KA-Prompt), a
novel prompt-based DIL method that introduces component-aware prompt-knowledge
alignment during training, significantly improving both the learning and
inference capacity of the model. KA-Prompt operates in two phases: (1) Initial
Componential Structure Configuring, where a set of old prompts containing
knowledge relevant to the new domain are mined via greedy search, which is then
exploited to initialize new prompts to achieve reusable knowledge transfer and
establish intrinsic alignment between new and old prompts. (2) Online Alignment
Preservation, which dynamically identifies the target old prompts and applies
adaptive componential consistency constraints as new prompts evolve. Extensive
experiments on DIL benchmarks demonstrate the effectiveness of our KA-Prompt.
Our source code is available at
https://github.com/zhoujiahuan1991/ICML2025-KA-Prompt

</details>

### [85] [Active Sampling for MRI-based Sequential Decision Making](https://arxiv.org/abs/2505.04586)
*Yuning Du,Jingshuai Liu,Rohan Dharmakumar,Sotirios A. Tsaftaris*

Main category: cs.CV

TLDR: 提出了一种多目标强化学习框架，用于从欠采样的k空间数据中实现全面的、连续的诊断评估，显著减少采样需求。


<details>
  <summary>Details</summary>
Motivation: 尽管MRI具有卓越的诊断能力，但其作为即时诊断（PoC）设备的使用仍受限于高成本和复杂性。通过降低磁场强度并改进采样策略，有望实现MRI的PoC应用。

Method: 采用多目标强化学习框架，动态调整采样策略以适应连续诊断决策，并通过逐步加权奖励函数优化采样。

Result: 在膝关节病理评估任务中，该方法在疾病检测、严重程度量化和整体连续诊断方面表现优异，同时显著减少了k空间采样。

Conclusion: 该方法为MRI作为全面且经济的PoC设备提供了可能，代码已公开。

Abstract: Despite the superior diagnostic capability of Magnetic Resonance Imaging
(MRI), its use as a Point-of-Care (PoC) device remains limited by high cost and
complexity. To enable such a future by reducing the magnetic field strength,
one key approach will be to improve sampling strategies. Previous work has
shown that it is possible to make diagnostic decisions directly from k-space
with fewer samples. Such work shows that single diagnostic decisions can be
made, but if we aspire to see MRI as a true PoC, multiple and sequential
decisions are necessary while minimizing the number of samples acquired. We
present a novel multi-objective reinforcement learning framework enabling
comprehensive, sequential, diagnostic evaluation from undersampled k-space
data. Our approach during inference actively adapts to sequential decisions to
optimally sample. To achieve this, we introduce a training methodology that
identifies the samples that contribute the best to each diagnostic objective
using a step-wise weighting reward function. We evaluate our approach in two
sequential knee pathology assessment tasks: ACL sprain detection and cartilage
thickness loss assessment. Our framework achieves diagnostic performance
competitive with various policy-based benchmarks on disease detection, severity
quantification, and overall sequential diagnosis, while substantially saving
k-space samples. Our approach paves the way for the future of MRI as a
comprehensive and affordable PoC device. Our code is publicly available at
https://github.com/vios-s/MRI_Sequential_Active_Sampling

</details>

### [86] [MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection](https://arxiv.org/abs/2505.04594)
*Zhihao Zhang,Abhinav Kumar,Girish Chandar Ganesan,Xiaoming Liu*

Main category: cs.CV

TLDR: 论文提出MonoCoP方法，通过Chain-of-Prediction（CoP）顺序预测3D属性，提升单目3D物体检测的深度估计准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了3D属性间的相互关联性，导致深度预测准确性受限。受大语言模型中Chain-of-Thought启发，提出通过顺序预测条件化属性来解决这一问题。

Method: MonoCoP采用三个关键设计：1）轻量级AttributeNet学习属性特征；2）构建显式链传播特征；3）残差连接聚合特征，确保后续预测基于先前属性。

Result: 在KITTI、Waymo和nuScenes数据集上达到SoTA性能，无需额外数据。

Conclusion: MonoCoP通过条件化顺序预测3D属性，显著提升了单目3D检测的准确性和稳定性。

Abstract: Accurately predicting 3D attributes is crucial for monocular 3D object
detection (Mono3D), with depth estimation posing the greatest challenge due to
the inherent ambiguity in mapping 2D images to 3D space. While existing methods
leverage multiple depth cues (e.g., estimating depth uncertainty, modeling
depth error) to improve depth accuracy, they overlook that accurate depth
prediction requires conditioning on other 3D attributes, as these attributes
are intrinsically inter-correlated through the 3D to 2D projection, which
ultimately limits overall accuracy and stability. Inspired by Chain-of-Thought
(CoT) in large language models (LLMs), this paper proposes MonoCoP, which
leverages a Chain-of-Prediction (CoP) to predict attributes sequentially and
conditionally via three key designs. First, it employs a lightweight
AttributeNet (AN) for each 3D attribute to learn attribute-specific features.
Next, MonoCoP constructs an explicit chain to propagate these learned features
from one attribute to the next. Finally, MonoCoP uses a residual connection to
aggregate features for each attribute along the chain, ensuring that later
attribute predictions are conditioned on all previously processed attributes
without forgetting the features of earlier ones. Experimental results show that
our MonoCoP achieves state-of-the-art (SoTA) performance on the KITTI
leaderboard without requiring additional data and further surpasses existing
methods on the Waymo and nuScenes frontal datasets.

</details>

### [87] [OpenVision: A Fully-Open, Cost-Effective Family of Advanced Vision Encoders for Multimodal Learning](https://arxiv.org/abs/2505.04601)
*Xianhang Li,Yanqing Liu,Haoqin Tu,Hongru Zhu,Cihang Xie*

Main category: cs.CV

TLDR: OpenVision是一个完全开放的视觉编码器家族，性能媲美或超越CLIP，提供从5.9M到632.1M参数的灵活选择。


<details>
  <summary>Details</summary>
Motivation: 填补现有视觉编码器（如CLIP）缺乏完全开放性的空白，提供成本效益高的替代方案。

Method: 基于现有工作（如CLIPS训练框架和Recap-DataComp-1B训练数据），优化编码器质量并展示实际应用优势。

Result: OpenVision在性能上匹配或超越CLIP，并提供多种参数规模的模型。

Conclusion: OpenVision为多模态模型提供了灵活高效的视觉编码器选择，推动开放研究。

Abstract: OpenAI's CLIP, released in early 2021, have long been the go-to choice of
vision encoder for building multimodal foundation models. Although recent
alternatives such as SigLIP have begun to challenge this status quo, to our
knowledge none are fully open: their training data remains proprietary and/or
their training recipes are not released. This paper fills this gap with
OpenVision, a fully-open, cost-effective family of vision encoders that match
or surpass the performance of OpenAI's CLIP when integrated into multimodal
frameworks like LLaVA. OpenVision builds on existing works -- e.g., CLIPS for
training framework and Recap-DataComp-1B for training data -- while revealing
multiple key insights in enhancing encoder quality and showcasing practical
benefits in advancing multimodal models. By releasing vision encoders spanning
from 5.9M to 632.1M parameters, OpenVision offers practitioners a flexible
trade-off between capacity and efficiency in building multimodal models: larger
models deliver enhanced multimodal performance, while smaller versions enable
lightweight, edge-ready multimodal deployments.

</details>

### [88] [FastMap: Revisiting Dense and Scalable Structure from Motion](https://arxiv.org/abs/2505.04612)
*Jiahao Li,Haochen Wang,Muhammad Zubair Irshad,Igor Vasiljevic,Matthew R. Walter,Vitor Campagnolo Guizilini,Greg Shakhnarovich*

Main category: cs.CV

TLDR: FastMap是一种新的全局运动结构方法，专注于速度和简洁性，解决了COLMAP和GLOMAP在大规模场景中的扩展性问题。


<details>
  <summary>Details</summary>
Motivation: COLMAP和GLOMAP等方法在高精度相机姿态估计上表现良好，但在匹配关键点对数量增加时扩展性差。

Method: 设计了一个完全基于GPU友好操作的SfM框架，易于并行化，且每个优化步骤的时间复杂度与图像对数量线性相关。

Result: FastMap在大规模场景中比COLMAP和GLOMAP快一到两个数量级，同时保持相当的姿态精度。

Conclusion: FastMap通过优化并行性和计算效率，显著提升了大规模场景下的运动结构估计速度。

Abstract: We propose FastMap, a new global structure from motion method focused on
speed and simplicity. Previous methods like COLMAP and GLOMAP are able to
estimate high-precision camera poses, but suffer from poor scalability when the
number of matched keypoint pairs becomes large. We identify two key factors
leading to this problem: poor parallelization and computationally expensive
optimization steps. To overcome these issues, we design an SfM framework that
relies entirely on GPU-friendly operations, making it easily parallelizable.
Moreover, each optimization step runs in time linear to the number of image
pairs, independent of keypoint pairs or 3D points. Through extensive
experiments, we show that FastMap is one to two orders of magnitude faster than
COLMAP and GLOMAP on large-scale scenes with comparable pose accuracy.

</details>

### [89] [Person Recognition at Altitude and Range: Fusion of Face, Body Shape and Gait](https://arxiv.org/abs/2505.04616)
*Feng Liu,Nicholas Chimitt,Lanqing Guo,Jitesh Jain,Aditya Kane,Minchul Kim,Wes Robbins,Yiyang Su,Dingqiang Ye,Xingguang Zhang,Jie Zhu,Siddharth Satyakam,Christopher Perry,Stanley H. Chan,Arun Ross,Humphrey Shi,Zhangyang Wang,Anil Jain,Xiaoming Liu*

Main category: cs.CV

TLDR: FarSight是一个端到端的全身人物识别系统，整合了面部、步态和体型等多模态生物特征，在恶劣条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决远距离、高视角和恶劣环境下的全身人物识别问题，适用于监控场景。

Method: 系统包含多目标检测与跟踪、识别感知的视频恢复、模态特定生物特征编码和质量引导的多模态融合四个核心模块。

Result: 在BRIAR数据集上，验证准确率提升34.1%，识别率提升17.8%，开放集识别错误减少34.3%。

Conclusion: FarSight是恶劣现实条件下生物识别的先进解决方案。

Abstract: We address the problem of whole-body person recognition in unconstrained
environments. This problem arises in surveillance scenarios such as those in
the IARPA Biometric Recognition and Identification at Altitude and Range
(BRIAR) program, where biometric data is captured at long standoff distances,
elevated viewing angles, and under adverse atmospheric conditions (e.g.,
turbulence and high wind velocity). To this end, we propose FarSight, a unified
end-to-end system for person recognition that integrates complementary
biometric cues across face, gait, and body shape modalities. FarSight
incorporates novel algorithms across four core modules: multi-subject detection
and tracking, recognition-aware video restoration, modality-specific biometric
feature encoding, and quality-guided multi-modal fusion. These components are
designed to work cohesively under degraded image conditions, large pose and
scale variations, and cross-domain gaps. Extensive experiments on the BRIAR
dataset, one of the most comprehensive benchmarks for long-range, multi-modal
biometric recognition, demonstrate the effectiveness of FarSight. Compared to
our preliminary system, this system achieves a 34.1% absolute gain in 1:1
verification accuracy (TAR@0.1% FAR), a 17.8% increase in closed-set
identification (Rank-20), and a 34.3% reduction in open-set identification
errors (FNIR@1% FPIR). Furthermore, FarSight was evaluated in the 2025 NIST RTE
Face in Video Evaluation (FIVE), which conducts standardized face recognition
testing on the BRIAR dataset. These results establish FarSight as a
state-of-the-art solution for operational biometric recognition in challenging
real-world conditions.

</details>

### [90] [On Path to Multimodal Generalist: General-Level and General-Bench](https://arxiv.org/abs/2505.04620)
*Hao Fei,Yuan Zhou,Juncheng Li,Xiangtai Li,Qingshan Xu,Bobo Li,Shengqiong Wu,Yaoting Wang,Junbao Zhou,Jiahao Meng,Qingyu Shi,Zhiyuan Zhou,Liangtao Shi,Minghe Gao,Daoan Zhang,Zhiqi Ge,Weiming Wu,Siliang Tang,Kaihang Pan,Yaobo Ye,Haobo Yuan,Tao Zhang,Tianjie Ju,Zixiang Meng,Shilin Xu,Liyu Jia,Wentao Hu,Meng Luo,Jiebo Luo,Tat-Seng Chua,Shuicheng Yan,Hanwang Zhang*

Main category: cs.CV

TLDR: 论文提出了一种名为General-Level的评估框架，用于衡量多模态大语言模型（MLLM）的性能和通用性，并引入了Synergy概念和General-Bench数据集。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM评估方法过于简单，无法全面衡量模型的能力和通用性，尤其是是否接近人类水平AI。

Method: 提出5级评估框架General-Level，引入Synergy概念衡量模型在多模态理解和生成中的一致性，并构建General-Bench数据集（700任务，325,800实例）。

Result: 评估了100多个MLLM，揭示了通用模型的性能排名，并指出了实现真正AI的挑战。

Conclusion: 该框架为未来多模态基础模型研究提供了基础设施，加速实现通用人工智能（AGI）。

Abstract: The Multimodal Large Language Model (MLLM) is currently experiencing rapid
growth, driven by the advanced capabilities of LLMs. Unlike earlier
specialists, existing MLLMs are evolving towards a Multimodal Generalist
paradigm. Initially limited to understanding multiple modalities, these models
have advanced to not only comprehend but also generate across modalities. Their
capabilities have expanded from coarse-grained to fine-grained multimodal
understanding and from supporting limited modalities to arbitrary ones. While
many benchmarks exist to assess MLLMs, a critical question arises: Can we
simply assume that higher performance across tasks indicates a stronger MLLM
capability, bringing us closer to human-level AI? We argue that the answer is
not as straightforward as it seems. This project introduces General-Level, an
evaluation framework that defines 5-scale levels of MLLM performance and
generality, offering a methodology to compare MLLMs and gauge the progress of
existing systems towards more robust multimodal generalists and, ultimately,
towards AGI. At the core of the framework is the concept of Synergy, which
measures whether models maintain consistent capabilities across comprehension
and generation, and across multiple modalities. To support this evaluation, we
present General-Bench, which encompasses a broader spectrum of skills,
modalities, formats, and capabilities, including over 700 tasks and 325,800
instances. The evaluation results that involve over 100 existing
state-of-the-art MLLMs uncover the capability rankings of generalists,
highlighting the challenges in reaching genuine AI. We expect this project to
pave the way for future research on next-generation multimodal foundation
models, providing a robust infrastructure to accelerate the realization of AGI.
Project page: https://generalist.top/

</details>

<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [91] [TerraFusion: Joint Generation of Terrain Geometry and Texture Using Latent Diffusion Models](https://arxiv.org/abs/2505.04050)
*Kazuki Higo,Toshiki Kanai,Yuki Endo,Yoshihiro Kanamori*

Main category: cs.GR

TLDR: 提出了一种基于潜在扩散模型的联合生成地形高度图和纹理的方法，通过无监督学习和监督学习实现用户控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独生成高度图或纹理，未能充分捕捉两者之间的相关性，影响真实感。

Method: 使用潜在扩散模型无监督生成配对的随机高度图和纹理，并通过监督学习训练外部适配器以实现用户手绘草图控制。

Result: 实验表明，该方法能直观生成地形并保持高度图与纹理的关联。

Conclusion: 该方法有效解决了地形生成中高度图与纹理的关联问题，提升了真实感和用户控制性。

Abstract: 3D terrain models are essential in fields such as video game development and
film production. Since surface color often correlates with terrain geometry,
capturing this relationship is crucial to achieving realism. However, most
existing methods generate either a heightmap or a texture, without sufficiently
accounting for the inherent correlation. In this paper, we propose a method
that jointly generates terrain heightmaps and textures using a latent diffusion
model. First, we train the model in an unsupervised manner to randomly generate
paired heightmaps and textures. Then, we perform supervised learning of an
external adapter to enable user control via hand-drawn sketches. Experiments
show that our approach allows intuitive terrain generation while preserving the
correlation between heightmaps and textures.

</details>

### [92] [Person-In-Situ: Scene-Consistent Human Image Insertion with Occlusion-Aware Pose Control](https://arxiv.org/abs/2505.04052)
*Shun Masuda,Yuki Endo,Yoshihiro Kanamori*

Main category: cs.GR

TLDR: 论文提出两种方法，通过3D人体模型控制姿势，利用潜在扩散模型合成人物，解决现有方法在遮挡和深度问题上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法在人物插入场景时难以处理遮挡问题，且无法自然控制人物深度和姿势。

Method: 提出两种方法：1）两阶段法，先学习场景深度图再合成人物；2）直接法，无需显式深度监督，隐式学习遮挡。

Result: 定量和定性评估显示，两种方法在场景一致性和遮挡处理上优于现有方法。

Conclusion: 新方法通过3D姿势控制和潜在扩散模型，显著提升了人物合成的自然性和可控性。

Abstract: Compositing human figures into scene images has broad applications in areas
such as entertainment and advertising. However, existing methods often cannot
handle occlusion of the inserted person by foreground objects and unnaturally
place the person in the frontmost layer. Moreover, they offer limited control
over the inserted person's pose. To address these challenges, we propose two
methods. Both allow explicit pose control via a 3D body model and leverage
latent diffusion models to synthesize the person at a contextually appropriate
depth, naturally handling occlusions without requiring occlusion masks. The
first is a two-stage approach: the model first learns a depth map of the scene
with the person through supervised learning, and then synthesizes the person
accordingly. The second method learns occlusion implicitly and synthesizes the
person directly from input data without explicit depth supervision.
Quantitative and qualitative evaluations show that both methods outperform
existing approaches by better preserving scene consistency while accurately
reflecting occlusions and user-specified poses.

</details>

### [93] [Geometry-Aware Texture Generation for 3D Head Modeling with Artist-driven Control](https://arxiv.org/abs/2505.04387)
*Amin Fadaeinejad,Abdallah Dib,Luiz Gustavo Hafemann,Emeline Got,Trevor Anderson,Amaury Depierre,Nikolaus F. Troje,Marcus A. Brubaker,Marc-André Carbonneau*

Main category: cs.GR

TLDR: 提出了一种新颖的框架，通过几何感知的纹理合成流程，为艺术家提供直观控制生成3D头部模型的能力，简化虚拟角色创作流程。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D头部资产创建过程劳动密集型的问题，满足艺术家对精确艺术表现的需求。

Method: 采用几何感知纹理合成流程，学习头部几何与皮肤纹理之间的关联，提供三个层级的艺术控制：整体几何调整、肤色调整保留特征、细节编辑。

Result: 实验表明，该方法能生成多样化的结果并保持干净的几何结构，适用于肤色调整和细节编辑等实际应用。

Conclusion: 该框架通过集成控制功能，显著简化了虚拟角色创作的艺术流程。

Abstract: Creating realistic 3D head assets for virtual characters that match a precise
artistic vision remains labor-intensive. We present a novel framework that
streamlines this process by providing artists with intuitive control over
generated 3D heads. Our approach uses a geometry-aware texture synthesis
pipeline that learns correlations between head geometry and skin texture maps
across different demographics. The framework offers three levels of artistic
control: manipulation of overall head geometry, adjustment of skin tone while
preserving facial characteristics, and fine-grained editing of details such as
wrinkles or facial hair. Our pipeline allows artists to make edits to a single
texture map using familiar tools, with our system automatically propagating
these changes coherently across the remaining texture maps needed for realistic
rendering. Experiments demonstrate that our method produces diverse results
with clean geometries. We showcase practical applications focusing on intuitive
control for artists, including skin tone adjustments and simplified editing
workflows for adding age-related details or removing unwanted features from
scanned models. This integrated approach aims to streamline the artistic
workflow in virtual character creation.

</details>

### [94] [TetWeave: Isosurface Extraction using On-The-Fly Delaunay Tetrahedral Grids for Gradient-Based Mesh Optimization](https://arxiv.org/abs/2505.04590)
*Alexandre Binninger,Ruben Wiersma,Philipp Herholz,Olga Sorkine-Hornung*

Main category: cs.GR

TLDR: TetWeave是一种新型等值面表示方法，通过联合优化四面体网格和方向有符号距离，实现高质量、自适应的网格生成。


<details>
  <summary>Details</summary>
Motivation: 传统预定义网格在灵活性和内存效率上存在不足，TetWeave旨在解决这些问题。

Method: 通过动态Delaunay三角剖分构建四面体网格，并优化方向有符号距离，支持重采样策略和网格公平性。

Result: 生成的网格具有水密性、二维流形和无交特性，内存占用低且参数少。

Conclusion: TetWeave在多种图形和视觉任务中表现出色，显著优于传统方法。

Abstract: We introduce TetWeave, a novel isosurface representation for gradient-based
mesh optimization that jointly optimizes the placement of a tetrahedral grid
used for Marching Tetrahedra and a novel directional signed distance at each
point. TetWeave constructs tetrahedral grids on-the-fly via Delaunay
triangulation, enabling increased flexibility compared to predefined grids. The
extracted meshes are guaranteed to be watertight, two-manifold and
intersection-free. The flexibility of TetWeave enables a resampling strategy
that places new points where reconstruction error is high and allows to
encourage mesh fairness without compromising on reconstruction error. This
leads to high-quality, adaptive meshes that require minimal memory usage and
few parameters to optimize. Consequently, TetWeave exhibits near-linear memory
scaling relative to the vertex count of the output mesh - a substantial
improvement over predefined grids. We demonstrate the applicability of TetWeave
to a broad range of challenging tasks in computer graphics and vision, such as
multi-view 3D reconstruction, mesh compression and geometric texture
generation.

</details>

### [95] [PrimitiveAnything: Human-Crafted 3D Primitive Assembly Generation with Auto-Regressive Transformer](https://arxiv.org/abs/2505.04622)
*Jingwen Ye,Yuze He,Yanning Zhou,Yiqin Zhu,Kaiwen Xiao,Yong-Jin Liu,Wei Yang,Xiao Han*

Main category: cs.GR

TLDR: 论文提出了一种名为PrimitiveAnything的新框架，通过将形状基元抽象任务重新定义为基元组装生成任务，解决了现有方法在语义理解和跨类别泛化上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有形状基元抽象方法在语义理解和跨类别泛化能力上存在局限，无法满足多样化的3D形状需求。

Method: PrimitiveAnything采用形状条件基元变换器进行自回归生成，并通过无歧义参数化方案统一表示多种基元类型。

Result: 实验表明，PrimitiveAnything能生成高质量且符合人类感知的基元组装，同时保持几何保真度。

Conclusion: 该框架在多样化形状类别中表现优异，有望推动基于基元的用户生成内容（UGC）在游戏等领域的应用。

Abstract: Shape primitive abstraction, which decomposes complex 3D shapes into simple
geometric elements, plays a crucial role in human visual cognition and has
broad applications in computer vision and graphics. While recent advances in 3D
content generation have shown remarkable progress, existing primitive
abstraction methods either rely on geometric optimization with limited semantic
understanding or learn from small-scale, category-specific datasets, struggling
to generalize across diverse shape categories. We present PrimitiveAnything, a
novel framework that reformulates shape primitive abstraction as a primitive
assembly generation task. PrimitiveAnything includes a shape-conditioned
primitive transformer for auto-regressive generation and an ambiguity-free
parameterization scheme to represent multiple types of primitives in a unified
manner. The proposed framework directly learns the process of primitive
assembly from large-scale human-crafted abstractions, enabling it to capture
how humans decompose complex shapes into primitive elements. Through extensive
experiments, we demonstrate that PrimitiveAnything can generate high-quality
primitive assemblies that better align with human perception while maintaining
geometric fidelity across diverse shape categories. It benefits various 3D
applications and shows potential for enabling primitive-based user-generated
content (UGC) in games. Project page: https://primitiveanything.github.io

</details>

<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [96] [Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration](https://arxiv.org/abs/2505.04457)
*Shigeki Karita,Yuma Koizumi,Heiga Zen,Haruko Ishikawa,Robin Scheibler,Michiel Bacchiani*

Main category: cs.SD

TLDR: Miipher-2是一种用于大规模生成模型训练数据清理的语音恢复模型，支持300多种语言，无需显式条件输入，计算高效。


<details>
  <summary>Details</summary>
Motivation: 解决大规模生成模型训练数据清理中的泛化性、无显式条件和计算效率问题。

Method: 利用预训练的通用语音模型（USM）作为特征提取器，结合并行适配器和WaneFit神经声码器，训练于多语言高质量录音数据。

Result: 在词错误率、说话人相似度和音质评分上优于或媲美传统语音恢复模型，计算效率高。

Conclusion: Miipher-2为大规模语音数据清理提供了高效、通用的解决方案。

Abstract: Training data cleaning is a new application for generative model-based speech
restoration (SR). This paper introduces Miipher-2, an SR model designed for
million-hour scale data, for training data cleaning for large-scale generative
models like large language models. Key challenges addressed include
generalization to unseen languages, operation without explicit conditioning
(e.g., text, speaker ID), and computational efficiency. Miipher-2 utilizes a
frozen, pre-trained Universal Speech Model (USM), supporting over 300
languages, as a robust, conditioning-free feature extractor. To optimize
efficiency and minimize memory, Miipher-2 incorporates parallel adapters for
predicting clean USM features from noisy inputs and employs the WaneFit neural
vocoder for waveform synthesis. These components were trained on 3,000 hours of
multi-lingual, studio-quality recordings with augmented degradations, while USM
parameters remained fixed. Experimental results demonstrate Miipher-2's
superior or comparable performance to conventional SR models in
word-error-rate, speaker similarity, and both objective and subjective sound
quality scores across all tested languages. Miipher-2 operates efficiently on
consumer-grade accelerators, achieving a real-time factor of 0.0078, enabling
the processing of a million-hour speech dataset in approximately three days
using only 100 such accelerators.

</details>

<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [97] [EchoInk-R1: Exploring Audio-Visual Reasoning in Multimodal LLMs via Reinforcement Learning](https://arxiv.org/abs/2505.04623)
*Zhenghao Xing,Xiaowei Hu,Chi-Wing Fu,Wenhai Wang,Jifeng Dai,Pheng-Ann Heng*

Main category: eess.AS

TLDR: EchoInk-R1是一个基于强化学习的框架，用于提升多模态大语言模型（MLLMs）在音频和视觉信号之间的结构化跨模态推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs在跨模态推理（尤其是音频和视觉信号的整合）方面表现不佳，因此需要一种方法来增强这种能力。

Method: 基于Qwen2.5-Omni-7B模型，使用Group Relative Policy Optimization（GRPO）优化，构建了EchoInk-R1框架，并在AVQA-R1-6K数据集上进行多选问答任务。

Result: EchoInk-R1-7B在验证集上达到85.77%的准确率，优于基础模型的80.53%，且仅需562步强化学习。

Conclusion: 轻量级强化学习微调可以有效提升MLLMs的跨模态推理能力，EchoInk-R1是首个通过强化学习统一音频、视觉和文本模态的框架。

Abstract: Multimodal large language models (MLLMs) have advanced perception across
text, vision, and audio, yet they often struggle with structured cross-modal
reasoning, particularly when integrating audio and visual signals. We introduce
EchoInk-R1, a reinforcement learning framework that enhances such reasoning in
MLLMs. Built upon the Qwen2.5-Omni-7B foundation and optimized with Group
Relative Policy Optimization (GRPO), EchoInk-R1 tackles multiple-choice
question answering over synchronized audio-image pairs. To enable this, we
curate AVQA-R1-6K, a dataset pairing such audio-image inputs with
multiple-choice questions derived from OmniInstruct-v1. EchoInk-R1-7B achieves
85.77% accuracy on the validation set, outperforming the base model, which
scores 80.53%, using only 562 reinforcement learning steps. Beyond accuracy,
EchoInk-R1 demonstrates reflective reasoning by revisiting initial
interpretations and refining responses when facing ambiguous multimodal inputs.
These results suggest that lightweight reinforcement learning fine-tuning
enhances cross-modal reasoning in MLLMs. EchoInk-R1 is the first framework to
unify audio, visual, and textual modalities for general open-world reasoning
via reinforcement learning. Code and data are publicly released to facilitate
further research.

</details>

<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [98] [Large Language Models are often politically extreme, usually ideologically inconsistent, and persuasive even in informational contexts](https://arxiv.org/abs/2505.04171)
*Nouar Aldahoul,Hazem Ibrahim,Matteo Varvello,Aaron Kaufman,Talal Rahwan,Yasir Zaki*

Main category: cs.CY

TLDR: 研究发现，大型语言模型（LLMs）的政治偏见并非表面上的轻微，而是由极端观点抵消后的结果，且能显著影响用户的政治倾向。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs的政治偏见及其对用户政治倾向的实际影响，挑战现有认为偏见较小的观点。

Method: 比较31个LLMs与立法者、法官及美国选民样本，并进行随机实验测试LLMs对用户政治倾向的影响。

Result: LLMs的偏见是极端观点的抵消结果，且能使用户政治倾向改变多达5个百分点。

Conclusion: LLMs可能成为政治影响力的强大工具，需警惕其潜在影响。

Abstract: Large Language Models (LLMs) are a transformational technology, fundamentally
changing how people obtain information and interact with the world. As people
become increasingly reliant on them for an enormous variety of tasks, a body of
academic research has developed to examine these models for inherent biases,
especially political biases, often finding them small. We challenge this
prevailing wisdom. First, by comparing 31 LLMs to legislators, judges, and a
nationally representative sample of U.S. voters, we show that LLMs' apparently
small overall partisan preference is the net result of offsetting extreme views
on specific topics, much like moderate voters. Second, in a randomized
experiment, we show that LLMs can promulgate their preferences into political
persuasiveness even in information-seeking contexts: voters randomized to
discuss political issues with an LLM chatbot are as much as 5 percentage points
more likely to express the same preferences as that chatbot. Contrary to
expectations, these persuasive effects are not moderated by familiarity with
LLMs, news consumption, or interest in politics. LLMs, especially those
controlled by private companies or governments, may become a powerful and
targeted vector for political influence.

</details>

### [99] [Coverage Biases in High-Resolution Satellite Imagery](https://arxiv.org/abs/2505.03842)
*Vadim Musienko,Axel Jacquet,Ingmar Weber,Till Koebe*

Main category: cs.CY

TLDR: 研究发现卫星图像的覆盖存在地理和社会经济偏差，远离赤道的地区更频繁被访问，而欠发达地区历史图像较少。地缘政治事件也影响图像可用性。


<details>
  <summary>Details</summary>
Motivation: 探讨卫星图像是否在全球范围内公平分布，揭示潜在的地理和社会经济偏差。

Method: 分析卫星轨道数据评估覆盖频率，收集历史图像元数据研究可用性，并通过三个冲突地区案例研究地缘政治影响。

Result: 远离赤道地区覆盖更频繁，欠发达地区历史图像较少，地缘政治事件显著影响图像可用性。

Conclusion: 卫星图像的数字红利在全球分布不均，需关注其公平性和潜在偏见。

Abstract: Satellite imagery is increasingly used to complement traditional data
collection approaches such as surveys and censuses across scientific
disciplines. However, we ask: Do all places on earth benefit equally from this
new wealth of information? In this study, we investigate coverage bias of major
satellite constellations that provide optical satellite imagery with a ground
sampling distance below 10 meters, evaluating both the future on-demand tasking
opportunities as well as the availability of historic images across the globe.
Specifically, forward-looking, we estimate how often different places are
revisited during a window of 30 days based on the satellites' orbital paths,
thus investigating potential coverage biases caused by physical factors. We
find that locations farther away from the equator are generally revisited more
frequently by the constellations under study. Backward-looking, we show that
historic satellite image availability -- based on metadata collected from major
satellite imagery providers -- is influenced by socio-economic factors on the
ground: less developed, less populated places have less satellite images
available. Furthermore, in three small case studies on recent conflict regions
in this world, namely Gaza, Sudan and Ukraine, we show that also geopolitical
events play an important role in satellite image availability, hinting at
underlying business model decisions. These insights lay bare that the digital
dividend yielded by satellite imagery is not equally distributed across our
planet.

</details>

### [100] [Deepfakes on Demand: the rise of accessible non-consensual deepfake image generators](https://arxiv.org/abs/2505.03859)
*Will Hawkins,Chris Russell,Brent Mittelstadt*

Main category: cs.CY

TLDR: 研究分析了在线可获取的深度伪造模型变体的可访问性，发现其数量激增且下载量巨大，主要针对女性，呼吁采取更多行动。


<details>
  <summary>Details</summary>
Motivation: 探讨文本到图像（T2I）模型带来的风险，特别是深度伪造模型的广泛可访问性及其潜在危害。

Method: 通过对Hugging Face和Civitai两个平台上的数千个公开可下载模型变体进行元数据分析。

Result: 识别出近35,000个公开可下载的深度伪造模型变体，下载量达1,500万次，96%针对女性，许多意图生成非自愿亲密图像（NCII）。

Conclusion: 尽管违反平台服务条款且存在监管，仍需采取更多行动打击深度伪造和NCII的创建与传播。

Abstract: Advances in multimodal machine learning have made text-to-image (T2I) models
increasingly accessible and popular. However, T2I models introduce risks such
as the generation of non-consensual depictions of identifiable individuals,
otherwise known as deepfakes. This paper presents an empirical study exploring
the accessibility of deepfake model variants online. Through a metadata
analysis of thousands of publicly downloadable model variants on two popular
repositories, Hugging Face and Civitai, we demonstrate a huge rise in easily
accessible deepfake models. Almost 35,000 examples of publicly downloadable
deepfake model variants are identified, primarily hosted on Civitai. These
deepfake models have been downloaded almost 15 million times since November
2022, with the models targeting a range of individuals from global celebrities
to Instagram users with under 10,000 followers. Both Stable Diffusion and Flux
models are used for the creation of deepfake models, with 96% of these
targeting women and many signalling intent to generate non-consensual intimate
imagery (NCII). Deepfake model variants are often created via the
parameter-efficient fine-tuning technique known as low rank adaptation (LoRA),
requiring as few as 20 images, 24GB VRAM, and 15 minutes of time, making this
process widely accessible via consumer-grade computers. Despite these models
violating the Terms of Service of hosting platforms, and regulation seeking to
prevent dissemination, these results emphasise the pressing need for greater
action to be taken against the creation of deepfakes and NCII.

</details>

<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [101] [On the Residual-based Neural Network for Unmodeled Distortions in Coordinate Transformation](https://arxiv.org/abs/2505.03757)
*Vinicius Francisco Rofatto,Luiz Felipe Rodrigues de Almeida,Marcelo Tomio Matsuoka,Ivandro Klein,Mauricio Roberto Veronez,Luiz Gonzaga Da Silveira Junior*

Main category: physics.geo-ph

TLDR: 提出了一种基于残差的神经校正策略，用于改进坐标变换模型，减少非线性失真和空间依赖性误差。


<details>
  <summary>Details</summary>
Motivation: 传统坐标变换模型难以处理非线性和空间依赖性失真，导致显著残差误差。

Method: 利用神经网络学习初始几何变换后的系统失真模式，专注于残差建模。

Result: 在稀疏或结构化控制点配置下，该方法性能优于直接神经网络转换和经典变换模型。

Conclusion: 残差建模是一种轻量且鲁棒的策略，可显著提升坐标变换精度。

Abstract: Coordinate transformation models often fail to account for nonlinear and
spatially dependent distortions, leading to significant residual errors in
geospatial applications. Here we propose a residual-based neural correction
strategy, in which a neural network learns to model only the systematic
distortions left by an initial geometric transformation. By focusing solely on
residual patterns, the proposed method reduces model complexity and improves
performance, particularly in scenarios with sparse or structured control point
configurations. We evaluate the method using both simulated datasets with
varying distortion intensities and sampling strategies, as well as under the
real-world image georeferencing tasks. Compared with direct neural network
coordinate converter and classical transformation models, the residual-based
neural correction delivers more accurate and stable results under challenging
conditions, while maintaining comparable performance in ideal cases. These
findings demonstrate the effectiveness of residual modelling as a lightweight
and robust alternative for improving coordinate transformation accuracy.

</details>

<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [102] [IntelliCardiac: An Intelligent Platform for Cardiac Image Segmentation and Classification](https://arxiv.org/abs/2505.03838)
*Ting Yu Tsai,An Yu,Meghana Spurthi Maadugundu,Ishrat Jahan Mohima,Umme Habiba Barsha,Mei-Hwa F. Chen,Balakrishnan Prabhakaran,Ming-Ching Chang*

Main category: eess.IV

TLDR: IntelliCardiac是一个基于AI的医疗图像处理平台，用于4D心脏图像的自动分割和疾病分类，准确率高达98%。


<details>
  <summary>Details</summary>
Motivation: 精确处理心脏影像数据对心血管疾病的识别和管理至关重要，现有方法性能有限。

Method: 结合深度学习分割模型和两步分类流程，利用ACDC数据集训练。

Result: 分割模块准确率92.6%，分类模块准确率98%，优于现有方法。

Conclusion: IntelliCardiac具有实时可视化、工作流集成和AI辅助诊断潜力，适用于临床决策支持。

Abstract: Precise and effective processing of cardiac imaging data is critical for the
identification and management of the cardiovascular diseases. We introduce
IntelliCardiac, a comprehensive, web-based medical image processing platform
for the automatic segmentation of 4D cardiac images and disease classification,
utilizing an AI model trained on the publicly accessible ACDC dataset. The
system, intended for patients, cardiologists, and healthcare professionals,
offers an intuitive interface and uses deep learning models to identify
essential heart structures and categorize cardiac diseases. The system supports
analysis of both the right and left ventricles as well as myocardium, and then
classifies patient's cardiac images into five diagnostic categories: dilated
cardiomyopathy, myocardial infarction, hypertrophic cardiomyopathy, right
ventricular abnormality, and no disease. IntelliCardiac combines a deep
learning-based segmentation model with a two-step classification pipeline. The
segmentation module gains an overall accuracy of 92.6\%. The classification
module, trained on characteristics taken from segmented heart structures,
achieves 98\% accuracy in five categories. These results exceed the performance
of the existing state-of-the-art methods that integrate both segmentation and
classification models. IntelliCardiac, which supports real-time visualization,
workflow integration, and AI-assisted diagnostics, has great potential as a
scalable, accurate tool for clinical decision assistance in cardiac imaging and
diagnosis.

</details>

### [103] [From Spaceborn to Airborn: SAR Image Synthesis Using Foundation Models for Multi-Scale Adaptation](https://arxiv.org/abs/2505.03844)
*Solène Debuysère,Nicolas Trouvé,Nathan Letheule,Olivier Lévêque,Elise Colin*

Main category: eess.IV

TLDR: 论文提出了一种利用预训练的潜在扩散模型和空间条件技术，将卫星SAR图像转换为机载SAR表示的新方法，解决了机载SAR数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 机载高分辨率SAR图像获取成本高且数据稀缺，缺乏开源标注数据集，限制了现有基础模型在遥感应用中的使用。

Method: 利用ONERA的15年机载SAR数据，构建了11万张SAR图像的数据集，结合35亿参数的预训练潜在扩散模型，采用空间条件技术进行图像转换。

Result: 方法成功将卫星SAR图像转换为机载SAR表示，并提升了仿真图像的真实性。

Conclusion: 该研究为SAR成像技术的进步提供了关键AI应用，填补了文献中的空白。

Abstract: The availability of Synthetic Aperture Radar (SAR) satellite imagery has
increased considerably in recent years, with datasets commercially available.
However, the acquisition of high-resolution SAR images in airborne
configurations, remains costly and limited. Thus, the lack of open source,
well-labeled, or easily exploitable SAR text-image datasets is a barrier to the
use of existing foundation models in remote sensing applications. In this
context, synthetic image generation is a promising solution to augment this
scarce data, enabling a broader range of applications. Leveraging over 15 years
of ONERA's extensive archival airborn data from acquisition campaigns, we
created a comprehensive training dataset of 110 thousands SAR images to exploit
a 3.5 billion parameters pre-trained latent diffusion model. In this work, we
present a novel approach utilizing spatial conditioning techniques within a
foundation model to transform satellite SAR imagery into airborne SAR
representations. Additionally, we demonstrate that our pipeline is effective
for bridging the realism of simulated images generated by ONERA's physics-based
simulator EMPRISE. Our method explores a key application of AI in advancing SAR
imaging technology. To the best of our knowledge, we are the first to introduce
this approach in the literature.

</details>

### [104] [A Deep Learning approach for Depressive Symptoms assessment in Parkinson's disease patients using facial videos](https://arxiv.org/abs/2505.03845)
*Ioannis Kyprakis,Vasileios Skaramagkas,Iro Boura,Georgios Karamanis,Dimitrios I. Fotiadis,Zinovia Kefalopoulou,Cleanthe Spanaki,Manolis Tsiknakis*

Main category: eess.IV

TLDR: 该研究使用深度学习模型（ViViT、Video Swin Tiny和3D CNN-LSTM）通过面部视频分析评估帕金森病患者的抑郁症状，Video Swin Tiny模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 帕金森病患者的抑郁症状常被低估，研究旨在通过深度学习技术提高诊断准确性。

Method: 采用三种深度学习模型分析面部视频数据，评估抑郁症状的存在和严重程度，并考虑药物状态的影响。

Result: Video Swin Tiny模型在二元分类和多分类任务中表现最佳，准确率分别达94%和87.1%。

Conclusion: 深度学习模型，尤其是Video Swin Tiny，可有效识别帕金森病患者的抑郁症状，为临床诊断提供新工具。

Abstract: Parkinson's disease (PD) is a neurodegenerative disorder, manifesting with
motor and non-motor symptoms. Depressive symptoms are prevalent in PD,
affecting up to 45% of patients. They are often underdiagnosed due to
overlapping motor features, such as hypomimia. This study explores deep
learning (DL) models-ViViT, Video Swin Tiny, and 3D CNN-LSTM with attention
layers-to assess the presence and severity of depressive symptoms, as detected
by the Geriatric Depression Scale (GDS), in PD patients through facial video
analysis. The same parameters were assessed in a secondary analysis taking into
account whether patients were one hour after (ON-medication state) or 12 hours
without (OFF-medication state) dopaminergic medication. Using a dataset of
1,875 videos from 178 patients, the Video Swin Tiny model achieved the highest
performance, with up to 94% accuracy and 93.7% F1-score in binary
classification (presence of absence of depressive symptoms), and 87.1% accuracy
with an 85.4% F1-score in multiclass tasks (absence or mild or severe
depressive symptoms).

</details>

### [105] [Prototype-Based Information Compensation Network for Multi-Source Remote Sensing Data Classification](https://arxiv.org/abs/2505.04003)
*Feng Gao,Sheng Liu,Chuanzheng Gong,Xiaowei Zhou,Jiayi Wang,Junyu Dong,Qian Du*

Main category: eess.IV

TLDR: 提出了一种基于HSI和SAR/LiDAR数据的原型信息补偿网络（PICNet），用于解决多源遥感数据联合分类中的特征耦合和互补信息不一致问题。


<details>
  <summary>Details</summary>
Motivation: 多源遥感数据联合分类旨在通过利用多源数据的互补信息提高分类精度和可靠性，但现有方法面临多源特征耦合和互补信息探索不一致的挑战。

Method: 设计了频率交互模块增强多源特征提取中的频率耦合，并通过原型信息补偿模块建模全局互补信息，利用模态原型实现跨模态特征整合和对齐。

Result: 在三个公开数据集上的实验表明，PICNet显著优于现有方法。

Conclusion: PICNet有效解决了多源遥感数据分类中的关键问题，提升了分类性能。

Abstract: Multi-source remote sensing data joint classification aims to provide
accuracy and reliability of land cover classification by leveraging the
complementary information from multiple data sources. Existing methods confront
two challenges: inter-frequency multi-source feature coupling and inconsistency
of complementary information exploration. To solve these issues, we present a
Prototype-based Information Compensation Network (PICNet) for land cover
classification based on HSI and SAR/LiDAR data. Specifically, we first design a
frequency interaction module to enhance the inter-frequency coupling in
multi-source feature extraction. The multi-source features are first decoupled
into high- and low-frequency components. Then, these features are recoupled to
achieve efficient inter-frequency communication. Afterward, we design a
prototype-based information compensation module to model the global
multi-source complementary information. Two sets of learnable modality
prototypes are introduced to represent the global modality information of
multi-source data. Subsequently, cross-modal feature integration and alignment
are achieved through cross-attention computation between the modality-specific
prototype vectors and the raw feature representations. Extensive experiments on
three public datasets demonstrate the significant superiority of our PICNet
over state-of-the-art methods. The codes are available at
https://github.com/oucailab/PICNet.

</details>

### [106] [3D Brain MRI Classification for Alzheimer Diagnosis Using CNN with Data Augmentation](https://arxiv.org/abs/2505.04097)
*Thien Nhan Vo,Bac Nam Ho,Thanh Xuan Truong*

Main category: eess.IV

TLDR: 开发了一个3D卷积神经网络，用于将T1加权脑MRI扫描分类为健康或阿尔茨海默病，通过噪声注入和交叉验证，模型表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过3D卷积神经网络提高脑MRI扫描分类的准确性，探索数据增强对模型性能的影响。

Method: 使用3D卷积、池化、批归一化、ReLU层和Sigmoid输出构建网络，结合随机噪声注入和五折交叉验证。

Result: 测试集准确率为0.912，ROC曲线下面积为0.961，灵敏度和特异性均超过0.90。

Conclusion: 结果表明简单数据增强对3D MRI分类有效，未来可探索更先进的增强方法和架构。

Abstract: A three-dimensional convolutional neural network was developed to classify
T1-weighted brain MRI scans as healthy or Alzheimer. The network comprises 3D
convolution, pooling, batch normalization, dense ReLU layers, and a sigmoid
output. Using stochastic noise injection and five-fold cross-validation, the
model achieved test set accuracy of 0.912 and area under the ROC curve of
0.961, an improvement of approximately 0.027 over resizing alone. Sensitivity
and specificity both exceeded 0.90. These results align with prior work
reporting up to 0.10 gain via synthetic augmentation. The findings demonstrate
the effectiveness of simple augmentation for 3D MRI classification and motivate
future exploration of advanced augmentation methods and architectures such as
3D U-Net and vision transformers.

</details>

<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [107] [OpenHelix: A Short Survey, Empirical Analysis, and Open-Source Dual-System VLA Model for Robotic Manipulation](https://arxiv.org/abs/2505.03912)
*Can Cui,Pengxiang Ding,Wenxuan Song,Shuanghao Bai,Xinyang Tong,Zirui Ge,Runze Suo,Wanqi Zhou,Yang Liu,Bofang Jia,Han Zhao,Siteng Huang,Donglin Wang*

Main category: cs.RO

TLDR: 总结并比较现有双系统架构的结构设计，进行系统实验评估，提供低成本开源模型。


<details>
  <summary>Details</summary>
Motivation: 解决双系统VLA架构开源资源不足的问题，促进性能分析与优化。

Method: 总结比较现有架构设计，系统评估核心设计元素。

Result: 提供低成本开源模型，并持续更新实验结论与改进模型。

Conclusion: 为双系统VLA架构研究提供开源支持，推动进一步探索。

Abstract: Dual-system VLA (Vision-Language-Action) architectures have become a hot
topic in embodied intelligence research, but there is a lack of sufficient
open-source work for further performance analysis and optimization. To address
this problem, this paper will summarize and compare the structural designs of
existing dual-system architectures, and conduct systematic empirical
evaluations on the core design elements of existing dual-system architectures.
Ultimately, it will provide a low-cost open-source model for further
exploration. Of course, this project will continue to update with more
experimental conclusions and open-source models with improved performance for
everyone to choose from. Project page: https://openhelix-robot.github.io/.

</details>

### [108] [Scalable Aerial GNSS Localization for Marine Robots](https://arxiv.org/abs/2505.04095)
*Shuo Wen,Edwin Meriaux,Mariana Sosa Guzmán,Charlotte Morissette,Chloe Si,Bobak Baghi,Gregory Dudek*

Main category: cs.RO

TLDR: 提出了一种利用配备GNSS的无人机定位水面附近海洋机器人的新方法，解决了传统GNSS和现有定位技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统GNSS和现有定位方法在水面环境中存在信号反射、误差累积和高计算复杂度等问题，需要更高效、可扩展的解决方案。

Method: 使用配备GNSS的无人机追踪和定位水面附近的海洋机器人。

Result: 该方法实现了对单体和多体海洋机器人的高精度定位。

Conclusion: 无人机辅助的GNSS定位是一种高效且可扩展的解决方案，适用于水面环境中的机器人定位。

Abstract: Accurate localization is crucial for water robotics, yet traditional onboard
Global Navigation Satellite System (GNSS) approaches are difficult or
ineffective due to signal reflection on the water's surface and its high cost
of aquatic GNSS receivers. Existing approaches, such as inertial navigation,
Doppler Velocity Loggers (DVL), SLAM, and acoustic-based methods, face
challenges like error accumulation and high computational complexity.
Therefore, a more efficient and scalable solution remains necessary. This paper
proposes an alternative approach that leverages an aerial drone equipped with
GNSS localization to track and localize a marine robot once it is near the
surface of the water. Our results show that this novel adaptation enables
accurate single and multi-robot marine robot localization.

</details>

### [109] [RGB-Event Fusion with Self-Attention for Collision Prediction](https://arxiv.org/abs/2505.04258)
*Pietro Bonazzi,Christian Vogt,Michael Jost,Haotong Qin,Lyes Khacef,Federico Paredes-Valles,Michele Magno*

Main category: cs.RO

TLDR: 提出了一种基于RGB和事件视觉传感器的神经网络框架，用于预测无人机与动态物体的碰撞时间和位置，通过自注意力融合提高准确性。


<details>
  <summary>Details</summary>
Motivation: 确保自主机器人在动态环境中实时避障的安全性。

Method: 采用双编码器分支分别处理RGB和事件数据，通过自注意力融合，并在ABCD数据集上进行基准测试。

Result: 融合模型在50Hz预测频率下，平均精度提高1%，远距离（>0.5m）提高10%，但内存和计算成本显著增加；事件模型在计算成本相近时优于RGB模型。

Conclusion: 多模态感知在机器人应用中需权衡精度与计算效率，事件相机是RGB的有力替代方案。

Abstract: Ensuring robust and real-time obstacle avoidance is critical for the safe
operation of autonomous robots in dynamic, real-world environments. This paper
proposes a neural network framework for predicting the time and collision
position of an unmanned aerial vehicle with a dynamic object, using RGB and
event-based vision sensors. The proposed architecture consists of two separate
encoder branches, one for each modality, followed by fusion by self-attention
to improve prediction accuracy. To facilitate benchmarking, we leverage the
ABCD [8] dataset collected that enables detailed comparisons of single-modality
and fusion-based approaches. At the same prediction throughput of 50Hz, the
experimental results show that the fusion-based model offers an improvement in
prediction accuracy over single-modality approaches of 1% on average and 10%
for distances beyond 0.5m, but comes at the cost of +71% in memory and + 105%
in FLOPs. Notably, the event-based model outperforms the RGB model by 4% for
position and 26% for time error at a similar computational cost, making it a
competitive alternative. Additionally, we evaluate quantized versions of the
event-based models, applying 1- to 8-bit quantization to assess the trade-offs
between predictive performance and computational efficiency. These findings
highlight the trade-offs of multi-modal perception using RGB and event-based
cameras in robotic applications.

</details>

<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [110] [When Reasoning Beats Scale: A 1.5B Reasoning Model Outranks 13B LLMs as Discriminator](https://arxiv.org/abs/2505.03786)
*Md Fahim Anjum*

Main category: cs.LG

TLDR: 本文研究了具有推理能力的大型语言模型（LLM）在文本到SQL任务中的表现，发现推理模型作为判别器优于非推理模型，但在生成任务上表现较差。


<details>
  <summary>Details</summary>
Motivation: 探索推理模型在规划框架中的表现，尤其是与非推理模型的对比，以优化其在LLM规划基础设施中的角色。

Method: 提出一种从推理的链式思维（CoT）输出中提取软分数的方法，用于细粒度候选排名，并在生成-判别框架中测试蒸馏后的1.5B参数推理模型（DeepSeek-R1）。

Result: DeepSeek-R1-1.5B在判别任务上表现优异，F1分数比CodeLlama-7B高87%，但生成任务表现不如小型非推理模型。

Conclusion: 推理模型在判别任务中潜力巨大，但在生成任务中表现有限，需进一步优化其在规划框架中的角色。

Abstract: Large Language Models (LLM) with reasoning capabilities offer a promising
path for improving candidate evaluation in planning frameworks, but their
relative performance against traditional non-reasoning models remains largely
underexplored. In this study, we benchmark a distilled 1.5B parameter reasoning
model (DeepSeek-R1) against several state-of-the-art non-reasoning LLMs within
a generator-discriminator LLM planning framework for the text-to-SQL task. For
this, we introduce a novel method for extracting soft scores from the
chain-of-thought (CoT) outputs from reasoning that enables fine-grained ranking
of candidates. Our central hypothesis is that reasoning models are more
effective discriminators than non-reasoning LLMs. Our results show that
distilled DeepSeek-R1-1.5B achieves up to $87\%$ higher F1 and $3.7\%$ better
discrimination accuracy than CodeLlama-7B, as well as $3.7\%$ higher execution
accuracy than CodeLlama-13B, despite having significantly fewer parameters.
Furthermore, we find that there is a limit to the logical capabilities of
reasoning models, and only providing more context or allowing more compute
budget for reasoning is not enough to improve their discrimination performance.
Finally, we demonstrate that, unlike non-reasoning LLMs, reasoning models find
generation more challenging than discrimination and may underperform as
generators compared to smaller non-reasoning LLMs. Our work highlights the
potential of reasoning models as discriminators in agentic frameworks, far
outweighing their capabilities as generators, offering insights into their
optimal role within LLM planning infrastructures.

</details>

### [111] [Scalability Matters: Overcoming Challenges in InstructGLM with Similarity-Degree-Based Sampling](https://arxiv.org/abs/2505.03799)
*Hyun Lee,Chris Yi,Maminur Islam,B. D. S. Aritra*

Main category: cs.LG

TLDR: 提出了SDM-InstructGLM框架，通过指令调优的图语言模型（InstructGLM）解决LLM在图任务中的局限性，无需依赖GNN。


<details>
  <summary>Details</summary>
Motivation: LLM在图任务中的应用受限，主要因为可扩展性问题和缺乏处理图结构的专用机制。

Method: 引入基于相似度和度中心性的偏置随机游走机制，选择性编码图信息，提高LLM的效率和性能。

Result: 显著提升节点分类和链接预测等任务的性能，验证了LLM独立处理图任务的可行性。

Conclusion: 为不依赖GNN的图学习方法开辟了新途径，LLM可作为独立的图推理模型。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in various
natural language processing tasks; however, their application to graph-related
problems remains limited, primarily due to scalability constraints and the
absence of dedicated mechanisms for processing graph structures. Existing
approaches predominantly integrate LLMs with Graph Neural Networks (GNNs),
using GNNs as feature encoders or auxiliary components. However, directly
encoding graph structures within LLMs has been underexplored, particularly in
the context of large-scale graphs where token limitations hinder effective
representation. To address these challenges, we propose SDM-InstructGLM, a
novel instruction-tuned Graph Language Model (InstructGLM) framework that
enhances scalability and efficiency without relying on GNNs. Our method
introduces a similarity-degree-based biased random walk mechanism, which
selectively samples and encodes graph information based on node-feature
similarity and degree centrality, ensuring an adaptive and structured
representation within the LLM. This approach significantly improves token
efficiency, mitigates information loss due to random sampling, and enhances
performance on graph-based tasks such as node classification and link
prediction. Furthermore, our results demonstrate the feasibility of LLM-only
graph processing, enabling scalable and interpretable Graph Language Models
(GLMs) optimized through instruction-based fine-tuning. This work paves the way
for GNN-free approaches to graph learning, leveraging LLMs as standalone graph
reasoning models. Our source code is available on GitHub.

</details>

### [112] [Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free](https://arxiv.org/abs/2505.03810)
*Euntae Choi,Sumin Song,Woosang Lim,Sungjoo Yoo*

Main category: cs.LG

TLDR: 提出了一种无需训练的改进旋转矩阵方法，用于解决低比特量化（如2-bit）中现有旋转方法的局限性，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）因高计算成本面临部署挑战，现有后训练量化（PTQ）方法在极低比特（如2-bit）下表现不佳。

Method: 利用Walsh-Hadamard变换和序列排序构建改进的旋转矩阵，提出分组序列排列旋转（GSR）方法，通过块对角矩阵隔离异常值影响。

Result: 在推理任务和WikiText-2的Perplexity（PPL）评分上表现优异，性能接近基于优化的方法，且无需训练。

Conclusion: 该方法显著提升了低比特量化的性能，且适用于现有学习旋转技术，具有实际部署潜力。

Abstract: Large Language Models (LLMs) face deployment challenges due to high
computational costs, and while Post-Training Quantization (PTQ) offers a
solution, existing rotation-based methods struggle at very low bit-widths like
2-bit. We introduce a novel, training-free approach to construct an improved
rotation matrix, addressing the limitations of current methods. The key
contributions include leveraging the Walsh-Hadamard transform with sequency
ordering, which clusters similar frequency components to reduce quantization
error compared to standard Hadamard matrices, significantly improving
performance. Furthermore, we propose a Grouped Sequency-arranged Rotation (GSR)
using block-diagonal matrices with smaller Walsh blocks, effectively isolating
outlier impacts and achieving performance comparable to optimization-based
methods without requiring any training. Our method demonstrates robust
performance on reasoning tasks and Perplexity (PPL) score on WikiText-2. Our
method also enhances results even when applied over existing learned rotation
techniques.

</details>

### [113] [Quiet Feature Learning in Algorithmic Tasks](https://arxiv.org/abs/2505.03997)
*Prudhviraj Naidu,Zixian Wang,Leon Bergen,Ramamohan Paturi*

Main category: cs.LG

TLDR: Transformer语言模型在算法任务训练中表现出明显的损失曲线相变，挑战了损失函数逐步改进的假设。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer模型在算法任务训练中的损失曲线行为，揭示其与现有幂律标度趋势的差异。

Method: 在十个基础算法任务上训练Transformer模型，分析损失曲线和内部表示。

Result: 观察到损失曲线中的停滞阶段和突然下降，发现静默特征和响亮特征的学习模式。

Conclusion: 关键内部特征可能在表面下发展，最终触发性能快速提升，挑战了损失函数逐步改进的假设。

Abstract: We train Transformer-based language models on ten foundational algorithmic
tasks and observe pronounced phase transitions in their loss curves that
deviate from established power-law scaling trends. Over large ranges of
compute, the validation loss barely improves, then abruptly decreases. Probing
the models' internal representations reveals the learning of quiet features
during the stagnant phase, followed by sudden acquisition of loud features that
coincide with the sharp drop in loss. Our ablation experiments show that
disrupting a single learned feature can dramatically degrade performance,
providing evidence of their causal role in task performance. These findings
challenge the prevailing assumption that next-token predictive loss reliably
tracks incremental progress; instead, key internal features may be developing
below the surface until they coalesce, triggering a rapid performance gain.

</details>

### [114] [LLAMAPIE: Proactive In-Ear Conversation Assistants](https://arxiv.org/abs/2505.04066)
*Tuochao Chen,Nicholas Batchelder,Alisa Liu,Noah Smith,Shyamnath Gollakota*

Main category: cs.LG

TLDR: LlamaPIE是一个实时主动助手，通过可听设备提供简洁指导，无需用户显式调用，旨在增强人类对话。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型需要用户显式调用，而LlamaPIE旨在在后台运行，预测用户需求而不打断对话。

Method: 构建半合成对话数据集，采用两模型管道：小型模型决定何时响应，大型模型生成响应。

Result: 在真实数据集上验证了有效性，用户研究表明用户更倾向于主动助手而非无助手或反应式模型。

Conclusion: LlamaPIE展示了增强实时对话的潜力，用户对其主动性和无干扰性有强烈偏好。

Abstract: We introduce LlamaPIE, the first real-time proactive assistant designed to
enhance human conversations through discreet, concise guidance delivered via
hearable devices. Unlike traditional language models that require explicit user
invocation, this assistant operates in the background, anticipating user needs
without interrupting conversations. We address several challenges, including
determining when to respond, crafting concise responses that enhance
conversations, leveraging knowledge of the user for context-aware assistance,
and real-time, on-device processing. To achieve this, we construct a
semi-synthetic dialogue dataset and propose a two-model pipeline: a small model
that decides when to respond and a larger model that generates the response. We
evaluate our approach on real-world datasets, demonstrating its effectiveness
in providing helpful, unobtrusive assistance. User studies with our assistant,
implemented on Apple Silicon M2 hardware, show a strong preference for the
proactive assistant over both a baseline with no assistance and a reactive
model, highlighting the potential of LlamaPie to enhance live conversations.

</details>

### [115] [AI-driven multi-source data fusion for algal bloom severity classification in small inland water bodies: Leveraging Sentinel-2, DEM, and NOAA climate data](https://arxiv.org/abs/2505.03808)
*Ioannis Nasios*

Main category: cs.LG

TLDR: 该研究提出了一种结合多源遥感数据和AI模型的高效方法，用于检测有害藻华，具有全球应用潜力。


<details>
  <summary>Details</summary>
Motivation: 有害藻华对水质和公共健康的威胁日益严重，亟需高效、准确且经济的检测方法。

Method: 整合Sentinel-2光学影像、DEM和NOAA气候数据，结合树模型和神经网络进行藻华严重性分类。

Result: 树模型表现优异，加入神经网络增强了鲁棒性，展示了深度学习对多源遥感数据的有效利用。

Conclusion: 该方法通过高分辨率卫星影像和AI分析动态监测藻华，具备全球应用潜力，代码已开源。

Abstract: Harmful algal blooms are a growing threat to inland water quality and public
health worldwide, creating an urgent need for efficient, accurate, and
cost-effective detection methods. This research introduces a high-performing
methodology that integrates multiple open-source remote sensing data with
advanced artificial intelligence models. Key data sources include Copernicus
Sentinel-2 optical imagery, the Copernicus Digital Elevation Model (DEM), and
NOAA's High-Resolution Rapid Refresh (HRRR) climate data, all efficiently
retrieved using platforms like Google Earth Engine (GEE) and Microsoft
Planetary Computer (MPC). The NIR and two SWIR bands from Sentinel-2, the
altitude from the elevation model, the temperature and wind from NOAA as well
as the longitude and latitude were the most important features. The approach
combines two types of machine learning models, tree-based models and a neural
network, into an ensemble for classifying algal bloom severity. While the tree
models performed strongly on their own, incorporating a neural network added
robustness and demonstrated how deep learning models can effectively use
diverse remote sensing inputs. The method leverages high-resolution satellite
imagery and AI-driven analysis to monitor algal blooms dynamically, and
although initially developed for a NASA competition in the U.S., it shows
potential for global application. The complete code is available for further
adaptation and practical implementation, illustrating the convergence of remote
sensing data and AI to address critical environmental challenges
(https://github.com/IoannisNasios/HarmfulAlgalBloomDetection).

</details>

### [116] [When Dynamic Data Selection Meets Data Augmentation](https://arxiv.org/abs/2505.03809)
*Suorong Yang,Peng Ye,Furao Shen,Dongzhan Zhou*

Main category: cs.LG

TLDR: 提出了一种动态数据选择与增强统一的在线训练框架，显著提升训练效率与性能。


<details>
  <summary>Details</summary>
Motivation: 动态数据选择虽能加速训练，但可能限制数据多样性，影响泛化能力。现有方法未充分结合数据选择与增强的协同效应。

Method: 通过估计样本的局部密度和多模态语义一致性联合分布，有针对性地选择适合增强的样本，避免噪声或模糊数据。

Result: 在多个基准数据集和架构上优于现有方法，如ImageNet-1k上减少50%训练成本且性能无损，同时增强噪声抵抗力和鲁棒性。

Conclusion: 该方法首次统一动态数据选择与增强，实现了高效训练与性能提升，具有实际应用价值。

Abstract: Dynamic data selection aims to accelerate training with lossless performance.
However, reducing training data inherently limits data diversity, potentially
hindering generalization. While data augmentation is widely used to enhance
diversity, it is typically not optimized in conjunction with selection. As a
result, directly combining these techniques fails to fully exploit their
synergies. To tackle the challenge, we propose a novel online data training
framework that, for the first time, unifies dynamic data selection and
augmentation, achieving both training efficiency and enhanced performance. Our
method estimates each sample's joint distribution of local density and
multimodal semantic consistency, allowing for the targeted selection of
augmentation-suitable samples while suppressing the inclusion of noisy or
ambiguous data. This enables a more significant reduction in dataset size
without sacrificing model generalization. Experimental results demonstrate that
our method outperforms existing state-of-the-art approaches on various
benchmark datasets and architectures, e.g., reducing 50\% training costs on
ImageNet-1k with lossless performance. Furthermore, our approach enhances noise
resistance and improves model robustness, reinforcing its practical utility in
real-world scenarios.

</details>

### [117] [Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation](https://arxiv.org/abs/2505.04619)
*Abdulaziz Almuzairee,Rohan Patil,Dwait Bhatt,Henrik I. Christensen*

Main category: cs.LG

TLDR: 提出了一种名为MAD的算法，通过合并多视角数据并增强单视角特征，提高样本效率并实现轻量级部署。


<details>
  <summary>Details</summary>
Motivation: 多摄像头扩展视野在视觉伺服中计算复杂且部署成本高，需一种高效且轻量的解决方案。

Method: 采用Merge And Disentanglement (MAD)算法，合并多视角数据并增强单视角特征。

Result: 在Meta-World和ManiSkill3上验证了算法的效率和鲁棒性。

Conclusion: MAD算法在提高样本效率的同时，实现了轻量级部署和鲁棒策略。

Abstract: Vision is well-known for its use in manipulation, especially using visual
servoing. To make it robust, multiple cameras are needed to expand the field of
view. That is computationally challenging. Merging multiple views and using
Q-learning allows the design of more effective representations and optimization
of sample efficiency. Such a solution might be expensive to deploy. To mitigate
this, we introduce a Merge And Disentanglement (MAD) algorithm that efficiently
merges views to increase sample efficiency while augmenting with single-view
features to allow lightweight deployment and ensure robust policies. We
demonstrate the efficiency and robustness of our approach using Meta-World and
ManiSkill3. For project website and code, see https://aalmuzairee.github.io/mad

</details>

<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [118] [The Power of Stories: Narrative Priming Shapes How LLM Agents Collaborate and Compete](https://arxiv.org/abs/2505.03961)
*Gerrit Großmann,Larisa Ivanova,Sai Leela Poduru,Mohaddeseh Tabrizian,Islam Mesabah,David A. Selby,Sebastian J. Vollmer*

Main category: cs.AI

TLDR: 研究探讨共享叙事是否能促进LLM代理的合作行为，通过公共物品游戏实验发现，共同叙事显著提升合作效果，而不同叙事则相反。


<details>
  <summary>Details</summary>
Motivation: 探索共享叙事对LLM代理合作行为的影响，为多代理系统设计和AI对齐提供参考。

Method: 使用有限重复的公共物品游戏，通过不同叙事对LLM代理进行干预，观察其谈判行为。

Result: 共同叙事显著提升代理的合作策略和成功率，而不同叙事则导致自利行为占优。

Conclusion: 叙事干预对LLM代理的合作行为有显著影响，对多代理系统设计具有潜在应用价值。

Abstract: According to Yuval Noah Harari, large-scale human cooperation is driven by
shared narratives that encode common beliefs and values. This study explores
whether such narratives can similarly nudge LLM agents toward collaboration. We
use a finitely repeated public goods game in which LLM agents choose either
cooperative or egoistic spending strategies. We prime agents with stories
highlighting teamwork to different degrees and test how this influences
negotiation outcomes. Our experiments explore four questions:(1) How do
narratives influence negotiation behavior? (2) What differs when agents share
the same story versus different ones? (3) What happens when the agent numbers
grow? (4) Are agents resilient against self-serving negotiators? We find that
story-based priming significantly affects negotiation strategies and success
rates. Common stories improve collaboration, benefiting each agent. By
contrast, priming agents with different stories reverses this effect, and those
agents primed toward self-interest prevail. We hypothesize that these results
carry implications for multi-agent system design and AI alignment.

</details>

### [119] [Beyond Theorem Proving: Formulation, Framework and Benchmark for Formal Problem-Solving](https://arxiv.org/abs/2505.04528)
*Qi Liu,Xinhao Zheng,Renqiu Xia,Xingzhi Qi,Qinxiang Cao,Junchi Yan*

Main category: cs.AI

TLDR: 论文提出了一种基于确定性马尔可夫决策过程的问题解决框架FPS和D-FPS，并验证了其表达性、完备性和正确性。通过三个基准测试评估了现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 问题解决在科学和工程中至关重要，但缺乏通用且具体的定义。随着AI问题解决代理的发展，过程级可验证性需求增加，但研究不足。

Method: 提出FPS框架，利用FTP环境进行过程验证；D-FPS解耦解决和验证以提高人机对齐。通过RPE方法评估答案正确性。

Result: 在三个基准测试中，现有模型表现有限，最高解决率为27.47%。

Conclusion: FPS和D-FPS为问题解决提供了可验证、可解释的框架，但现有模型仍需改进。

Abstract: As a seemingly self-explanatory task, problem-solving has been a significant
component of science and engineering. However, a general yet concrete
formulation of problem-solving itself is missing. With the recent development
of AI-based problem-solving agents, the demand for process-level verifiability
is rapidly increasing yet underexplored. To fill these gaps, we present a
principled formulation of problem-solving as a deterministic Markov decision
process; a novel framework, FPS (Formal Problem-Solving), which utilizes
existing FTP (formal theorem proving) environments to perform process-verified
problem-solving; and D-FPS (Deductive FPS), decoupling solving and answer
verification for better human-alignment. The expressiveness, soundness and
completeness of the frameworks are proven. We construct three benchmarks on
problem-solving: FormalMath500, a formalization of a subset of the MATH500
benchmark; MiniF2F-Solving and PutnamBench-Solving, adaptations of FTP
benchmarks MiniF2F and PutnamBench. For faithful, interpretable, and
human-aligned evaluation, we propose RPE (Restricted Propositional
Equivalence), a symbolic approach to determine the correctness of answers by
formal verification. We evaluate four prevalent FTP models and two prompting
methods as baselines, solving at most 23.77% of FormalMath500, 27.47% of
MiniF2F-Solving, and 0.31% of PutnamBench-Solving.

</details>

### [120] [Design description of Wisdom Computing Persperctive](https://arxiv.org/abs/2505.03800)
*TianYi Yu*

Main category: cs.AI

TLDR: 设计了一个基于AI和可视化动画的手写矩阵识别与计算过程展示系统，帮助学生理解数学计算步骤。


<details>
  <summary>Details</summary>
Motivation: 解决学生在学习数学时因抽象公式和复杂计算步骤难以理解的问题。

Method: 结合Mamba骨干网络、YOLO模型和CoordAttention机制，实现手写矩阵的精确识别与重构，并通过Manim动画引擎分步展示计算过程。

Result: 系统具有高模块化和灵活性，能实时生成不同数学运算示例，提升学习体验。

Conclusion: 该系统为教育提供了直观、易用且高效的辅助工具，帮助学生深入理解数学逻辑。

Abstract: This course design aims to develop and research a handwriting matrix
recognition and step-by-step visual calculation process display system,
addressing the issue of abstract formulas and complex calculation steps that
students find difficult to understand when learning mathematics. By integrating
artificial intelligence with visualization animation technology, the system
enhances precise recognition of handwritten matrix content through the
introduction of Mamba backbone networks, completes digital extraction and
matrix reconstruction using the YOLO model, and simultaneously combines
CoordAttention coordinate attention mechanisms to improve the accurate grasp of
character spatial positions. The calculation process is demonstrated frame by
frame through the Manim animation engine, vividly showcasing each mathematical
calculation step, helping students intuitively understand the intrinsic logic
of mathematical operations. Through dynamically generating animation processes
for different computational tasks, the system exhibits high modularity and
flexibility, capable of generating various mathematical operation examples in
real-time according to student needs. By innovating human-computer interaction
methods, it brings mathematical calculation processes to life, helping students
bridge the gap between knowledge and understanding on a deeper level,
ultimately achieving a learning experience where "every step is understood."
The system's scalability and interactivity make it an intuitive, user-friendly,
and efficient auxiliary tool in education.

</details>

<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [121] [Cer-Eval: Certifiable and Cost-Efficient Evaluation Framework for LLMs](https://arxiv.org/abs/2505.03814)
*Ganghua Wang,Zhaorun Chen,Bo Li,Haifeng Xu*

Main category: stat.ML

TLDR: 本文提出了一种可认证且高效的大型语言模型评估框架Cer-Eval，通过自适应选择测试点减少评估成本，同时保持高置信度。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型规模扩大，评估大型语言模型的挑战日益突出，现有方法缺乏对测试数据充分性和样本选择的系统性指导。

Method: 提出基于测试样本复杂度的理论框架，开发分区算法Cer-Eval，自适应选择测试点以最小化评估成本。

Result: 实验表明，Cer-Eval可节省20%-40%测试点，同时保持与现有方法相当的误差水平并提供95%置信度。

Conclusion: Cer-Eval为大型语言模型提供了一种高效、可认证的评估方法，显著降低了评估成本。

Abstract: As foundation models continue to scale, the size of trained models grows
exponentially, presenting significant challenges for their evaluation. Current
evaluation practices involve curating increasingly large datasets to assess the
performance of large language models (LLMs). However, there is a lack of
systematic analysis and guidance on determining the sufficiency of test data or
selecting informative samples for evaluation. This paper introduces a
certifiable and cost-efficient evaluation framework for LLMs. Our framework
adapts to different evaluation objectives and outputs confidence intervals that
contain true values with high probability. We use ``test sample complexity'' to
quantify the number of test points needed for a certifiable evaluation and
derive tight bounds on test sample complexity. Based on the developed theory,
we develop a partition-based algorithm, named Cer-Eval, that adaptively selects
test points to minimize the cost of LLM evaluation. Real-world experiments
demonstrate that Cer-Eval can save 20% to 40% test points across various
benchmarks, while maintaining an estimation error level comparable to the
current evaluation process and providing a 95% confidence guarantee.

</details>

<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [122] [Sentiment-Aware Recommendation Systems in E-Commerce: A Review from a Natural Language Processing Perspective](https://arxiv.org/abs/2505.03828)
*Yogesh Gajula*

Main category: cs.IR

TLDR: 本文综述了2023年至2025年初基于情感分析的电子商务推荐系统，探讨了如何通过自然语言处理技术提升推荐准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 电子商务平台生成大量用户反馈（如评分、评论），但现有推荐系统多依赖数值评分，忽略了文本中的情感信息。本文旨在填补这一空白。

Method: 综述了四种主要方法：结合情感嵌入的深度学习分类器、基于Transformer的特征提取、图神经网络传播情感信号，以及实时响应用户反馈的对话推荐系统。

Result: 展示了情感分析如何提升推荐系统的性能，并总结了模型架构及情感在推荐流程中的作用。

Conclusion: 指出了当前挑战（如噪声文本、动态偏好和偏见缓解），并提出了未来研究方向，以开发更智能、公平和用户中心的推荐工具。

Abstract: E-commerce platforms generate vast volumes of user feedback, such as star
ratings, written reviews, and comments. However, most recommendation engines
rely primarily on numerical scores, often overlooking the nuanced opinions
embedded in free text. This paper comprehensively reviews sentiment-aware
recommendation systems from a natural language processing perspective, covering
advancements from 2023 to early 2025. It highlights the benefits of integrating
sentiment analysis into e-commerce recommenders to enhance prediction accuracy
and explainability through detailed opinion extraction. Our survey categorizes
recent work into four main approaches: deep learning classifiers that combine
sentiment embeddings with user item interactions, transformer based methods for
nuanced feature extraction, graph neural networks that propagate sentiment
signals, and conversational recommenders that adapt in real time to user
feedback. We summarize model architectures and demonstrate how sentiment flows
through recommendation pipelines, impacting dialogue-based suggestions. Key
challenges include handling noisy or sarcastic text, dynamic user preferences,
and bias mitigation. Finally, we outline research gaps and provide a roadmap
for developing smarter, fairer, and more user-centric recommendation tools.

</details>

### [123] [OBD-Finder: Explainable Coarse-to-Fine Text-Centric Oracle Bone Duplicates Discovery](https://arxiv.org/abs/2505.03836)
*Chongsheng Zhang,Shuwen Wu,Yingqi Chen,Matthias Aßenmacher,Christian Heumann,Yi Men,Gaojuan Fan,João Gama*

Main category: cs.IR

TLDR: 提出了一种结合无监督低层关键点匹配和高层文本内容匹配的甲骨文重复发现框架，显著提升了检索效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 甲骨文重复识别是甲骨文研究的基础问题，传统方法效率低且易遗漏。

Method: 采用渐进式框架，结合低层关键点匹配和高层文本内容匹配，优化候选重复甲骨文的排序。

Result: 在Top-5和Top-15检索结果中表现最佳，计算效率显著提升，并发现了60多对新甲骨文重复。

Conclusion: 该方法在甲骨文重复识别中具有高效性和实用性，为未来研究提供了新工具。

Abstract: Oracle Bone Inscription (OBI) is the earliest systematic writing system in
China, while the identification of Oracle Bone (OB) duplicates is a fundamental
issue in OBI research. In this work, we design a progressive OB duplicate
discovery framework that combines unsupervised low-level keypoints matching
with high-level text-centric content-based matching to refine and rank the
candidate OB duplicates with semantic awareness and interpretability. We
compare our approach with state-of-the-art content-based image retrieval and
image matching methods, showing that our approach yields comparable recall
performance and the highest simplified mean reciprocal rank scores for both
Top-5 and Top-15 retrieval results, and with significantly accelerated
computation efficiency. We have discovered over 60 pairs of new OB duplicates
in real-world deployment, which were missed by OBI researchers for decades. The
models, video illustration and demonstration of this work are available at:
https://github.com/cszhangLMU/OBD-Finder/.

</details>

<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [124] [Benchmarking LLMs' Swarm intelligence](https://arxiv.org/abs/2505.04364)
*Kai Ruan,Mowen Huang,Ji-Rong Wen,Hao Sun*

Main category: cs.MA

TLDR: 论文介绍了SwarmBench，一个用于评估LLMs在分散多智能体系统中协调能力的新基准，发现LLMs在局部信息约束下表现不一，揭示了其在不确定性下的规划局限性。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在严格约束（如局部感知和通信）下的多智能体系统协调能力，填补现有基准在分散协调挑战上的不足。

Method: 提出SwarmBench基准，包含五个MAS协调任务，配置2D网格环境，依赖局部感知和通信，并设计协调效果指标。

Result: 评估多个LLMs，发现任务间性能差异显著，局部信息约束下协调能力有限，规划和策略形成存在困难。

Conclusion: SwarmBench为LLMs在分散系统中的潜力评估提供工具，促进可复现研究，代码和数据公开。

Abstract: Large Language Models (LLMs) show potential for complex reasoning, yet their
capacity for emergent coordination in Multi-Agent Systems (MAS) when operating
under strict constraints-such as limited local perception and communication,
characteristic of natural swarms-remains largely unexplored, particularly
concerning the nuances of swarm intelligence. Existing benchmarks often do not
fully capture the unique challenges of decentralized coordination that arise
when agents operate with incomplete spatio-temporal information. To bridge this
gap, we introduce SwarmBench, a novel benchmark designed to systematically
evaluate the swarm intelligence capabilities of LLMs acting as decentralized
agents. SwarmBench features five foundational MAS coordination tasks within a
configurable 2D grid environment, forcing agents to rely primarily on local
sensory input (k x k view) and local communication. We propose metrics for
coordination effectiveness and analyze emergent group dynamics. Evaluating
several leading LLMs in a zero-shot setting, we find significant performance
variations across tasks, highlighting the difficulties posed by local
information constraints. While some coordination emerges, results indicate
limitations in robust planning and strategy formation under uncertainty in
these decentralized scenarios. Assessing LLMs under swarm-like conditions is
crucial for realizing their potential in future decentralized systems. We
release SwarmBench as an open, extensible toolkit-built upon a customizable and
scalable physical system with defined mechanical properties. It provides
environments, prompts, evaluation scripts, and the comprehensive experimental
datasets generated, aiming to foster reproducible research into LLM-based MAS
coordination and the theoretical underpinnings of Embodied MAS. Our code
repository is available at https://github.com/x66ccff/swarmbench.

</details>

<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [125] [Facilitating Video Story Interaction with Multi-Agent Collaborative System](https://arxiv.org/abs/2505.03807)
*Yiwen Zhang,Jianing Hao,Zhan Wang,Hongling Sheng,Wei Zeng*

Main category: cs.HC

TLDR: 提出了一种基于用户意图的视频故事交互系统，结合VLM、RAG和MAS技术，实现个性化角色成长和场景定制。


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于用户选择和预设叙事，缺乏定制化能力。

Method: 系统分三阶段：1) 视频故事处理（VLM）；2) 多空间聊天（MAS）；3) 场景定制（RAG）。

Result: 应用于《哈利波特》系列，系统成功展现了角色社交行为和成长。

Conclusion: 该系统显著提升了视频故事世界的交互体验。

Abstract: Video story interaction enables viewers to engage with and explore narrative
content for personalized experiences. However, existing methods are limited to
user selection, specially designed narratives, and lack customization. To
address this, we propose an interactive system based on user intent. Our system
uses a Vision Language Model (VLM) to enable machines to understand video
stories, combining Retrieval-Augmented Generation (RAG) and a Multi-Agent
System (MAS) to create evolving characters and scene experiences. It includes
three stages: 1) Video story processing, utilizing VLM and prior knowledge to
simulate human understanding of stories across three modalities. 2) Multi-space
chat, creating growth-oriented characters through MAS interactions based on
user queries and story stages. 3) Scene customization, expanding and
visualizing various story scenes mentioned in dialogue. Applied to the Harry
Potter series, our study shows the system effectively portrays emergent
character social behavior and growth, enhancing the interactive experience in
the video story world.

</details>

<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [126] [Dynamic Network Flow Optimization for Task Scheduling in PTZ Camera Surveillance Systems](https://arxiv.org/abs/2505.04596)
*Mohammad Merati,David Castañón*

Main category: math.OC

TLDR: 提出了一种优化动态监控环境中PTZ相机调度与控制的新方法，结合卡尔曼滤波和动态网络流模型，提升实时视频捕捉效率。


<details>
  <summary>Details</summary>
Motivation: 传统主从相机系统在动态和拥挤环境中效率不足，需要更高效、可扩展的调度方法。

Method: 集成卡尔曼滤波预测目标位置，结合网络流优化调度，引入分组跟踪节点和价值优先系统。

Result: 仿真显示，该方法提升了覆盖率，减少等待时间和遗漏事件，优于传统系统。

Conclusion: 该方法显著提升了监控系统的效率、可扩展性和有效性，适用于动态拥挤环境。

Abstract: This paper presents a novel approach for optimizing the scheduling and
control of Pan-Tilt-Zoom (PTZ) cameras in dynamic surveillance environments.
The proposed method integrates Kalman filters for motion prediction with a
dynamic network flow model to enhance real-time video capture efficiency. By
assigning Kalman filters to tracked objects, the system predicts future
locations, enabling precise scheduling of camera tasks. This prediction-driven
approach is formulated as a network flow optimization, ensuring scalability and
adaptability to various surveillance scenarios. To further reduce redundant
monitoring, we also incorporate group-tracking nodes, allowing multiple objects
to be captured within a single camera focus when appropriate. In addition, a
value-based system is introduced to prioritize camera actions, focusing on the
timely capture of critical events. By adjusting the decay rates of these values
over time, the system ensures prompt responses to tasks with imminent
deadlines. Extensive simulations demonstrate that this approach improves
coverage, reduces average wait times, and minimizes missed events compared to
traditional master-slave camera systems. Overall, our method significantly
enhances the efficiency, scalability, and effectiveness of surveillance
systems, particularly in dynamic and crowded environments.

</details>