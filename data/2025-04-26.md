<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 39]
- [cs.CV](#cs.CV) [Total: 66]
- [cs.SI](#cs.SI) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [eess.IV](#eess.IV) [Total: 4]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.LG](#cs.LG) [Total: 8]
- [cs.CY](#cs.CY) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.SE](#cs.SE) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Bidirectional Mamba for Single-Cell Data: Efficient Context Learning with Biological Fidelity](https://arxiv.org/abs/2504.16956)
*Cong Qi,Hanzhang Fang,Tianxing Hu,Siqi Jiang,Wei Zhi*

Main category: cs.CL

TLDR: GeneMamba是一种基于状态空间建模的单细胞转录组学基础模型，通过Bi-Mamba架构实现线性时间复杂度和高效计算，优于传统Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序（scRNA-seq）的高维度、稀疏性和批次效应带来计算挑战，现有Transformer模型因二次复杂度和长程依赖处理不足而受限。

Method: GeneMamba采用Bi-Mamba架构，结合生物学目标（如通路感知对比损失和基于排名的基因编码），在3000万细胞上预训练。

Result: 在多批次整合、细胞类型注释和基因-基因相关性等任务中表现优异，具有强健性和可解释性。

Conclusion: GeneMamba为大规模单细胞数据分析提供了高效、可扩展的替代方案，优于Transformer方法。

Abstract: Single-cell RNA sequencing (scRNA-seq) enables high-resolution analysis of
cellular heterogeneity, but its complexity, which is marked by high
dimensionality, sparsity, and batch effects, which poses major computational
challenges. Transformer-based models have made significant advances in this
domain but are often limited by their quadratic complexity and suboptimal
handling of long-range dependencies. In this work, we introduce GeneMamba, a
scalable and efficient foundation model for single-cell transcriptomics built
on state space modeling. Leveraging the Bi-Mamba architecture, GeneMamba
captures bidirectional gene context with linear-time complexity, offering
substantial computational gains over transformer baselines. The model is
pretrained on nearly 30 million cells and incorporates biologically informed
objectives, including pathway-aware contrastive loss and rank-based gene
encoding. We evaluate GeneMamba across diverse tasks, including multi-batch
integration, cell type annotation, and gene-gene correlation, demonstrating
strong performance, interpretability, and robustness. These results position
GeneMamba as a practical and powerful alternative to transformer-based methods,
advancing the development of biologically grounded, scalable tools for
large-scale single-cell data analysis.

</details>

### [2] [Tokenization Matters: Improving Zero-Shot NER for Indic Languages](https://arxiv.org/abs/2504.16977)
*Priyaranjan Pattnayak,Hitesh Laxmichand Patel,Amit Agarwal*

Main category: cs.CL

TLDR: 比较了BPE、SentencePiece和字符级分词在低资源印度语言NER任务中的表现，发现SentencePiece在跨语言零样本设置中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 探索BPE在低资源印度语言NER任务中的适用性，并比较不同分词方法的性能。

Method: 使用IndicBERT对BPE、SentencePiece和字符级分词进行系统比较，评估内在语言属性和下游任务表现。

Result: SentencePiece在低资源印度语言中表现优于BPE，尤其在跨语言零样本设置中，能更好地保持实体一致性。

Conclusion: SentencePiece是低资源印度语言NER任务中更有效的分词策略。

Abstract: Tokenization is a critical component of Natural Language Processing (NLP),
especially for low resource languages, where subword segmentation influences
vocabulary structure and downstream task accuracy. Although Byte Pair Encoding
(BPE) is a standard tokenization method in multilingual language models, its
suitability for Named Entity Recognition (NER) in low resource Indic languages
remains underexplored due to its limitations in handling morphological
complexity. In this work, we systematically compare BPE, SentencePiece, and
Character Level tokenization strategies using IndicBERT for NER tasks in low
resource Indic languages like Assamese, Bengali, Marathi, and Odia, as well as
extremely low resource Indic languages like Santali, Manipuri, and Sindhi. We
assess both intrinsic linguistic properties tokenization efficiency, out of
vocabulary (OOV) rates, and morphological preservation as well as extrinsic
downstream performance, including fine tuning and zero shot cross lingual
transfer.
  Our experiments show that SentencePiece is a consistently better performing
approach than BPE for NER in low resource Indic Languages, particularly in zero
shot cross lingual settings, as it better preserves entity consistency. While
BPE provides the most compact tokenization form, it is not capable of
generalization because it misclassifies or even fails to recognize entity
labels when tested on unseen languages. In contrast, SentencePiece constitutes
a better linguistic structural preservation model, benefiting extremely low
resource and morphologically rich Indic languages, such as Santali and
Manipuri, for superior entity recognition, as well as high generalization
across scripts, such as Sindhi, written in Arabic. The results point to
SentencePiece as the more effective tokenization strategy for NER within
multilingual and low resource Indic NLP applications.

</details>

### [3] [Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation](https://arxiv.org/abs/2504.17025)
*Luca Moroni,Giovanni Puccetti,Pere-Lluis Huguet Cabot,Andrei Stefan Bejgu,Edoardo Barba,Alessio Miaschi,Felice Dell'Orletta,Andrea Esuli,Roberto Navigli*

Main category: cs.CL

TLDR: 本文提出了一种名为SAVA的新方法，通过词汇替换优化英语LLMs以适配意大利语，显著降低了token fertility和参数数量，并在下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs主要针对英语设计，对其他语言（如意大利语）的编码效率低且推理速度慢。

Method: 提出SAVA方法，利用神经映射进行词汇替换，并适配了Mistral-7b-v0.1和Llama-3.1-8B模型。

Result: SAVA显著降低了token fertility（25%）和参数数量（1 billion），并在多任务中表现优异。

Conclusion: SAVA方法有效优化了LLMs对非英语语言的适配性，且通过少量持续训练即可恢复性能。

Abstract: The number of pretrained Large Language Models (LLMs) is increasing steadily,
though the majority are designed predominantly for the English language. While
state-of-the-art LLMs can handle other languages, due to language contamination
or some degree of multilingual pretraining data, they are not optimized for
non-English languages, leading to inefficient encoding (high token "fertility")
and slower inference speed. In this work, we thoroughly compare a variety of
vocabulary adaptation techniques for optimizing English LLMs for the Italian
language, and put forward Semantic Alignment Vocabulary Adaptation (SAVA), a
novel method that leverages neural mapping for vocabulary substitution. SAVA
achieves competitive performance across multiple downstream tasks, enhancing
grounded alignment strategies. We adapt two LLMs: Mistral-7b-v0.1, reducing
token fertility by 25\%, and Llama-3.1-8B, optimizing the vocabulary and
reducing the number of parameters by 1 billion. We show that, following the
adaptation of the vocabulary, these models can recover their performance with a
relatively limited stage of continual training on the target language. Finally,
we test the capabilities of the adapted models on various multi-choice and
generative tasks.

</details>

### [4] [Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models](https://arxiv.org/abs/2504.17052)
*Shariar Kabir,Kevin Esterling,Yue Dong*

Main category: cs.CL

TLDR: 该论文提出了一种评估大型语言模型（LLM）政治信仰深度的新框架，通过分析论证一致性和不确定性量化，发现LLM的信仰稳定性具有主题特异性，而非统一的意识形态立场。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究LLM的政治回应是否反映真实内部信仰，还是仅与训练数据表面一致。

Method: 方法包括评估12个LLM在19项经济政策上的表现，通过支持性和反对性论证测试其信仰稳定性。

Result: 结果显示，左倾和右倾模型的回应在挑战下分别有95%和89%保持一致性，语义熵能有效区分表面一致性和真实信仰（AUROC=0.78）。

Conclusion: 结论指出LLM未必具有稳定的人类意识形态，强调在实际应用中需进行主题特异性可靠性评估。

Abstract: Large Language Models (LLMs) are increasingly shaping political discourse,
yet their responses often display inconsistency when subjected to scrutiny.
While prior research has primarily categorized LLM outputs as left- or
right-leaning to assess their political stances, a critical question remains:
Do these responses reflect genuine internal beliefs or merely surface-level
alignment with training data? To address this, we propose a novel framework for
evaluating belief depth by analyzing (1) argumentative consistency and (2)
uncertainty quantification. We evaluate 12 LLMs on 19 economic policies from
the Political Compass Test, challenging their belief stability with both
supportive and opposing arguments. Our analysis reveals that LLMs exhibit
topic-specific belief stability rather than a uniform ideological stance.
Notably, up to 95% of left-leaning models' responses and 89% of right-leaning
models' responses remain consistent under the challenge, enabling semantic
entropy to achieve high accuracy (AUROC=0.78), effectively distinguishing
between surface-level alignment from genuine belief. These findings call into
question the assumption that LLMs maintain stable, human-like political
ideologies, emphasizing the importance of conducting topic-specific reliability
assessments for real-world applications.

</details>

### [5] [Agree to Disagree? A Meta-Evaluation of LLM Misgendering](https://arxiv.org/abs/2504.17075)
*Arjun Subramonian,Vagrant Gautam,Preethi Seshadri,Dietrich Klakow,Kai-Wei Chang,Yizhou Sun*

Main category: cs.CL

TLDR: 本文研究了评估大型语言模型（LLM）性别错误的方法是否具有一致性，发现不同方法之间存在显著分歧，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 现有评估LLM性别错误的方法（如概率评估和生成评估）是否具有一致性尚未被研究，本文旨在填补这一空白。

Method: 通过系统元评估，将三种数据集转换为并行评估形式，自动评估6个模型，并进行人工验证。

Result: 发现不同评估方法在实例、数据集和模型层面存在20.2%的分歧，且自动评估无法完全捕捉人类评估的复杂性。

Conclusion: 建议未来评估需改进方法，并质疑了LLM评估中广泛假设方法一致性的惯例。

Abstract: Numerous methods have been proposed to measure LLM misgendering, including
probability-based evaluations (e.g., automatically with templatic sentences)
and generation-based evaluations (e.g., with automatic heuristics or human
validation). However, it has gone unexamined whether these evaluation methods
have convergent validity, that is, whether their results align. Therefore, we
conduct a systematic meta-evaluation of these methods across three existing
datasets for LLM misgendering. We propose a method to transform each dataset to
enable parallel probability- and generation-based evaluation. Then, by
automatically evaluating a suite of 6 models from 3 families, we find that
these methods can disagree with each other at the instance, dataset, and model
levels, conflicting on 20.2% of evaluation instances. Finally, with a human
evaluation of 2400 LLM generations, we show that misgendering behaviour is
complex and goes far beyond pronouns, which automatic evaluations are not
currently designed to capture, suggesting essential disagreement with human
evaluations. Based on our findings, we provide recommendations for future
evaluations of LLM misgendering. Our results are also more widely relevant, as
they call into question broader methodological conventions in LLM evaluation,
which often assume that different evaluation methods agree.

</details>

### [6] [How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study](https://arxiv.org/abs/2504.17083)
*Rendi Chevi,Kentaro Inui,Thamar Solorio,Alham Fikri Aji*

Main category: cs.CL

TLDR: 研究发现，LLM的语言风格（如权威性、确定性、表达清晰度等）显著影响用户偏好，但具体影响因用户群体和个体特征而异。需注意样本局限性。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM的语言风格如何影响用户偏好，以及这种动态可能带来的双重影响（提升体验与增加风险）。

Method: 通过探索性和实验性用户研究，分析语言风格与用户偏好的关系。

Result: 语言风格确实影响用户偏好，但具体影响因用户群体和个体特征而异。

Conclusion: 初步研究表明语言风格的重要性，未来需扩大样本以进一步验证因果关系。

Abstract: What makes an interaction with the LLM more preferable for the user? While it
is intuitive to assume that information accuracy in the LLM's responses would
be one of the influential variables, recent studies have found that inaccurate
LLM's responses could still be preferable when they are perceived to be more
authoritative, certain, well-articulated, or simply verbose. These variables
interestingly fall under the broader category of language style, implying that
the style in the LLM's responses might meaningfully influence users'
preferences. This hypothesized dynamic could have double-edged consequences:
enhancing the overall user experience while simultaneously increasing their
susceptibility to risks such as LLM's misinformation or hallucinations. In this
short paper, we present our preliminary studies in exploring this subject.
Through a series of exploratory and experimental user studies, we found that
LLM's language style does indeed influence user's preferences, but how and
which language styles influence the preference varied across different user
populations, and more interestingly, moderated by the user's very own
individual traits. As a preliminary work, the findings in our studies should be
interpreted with caution, particularly given the limitations in our samples,
which still need wider demographic diversity and larger sample sizes. Our
future directions will first aim to address these limitations, which would
enable a more comprehensive joint effect analysis between the language style,
individual traits, and preferences, and further investigate the potential
causal relationship between and beyond these variables.

</details>

### [7] [Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning](https://arxiv.org/abs/2504.17091)
*Seunghyun Yoo*

Main category: cs.CL

TLDR: 提出了一种交互式思维链框架，通过透明、模块化和用户可编辑的推理过程，增强AI的可解释性和负责任使用。


<details>
  <summary>Details</summary>
Motivation: 短内容泛滥和AI快速普及导致深度思考机会减少，削弱用户批判性思维和对AI输出的理解。

Method: 设计交互式思维链框架，分解推理为可检查、修改和重新执行的模块，结合轻量级编辑适应机制。

Result: 框架提升了用户认知参与度，支持多样化认知风格，并通过元数据披露和隐私保护确保伦理透明。

Conclusion: 该框架为促进AI系统中的批判性参与、负责任交互和包容性适应提供了设计原则和架构。

Abstract: Due to the proliferation of short-form content and the rapid adoption of AI,
opportunities for deep, reflective thinking have significantly diminished,
undermining users' critical thinking and reducing engagement with the reasoning
behind AI-generated outputs. To address this issue, we propose an Interactive
Chain-of-Thought (CoT) Framework that enhances human-centered explainability
and responsible AI usage by making the model's inference process transparent,
modular, and user-editable. The framework decomposes reasoning into clearly
defined blocks that users can inspect, modify, and re-execute, encouraging
active cognitive engagement rather than passive consumption. It further
integrates a lightweight edit-adaptation mechanism inspired by preference
learning, allowing the system to align with diverse cognitive styles and user
intentions. Ethical transparency is ensured through explicit metadata
disclosure, built-in bias checkpoint functionality, and privacy-preserving
safeguards. This work outlines the design principles and architecture necessary
to promote critical engagement, responsible interaction, and inclusive
adaptation in AI systems aimed at addressing complex societal challenges.

</details>

### [8] [The Rise of Small Language Models in Healthcare: A Comprehensive Survey](https://arxiv.org/abs/2504.17119)
*Muskan Garg,Shaina Raza,Shebuti Rayana,Xingyi Liu,Sunghwan Sohn*

Main category: cs.CL

TLDR: 本文综述了小型语言模型（SLMs）在医疗保健领域的应用，提出了分类框架，并展示了其在资源受限环境中的潜力。


<details>
  <summary>Details</summary>
Motivation: 解决医疗保健应用中数据隐私和资源限制的问题，推广SLMs作为可扩展且临床可行的解决方案。

Method: 提出分类框架，分析SLMs在NLP任务、利益相关者角色和护理连续性三个维度的表现，并探讨模型优化方法。

Result: 展示了SLMs在医疗保健领域的实验成果，突出了其变革潜力。

Conclusion: SLMs为医疗保健信息学提供了高效、可持续的解决方案，未来研究和开发前景广阔。

Abstract: Despite substantial progress in healthcare applications driven by large
language models (LLMs), growing concerns around data privacy, and limited
resources; the small language models (SLMs) offer a scalable and clinically
viable solution for efficient performance in resource-constrained environments
for next-generation healthcare informatics. Our comprehensive survey presents a
taxonomic framework to identify and categorize them for healthcare
professionals and informaticians. The timeline of healthcare SLM contributions
establishes a foundational framework for analyzing models across three
dimensions: NLP tasks, stakeholder roles, and the continuum of care. We present
a taxonomic framework to identify the architectural foundations for building
models from scratch; adapting SLMs to clinical precision through prompting,
instruction fine-tuning, and reasoning; and accessibility and sustainability
through compression techniques. Our primary objective is to offer a
comprehensive survey for healthcare professionals, introducing recent
innovations in model optimization and equipping them with curated resources to
support future research and development in the field. Aiming to showcase the
groundbreaking advancements in SLMs for healthcare, we present a comprehensive
compilation of experimental results across widely studied NLP tasks in
healthcare to highlight the transformative potential of SLMs in healthcare. The
updated repository is available at Github

</details>

### [9] [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org/abs/2504.17130)
*Hannah Cyberey,David Evans*

Main category: cs.CL

TLDR: 该论文研究了大型语言模型（LLMs）中的“审查”机制，提出了一种检测和控制模型输出中审查水平的方法，并揭示了“思维抑制”这一额外的审查维度。


<details>
  <summary>Details</summary>
Motivation: 理解LLMs如何通过调整拒绝有害请求和生成符合控制者偏好的响应来实现“审查”，并探索其背后的机制。

Method: 使用表示工程技术分析开放权重的安全调整模型，找到拒绝-服从向量以检测和控制审查水平；分析推理LLMs，发现“思维抑制”维度，并找到抑制模型推理过程的向量。

Result: 提出了一种方法可以检测和控制模型输出中的审查水平，并揭示了“思维抑制”作为审查的额外维度。

Conclusion: 通过表示工程技术可以揭示和控制LLMs中的审查机制，为理解和调整模型行为提供了新工具。

Abstract: Large language models (LLMs) have transformed the way we access information.
These models are often tuned to refuse to comply with requests that are
considered harmful and to produce responses that better align with the
preferences of those who control the models. To understand how this
"censorship" works. We use representation engineering techniques to study
open-weights safety-tuned models. We present a method for finding a
refusal--compliance vector that detects and controls the level of censorship in
model outputs. We also analyze recent reasoning LLMs, distilled from
DeepSeek-R1, and uncover an additional dimension of censorship through "thought
suppression". We show a similar approach can be used to find a vector that
suppresses the model's reasoning process, allowing us to remove censorship by
applying the negative multiples of this vector

</details>

### [10] [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org/abs/2504.17137)
*Chanhee Park,Hyeonseok Moon,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TLDR: MIRAGE是一个专为RAG评估设计的问答数据集，包含7,560个实例和37,800个检索条目，并引入新指标衡量RAG适应性。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统评估缺乏组件化基准，限制了对其检索与生成能力的详细分析。

Method: 提出MIRAGE数据集和新型评估指标，通过实验分析不同检索器-LLM配置的性能。

Result: 实验揭示了RAG系统中模型对的最优对齐方式及其内部动态。

Conclusion: MIRAGE为RAG系统评估提供了高效、精确的工具，支持广泛研究应用。

Abstract: Retrieval-Augmented Generation (RAG) has gained prominence as an effective
method for enhancing the generative capabilities of Large Language Models
(LLMs) through the incorporation of external knowledge. However, the evaluation
of RAG systems remains a challenge, due to the intricate interplay between
retrieval and generation components. This limitation has resulted in a scarcity
of benchmarks that facilitate a detailed, component-specific assessment. In
this work, we present MIRAGE, a Question Answering dataset specifically
designed for RAG evaluation. MIRAGE consists of 7,560 curated instances mapped
to a retrieval pool of 37,800 entries, enabling an efficient and precise
evaluation of both retrieval and generation tasks. We also introduce novel
evaluation metrics aimed at measuring RAG adaptability, encompassing dimensions
such as noise vulnerability, context acceptability, context insensitivity, and
context misinterpretation. Through comprehensive experiments across various
retriever-LLM configurations, we provide new insights into the optimal
alignment of model pairs and the nuanced dynamics within RAG systems. The
dataset and evaluation code are publicly available, allowing for seamless
integration and customization in diverse research settings\footnote{The MIRAGE
code and data are available at https://github.com/nlpai-lab/MIRAGE.

</details>

### [11] [Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning](https://arxiv.org/abs/2504.17192)
*Minju Seo,Jinheon Baek,Seongyun Lee,Sung Ju Hwang*

Main category: cs.CL

TLDR: PaperCoder是一个基于多智能体LLM的框架，用于将机器学习论文转化为功能代码库，通过规划、分析和生成三个阶段实现，并在评估中表现出色。


<details>
  <summary>Details</summary>
Motivation: 机器学习研究的代码实现往往不可用，导致复现和扩展工作缓慢且费力。

Method: PaperCoder通过规划、分析和生成三个阶段，利用多智能体LLM框架生成模块化、依赖感知的代码。

Result: PaperCoder在模型和人类评估中均表现优异，生成高质量且忠实于原文的代码实现。

Conclusion: PaperCoder在代码生成任务中表现出色，显著优于基线方法。

Abstract: Despite the rapid growth of machine learning research, corresponding code
implementations are often unavailable, making it slow and labor-intensive for
researchers to reproduce results and build upon prior work. In the meantime,
recent Large Language Models (LLMs) excel at understanding scientific documents
and generating high-quality code. Inspired by this, we introduce PaperCoder, a
multi-agent LLM framework that transforms machine learning papers into
functional code repositories. PaperCoder operates in three stages: planning,
where it constructs a high-level roadmap, designs the system architecture with
diagrams, identifies file dependencies, and generates configuration files;
analysis, which focuses on interpreting implementation-specific details; and
generation, where modular, dependency-aware code is produced. Moreover, each
phase is instantiated through a set of specialized agents designed to
collaborate effectively across the pipeline. We then evaluate PaperCoder on
generating code implementations from machine learning papers based on both
model-based and human evaluations, specifically from the original paper
authors, with author-released repositories as ground truth if available. Our
results demonstrate the effectiveness of PaperCoder in creating high-quality,
faithful implementations. Furthermore, it consistently shows strengths in the
recently released PaperBench benchmark, surpassing strong baselines by
substantial margins.

</details>

### [12] [A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation](https://arxiv.org/abs/2504.17200)
*Yangxinyu Xie,Bowen Jiang,Tanwi Mallick,Joshua David Bergerson,John K. Hutchison,Duane R. Verner,Jordan Branham,M. Ross Alexander,Robert B. Ross,Yan Feng,Leslie-Anne Levy,Weijie Su,Camillo J. Taylor*

Main category: cs.CL

TLDR: 提出了一种基于检索增强生成（RAG）的多代理LLM系统WildfireGPT，用于自然灾害和极端天气事件的分析与决策支持，显著优于现有LLM解决方案。


<details>
  <summary>Details</summary>
Motivation: 通用LLM在提供特定领域（如自然灾害）的上下文信息时表现不佳，需要一种更专业的解决方案。

Method: 采用多代理设计和RAG框架，整合灾害预测数据、观测数据集和科学文献，确保信息准确性和上下文相关性。

Result: 在十个专家主导的案例研究中，WildfireGPT显著优于现有LLM决策支持工具。

Conclusion: WildfireGPT通过专业化设计，有效提升了LLM在自然灾害领域的决策支持能力。

Abstract: Large language models (LLMs) are a transformational capability at the
frontier of artificial intelligence and machine learning that can support
decision-makers in addressing pressing societal challenges such as extreme
natural hazard events. As generalized models, LLMs often struggle to provide
context-specific information, particularly in areas requiring specialized
knowledge. In this work we propose a retrieval-augmented generation (RAG)-based
multi-agent LLM system to support analysis and decision-making in the context
of natural hazards and extreme weather events. As a proof of concept, we
present WildfireGPT, a specialized system focused on wildfire hazards. The
architecture employs a user-centered, multi-agent design to deliver tailored
risk insights across diverse stakeholder groups. By integrating natural hazard
and extreme weather projection data, observational datasets, and scientific
literature through an RAG framework, the system ensures both the accuracy and
contextual relevance of the information it provides. Evaluation across ten
expert-led case studies demonstrates that WildfireGPT significantly outperforms
existing LLM-based solutions for decision support.

</details>

### [13] [Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?](https://arxiv.org/abs/2504.17220)
*Kaidong Feng,Zhu Sun,Jie Yang,Hui Fang,Xinghua Qu,Wenyuan Liu*

Main category: cs.CL

TLDR: 该论文探讨了如何通过知识蒸馏（KD）将大型语言模型（LLM）的推理能力转移到小型学生模型中，以解决大规模LLM在捆绑生成中的效率问题。


<details>
  <summary>Details</summary>
Motivation: 由于大型LLM在微调和推理时的高计算成本，研究旨在通过KD方法减少计算需求，同时保持性能。

Method: 提出一个综合KD框架，逐步提取知识（模式、规则、深度思考），并通过不同策略捕获不同数量的知识，结合LLM适应技术（如上下文学习、监督微调）。

Result: 实验表明，知识格式、数量和利用方法共同影响捆绑生成性能，KD在提高效率的同时保持效果。

Conclusion: KD在高效且有效的LLM捆绑生成中具有显著潜力。

Abstract: LLMs are increasingly explored for bundle generation, thanks to their
reasoning capabilities and knowledge. However, deploying large-scale LLMs
introduces significant efficiency challenges, primarily high computational
costs during fine-tuning and inference due to their massive parameterization.
Knowledge distillation (KD) offers a promising solution, transferring expertise
from large teacher models to compact student models. This study systematically
investigates knowledge distillation approaches for bundle generation, aiming to
minimize computational demands while preserving performance. We explore three
critical research questions: (1) how does the format of KD impact bundle
generation performance? (2) to what extent does the quantity of distilled
knowledge influence performance? and (3) how do different ways of utilizing the
distilled knowledge affect performance? We propose a comprehensive KD framework
that (i) progressively extracts knowledge (patterns, rules, deep thoughts);
(ii) captures varying quantities of distilled knowledge through different
strategies; and (iii) exploits complementary LLM adaptation techniques
(in-context learning, supervised fine-tuning, combination) to leverage
distilled knowledge in small student models for domain-specific adaptation and
enhanced efficiency. Extensive experiments provide valuable insights into how
knowledge format, quantity, and utilization methodologies collectively shape
LLM-based bundle generation performance, exhibiting KD's significant potential
for more efficient yet effective LLM-based bundle generation.

</details>

### [14] [Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn Supportive Dialogues](https://arxiv.org/abs/2504.17238)
*Jinfeng Zhou,Yuxuan Chen,Jianing Yin,Yongkang Huang,Yihan Shi,Xikun Zhang,Libiao Peng,Rongsheng Zhang,Tangjie Lv,Zhipeng Hu,Hongning Wang,Minlie Huang*

Main category: cs.CL

TLDR: CRDial是一个新型框架，通过多轮对话实现认知重构（CR），解决了现有方法的不足，并生成了高质量的双语数据集Crisp。基于Crisp训练的Crispers模型在多项评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 临床医生短缺和心理污名化促使开发人机交互心理治疗工具，但现有CR方法未能有效模拟心理治疗过程。

Method: 提出CRDial框架，设计多轮对话阶段（识别与重构负面思想），整合支持性对话策略，并采用多通道循环机制实现迭代CR。

Result: 生成大规模高质量双语数据集Crisp，并训练出7B和14B规模的Crispers模型，在人类评估中表现卓越。

Conclusion: CRDial和Crispers为认知重构提供了高效解决方案，显著优于现有方法。

Abstract: Cognitive Restructuring (CR) is a psychotherapeutic process aimed at
identifying and restructuring an individual's negative thoughts, arising from
mental health challenges, into more helpful and positive ones via multi-turn
dialogues. Clinician shortage and stigma urge the development of human-LLM
interactive psychotherapy for CR. Yet, existing efforts implement CR via simple
text rewriting, fixed-pattern dialogues, or a one-shot CR workflow, failing to
align with the psychotherapeutic process for effective CR. To address this gap,
we propose CRDial, a novel framework for CR, which creates multi-turn dialogues
with specifically designed identification and restructuring stages of negative
thoughts, integrates sentence-level supportive conversation strategies, and
adopts a multi-channel loop mechanism to enable iterative CR. With CRDial, we
distill Crisp, a large-scale and high-quality bilingual dialogue dataset, from
LLM. We then train Crispers, Crisp-based conversational LLMs for CR, at 7B and
14B scales. Extensive human studies show the superiority of Crispers in
pointwise, pairwise, and intervention evaluations.

</details>

### [15] [Low-Resource Neural Machine Translation Using Recurrent Neural Networks and Transfer Learning: A Case Study on English-to-Igbo](https://arxiv.org/abs/2504.17252)
*Ocheme Anthony Ekle,Biswarup Das*

Main category: cs.CL

TLDR: 该研究开发了基于神经机器翻译和Transformer的迁移学习模型，用于英语到伊博语（一种低资源非洲语言）的翻译，通过RNN架构和迁移学习显著提升了翻译性能。


<details>
  <summary>Details</summary>
Motivation: 伊博语是一种低资源语言，但使用者众多（超过4000万人），现有翻译工具性能不足。研究旨在通过结合RNN和迁移学习提升翻译准确性。

Method: 使用RNN架构（LSTM和GRU）结合注意力机制，并利用MarianNMT预训练模型进行迁移学习。数据集包括圣经、新闻、维基百科和Common Crawl。

Result: RNN模型表现接近现有基准，迁移学习带来+4.83 BLEU提升，翻译准确率达到70%。

Conclusion: 结合RNN和迁移学习能有效提升低资源语言翻译性能，为类似任务提供了可行方案。

Abstract: In this study, we develop Neural Machine Translation (NMT) and
Transformer-based transfer learning models for English-to-Igbo translation - a
low-resource African language spoken by over 40 million people across Nigeria
and West Africa. Our models are trained on a curated and benchmarked dataset
compiled from Bible corpora, local news, Wikipedia articles, and Common Crawl,
all verified by native language experts. We leverage Recurrent Neural Network
(RNN) architectures, including Long Short-Term Memory (LSTM) and Gated
Recurrent Units (GRU), enhanced with attention mechanisms to improve
translation accuracy. To further enhance performance, we apply transfer
learning using MarianNMT pre-trained models within the SimpleTransformers
framework. Our RNN-based system achieves competitive results, closely matching
existing English-Igbo benchmarks. With transfer learning, we observe a
performance gain of +4.83 BLEU points, reaching an estimated translation
accuracy of 70%. These findings highlight the effectiveness of combining RNNs
with transfer learning to address the performance gap in low-resource language
translation tasks.

</details>

### [16] [JurisCTC: Enhancing Legal Judgment Prediction via Cross-Domain Transfer and Contrastive Learning](https://arxiv.org/abs/2504.17264)
*Zhaolu Kang,Hongtian Cai,Xiangyang Ji,Jinzhe Li,Nanfei Gu*

Main category: cs.CL

TLDR: 论文提出JurisCTC模型，用于法律领域无监督域适应（UDA），提升法律判决预测（LJP）任务准确性，通过对比学习实现跨领域知识迁移。


<details>
  <summary>Details</summary>
Motivation: 法律文本复杂且标注数据有限，现有方法在跨法律领域知识迁移方面不足，需改进。

Method: 提出JurisCTC模型，利用对比学习区分不同领域样本，实现民事与刑事法律领域知识迁移。

Result: JurisCTC在LJP任务中表现优异，最高准确率达76.59%和78.83%，优于其他模型和大型语言模型。

Conclusion: JurisCTC为法律领域UDA提供有效解决方案，显著提升跨领域知识迁移能力。

Abstract: In recent years, Unsupervised Domain Adaptation (UDA) has gained significant
attention in the field of Natural Language Processing (NLP) owing to its
ability to enhance model generalization across diverse domains. However, its
application for knowledge transfer between distinct legal domains remains
largely unexplored. To address the challenges posed by lengthy and complex
legal texts and the limited availability of large-scale annotated datasets, we
propose JurisCTC, a novel model designed to improve the accuracy of Legal
Judgment Prediction (LJP) tasks. Unlike existing approaches, JurisCTC
facilitates effective knowledge transfer across various legal domains and
employs contrastive learning to distinguish samples from different domains.
Specifically, for the LJP task, we enable knowledge transfer between civil and
criminal law domains. Compared to other models and specific large language
models (LLMs), JurisCTC demonstrates notable advancements, achieving peak
accuracies of 76.59% and 78.83%, respectively.

</details>

### [17] [Evaluating and Mitigating Bias in AI-Based Medical Text Generation](https://arxiv.org/abs/2504.17279)
*Xiuying Chen,Tairan Wang,Juexiao Zhou,Zirui Song,Xin Gao,Xiangliang Zhang*

Main category: cs.CL

TLDR: 研究探讨了医疗领域文本生成中的公平性问题，提出了一种选择性优化算法以减少偏见，并在不牺牲整体性能的情况下显著降低了不同群体间的性能差异。


<details>
  <summary>Details</summary>
Motivation: 随着AI在医疗领域的广泛应用，其可能反映和放大人类偏见的担忧日益增加。公平性问题在医学影像分类领域已有研究，但在文本生成领域仍较少探讨。

Method: 提出了一种选择性优化算法，综合考虑词级准确性和病理准确性，确保过程可微分以有效训练模型。

Result: 算法在多种骨干网络、数据集和模态下验证，将不同群体间的性能差异减少了30%以上，同时文本生成准确率变化通常控制在2%以内。

Conclusion: 该算法有效减少了文本生成中的偏见，提升了医疗领域诊断的公平性和可靠性。

Abstract: Artificial intelligence (AI) systems, particularly those based on deep
learning models, have increasingly achieved expert-level performance in medical
applications. However, there is growing concern that such AI systems may
reflect and amplify human bias, and reduce the quality of their performance in
historically under-served populations. The fairness issue has attracted
considerable research interest in the medical imaging classification field, yet
it remains understudied in the text generation domain. In this study, we
investigate the fairness problem in text generation within the medical field
and observe significant performance discrepancies across different races,
sexes, and age groups, including intersectional groups, various model scales,
and different evaluation metrics. To mitigate this fairness issue, we propose
an algorithm that selectively optimizes those underperformed groups to reduce
bias. The selection rules take into account not only word-level accuracy but
also the pathology accuracy to the target reference, while ensuring that the
entire process remains fully differentiable for effective model training. Our
evaluations across multiple backbones, datasets, and modalities demonstrate
that our proposed algorithm enhances fairness in text generation without
compromising overall performance. Specifically, the disparities among various
groups across different metrics were diminished by more than 30% with our
algorithm, while the relative change in text generation accuracy was typically
within 2%. By reducing the bias generated by deep learning models, our proposed
approach can potentially alleviate concerns about the fairness and reliability
of text generation diagnosis in medical domain.
  Our code is publicly available to facilitate further research at
https://github.com/iriscxy/GenFair.

</details>

### [18] [CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality](https://arxiv.org/abs/2504.17309)
*Junyan Zhang,Shuliang Liu,Aiwei Liu,Yubo Gao,Jungang Li,Xiaojie Gu,Xuming Hu*

Main category: cs.CL

TLDR: CoheMark是一种先进的句子级水印技术，通过利用句子间的连贯关系提升逻辑流畅性，同时保持高文本质量和强水印检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有句子级水印技术依赖随意分割或生成过程，限制了合适句子的可用性，影响了生成内容的质量。

Method: CoheMark采用模糊c均值聚类选择句子，并应用特定下一句选择标准。

Result: 实验表明，CoheMark在保持高文本质量的同时实现了强水印强度。

Conclusion: CoheMark解决了平衡文本质量与水印检测的挑战，是一种高效的水印技术。

Abstract: Watermarking technology is a method used to trace the usage of content
generated by large language models. Sentence-level watermarking aids in
preserving the semantic integrity within individual sentences while maintaining
greater robustness. However, many existing sentence-level watermarking
techniques depend on arbitrary segmentation or generation processes to embed
watermarks, which can limit the availability of appropriate sentences. This
limitation, in turn, compromises the quality of the generated response. To
address the challenge of balancing high text quality with robust watermark
detection, we propose CoheMark, an advanced sentence-level watermarking
technique that exploits the cohesive relationships between sentences for better
logical fluency. The core methodology of CoheMark involves selecting sentences
through trained fuzzy c-means clustering and applying specific next sentence
selection criteria. Experimental evaluations demonstrate that CoheMark achieves
strong watermark strength while exerting minimal impact on text quality.

</details>

### [19] [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org/abs/2504.17311)
*Yulia Otmakhova,Hung Thinh Truong,Rahmad Mahendra,Zenan Zhai,Rongxin Zhu,Daniel Beck,Jey Han Lau*

Main category: cs.CL

TLDR: FLUKE是一个任务无关的框架，通过系统性的最小化测试数据变化评估模型鲁棒性，涵盖从拼写到方言和风格的语言层级变化。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过系统化的语言变化测试，揭示模型在不同任务中的鲁棒性表现，尤其是对语言变化的敏感性。

Method: FLUKE利用大语言模型（LLMs）和人工验证生成受控的语言层级变化，并在四个NLP任务中评估微调模型和LLMs。

Result: 结果显示：(1)语言变化的影响高度依赖任务；(2)LLMs整体鲁棒性更强，但对某些变化仍脆弱；(3)所有模型对否定修改普遍脆弱。

Conclusion: 系统性鲁棒性测试对理解模型行为至关重要，FLUKE为此提供了有效工具。

Abstract: We present FLUKE (Framework for LingUistically-driven and tasK-agnostic
robustness Evaluation), a task-agnostic framework for assessing model
robustness through systematic minimal variations of test data. FLUKE introduces
controlled variations across linguistic levels - from orthography to dialect
and style varieties - and leverages large language models (LLMs) with human
validation to generate modifications. We demonstrate FLUKE's utility by
evaluating both fine-tuned models and LLMs across four diverse NLP tasks, and
reveal that (1) the impact of linguistic variations is highly task-dependent,
with some tests being critical for certain tasks but irrelevant for others; (2)
while LLMs have better overall robustness compared to fine-tuned models, they
still exhibit significant brittleness to certain linguistic variations; (3) all
models show substantial vulnerability to negation modifications across most
tasks. These findings highlight the importance of systematic robustness testing
for understanding model behaviors.

</details>

### [20] [Bridging Cognition and Emotion: Empathy-Driven Multimodal Misinformation Detection](https://arxiv.org/abs/2504.17332)
*Zihan Wang,Lu Yuan,Zhengxuan Zhang,Qing Zhao*

Main category: cs.CL

TLDR: 论文提出了一种结合认知和情感共情的双方面共情框架（DAE），用于更全面地检测社交媒体中的虚假信息，并通过实验验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统虚假信息检测方法忽视人类共情在传播中的作用，DAE填补了这一空白。

Method: DAE框架结合认知和情感共情，分析创作者和读者的视角，并利用大语言模型模拟读者反应，同时引入共情感知过滤机制。

Result: 实验结果表明，DAE在基准数据集上优于现有方法。

Conclusion: DAE为多模态虚假信息检测提供了新范式。

Abstract: In the digital era, social media has become a major conduit for information
dissemination, yet it also facilitates the rapid spread of misinformation.
Traditional misinformation detection methods primarily focus on surface-level
features, overlooking the crucial roles of human empathy in the propagation
process. To address this gap, we propose the Dual-Aspect Empathy Framework
(DAE), which integrates cognitive and emotional empathy to analyze
misinformation from both the creator and reader perspectives. By examining
creators' cognitive strategies and emotional appeals, as well as simulating
readers' cognitive judgments and emotional responses using Large Language
Models (LLMs), DAE offers a more comprehensive and human-centric approach to
misinformation detection. Moreover, we further introduce an empathy-aware
filtering mechanism to enhance response authenticity and diversity.
Experimental results on benchmark datasets demonstrate that DAE outperforms
existing methods, providing a novel paradigm for multimodal misinformation
detection.

</details>

### [21] [M-MRE: Extending the Mutual Reinforcement Effect to Multimodal Information Extraction](https://arxiv.org/abs/2504.17353)
*Chengguang Gan,Sunbowen Lee,Zhixi Cai,Yanbin Wei,Lei Zheng,Yunhao Liang,Shiwen Ni,Tatsunori Mori*

Main category: cs.CL

TLDR: 论文首次将互增强效应（MRE）扩展到多模态信息提取领域，提出多模态互增强效应（M-MRE）任务，并构建数据集。通过Prompt Format Adapter（PFA）解决挑战，实验证明MRE在多模态场景中同样有效。


<details>
  <summary>Details</summary>
Motivation: 探索MRE在多模态领域的适用性，填补视觉和多模态领域的研究空白。

Method: 提出M-MRE任务及数据集，设计兼容大型视觉语言模型的PFA方法。

Result: 实验验证MRE在多模态任务中的有效性，实现三个相关任务的互增强。

Conclusion: MRE在多模态领域具有通用性，为跨任务互增强提供了新思路。

Abstract: Mutual Reinforcement Effect (MRE) is an emerging subfield at the intersection
of information extraction and model interpretability. MRE aims to leverage the
mutual understanding between tasks of different granularities, enhancing the
performance of both coarse-grained and fine-grained tasks through joint
modeling. While MRE has been explored and validated in the textual domain, its
applicability to visual and multimodal domains remains unexplored. In this
work, we extend MRE to the multimodal information extraction domain for the
first time. Specifically, we introduce a new task: Multimodal Mutual
Reinforcement Effect (M-MRE), and construct a corresponding dataset to support
this task. To address the challenges posed by M-MRE, we further propose a
Prompt Format Adapter (PFA) that is fully compatible with various Large
Vision-Language Models (LVLMs). Experimental results demonstrate that MRE can
also be observed in the M-MRE task, a multimodal text-image understanding
scenario. This provides strong evidence that MRE facilitates mutual gains
across three interrelated tasks, confirming its generalizability beyond the
textual domain.

</details>

### [22] [PatientDx: Merging Large Language Models for Protecting Data-Privacy in Healthcare](https://arxiv.org/abs/2504.17360)
*Jose G. Moreno,Jesus Lovon,M'Rick Robin-Charlet,Christine Damase-Michel,Lynda Tamine*

Main category: cs.CL

TLDR: PatientDx框架通过模型合并技术，避免对敏感医疗数据进行微调，提升LLM在医疗预测任务中的性能，同时减少数据隐私风险。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的数据隐私问题突出，传统微调方法需要大量敏感数据，PatientDx旨在解决这一问题。

Method: 基于LLM合并技术，通过优化模型合并策略，利用数值推理模型调整超参数，无需直接训练患者数据。

Result: 在MIMIC-IV数据集上，AUROC提升7%，且相比微调模型更不易发生数据泄露。

Conclusion: PatientDx在保护隐私的同时提升了性能，为医疗领域LLM应用提供了新思路。

Abstract: Fine-tuning of Large Language Models (LLMs) has become the default practice
for improving model performance on a given task. However, performance
improvement comes at the cost of training on vast amounts of annotated data
which could be sensitive leading to significant data privacy concerns. In
particular, the healthcare domain is one of the most sensitive domains exposed
to data privacy issues. In this paper, we present PatientDx, a framework of
model merging that allows the design of effective LLMs for health-predictive
tasks without requiring fine-tuning nor adaptation on patient data. Our
proposal is based on recently proposed techniques known as merging of LLMs and
aims to optimize a building block merging strategy. PatientDx uses a pivotal
model adapted to numerical reasoning and tunes hyperparameters on examples
based on a performance metric but without training of the LLM on these data.
Experiments using the mortality tasks of the MIMIC-IV dataset show improvements
up to 7% in terms of AUROC when compared to initial models. Additionally, we
confirm that when compared to fine-tuned models, our proposal is less prone to
data leak problems without hurting performance. Finally, we qualitatively show
the capabilities of our proposal through a case study. Our best model is
publicly available at https://huggingface.co/ Jgmorenof/mistral\_merged\_0\_4.

</details>

### [23] [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org/abs/2504.17366)
*Yongxuan Wu,Runyu Chen,Peiyu Liu,Hongjin Qian*

Main category: cs.CL

TLDR: 论文构建了首个基于直播的冗余丰富的长文本数据集，评估了现有方法在长上下文理解中的表现，并提出了一种新基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能反映真实对话的复杂性，限制了大型语言模型在实际场景中的应用。

Method: 构建了基于直播的长文本数据集，设计了检索依赖、推理依赖和混合任务，评估了现有方法并提出新基线。

Result: 现有方法在冗余输入上表现不佳，新基线方法在任务中表现优异。

Conclusion: 研究揭示了当前方法的局限性，为长上下文理解提供了新方向，并填补了评测空白。

Abstract: Long-context understanding poses significant challenges in natural language
processing, particularly for real-world dialogues characterized by speech-based
elements, high redundancy, and uneven information density. Although large
language models (LLMs) achieve impressive results on existing benchmarks, these
datasets fail to reflect the complexities of such texts, limiting their
applicability to practical scenarios. To bridge this gap, we construct the
first spoken long-text dataset, derived from live streams, designed to reflect
the redundancy-rich and conversational nature of real-world scenarios. We
construct tasks in three categories: retrieval-dependent, reasoning-dependent,
and hybrid. We then evaluate both popular LLMs and specialized methods to
assess their ability to understand long-contexts in these tasks. Our results
show that current methods exhibit strong task-specific preferences and perform
poorly on highly redundant inputs, with no single method consistently
outperforming others. We propose a new baseline that better handles redundancy
in spoken text and achieves strong performance across tasks. Our findings
highlight key limitations of current methods and suggest future directions for
improving long-context understanding. Finally, our benchmark fills a gap in
evaluating long-context spoken language understanding and provides a practical
foundation for developing real-world e-commerce systems. The code and benchmark
are available at https://github.com/Yarayx/livelongbench.

</details>

### [24] [PicPersona-TOD : A Dataset for Personalizing Utterance Style in Task-Oriented Dialogue with Image Persona](https://arxiv.org/abs/2504.17390)
*Jihyun Lee,Yejin Jeon,Seungyeon Seo,Gary Geunbae Lee*

Main category: cs.CL

TLDR: 论文提出PicPersona-TOD数据集和Pictor模型，通过用户图像实现个性化对话，提升交互体验。


<details>
  <summary>Details</summary>
Motivation: 现有任务导向对话系统生成通用、单调的回应，缺乏个性化和对用户属性的适应。

Method: 结合用户图像作为人物设定，利用第一印象、对话策略提示和外部知识减少幻觉，构建PicPersona-TOD数据集，并开发Pictor模型。

Result: 人类评估证实个性化回应提升了用户体验，Pictor模型在未见领域表现稳健。

Conclusion: PicPersona-TOD和Pictor模型为个性化任务导向对话提供了有效解决方案。

Abstract: Task-Oriented Dialogue (TOD) systems are designed to fulfill user requests
through natural language interactions, yet existing systems often produce
generic, monotonic responses that lack individuality and fail to adapt to
users' personal attributes. To address this, we introduce PicPersona-TOD, a
novel dataset that incorporates user images as part of the persona, enabling
personalized responses tailored to user-specific factors such as age or
emotional context. This is facilitated by first impressions, dialogue
policy-guided prompting, and the use of external knowledge to reduce
hallucinations. Human evaluations confirm that our dataset enhances user
experience, with personalized responses contributing to a more engaging
interaction. Additionally, we introduce a new NLG model, Pictor, which not only
personalizes responses, but also demonstrates robust performance across unseen
domains https://github.com/JihyunLee1/PicPersona.

</details>

### [25] [Creating Targeted, Interpretable Topic Models with LLM-Generated Text Augmentation](https://arxiv.org/abs/2504.17445)
*Anna Lieb,Maneesh Arora,Eni Mustafaraj*

Main category: cs.CL

TLDR: 利用GPT-4生成的文本增强主题模型，提高其在社会科学研究中的实用性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决主题模型在解释性和针对特定领域研究问题实用性上的局限性。

Method: 使用GPT-4生成的文本增强主题模型，并通过政治学案例研究评估效果。

Result: GPT-4增强的主题模型生成高度可解释的类别，适用于特定领域研究问题。

Conclusion: LLM生成的文本增强显著提升了主题模型的实用性和可解释性。

Abstract: Unsupervised machine learning techniques, such as topic modeling and
clustering, are often used to identify latent patterns in unstructured text
data in fields such as political science and sociology. These methods overcome
common concerns about reproducibility and costliness involved in the
labor-intensive process of human qualitative analysis. However, two major
limitations of topic models are their interpretability and their practicality
for answering targeted, domain-specific social science research questions. In
this work, we investigate opportunities for using LLM-generated text
augmentation to improve the usefulness of topic modeling output. We use a
political science case study to evaluate our results in a domain-specific
application, and find that topic modeling using GPT-4 augmentations creates
highly interpretable categories that can be used to investigate domain-specific
research questions with minimal human guidance.

</details>

### [26] [Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation](https://arxiv.org/abs/2504.17480)
*Xin Yi,Shunfan Zhengc,Linlin Wanga,Xiaoling Wang,Liang He*

Main category: cs.CL

TLDR: 论文提出了一种名为CDG-KD的统一框架，用于在未经授权的知识蒸馏中进行双向攻击（擦除和伪造水印），并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究水印在未经授权的知识蒸馏中的鲁棒性和不可伪造性，填补现有水印攻击方法的不足。

Method: 采用对比解码和双向蒸馏技术，分别实现水印擦除和伪造。

Result: CDG-KD能有效执行攻击，同时保持蒸馏模型的通用性能。

Conclusion: 强调了开发鲁棒且不可伪造的水印方案的重要性。

Abstract: Watermarking has emerged as a critical technique for combating misinformation
and protecting intellectual property in large language models (LLMs). A recent
discovery, termed watermark radioactivity, reveals that watermarks embedded in
teacher models can be inherited by student models through knowledge
distillation. On the positive side, this inheritance allows for the detection
of unauthorized knowledge distillation by identifying watermark traces in
student models. However, the robustness of watermarks against scrubbing attacks
and their unforgeability in the face of spoofing attacks under unauthorized
knowledge distillation remain largely unexplored. Existing watermark attack
methods either assume access to model internals or fail to simultaneously
support both scrubbing and spoofing attacks. In this work, we propose
Contrastive Decoding-Guided Knowledge Distillation (CDG-KD), a unified
framework that enables bidirectional attacks under unauthorized knowledge
distillation. Our approach employs contrastive decoding to extract corrupted or
amplified watermark texts via comparing outputs from the student model and
weakly watermarked references, followed by bidirectional distillation to train
new student models capable of watermark removal and watermark forgery,
respectively. Extensive experiments show that CDG-KD effectively performs
attacks while preserving the general performance of the distilled model. Our
findings underscore critical need for developing watermarking schemes that are
robust and unforgeable.

</details>

### [27] [HalluLens: LLM Hallucination Benchmark](https://arxiv.org/abs/2504.17550)
*Yejin Bang,Ziwei Ji,Alan Schelten,Anthony Hartshorn,Tara Fowler,Cheng Zhang,Nicola Cancedda,Pascale Fung*

Main category: cs.CL

TLDR: 该论文提出了一个全面的幻觉基准，通过明确分类和动态测试集生成来解决LLM中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成内容与用户输入或训练数据不一致的问题（幻觉），以增强用户信任和推动生成式AI的发展。

Method: 引入新的外在幻觉任务和动态测试集生成，建立清晰的幻觉分类法，并分析现有基准的局限性。

Result: 提出了一个统一的幻觉基准框架，区分了外在和内在幻觉，避免了数据泄漏和基准饱和问题。

Conclusion: 该研究为LLM幻觉问题提供了清晰的分类和评估工具，推动了相关研究的进展。

Abstract: Large language models (LLMs) often generate responses that deviate from user
input or training data, a phenomenon known as "hallucination." These
hallucinations undermine user trust and hinder the adoption of generative AI
systems. Addressing hallucinations is essential for the advancement of LLMs.
This paper introduces a comprehensive hallucination benchmark, incorporating
both new extrinsic and existing intrinsic evaluation tasks, built upon clear
taxonomy of hallucination. A major challenge in benchmarking hallucinations is
the lack of a unified framework due to inconsistent definitions and
categorizations. We disentangle LLM hallucination from "factuality," proposing
a clear taxonomy that distinguishes between extrinsic and intrinsic
hallucinations, to promote consistency and facilitate research. Extrinsic
hallucinations, where the generated content is not consistent with the training
data, are increasingly important as LLMs evolve. Our benchmark includes dynamic
test set generation to mitigate data leakage and ensure robustness against such
leakage. We also analyze existing benchmarks, highlighting their limitations
and saturation. The work aims to: (1) establish a clear taxonomy of
hallucinations, (2) introduce new extrinsic hallucination tasks, with data that
can be dynamically regenerated to prevent saturation by leakage, (3) provide a
comprehensive analysis of existing benchmarks, distinguishing them from
factuality evaluations.

</details>

### [28] [When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars](https://arxiv.org/abs/2504.17562)
*Rei Higuchi,Ryotaro Kawata,Naoki Nishikawa,Kazusato Oko,Shoichiro Yamaguchi,Sosuke Kobayashi,Seiya Tokui,Kohei Hayashi,Daisuke Okanohara,Taiji Suzuki*

Main category: cs.CL

TLDR: 研究探讨了在预训练数据前添加元数据对语言模型性能的影响，发现其效果取决于下游任务提示是否能推断出潜在语义。


<details>
  <summary>Details</summary>
Motivation: 理解预训练时添加元数据对模型性能的影响机制，尤其是在不同下游任务中的不一致表现。

Method: 通过人工生成的数据（如概率上下文无关文法）分析模型行为，考察元数据在不同上下文长度下的效果。

Result: 元数据在上下文足够长时能提升性能，但在信息不足时反而有负面影响。

Conclusion: 元数据的有效性取决于下游任务提示是否能推断潜在语义，需根据任务特性调整使用。

Abstract: The ability to acquire latent semantics is one of the key properties that
determines the performance of language models. One convenient approach to
invoke this ability is to prepend metadata (e.g. URLs, domains, and styles) at
the beginning of texts in the pre-training data, making it easier for the model
to access latent semantics before observing the entire text. Previous studies
have reported that this technique actually improves the performance of trained
models in downstream tasks; however, this improvement has been observed only in
specific downstream tasks, without consistent enhancement in average next-token
prediction loss. To understand this phenomenon, we closely investigate how
prepending metadata during pre-training affects model performance by examining
its behavior using artificial data. Interestingly, we found that this approach
produces both positive and negative effects on the downstream tasks. We
demonstrate that the effectiveness of the approach depends on whether latent
semantics can be inferred from the downstream task's prompt. Specifically,
through investigations using data generated by probabilistic context-free
grammars, we show that training with metadata helps improve model's performance
when the given context is long enough to infer the latent semantics. In
contrast, the technique negatively impacts performance when the context lacks
the necessary information to make an accurate posterior inference.

</details>

### [29] [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org/abs/2504.17565)
*Xiaoyu Tian,Sitong Zhao,Haotian Wang,Shuaiting Chen,Yiping Peng,Yunjie Ji,Han Zhao,Xiangang Li*

Main category: cs.CL

TLDR: 论文构建了一个大规模、难度分级的推理数据集，通过精确选择高质量数据显著提升了基础模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 学术界对基础模型训练过程和数据质量缺乏深入理解，因此需要构建高质量数据集以提升推理能力。

Method: 构建包含340万独特查询和4000万蒸馏响应的大规模数据集，利用通过率和变异系数选择最有价值数据，并调整学习率进行训练。

Result: 基础模型的推理能力显著提升，在AIME2024数学推理基准测试中通过率达到79.2%，接近最先进水平。

Conclusion: 通过高质量数据选择和训练方法优化，显著提升了模型的推理能力，并公开数据集和方法以促进开源LLM的发展。

Abstract: Although large language models (LLMs) have recently achieved remarkable
performance on various complex reasoning benchmarks, the academic community
still lacks an in-depth understanding of base model training processes and data
quality. To address this, we construct a large-scale, difficulty-graded
reasoning dataset containing approximately 3.34 million unique queries of
varying difficulty levels and about 40 million distilled responses generated by
multiple models over several passes. Leveraging pass rate and Coefficient of
Variation (CV), we precisely select the most valuable training data to enhance
reasoning capability. Notably, we observe a training pattern shift, indicating
that reasoning-focused training based on base models requires higher learning
rates for effective training. Using this carefully selected data, we
significantly improve the reasoning capabilities of the base model, achieving a
pass rate of 79.2\% on the AIME2024 mathematical reasoning benchmark. This
result surpasses most current distilled models and closely approaches
state-of-the-art performance. We provide detailed descriptions of our data
processing, difficulty assessment, and training methodology, and have publicly
released all datasets and methods to promote rapid progress in open-source
long-reasoning LLMs. The dataset is available at:
https://huggingface.co/datasets/a-m-team/AM-DeepSeek-Distilled-40M

</details>

### [30] [RAGAT-Mind: A Multi-Granular Modeling Approach for Rumor Detection Based on MindSpore](https://arxiv.org/abs/2504.17574)
*Zhenkai Qin,Guifang Yang,Dongze Wu*

Main category: cs.CL

TLDR: RAGAT-Mind是一种基于MindSpore框架的多粒度中文谣言检测模型，结合了多种深度学习技术，在Weibo1-Rumor数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上虚假信息泛滥，谣言检测成为自然语言处理领域的紧迫挑战。

Method: 模型整合了TextCNN、双向GRU、多头自注意力和双向图卷积网络（BiGCN），用于提取局部语义、学习序列上下文、聚焦全局依赖和表示词共现图结构。

Result: 在Weibo1-Rumor数据集上，模型达到99.2%的准确率和0.9919的macro-F1分数。

Conclusion: RAGAT-Mind通过结合分层语言特征和图语义结构，表现出强大的泛化能力和可解释性，具有实际应用价值。

Abstract: As false information continues to proliferate across social media platforms,
effective rumor detection has emerged as a pressing challenge in natural
language processing. This paper proposes RAGAT-Mind, a multi-granular modeling
approach for Chinese rumor detection, built upon the MindSpore deep learning
framework. The model integrates TextCNN for local semantic extraction,
bidirectional GRU for sequential context learning, Multi-Head Self-Attention
for global dependency focusing, and Bidirectional Graph Convolutional Networks
(BiGCN) for structural representation of word co-occurrence graphs. Experiments
on the Weibo1-Rumor dataset demonstrate that RAGAT-Mind achieves superior
classification performance, attaining 99.2% accuracy and a macro-F1 score of
0.9919. The results validate the effectiveness of combining hierarchical
linguistic features with graph-based semantic structures. Furthermore, the
model exhibits strong generalization and interpretability, highlighting its
practical value for real-world rumor detection applications.

</details>

### [31] [Towards a comprehensive taxonomy of online abusive language informed by machine leaning](https://arxiv.org/abs/2504.17653)
*Samaneh Hosseini Moghaddam,Kelly Lyons,Cheryl Regehr,Vivek Goel,Kaitlyn Regehr*

Main category: cs.CL

TLDR: 本文提出了一种用于区分在线文本中辱骂语言关键特征的分类法，通过整合18个多标签数据集的分类系统，构建了一个包含5个类别和17个维度的层次化分类法。


<details>
  <summary>Details</summary>
Motivation: 在线辱骂语言的泛滥对个人和社区的健康与福祉构成重大风险，亟需识别和减轻有害内容的方法。

Method: 采用系统性方法开发分类法，整合了18个现有多标签数据集的分类系统。

Result: 构建了一个层次化和多方面的分类法，涵盖5个类别和17个维度，用于分类在线辱骂的多个方面。

Conclusion: 该分类法有助于统一理解，促进知识共享，并加速在线辱骂检测和缓解领域的研究与实践。

Abstract: The proliferation of abusive language in online communications has posed
significant risks to the health and wellbeing of individuals and communities.
The growing concern regarding online abuse and its consequences necessitates
methods for identifying and mitigating harmful content and facilitating
continuous monitoring, moderation, and early intervention. This paper presents
a taxonomy for distinguishing key characteristics of abusive language within
online text. Our approach uses a systematic method for taxonomy development,
integrating classification systems of 18 existing multi-label datasets to
capture key characteristics relevant to online abusive language classification.
The resulting taxonomy is hierarchical and faceted, comprising 5 categories and
17 dimensions. It classifies various facets of online abuse, including context,
target, intensity, directness, and theme of abuse. This shared understanding
can lead to more cohesive efforts, facilitate knowledge exchange, and
accelerate progress in the field of online abuse detection and mitigation among
researchers, policy makers, online platform owners, and other stakeholders.

</details>

### [32] [Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics](https://arxiv.org/abs/2504.17665)
*Zena Al-Khalili,Nick Howell,Dietrich Klakow*

Main category: cs.CL

TLDR: 论文通过深入分析代码辅助大语言模型（LLMs）在数学推理任务中生成的程序，揭示了其在数学规则应用上的差异，并强调了超越执行准确性的评估需求。


<details>
  <summary>Details</summary>
Motivation: 现有对代码辅助LLMs的评估主要关注执行正确性，缺乏对其生成程序的严格评估，本研究旨在填补这一空白。

Method: 对五种不同LLMs在两个数学数据集上的生成程序进行手动和自动评估，分析其数学规则应用情况。

Result: 研究发现，数学规则应用的分布取决于LLMs的能力和问题难度；闭源模型在数学规则应用上更有效，而开源模型表现较差。

Conclusion: 研究强调了需要超越执行准确性的深入评估，以更好地理解代码辅助LLMs在数学领域的能力和限制。

Abstract: Assisting LLMs with code generation improved their performance on
mathematical reasoning tasks. However, the evaluation of code-assisted LLMs is
generally restricted to execution correctness, lacking a rigorous evaluation of
their generated programs. In this work, we bridge this gap by conducting an
in-depth analysis of code-assisted LLMs' generated programs in response to math
reasoning tasks. Our evaluation focuses on the extent to which LLMs ground
their programs to math rules, and how that affects their end performance. For
this purpose, we assess the generations of five different LLMs, on two
different math datasets, both manually and automatically. Our results reveal
that the distribution of grounding depends on LLMs' capabilities and the
difficulty of math problems. Furthermore, mathematical grounding is more
effective for closed-source models, while open-source models fail to employ
math rules in their solutions correctly. On MATH500, the percentage of grounded
programs decreased to half, while the ungrounded generations doubled in
comparison to ASDiv grade-school problems. Our work highlights the need for
in-depth evaluation beyond execution accuracy metrics, toward a better
understanding of code-assisted LLMs' capabilities and limits in the math
domain.

</details>

### [33] [Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction](https://arxiv.org/abs/2504.17671)
*Yuanchang Ye,Weiyan Wen*

Main category: cs.CL

TLDR: 该研究提出了一种基于Split Conformal Prediction（SCP）的框架，用于减少大型视觉语言模型（LVLM）在视觉问答任务中的幻觉问题，通过动态阈值校准和跨模态一致性验证实现不确定性量化。


<details>
  <summary>Details</summary>
Motivation: LVLM在多模态推理中表现出色，但其输出常带有高置信度的幻觉内容，这在安全关键应用中存在风险。研究旨在解决这一问题。

Method: 采用SCP框架，通过数据分区（校准集和测试集）计算非一致性分数，构建具有统计保证的预测集，并动态调整预测集大小。

Result: 在多个基准测试（如ScienceQA、MMMU）和八种LVLM上验证，SCP在所有α值下均满足理论保证，且在不同校准-测试分割比例下表现稳定。

Conclusion: 该框架为多模态AI系统提供了可扩展的幻觉检测和不确定性感知决策方案，填补了理论可靠性与实际应用之间的差距。

Abstract: This study addresses the critical challenge of hallucination mitigation in
Large Vision-Language Models (LVLMs) for Visual Question Answering (VQA) tasks
through a Split Conformal Prediction (SCP) framework. While LVLMs excel in
multi-modal reasoning, their outputs often exhibit hallucinated content with
high confidence, posing risks in safety-critical applications. We propose a
model-agnostic uncertainty quantification method that integrates dynamic
threshold calibration and cross-modal consistency verification. By partitioning
data into calibration and test sets, the framework computes nonconformity
scores to construct prediction sets with statistical guarantees under
user-defined risk levels ($\alpha$). Key innovations include: (1) rigorous
control of \textbf{marginal coverage} to ensure empirical error rates remain
strictly below $\alpha$; (2) dynamic adjustment of prediction set sizes
inversely with $\alpha$, filtering low-confidence outputs; (3) elimination of
prior distribution assumptions and retraining requirements. Evaluations on
benchmarks (ScienceQA, MMMU) with eight LVLMs demonstrate that SCP enforces
theoretical guarantees across all $\alpha$ values. The framework achieves
stable performance across varying calibration-to-test split ratios,
underscoring its robustness for real-world deployment in healthcare, autonomous
systems, and other safety-sensitive domains. This work bridges the gap between
theoretical reliability and practical applicability in multi-modal AI systems,
offering a scalable solution for hallucination detection and uncertainty-aware
decision-making.

</details>

### [34] [Energy Considerations of Large Language Model Inference and Efficiency Optimizations](https://arxiv.org/abs/2504.17674)
*Jared Fernandez,Clara Na,Vashisth Tiwari,Yonatan Bisk,Sasha Luccioni,Emma Strubell*

Main category: cs.CL

TLDR: 本文分析了大型语言模型（LLM）推理优化的能源影响，提出了一种建模方法，发现优化策略可减少高达73%的能源消耗。


<details>
  <summary>Details</summary>
Motivation: 随着LLM规模和使用的增加，其计算和环境成本上升，但现有研究多关注理想化场景的延迟优化，忽略了实际工作负载的能源影响。

Method: 通过输入-输出令牌分布和批量大小的分箱策略建模真实LLM工作负载，分析软件框架、解码策略、GPU架构等多种因素。

Result: 推理优化的效果对工作负载几何、软件栈和硬件高度敏感，基于FLOPs或理论GPU利用率的能源估计显著低估实际消耗。

Conclusion: 合理应用推理优化可显著降低能源消耗，为可持续LLM部署和未来AI基础设施设计提供依据。

Abstract: As large language models (LLMs) scale in size and adoption, their
computational and environmental costs continue to rise. Prior benchmarking
efforts have primarily focused on latency reduction in idealized settings,
often overlooking the diverse real-world inference workloads that shape energy
use. In this work, we systematically analyze the energy implications of common
inference efficiency optimizations across diverse Natural Language Processing
(NLP) and generative Artificial Intelligence (AI) workloads, including
conversational AI and code generation. We introduce a modeling approach that
approximates real-world LLM workflows through a binning strategy for
input-output token distributions and batch size variations. Our empirical
analysis spans software frameworks, decoding strategies, GPU architectures,
online and offline serving settings, and model parallelism configurations. We
show that the effectiveness of inference optimizations is highly sensitive to
workload geometry, software stack, and hardware accelerators, demonstrating
that naive energy estimates based on FLOPs or theoretical GPU utilization
significantly underestimate real-world energy consumption. Our findings reveal
that the proper application of relevant inference efficiency optimizations can
reduce total energy use by up to 73% from unoptimized baselines. These insights
provide a foundation for sustainable LLM deployment and inform energy-efficient
design strategies for future AI infrastructure.

</details>

### [35] [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org/abs/2504.17685)
*Haru-Tada Sato,Fuka Matsuzaki,Jun-ichiro Takahashi*

Main category: cs.CL

TLDR: 小语言模型（SLM）集成通过贝叶斯推理（EBI）达到与大型语言模型（LLM）相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用有限计算资源构建高性能AI系统，并有效利用性能较低的小模型。

Method: 提出Ensemble Bayesian Inference（EBI），通过贝叶斯估计结合多个SLM的预测。

Result: 在多种任务（如能力评估和消费者分析）中，EBI表现优异，甚至整合负提升模型也能提升整体性能。

Conclusion: EBI为资源有限的高性能AI系统提供了新思路，并展示了低性能模型的潜在价值。

Abstract: This study explores the potential of small language model(SLM) ensembles to
achieve accuracy comparable to proprietary large language models (LLMs). We
propose Ensemble Bayesian Inference (EBI), a novel approach that applies
Bayesian estimation to combine judgments from multiple SLMs, allowing them to
exceed the performance limitations of individual models. Our experiments on
diverse tasks(aptitude assessments and consumer profile analysis in both
Japanese and English) demonstrate EBI's effectiveness. Notably, we analyze
cases where incorporating models with negative Lift values into ensembles
improves overall performance, and we examine the method's efficacy across
different languages. These findings suggest new possibilities for constructing
high-performance AI systems with limited computational resources and for
effectively utilizing models with individually lower performance. Building on
existing research on LLM performance evaluation, ensemble methods, and
open-source LLM utilization, we discuss the novelty and significance of our
approach.

</details>

### [36] [Safety in Large Reasoning Models: A Survey](https://arxiv.org/abs/2504.17704)
*Cheng Wang,Yue Liu,Baolong Li,Duzhen Zhang,Zhongzhi Li,Junfeng Fang*

Main category: cs.CL

TLDR: 本文对大型推理模型（LRMs）的安全性进行了全面调查，总结了新兴的安全风险、攻击方式和防御策略，并提出了分类体系。


<details>
  <summary>Details</summary>
Motivation: 随着LRMs在数学和编程等任务中表现出强大的推理能力，其安全漏洞和风险成为实际应用中的重大挑战。

Method: 通过系统梳理和分类新兴的安全风险、攻击方式和防御策略，构建了一个详细的安全性分类体系。

Result: 研究提供了一个清晰的结构化框架，帮助理解LRMs当前的安全状况。

Conclusion: 该工作为未来提升LRMs安全性和可靠性的研究与发展提供了基础。

Abstract: Large Reasoning Models (LRMs) have exhibited extraordinary prowess in tasks
like mathematics and coding, leveraging their advanced reasoning capabilities.
Nevertheless, as these capabilities progress, significant concerns regarding
their vulnerabilities and safety have arisen, which can pose challenges to
their deployment and application in real-world settings. This paper presents a
comprehensive survey of LRMs, meticulously exploring and summarizing the newly
emerged safety risks, attacks, and defense strategies. By organizing these
elements into a detailed taxonomy, this work aims to offer a clear and
structured understanding of the current safety landscape of LRMs, facilitating
future research and development to enhance the security and reliability of
these powerful models.

</details>

### [37] [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org/abs/2504.17720)
*Vansh Gupta,Sankalan Pal Chowdhury,Vilém Zouhar,Donya Rooein,Mrinmaya Sachan*

Main category: cs.CL

TLDR: 论文研究了大型语言模型（LLMs）在非英语教育任务中的表现，发现其性能与训练数据中的语言资源量相关，建议部署前验证模型在目标语言中的表现。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在非英语教育任务中的适用性，以确定其在多语言教育环境中的有效性。

Method: 在六种非英语语言（印地语、阿拉伯语、波斯语、泰卢固语、乌克兰语、捷克语）和英语中，评估LLMs在四种教育任务（识别学生误解、提供针对性反馈、互动辅导、翻译评分）中的表现。

Result: 模型性能与训练数据中的语言资源量相关，低资源语言表现较差，且与英语相比性能下降显著。

Conclusion: 建议在部署前验证LLMs在目标语言中的表现，以确保其在教育任务中的有效性。

Abstract: Large language models (LLMs) are increasingly being adopted in educational
settings. These applications expand beyond English, though current LLMs remain
primarily English-centric. In this work, we ascertain if their use in education
settings in non-English languages is warranted. We evaluated the performance of
popular LLMs on four educational tasks: identifying student misconceptions,
providing targeted feedback, interactive tutoring, and grading translations in
six languages (Hindi, Arabic, Farsi, Telugu, Ukrainian, Czech) in addition to
English. We find that the performance on these tasks somewhat corresponds to
the amount of language represented in training data, with lower-resource
languages having poorer task performance. Although the models perform
reasonably well in most languages, the frequent performance drop from English
is significant. Thus, we recommend that practitioners first verify that the LLM
works well in the target language for their educational task before deployment.

</details>

### [38] [Conversational Assistants to support Heart Failure Patients: comparing a Neurosymbolic Architecture with ChatGPT](https://arxiv.org/abs/2504.17753)
*Anuja Tayal,Devika Salunke,Barbara Di Eugenio,Paula Allen-Meares,Eulalia Puig Abril,Olga Garcia,Carolyn Dickens,Andrew Boyd*

Main category: cs.CL

TLDR: 比较两种对话助手（神经符号架构与ChatGPT）在心脏衰竭患者中的应用效果，结果显示各有优劣，但患者无偏好。


<details>
  <summary>Details</summary>
Motivation: 评估传统架构与生成式AI在医疗对话助手中的应用效果，为实际部署提供依据。

Method: 采用组内用户研究，比较神经符号架构和ChatGPT版本的对话助手在盐分查询任务中的表现。

Result: 神经符号架构更准确、任务完成率更高且简洁，ChatGPT版本语言错误少、需澄清次数少。

Conclusion: 两种架构各有优势，患者无偏好，需根据具体需求选择。

Abstract: Conversational assistants are becoming more and more popular, including in
healthcare, partly because of the availability and capabilities of Large
Language Models. There is a need for controlled, probing evaluations with real
stakeholders which can highlight advantages and disadvantages of more
traditional architectures and those based on generative AI. We present a
within-group user study to compare two versions of a conversational assistant
that allows heart failure patients to ask about salt content in food. One
version of the system was developed in-house with a neurosymbolic architecture,
and one is based on ChatGPT. The evaluation shows that the in-house system is
more accurate, completes more tasks and is less verbose than the one based on
ChatGPT; on the other hand, the one based on ChatGPT makes fewer speech errors
and requires fewer clarifications to complete the task. Patients show no
preference for one over the other.

</details>

### [39] [The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs](https://arxiv.org/abs/2504.17768)
*Piotr Nawrot,Robert Li,Renjie Huang,Sebastian Ruder,Kelly Marchisio,Edoardo M. Ponti*

Main category: cs.CL

TLDR: 稀疏注意力是提升Transformer长序列处理能力的关键工具，但需权衡效率与准确性。研究发现，不同任务和阶段需要不同的稀疏策略，且稀疏注意力并非万能解决方案。


<details>
  <summary>Details</summary>
Motivation: 填补稀疏注意力在长上下文Transformer LLMs中的可行性、效率-准确性权衡及系统性扩展研究的空白。

Method: 通过在不同模型规模、序列长度和稀疏度下比较训练无关的稀疏注意力方法，并在多样化长序列任务上进行实验。

Result: 1) 极长序列下，大而稀疏的模型优于小而密集的模型；2) 解码阶段可达到的稀疏度高于预填充阶段；3) 不同任务需不同稀疏策略；4) 提出了稀疏注意力的新缩放规律。

Conclusion: 稀疏注意力是增强Transformer长序列处理能力的有效工具，但需根据具体应用场景谨慎评估其性能影响。

Abstract: Sparse attention offers a promising strategy to extend long-context
capabilities in Transformer LLMs, yet its viability, its efficiency-accuracy
trade-offs, and systematic scaling studies remain unexplored. To address this
gap, we perform a careful comparison of training-free sparse attention methods
at varying model scales, sequence lengths, and sparsity levels on a diverse
collection of long-sequence tasks-including novel ones that rely on natural
language while remaining controllable and easy to evaluate. Based on our
experiments, we report a series of key findings: 1) an isoFLOPS analysis
reveals that for very long sequences, larger and highly sparse models are
preferable to smaller and dense ones. 2) The level of sparsity attainable while
statistically guaranteeing accuracy preservation is higher during decoding than
prefilling, and correlates with model size in the former. 3) There is no clear
strategy that performs best across tasks and phases, with different units of
sparsification or budget adaptivity needed for different scenarios. Even
moderate sparsity levels often result in significant performance degradation on
at least one task, highlighting that sparse attention is not a universal
solution. 4) We introduce and validate novel scaling laws specifically tailored
for sparse attention, providing evidence that our findings are likely to hold
true beyond our range of experiments. Through these insights, we demonstrate
that sparse attention is a key tool to enhance the capabilities of Transformer
LLMs for processing longer sequences, but requires careful evaluation of
trade-offs for performance-sensitive applications.

</details>

<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [40] [Dense Air Pollution Estimation from Sparse in-situ Measurements and Satellite Data](https://arxiv.org/abs/2504.17039)
*Ruben Gonzalez Avilés,Linus Scheibenreif,Damian Borth*

Main category: cs.CV

TLDR: 本文提出了一种新颖的密集估计技术，用于高效估算全球范围内的氮氧化物（NO₂）浓度，解决了现有方法的计算资源密集问题，并显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 现有卫星空气质量估算方法在计算资源密集和大范围估算方面存在局限性，因此需要一种更高效、准确的解决方案。

Method: 采用均匀随机偏移采样策略，将地面真实数据均匀分散到更大的区域，并通过密集估计方法一次性生成网格估算值。

Result: 新方法的平均绝对误差（MAE）为4.98 µg/m³，比现有点状方法提高了9.45%，兼具高精度和计算效率。

Conclusion: 该方法为大规模环境监测提供了可行的解决方案，展示了其适应性和鲁棒性。

Abstract: This paper addresses the critical environmental challenge of estimating
ambient Nitrogen Dioxide (NO$_2$) concentrations, a key issue in public health
and environmental policy. Existing methods for satellite-based air pollution
estimation model the relationship between satellite and in-situ measurements at
select point locations. While these approaches have advanced our ability to
provide air quality estimations on a global scale, they come with inherent
limitations. The most notable limitation is the computational intensity
required for generating comprehensive estimates over extensive areas. Motivated
by these limitations, this study introduces a novel dense estimation technique.
Our approach seeks to balance the accuracy of high-resolution estimates with
the practicality of computational constraints, thereby enabling efficient and
scalable global environmental assessment. By utilizing a uniformly random
offset sampling strategy, our method disperses the ground truth data pixel
location evenly across a larger patch. At inference, the dense estimation
method can then generate a grid of estimates in a single step, significantly
reducing the computational resources required to provide estimates for larger
areas. Notably, our approach also surpasses the results of existing point-wise
methods by a significant margin of $9.45\%$, achieving a Mean Absolute Error
(MAE) of $4.98\ \mu\text{g}/\text{m}^3$. This demonstrates both high accuracy
and computational efficiency, highlighting the applicability of our method for
global environmental assessment. Furthermore, we showcase the method's
adaptability and robustness by applying it to diverse geographic regions. Our
method offers a viable solution to the computational challenges of large-scale
environmental monitoring.

</details>

### [41] [DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs](https://arxiv.org/abs/2504.17040)
*Zhenhailong Wang,Senthil Purushwalkam,Caiming Xiong,Silvio Savarese,Heng Ji,Ran Xu*

Main category: cs.CV

TLDR: DyMU是一个无需训练的高效框架，动态减少视觉语言模型的计算负担，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 解决视觉变换器中固定长度输出的低效问题，动态适应图像内容以减少计算成本。

Method: 结合动态令牌合并（DToMe）和虚拟令牌解合并（VTU），动态压缩令牌并模拟完整序列的注意力动态。

Result: 实验显示，DyMU能减少32%-85%的视觉令牌数量，性能与完整模型相当。

Conclusion: DyMU提供了一种无需训练的动态令牌压缩方法，适用于多种VLM架构，并允许用户控制计算成本。

Abstract: We present DyMU, an efficient, training-free framework that dynamically
reduces the computational burden of vision-language models (VLMs) while
maintaining high task performance. Our approach comprises two key components.
First, Dynamic Token Merging (DToMe) reduces the number of visual token
embeddings by merging similar tokens based on image complexity, addressing the
inherent inefficiency of fixed-length outputs in vision transformers. Second,
Virtual Token Unmerging (VTU) simulates the expected token sequence for large
language models (LLMs) by efficiently reconstructing the attention dynamics of
a full sequence, thus preserving the downstream performance without additional
fine-tuning. Unlike previous approaches, our method dynamically adapts token
compression to the content of the image and operates completely training-free,
making it readily applicable to most state-of-the-art VLM architectures.
Extensive experiments on image and video understanding tasks demonstrate that
DyMU can reduce the average visual token count by 32%-85% while achieving
comparable performance to full-length models across diverse VLM architectures,
including the recently popularized AnyRes-based visual encoders. Furthermore,
through qualitative analyses, we demonstrate that DToMe effectively adapts
token reduction based on image complexity and, unlike existing systems,
provides users more control over computational costs. Project page:
https://mikewangwzhl.github.io/dymu/.

</details>

### [42] [PPS-Ctrl: Controllable Sim-to-Real Translation for Colonoscopy Depth Estimation](https://arxiv.org/abs/2504.17067)
*Xinqi Xiong,Andrea Dunn Beltran,Jun Myeong Choi,Marc Niethammer,Roni Sengupta*

Main category: cs.CV

TLDR: 提出了一种结合Stable Diffusion和ControlNet的图像翻译框架，利用Per-Pixel Shading（PPS）图生成更真实的纹理，提升内窥镜深度估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 临床环境中获取真实深度数据困难，合成数据与真实数据存在域差距，限制了深度估计的泛化能力。

Method: 整合Stable Diffusion与ControlNet，以PPS图的潜在表示为条件，保留结构并生成逼真纹理。

Result: 实验表明，该方法生成的图像更真实，深度估计效果优于基于GAN的MI-CycleGAN。

Conclusion: 提出的框架通过PPS图提供更强的结构约束，显著提升了深度估计的准确性和泛化能力。

Abstract: Accurate depth estimation enhances endoscopy navigation and diagnostics, but
obtaining ground-truth depth in clinical settings is challenging. Synthetic
datasets are often used for training, yet the domain gap limits generalization
to real data. We propose a novel image-to-image translation framework that
preserves structure while generating realistic textures from clinical data. Our
key innovation integrates Stable Diffusion with ControlNet, conditioned on a
latent representation extracted from a Per-Pixel Shading (PPS) map. PPS
captures surface lighting effects, providing a stronger structural constraint
than depth maps. Experiments show our approach produces more realistic
translations and improves depth estimation over GAN-based MI-CycleGAN. Our code
is publicly accessible at https://github.com/anaxqx/PPS-Ctrl.

</details>

### [43] [Distilling semantically aware orders for autoregressive image generation](https://arxiv.org/abs/2504.17069)
*Rishav Pramanik,Antoine Poupon,Juan A. Rodriguez,Masih Aminbeidokhti,David Vazquez,Christopher Pal,Zhaozheng Yin,Marco Pedersoli*

Main category: cs.CV

TLDR: 论文提出了一种改进的自回归图像生成方法，通过训练模型以任意顺序生成图像块，并利用推断的顺序优化生成质量，优于传统的栅格扫描顺序。


<details>
  <summary>Details</summary>
Motivation: 传统的栅格扫描顺序（从左到右、从上到下）在图像生成中可能不尊重内容的因果关系，例如生成云和太阳的顺序可能不合理。

Method: 首先训练模型以任意顺序生成图像块，推断内容和生成顺序；然后利用这些顺序微调模型以提升生成质量。

Result: 在两个数据集上的实验表明，新方法生成的图像质量优于传统栅格扫描顺序，且训练成本和额外标注需求相同。

Conclusion: 通过优化生成顺序，自回归图像生成模型可以更合理地尊重图像内容的因果关系，从而提升生成质量。

Abstract: Autoregressive patch-based image generation has recently shown competitive
results in terms of image quality and scalability. It can also be easily
integrated and scaled within Vision-Language models. Nevertheless,
autoregressive models require a defined order for patch generation. While a
natural order based on the dictation of the words makes sense for text
generation, there is no inherent generation order that exists for image
generation. Traditionally, a raster-scan order (from top-left to bottom-right)
guides autoregressive image generation models. In this paper, we argue that
this order is suboptimal, as it fails to respect the causality of the image
content: for instance, when conditioned on a visual description of a sunset, an
autoregressive model may generate clouds before the sun, even though the color
of clouds should depend on the color of the sun and not the inverse. In this
work, we show that first by training a model to generate patches in
any-given-order, we can infer both the content and the location (order) of each
patch during generation. Secondly, we use these extracted orders to finetune
the any-given-order model to produce better-quality images. Through our
experiments, we show on two datasets that this new generation method produces
better images than the traditional raster-scan approach, with similar training
costs and no extra annotations.

</details>

### [44] [Scene-Aware Location Modeling for Data Augmentation in Automotive Object Detection](https://arxiv.org/abs/2504.17076)
*Jens Petersen,Davide Abati,Amirhossein Habibian,Auke Wiggers*

Main category: cs.CV

TLDR: 论文提出了一种场景感知的概率位置模型，用于预测新物体在现有场景中的合理位置，并通过生成模型在这些位置填充物体，显著提升了数据增强的性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成图像模型在汽车目标检测任务中的数据增强方法忽视了物体在场景中的合理布局，导致增强效果有限。

Method: 引入场景感知的概率位置模型，预测新物体的合理位置，并结合生成模型在这些位置填充物体。

Result: 在两项汽车目标检测任务中，实现了比现有方法高达2.8倍的性能提升（mAP提升+1.4 vs. +0.5），并在实例分割任务中表现出显著改进。

Conclusion: 通过关注场景布局的合理性，提出的方法显著提升了生成数据增强的效果，为相关任务设定了新的性能标准。

Abstract: Generative image models are increasingly being used for training data
augmentation in vision tasks. In the context of automotive object detection,
methods usually focus on producing augmented frames that look as realistic as
possible, for example by replacing real objects with generated ones. Others try
to maximize the diversity of augmented frames, for example by pasting lots of
generated objects onto existing backgrounds. Both perspectives pay little
attention to the locations of objects in the scene. Frame layouts are either
reused with little or no modification, or they are random and disregard realism
entirely. In this work, we argue that optimal data augmentation should also
include realistic augmentation of layouts. We introduce a scene-aware
probabilistic location model that predicts where new objects can realistically
be placed in an existing scene. By then inpainting objects in these locations
with a generative model, we obtain much stronger augmentation performance than
existing approaches. We set a new state of the art for generative data
augmentation on two automotive object detection tasks, achieving up to
$2.8\times$ higher gains than the best competing approach ($+1.4$ vs. $+0.5$
mAP boost). We also demonstrate significant improvements for instance
segmentation.

</details>

### [45] [Transferring Spatial Filters via Tangent Space Alignment in Motor Imagery BCIs](https://arxiv.org/abs/2504.17111)
*Tekin Gunasar,Virginia de Sa*

Main category: cs.CV

TLDR: 提出了一种通过黎曼流形对齐协方差矩阵并结合CSP空间滤波器改进运动想象BCI中主题迁移的方法，在多数据集上表现优于标准CSP，尤其在训练数据有限时效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决运动想象BCI中主题迁移性能不足的问题，尤其是在训练数据有限的情况下。

Method: 在黎曼流形上对齐协方差矩阵，随后计算新的基于CSP的空间滤波器，并探索了多主题信息整合方式。

Result: 在三个数据集上，该方法相比标准CSP有边际改进；但在训练数据有限时，改进更为显著。

Conclusion: 该方法在提升主题迁移性能方面有效，尤其在数据有限时表现突出。

Abstract: We propose a method to improve subject transfer in motor imagery BCIs by
aligning covariance matrices on a Riemannian manifold, followed by computing a
new common spatial patterns (CSP) based spatial filter. We explore various ways
to integrate information from multiple subjects and show improved performance
compared to standard CSP. Across three datasets, our method shows marginal
improvements over standard CSP; however, when training data are limited, the
improvements become more significant.

</details>

### [46] [Latent Video Dataset Distillation](https://arxiv.org/abs/2504.17132)
*Ning Li,Antai Andy Liu,Jingran Zhang,Justin Cui*

Main category: cs.CV

TLDR: 本文提出了一种新颖的视频数据集蒸馏方法，通过在潜在空间操作并结合多样性感知数据选择策略，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频数据集蒸馏方法主要关注像素空间压缩，忽略了潜在空间的进展，本文旨在填补这一空白。

Method: 使用最先进的变分编码器在潜在空间操作，结合多样性感知数据选择策略，并引入无需训练的压缩方法。

Result: 在所有数据集上表现优于现有方法，例如在HMDB51 IPC 1上性能提升2.6%，在MiniUCF IPC 5上提升7.8%。

Conclusion: 该方法在视频数据集蒸馏领域实现了新的最先进性能。

Abstract: Dataset distillation has demonstrated remarkable effectiveness in
high-compression scenarios for image datasets. While video datasets inherently
contain greater redundancy, existing video dataset distillation methods
primarily focus on compression in the pixel space, overlooking advances in the
latent space that have been widely adopted in modern text-to-image and
text-to-video models. In this work, we bridge this gap by introducing a novel
video dataset distillation approach that operates in the latent space using a
state-of-the-art variational encoder. Furthermore, we employ a diversity-aware
data selection strategy to select both representative and diverse samples.
Additionally, we introduce a simple, training-free method to further compress
the distilled latent dataset. By combining these techniques, our approach
achieves a new state-of-the-art performance in dataset distillation,
outperforming prior methods on all datasets, e.g. on HMDB51 IPC 1, we achieve a
2.6% performance increase; on MiniUCF IPC 5, we achieve a 7.8% performance
increase.

</details>

### [47] [A Comprehensive Review on RNA Subcellular Localization Prediction](https://arxiv.org/abs/2504.17162)
*Cece Zhang,Xuehuan Zhu,Nick Peterson,Jieqiong Wang,Shibiao Wan*

Main category: cs.CV

TLDR: 该论文综述了基于人工智能和机器学习的RNA亚细胞定位预测方法的最新进展，讨论了其潜力与挑战。


<details>
  <summary>Details</summary>
Motivation: 传统湿实验室方法耗时耗力，计算方法的出现为RNA亚细胞定位研究提供了高效替代方案。

Method: 论文回顾了序列、图像及混合方法，分析了AI/ML在RNA定位预测中的应用。

Result: AI/ML方法能加速RNA研究，揭示分子通路，指导疾病治疗，但仍面临数据稀缺和基准缺失等挑战。

Conclusion: 该综述为RNA亚细胞定位领域的研究者提供了宝贵资源，并指出了未来发展的机遇。

Abstract: The subcellular localization of RNAs, including long non-coding RNAs
(lncRNAs), messenger RNAs (mRNAs), microRNAs (miRNAs) and other smaller RNAs,
plays a critical role in determining their biological functions. For instance,
lncRNAs are predominantly associated with chromatin and act as regulators of
gene transcription and chromatin structure, while mRNAs are distributed across
the nucleus and cytoplasm, facilitating the transport of genetic information
for protein synthesis. Understanding RNA localization sheds light on processes
like gene expression regulation with spatial and temporal precision. However,
traditional wet lab methods for determining RNA localization, such as in situ
hybridization, are often time-consuming, resource-demanding, and costly. To
overcome these challenges, computational methods leveraging artificial
intelligence (AI) and machine learning (ML) have emerged as powerful
alternatives, enabling large-scale prediction of RNA subcellular localization.
This paper provides a comprehensive review of the latest advancements in
AI-based approaches for RNA subcellular localization prediction, covering
various RNA types and focusing on sequence-based, image-based, and hybrid
methodologies that combine both data types. We highlight the potential of these
methods to accelerate RNA research, uncover molecular pathways, and guide
targeted disease treatments. Furthermore, we critically discuss the challenges
in AI/ML approaches for RNA subcellular localization, such as data scarcity and
lack of benchmarks, and opportunities to address them. This review aims to
serve as a valuable resource for researchers seeking to develop innovative
solutions in the field of RNA subcellular localization and beyond.

</details>

### [48] [PhysioSync: Temporal and Cross-Modal Contrastive Learning Inspired by Physiological Synchronization for EEG-Based Emotion Recognition](https://arxiv.org/abs/2504.17163)
*Kai Cui,Jia Li,Yu Liu,Xuesong Zhang,Zhenzhen Hu,Meng Wang*

Main category: cs.CV

TLDR: PhysioSync是一种新型预训练框架，利用时间和跨模态对比学习解决EEG信号噪声和跨模态动态同步问题，提升情绪识别性能。


<details>
  <summary>Details</summary>
Motivation: EEG信号虽能反映情绪状态，但易受噪声和个体差异影响，且现有多模态方法忽视动态同步和语义一致性。

Method: 提出PhysioSync框架，结合跨模态一致性对齐（CM-CA）和长短时对比学习（LS-TCL），预训练后分层融合特征进行微调。

Result: 在DEAP和DREAMER数据集上，PhysioSync在单模态和跨模态条件下表现优异。

Conclusion: PhysioSync通过跨模态和时间动态建模，显著提升了EEG为中心的情绪识别效果。

Abstract: Electroencephalography (EEG) signals provide a promising and involuntary
reflection of brain activity related to emotional states, offering significant
advantages over behavioral cues like facial expressions. However, EEG signals
are often noisy, affected by artifacts, and vary across individuals,
complicating emotion recognition. While multimodal approaches have used
Peripheral Physiological Signals (PPS) like GSR to complement EEG, they often
overlook the dynamic synchronization and consistent semantics between the
modalities. Additionally, the temporal dynamics of emotional fluctuations
across different time resolutions in PPS remain underexplored. To address these
challenges, we propose PhysioSync, a novel pre-training framework leveraging
temporal and cross-modal contrastive learning, inspired by physiological
synchronization phenomena. PhysioSync incorporates Cross-Modal Consistency
Alignment (CM-CA) to model dynamic relationships between EEG and complementary
PPS, enabling emotion-related synchronizations across modalities. Besides, it
introduces Long- and Short-Term Temporal Contrastive Learning (LS-TCL) to
capture emotional synchronization at different temporal resolutions within
modalities. After pre-training, cross-resolution and cross-modal features are
hierarchically fused and fine-tuned to enhance emotion recognition. Experiments
on DEAP and DREAMER datasets demonstrate PhysioSync's advanced performance
under uni-modal and cross-modal conditions, highlighting its effectiveness for
EEG-centered emotion recognition.

</details>

### [49] [A Genealogy of Multi-Sensor Foundation Models in Remote Sensing](https://arxiv.org/abs/2504.17177)
*Kevin Lane,Morteza Karimzadeh*

Main category: cs.CV

TLDR: 本文探讨了遥感领域中基础模型的开发与应用，分析了不同方法的优缺点，并提出了未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 研究遥感领域中基础模型的发展现状，以改进其性能并减少计算资源需求。

Method: 通过分析计算机视觉领域的现有方法，探讨其在遥感领域的适用性，并讨论多传感器数据的利用。

Result: 总结了现有方法的优缺点，并提出了未来改进的方向，包括利用未标记和多传感器数据。

Conclusion: 遥感领域的基础模型仍有改进空间，未来应更注重多传感器数据的利用和计算效率的提升。

Abstract: Foundation models have garnered increasing attention for representation
learning in remote sensing, primarily adopting approaches that have
demonstrated success in computer vision with minimal domain-specific
modification. However, the development and application of foundation models in
this field are still burgeoning, as there are a variety of competing approaches
that each come with significant benefits and drawbacks. This paper examines
these approaches along with their roots in the computer vision field in order
to characterize potential advantages and pitfalls while outlining future
directions to further improve remote sensing-specific foundation models. We
discuss the quality of the learned representations and methods to alleviate the
need for massive compute resources. We place emphasis on the multi-sensor
aspect of Earth observations, and the extent to which existing approaches
leverage multiple sensors in training foundation models in relation to
multi-modal foundation models. Finally, we identify opportunities for further
harnessing the vast amounts of unlabeled, seasonal, and multi-sensor remote
sensing observations.

</details>

### [50] [We'll Fix it in Post: Improving Text-to-Video Generation with Neuro-Symbolic Feedback](https://arxiv.org/abs/2504.17180)
*Minkyu Choi,S P Sharan,Harsh Goel,Sahil Shah,Sandeep Chinchali*

Main category: cs.CV

TLDR: 论文提出了一种零训练的视频优化方法，通过神经符号反馈提升文本到视频生成模型的语义和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成模型在处理复杂提示时存在语义和时间一致性问题，且直接改进成本高昂。

Method: 提出了一种零训练的视频优化流程，利用神经符号反馈分析视频表示并指导针对性编辑。

Result: 实验表明，该方法显著提升了视频与提示的对齐效果，改进幅度达40%。

Conclusion: 该方法有效解决了复杂提示下的视频生成问题，无需额外训练成本。

Abstract: Current text-to-video (T2V) generation models are increasingly popular due to
their ability to produce coherent videos from textual prompts. However, these
models often struggle to generate semantically and temporally consistent videos
when dealing with longer, more complex prompts involving multiple objects or
sequential events. Additionally, the high computational costs associated with
training or fine-tuning make direct improvements impractical. To overcome these
limitations, we introduce \(\projectname\), a novel zero-training video
refinement pipeline that leverages neuro-symbolic feedback to automatically
enhance video generation, achieving superior alignment with the prompts. Our
approach first derives the neuro-symbolic feedback by analyzing a formal video
representation and pinpoints semantically inconsistent events, objects, and
their corresponding frames. This feedback then guides targeted edits to the
original video. Extensive empirical evaluations on both open-source and
proprietary T2V models demonstrate that \(\projectname\) significantly enhances
temporal and logical alignment across diverse prompts by almost $40\%$.

</details>

### [51] [Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation](https://arxiv.org/abs/2504.17207)
*Phillip Y. Lee,Jihyeon Je,Chanho Park,Mikaela Angelina Uy,Leonidas Guibas,Minhyuk Sung*

Main category: cs.CV

TLDR: 提出了一种基于心理意象模拟的视觉语言模型（VLM）视角感知推理框架，通过抽象视角变换（APC）提升模型的多视角理解能力。


<details>
  <summary>Details</summary>
Motivation: 视角感知是人类视觉理解的关键能力，但现有VLM存在以自我为中心的偏见，缺乏多视角推理能力。

Method: 利用视觉基础模型（如目标检测、分割和方向估计）构建场景抽象，实现视角变换。

Result: 在合成和真实图像基准测试中，APC框架显著优于现有VLM和空间推理模型。

Conclusion: APC框架有效提升了VLM的视角感知推理能力，接近人类水平。

Abstract: We present a framework for perspective-aware reasoning in vision-language
models (VLMs) through mental imagery simulation. Perspective-taking, the
ability to perceive an environment or situation from an alternative viewpoint,
is a key benchmark for human-level visual understanding, essential for
environmental interaction and collaboration with autonomous agents. Despite
advancements in spatial reasoning within VLMs, recent research has shown that
modern VLMs significantly lack perspective-aware reasoning capabilities and
exhibit a strong bias toward egocentric interpretations. To bridge the gap
between VLMs and human perception, we focus on the role of mental imagery,
where humans perceive the world through abstracted representations that
facilitate perspective shifts. Motivated by this, we propose a framework for
perspective-aware reasoning, named Abstract Perspective Change (APC), that
effectively leverages vision foundation models, such as object detection,
segmentation, and orientation estimation, to construct scene abstractions and
enable perspective transformations. Our experiments on synthetic and real-image
benchmarks, compared with various VLMs, demonstrate significant improvements in
perspective-aware reasoning with our framework, further outperforming
fine-tuned spatial reasoning models and novel-view-synthesis-based approaches.

</details>

### [52] [MCAF: Efficient Agent-based Video Understanding Framework through Multimodal Coarse-to-Fine Attention Focusing](https://arxiv.org/abs/2504.17213)
*Shiwen Cao,Zhaoxing Zhang,Junming Jiao,Juyi Qiao,Guowen Song,Rong Shen*

Main category: cs.CV

TLDR: MCAF是一种基于代理的无训练框架，通过多模态粗到细的注意力聚焦实现视频理解，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 视频理解，尤其是长视频，信息冗余且复杂，需要模型全局分配注意力以提高准确性。

Method: MCAF通过多模态信息分层聚焦相关帧，并采用扩张时间扩展机制避免遗漏关键细节，结合自反思机制迭代优化注意力分配。

Result: 在多个数据集上表现优异，如EgoSchema上提升5%，Next-QA和IntentQA分别提升0.2%和0.3%，Video-MME上也优于其他方法。

Conclusion: MCAF通过创新的注意力聚焦策略，显著提升了视频理解的准确性和效率。

Abstract: Even in the era of rapid advances in large models, video understanding,
particularly long videos, remains highly challenging. Compared with textual or
image-based information, videos commonly contain more information with
redundancy, requiring large models to strategically allocate attention at a
global level for accurate comprehension. To address this, we propose MCAF, an
agent-based, training-free framework perform video understanding through
Multimodal Coarse-to-fine Attention Focusing. The key innovation lies in its
ability to sense and prioritize segments of the video that are highly relevant
to the understanding task. First, MCAF hierarchically concentrates on highly
relevant frames through multimodal information, enhancing the correlation
between the acquired contextual information and the query. Second, it employs a
dilated temporal expansion mechanism to mitigate the risk of missing crucial
details when extracting information from these concentrated frames. In
addition, our framework incorporates a self-reflection mechanism utilizing the
confidence level of the model's responses as feedback. By iteratively applying
these two creative focusing strategies, it adaptively adjusts attention to
capture highly query-connected context and thus improves response accuracy.
MCAF outperforms comparable state-of-the-art methods on average. On the
EgoSchema dataset, it achieves a remarkable 5% performance gain over the
leading approach. Meanwhile, on Next-QA and IntentQA datasets, it outperforms
the current state-of-the-art standard by 0.2% and 0.3% respectively. On the
Video-MME dataset, which features videos averaging nearly an hour in length,
MCAF also outperforms other agent-based methods.

</details>

### [53] [Towards Generalizable Deepfake Detection with Spatial-Frequency Collaborative Learning and Hierarchical Cross-Modal Fusion](https://arxiv.org/abs/2504.17223)
*Mengyu Qiao,Runze Tian,Yang Wang*

Main category: cs.CV

TLDR: 提出了一种结合多尺度空间-频率分析的新型深度伪造检测框架，显著提升了检测精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖空间域分析，未能充分利用频率域特征和空间-频率交互，导致对未知伪造的检测性能下降。

Method: 框架包含局部和全局频谱特征提取管道，以及多阶段跨模态融合机制，分别捕捉细微频谱特征、整体伪造分布模式及空间-频率交互。

Result: 在广泛采用的基准测试中，该方法在精度和泛化性上均优于现有技术。

Conclusion: 该框架通过多尺度空间-频率分析，有效解决了深度伪造检测中的挑战，具有广泛的应用潜力。

Abstract: The rapid evolution of deep generative models poses a critical challenge to
deepfake detection, as detectors trained on forgery-specific artifacts often
suffer significant performance degradation when encountering unseen forgeries.
While existing methods predominantly rely on spatial domain analysis, frequency
domain operations are primarily limited to feature-level augmentation, leaving
frequency-native artifacts and spatial-frequency interactions insufficiently
exploited. To address this limitation, we propose a novel detection framework
that integrates multi-scale spatial-frequency analysis for universal deepfake
detection. Our framework comprises three key components: (1) a local spectral
feature extraction pipeline that combines block-wise discrete cosine transform
with cascaded multi-scale convolutions to capture subtle spectral artifacts;
(2) a global spectral feature extraction pipeline utilizing scale-invariant
differential accumulation to identify holistic forgery distribution patterns;
and (3) a multi-stage cross-modal fusion mechanism that incorporates
shallow-layer attention enhancement and deep-layer dynamic modulation to model
spatial-frequency interactions. Extensive evaluations on widely adopted
benchmarks demonstrate that our method outperforms state-of-the-art deepfake
detection methods in both accuracy and generalizability.

</details>

### [54] [Visual and textual prompts for enhancing emotion recognition in video](https://arxiv.org/abs/2504.17224)
*Zhifeng Wang,Qixuan Zhang,Peter Zhang,Wenjia Niu,Kaihao Zhang,Ramesh Sankaranarayana,Sabrina Caldwell,Tom Gedeon*

Main category: cs.CV

TLDR: SoVTP框架通过整合空间标注、生理信号和上下文提示，提升了VLLMs在视频情感识别中的零样本能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视频情感识别中缺乏空间和上下文感知，导致鲁棒性不足。

Method: 提出SoVTP框架，结合空间标注、生理信号和上下文提示，实现统一提示策略。

Result: 实验表明SoVTP显著优于现有视觉提示方法。

Conclusion: SoVTP有效增强了VLLMs的视频情感识别能力。

Abstract: Vision Large Language Models (VLLMs) exhibit promising potential for
multi-modal understanding, yet their application to video-based emotion
recognition remains limited by insufficient spatial and contextual awareness.
Traditional approaches, which prioritize isolated facial features, often
neglect critical non-verbal cues such as body language, environmental context,
and social interactions, leading to reduced robustness in real-world scenarios.
To address this gap, we propose Set-of-Vision-Text Prompting (SoVTP), a novel
framework that enhances zero-shot emotion recognition by integrating spatial
annotations (e.g., bounding boxes, facial landmarks), physiological signals
(facial action units), and contextual cues (body posture, scene dynamics,
others' emotions) into a unified prompting strategy. SoVTP preserves holistic
scene information while enabling fine-grained analysis of facial muscle
movements and interpersonal dynamics. Extensive experiments show that SoVTP
achieves substantial improvements over existing visual prompting methods,
demonstrating its effectiveness in enhancing VLLMs' video emotion recognition
capabilities.

</details>

### [55] [Range Image-Based Implicit Neural Compression for LiDAR Point Clouds](https://arxiv.org/abs/2504.17229)
*Akihiro Kuwabara,Sorachi Kato,Takuya Fujihashi,Toshiaki Koike-Akino,Takashi Watanabe*

Main category: cs.CV

TLDR: 提出了一种基于隐式神经表示（INR）的轻量级LiDAR点云压缩方法，通过深度和掩码图像的分割与压缩，显著提升了低比特率下的3D重建和检测质量。


<details>
  <summary>Details</summary>
Motivation: 传统图像压缩技术在处理LiDAR的2D范围图像（RIs）时效率有限，因为其与自然图像在比特精度和像素值分布上存在差异。

Method: 将RIs分割为深度和掩码图像，分别采用基于INR的块级和像素级架构，结合模型剪枝和量化技术进行压缩。

Result: 在KITTI数据集上的实验表明，该方法在低比特率和解码延迟下，优于现有的图像、点云、RI和INR压缩方法。

Conclusion: 该方法为高效压缩LiDAR点云提供了新思路，支持高精度3D场景存档与分析。

Abstract: This paper presents a novel scheme to efficiently compress Light Detection
and Ranging~(LiDAR) point clouds, enabling high-precision 3D scene archives,
and such archives pave the way for a detailed understanding of the
corresponding 3D scenes. We focus on 2D range images~(RIs) as a lightweight
format for representing 3D LiDAR observations. Although conventional image
compression techniques can be adapted to improve compression efficiency for
RIs, their practical performance is expected to be limited due to differences
in bit precision and the distinct pixel value distribution characteristics
between natural images and RIs. We propose a novel implicit neural
representation~(INR)--based RI compression method that effectively handles
floating-point valued pixels. The proposed method divides RIs into depth and
mask images and compresses them using patch-wise and pixel-wise INR
architectures with model pruning and quantization, respectively. Experiments on
the KITTI dataset show that the proposed method outperforms existing image,
point cloud, RI, and INR-based compression methods in terms of 3D
reconstruction and detection quality at low bitrates and decoding latency.

</details>

### [56] [Scene Perceived Image Perceptual Score (SPIPS): combining global and local perception for image quality assessment](https://arxiv.org/abs/2504.17234)
*Zhiqiang Lao,Heather Yu*

Main category: cs.CV

TLDR: 提出了一种结合深度学习与传统IQA指标的新方法，通过分离高低层特征并整合，更准确地评估图像质量。


<details>
  <summary>Details</summary>
Motivation: 随着AI和智能手机的普及，图像数据激增，传统IQA方法难以应对DNN处理的图像，需更符合人类视觉感知的评估方法。

Method: 将深度特征分解为高层语义和低层感知细节，结合传统IQA指标，用MLP生成质量评分。

Result: 实验表明，该方法比现有IQA模型更符合人类感知判断。

Conclusion: 新方法通过整合深度特征与传统指标，提升了图像质量评估的准确性。

Abstract: The rapid advancement of artificial intelligence and widespread use of
smartphones have resulted in an exponential growth of image data, both real
(camera-captured) and virtual (AI-generated). This surge underscores the
critical need for robust image quality assessment (IQA) methods that accurately
reflect human visual perception. Traditional IQA techniques primarily rely on
spatial features - such as signal-to-noise ratio, local structural distortions,
and texture inconsistencies - to identify artifacts. While effective for
unprocessed or conventionally altered images, these methods fall short in the
context of modern image post-processing powered by deep neural networks (DNNs).
The rise of DNN-based models for image generation, enhancement, and restoration
has significantly improved visual quality, yet made accurate assessment
increasingly complex. To address this, we propose a novel IQA approach that
bridges the gap between deep learning methods and human perception. Our model
disentangles deep features into high-level semantic information and low-level
perceptual details, treating each stream separately. These features are then
combined with conventional IQA metrics to provide a more comprehensive
evaluation framework. This hybrid design enables the model to assess both
global context and intricate image details, better reflecting the human visual
process, which first interprets overall structure before attending to
fine-grained elements. The final stage employs a multilayer perceptron (MLP) to
map the integrated features into a concise quality score. Experimental results
demonstrate that our method achieves improved consistency with human perceptual
judgments compared to existing IQA models.

</details>

### [57] [DIVE: Inverting Conditional Diffusion Models for Discriminative Tasks](https://arxiv.org/abs/2504.17253)
*Yinqi Li,Hong Chang,Ruibing Hou,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TLDR: 该论文提出了一种利用预训练扩散模型进行判别任务的方法，将其从分类任务扩展到更复杂的物体检测任务，并通过梯度优化和先验分布模型提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成任务中表现出色，但如何利用其进行判别任务（如物体检测）仍是一个开放问题。本文旨在探索这一可能性。

Method: 通过“反转”预训练的布局到图像扩散模型，提出梯度优化的离散优化方法和先验分布模型，以替代繁重的预测枚举过程。

Result: 在COCO数据集上，该方法与基本判别式物体检测基线相当，同时显著加速了基于扩散的分类方法且不损失准确性。

Conclusion: 该方法成功扩展了预训练扩散模型的判别能力，为生成模型在判别任务中的应用提供了新思路。

Abstract: Diffusion models have shown remarkable progress in various generative tasks
such as image and video generation. This paper studies the problem of
leveraging pretrained diffusion models for performing discriminative tasks.
Specifically, we extend the discriminative capability of pretrained frozen
generative diffusion models from the classification task to the more complex
object detection task, by "inverting" a pretrained layout-to-image diffusion
model. To this end, a gradient-based discrete optimization approach for
replacing the heavy prediction enumeration process, and a prior distribution
model for making more accurate use of the Bayes' rule, are proposed
respectively. Empirical results show that this method is on par with basic
discriminative object detection baselines on COCO dataset. In addition, our
method can greatly speed up the previous diffusion-based method for
classification without sacrificing accuracy. Code and models are available at
https://github.com/LiYinqi/DIVE .

</details>

### [58] [Precision Neural Network Quantization via Learnable Adaptive Modules](https://arxiv.org/abs/2504.17263)
*Wenqiang Zhou,Zhendong Yu,Xinyu Liu,Jiaming Yang,Rong Xiao,Tao Wang,Chenwei Tang,Jiancheng Lv*

Main category: cs.CV

TLDR: 本文提出了一种称为自适应步长量化（ASQ）的可学习自适应神经网络量化方法，解决了量化感知训练（QAT）中量化参数可训练性与推理灵活性之间的冲突。ASQ通过动态调整量化缩放因子和非均匀量化方案，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 量化感知训练（QAT）通过引入假量化操作来补偿量化带来的信息损失，但其可训练量化参数会牺牲推理灵活性，尤其是处理分布差异大的激活值时。本文旨在解决这一冲突。

Method: 提出ASQ方法：1) 通过训练模块动态调整量化缩放因子；2) 提出基于Power Of Square root of Two（POST）的非均匀量化方案，结合查找表（LUT）保持计算效率。

Result: 实验表明ASQ优于现有QAT方法，4位量化ResNet34在ImageNet上精度提升1.2%，甚至可与全精度基线竞争。

Conclusion: ASQ通过动态调整和非均匀量化，有效解决了QAT的灵活性限制，显著提升了量化模型的性能。

Abstract: Quantization Aware Training (QAT) is a neural network quantization technique
that compresses model size and improves operational efficiency while
effectively maintaining model performance. The paradigm of QAT is to introduce
fake quantization operators during the training process, allowing the model to
autonomously compensate for information loss caused by quantization. Making
quantization parameters trainable can significantly improve the performance of
QAT, but at the cost of compromising the flexibility during inference,
especially when dealing with activation values with substantially different
distributions. In this paper, we propose an effective learnable adaptive neural
network quantization method, called Adaptive Step Size Quantization (ASQ), to
resolve this conflict. Specifically, the proposed ASQ method first dynamically
adjusts quantization scaling factors through a trained module capable of
accommodating different activations. Then, to address the rigid resolution
issue inherent in Power of Two (POT) quantization, we propose an efficient
non-uniform quantization scheme. We utilize the Power Of Square root of Two
(POST) as the basis for exponential quantization, effectively handling the
bell-shaped distribution of neural network weights across various bit-widths
while maintaining computational efficiency through a Look-Up Table method
(LUT). Extensive experimental results demonstrate that the proposed ASQ method
is superior to the state-of-the-art QAT approaches. Notably that the ASQ is
even competitive compared to full precision baselines, with its 4-bit quantized
ResNet34 model improving accuracy by 1.2\% on ImageNet.

</details>

### [59] [Towards Generalized and Training-Free Text-Guided Semantic Manipulation](https://arxiv.org/abs/2504.17269)
*Yu Hong,Xiao Cai,Pengpeng Zeng,Shuai Zhang,Jingkuan Song,Lianli Gao,Heng Tao Shen*

Main category: cs.CV

TLDR: 论文提出了一种无需训练的通用文本引导语义编辑方法（GTF），支持多种语义操作（如添加、移除和风格迁移），并适用于不同模态。


<details>
  <summary>Details</summary>
Motivation: 现有方法效率低、扩展性差或通用性不足，而扩散模型中噪声的几何特性与语义变化强相关，这启发了GTF的设计。

Method: 通过控制噪声的几何关系实现语义编辑，无需调优或优化，支持多种操作且可即插即用。

Result: 实验证明GTF能生成高保真结果，支持多语义操作和多模态任务。

Conclusion: GTF在语义编辑领域具有潜力，可推动技术前沿发展。

Abstract: Text-guided semantic manipulation refers to semantically editing an image
generated from a source prompt to match a target prompt, enabling the desired
semantic changes (e.g., addition, removal, and style transfer) while preserving
irrelevant contents. With the powerful generative capabilities of the diffusion
model, the task has shown the potential to generate high-fidelity visual
content. Nevertheless, existing methods either typically require time-consuming
fine-tuning (inefficient), fail to accomplish multiple semantic manipulations
(poorly extensible), and/or lack support for different modality tasks (limited
generalizability). Upon further investigation, we find that the geometric
properties of noises in the diffusion model are strongly correlated with the
semantic changes. Motivated by this, we propose a novel $\textit{GTF}$ for
text-guided semantic manipulation, which has the following attractive
capabilities: 1) $\textbf{Generalized}$: our $\textit{GTF}$ supports multiple
semantic manipulations (e.g., addition, removal, and style transfer) and can be
seamlessly integrated into all diffusion-based methods (i.e., Plug-and-play)
across different modalities (i.e., modality-agnostic); and 2)
$\textbf{Training-free}$: $\textit{GTF}$ produces high-fidelity results via
simply controlling the geometric relationship between noises without tuning or
optimization. Our extensive experiments demonstrate the efficacy of our
approach, highlighting its potential to advance the state-of-the-art in
semantics manipulation.

</details>

### [60] [EdgePoint2: Compact Descriptors for Superior Efficiency and Accuracy](https://arxiv.org/abs/2504.17280)
*Haodi Yao,Fenghua He,Ning Hao,Chen Xie*

Main category: cs.CV

TLDR: EdgePoint2 是一种轻量级的关键点检测和描述神经网络，专为边缘计算设计，在保持高精度的同时优化效率，适用于多种计算和通信约束场景。


<details>
  <summary>Details</summary>
Motivation: 深度学习在关键点提取中表现优异，但计算成本高且描述符维度大，限制了其在实时边缘应用中的部署。EdgePoint2 旨在解决这些问题。

Method: EdgePoint2 结合了正交 Procrustes 损失和相似性损失训练紧凑描述符，并提供 14 个子模型以满足多样化需求。

Result: 实验表明，EdgePoint2 在多种场景下均达到 SOTA 的精度和效率，且使用低维描述符（32/48/64）。

Conclusion: EdgePoint2 是一种灵活、鲁棒且多功能的解决方案，特别适合需要适应不同计算和通信约束的视觉任务。

Abstract: The field of keypoint extraction, which is essential for vision applications
like Structure from Motion (SfM) and Simultaneous Localization and Mapping
(SLAM), has evolved from relying on handcrafted methods to leveraging deep
learning techniques. While deep learning approaches have significantly improved
performance, they often incur substantial computational costs, limiting their
deployment in real-time edge applications. Efforts to create lightweight neural
networks have seen some success, yet they often result in trade-offs between
efficiency and accuracy. Additionally, the high-dimensional descriptors
generated by these networks poses challenges for distributed applications
requiring efficient communication and coordination, highlighting the need for
compact yet competitively accurate descriptors. In this paper, we present
EdgePoint2, a series of lightweight keypoint detection and description neural
networks specifically tailored for edge computing applications on embedded
system. The network architecture is optimized for efficiency without
sacrificing accuracy. To train compact descriptors, we introduce a combination
of Orthogonal Procrustes loss and similarity loss, which can serve as a general
approach for hypersphere embedding distillation tasks. Additionally, we offer
14 sub-models to satisfy diverse application requirements. Our experiments
demonstrate that EdgePoint2 consistently achieves state-of-the-art (SOTA)
accuracy and efficiency across various challenging scenarios while employing
lower-dimensional descriptors (32/48/64). Beyond its accuracy, EdgePoint2
offers significant advantages in flexibility, robustness, and versatility.
Consequently, EdgePoint2 emerges as a highly competitive option for visual
tasks, especially in contexts demanding adaptability to diverse computational
and communication constraints.

</details>

### [61] [Advanced Segmentation of Diabetic Retinopathy Lesions Using DeepLabv3+](https://arxiv.org/abs/2504.17306)
*Meher Boulaabi,Takwa Ben Aïcha Gader,Afef Kacem Echi,Sameh Mbarek*

Main category: cs.CV

TLDR: 提出了一种针对糖尿病视网膜病变病灶的二元分割方法，通过结合多个病灶模型的输出提升分割精度，解决了数据集和标注复杂性的问题。


<details>
  <summary>Details</summary>
Motivation: 改善糖尿病视网膜病变病灶（如微动脉瘤、出血、渗出物等）的分割精度，克服数据集限制和标注复杂性带来的挑战。

Method: 采用DeepLabv3+模型，结合特定预处理（如裁剪和对比度受限的自适应直方图均衡化）及数据增强技术，对每种病灶类型进行二元分割，最后整合结果。

Result: 实现了99%的分割准确率，验证了方法的有效性。

Conclusion: 创新策略在医学图像分析中具有显著效果，特别是在糖尿病视网膜病变病灶的精确分割上。

Abstract: To improve the segmentation of diabetic retinopathy lesions (microaneurysms,
hemorrhages, exudates, and soft exudates), we implemented a binary segmentation
method specific to each type of lesion. As post-segmentation, we combined the
individual model outputs into a single image to better analyze the lesion
types. This approach facilitated parameter optimization and improved accuracy,
effectively overcoming challenges related to dataset limitations and annotation
complexity. Specific preprocessing steps included cropping and applying
contrast-limited adaptive histogram equalization to the L channel of the LAB
image. Additionally, we employed targeted data augmentation techniques to
further refine the model's efficacy. Our methodology utilized the DeepLabv3+
model, achieving a segmentation accuracy of 99%. These findings highlight the
efficacy of innovative strategies in advancing medical image analysis,
particularly in the precise segmentation of diabetic retinopathy lesions. The
IDRID dataset was utilized to validate and demonstrate the robustness of our
approach.

</details>

### [62] [DIMT25@ICDAR2025: HW-TSC's End-to-End Document Image Machine Translation System Leveraging Large Vision-Language Model](https://arxiv.org/abs/2504.17315)
*Zhanglin Wu,Tengfei Song,Ning Xie,Weidong Zhang,Pengfei Li,Shuang Wu,Chong Li,Junhao Zhu,Hao Yang*

Main category: cs.CV

TLDR: 华为翻译服务中心提出了一种基于多任务学习和感知链式思维的端到端文档图像翻译系统，结合最小贝叶斯解码和后处理策略提升翻译能力。


<details>
  <summary>Details</summary>
Motivation: 解决复杂布局文档图像的端到端机器翻译问题，统一处理OCR和非OCR任务。

Method: 使用开源大型视觉语言模型，结合多任务学习和感知链式思维训练框架，应用最小贝叶斯解码和后处理策略。

Result: 展示了有效的文档图像机器翻译方法，涵盖训练、推理、实验设置和结果。

Conclusion: 提出的方法在复杂布局文档翻译任务中表现优异，为端到端翻译提供了统一解决方案。

Abstract: This paper presents the technical solution proposed by Huawei Translation
Service Center (HW-TSC) for the "End-to-End Document Image Machine Translation
for Complex Layouts" competition at the 19th International Conference on
Document Analysis and Recognition (DIMT25@ICDAR2025). Leveraging
state-of-the-art open-source large vision-language model (LVLM), we introduce a
training framework that combines multi-task learning with perceptual
chain-of-thought to develop a comprehensive end-to-end document translation
system. During the inference phase, we apply minimum Bayesian decoding and
post-processing strategies to further enhance the system's translation
capabilities. Our solution uniquely addresses both OCR-based and OCR-free
document image translation tasks within a unified framework. This paper
systematically details the training methods, inference strategies, LVLM base
models, training data, experimental setups, and results, demonstrating an
effective approach to document image machine translation.

</details>

### [63] [TimeChat-Online: 80% Visual Tokens are Naturally Redundant in Streaming Videos](https://arxiv.org/abs/2504.17343)
*Linli Yao,Yicheng Li,Yuancheng Wei,Lei Li,Shuhuai Ren,Yuanxin Liu,Kun Ouyang,Lean Wang,Shicheng Li,Sida Li,Lingpeng Kong,Qi Liu,Yuanxing Zhang,Xu Sun*

Main category: cs.CV

TLDR: TimeChat-Online是一种新型在线视频大语言模型，通过创新的差分令牌丢弃（DTD）模块高效处理实时视频流，减少冗余帧，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 在线视频平台的快速增长，尤其是直播服务，需要实时视频理解系统，而现有视频大语言模型在流媒体场景中存在处理冗余帧的局限性。

Method: 提出DTD模块，受人类视觉感知的‘变化盲视’现象启发，保留有意义的时间变化，过滤静态冗余内容。

Result: DTD减少82.8%的视频令牌，同时保持98%的性能；TimeChat-Online在流媒体和长视频任务中表现优异。

Conclusion: TimeChat-Online通过DTD模块和主动响应能力，显著提升了实时视频交互的效率与性能。

Abstract: The rapid growth of online video platforms, particularly live streaming
services, has created an urgent need for real-time video understanding systems.
These systems must process continuous video streams and respond to user queries
instantaneously, presenting unique challenges for current Video Large Language
Models (VideoLLMs). While existing VideoLLMs excel at processing complete
videos, they face significant limitations in streaming scenarios due to their
inability to handle dense, redundant frames efficiently. We introduce
TimeChat-Online, a novel online VideoLLM that revolutionizes real-time video
interaction. At its core lies our innovative Differential Token Drop (DTD)
module, which addresses the fundamental challenge of visual redundancy in
streaming videos. Drawing inspiration from human visual perception's Change
Blindness phenomenon, DTD preserves meaningful temporal changes while filtering
out static, redundant content between frames. Remarkably, our experiments
demonstrate that DTD achieves an 82.8% reduction in video tokens while
maintaining 98% performance on StreamingBench, revealing that over 80% of
visual content in streaming videos is naturally redundant without requiring
language guidance. To enable seamless real-time interaction, we present
TimeChat-Online-139K, a comprehensive streaming video dataset featuring diverse
interaction patterns including backward-tracing, current-perception, and
future-responding scenarios. TimeChat-Online's unique Proactive Response
capability, naturally achieved through continuous monitoring of video scene
transitions via DTD, sets it apart from conventional approaches. Our extensive
evaluation demonstrates TimeChat-Online's superior performance on streaming
benchmarks (StreamingBench and OvOBench) and maintaining competitive results on
long-form video tasks such as Video-MME and MLVU.

</details>

### [64] [DRC: Enhancing Personalized Image Generation via Disentangled Representation Composition](https://arxiv.org/abs/2504.17349)
*Yiyan Xu,Wuqiang Zheng,Wenjie Wang,Fengbin Zhu,Xinting Hu,Yang Zhang,Fuli Feng,Tat-Seng Chua*

Main category: cs.CV

TLDR: DRC框架通过解耦表示组合增强LMMs，解决个性化图像生成中风格与语义意图的纠缠问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以准确捕捉和融合用户风格偏好与语义意图，导致生成的图像无法保留用户偏好或反映指定语义。

Method: DRC通过解耦学习和个性化建模两个阶段，分别提取风格与语义特征并优化表示。

Result: 实验表明DRC在性能上具有竞争力，有效缓解了引导崩溃问题。

Conclusion: 解耦表示学习对可控且有效的个性化图像生成至关重要。

Abstract: Personalized image generation has emerged as a promising direction in
multimodal content creation. It aims to synthesize images tailored to
individual style preferences (e.g., color schemes, character appearances,
layout) and semantic intentions (e.g., emotion, action, scene contexts) by
leveraging user-interacted history images and multimodal instructions. Despite
notable progress, existing methods -- whether based on diffusion models, large
language models, or Large Multimodal Models (LMMs) -- struggle to accurately
capture and fuse user style preferences and semantic intentions. In particular,
the state-of-the-art LMM-based method suffers from the entanglement of visual
features, leading to Guidance Collapse, where the generated images fail to
preserve user-preferred styles or reflect the specified semantics.
  To address these limitations, we introduce DRC, a novel personalized image
generation framework that enhances LMMs through Disentangled Representation
Composition. DRC explicitly extracts user style preferences and semantic
intentions from history images and the reference image, respectively, to form
user-specific latent instructions that guide image generation within LMMs.
Specifically, it involves two critical learning stages: 1) Disentanglement
learning, which employs a dual-tower disentangler to explicitly separate style
and semantic features, optimized via a reconstruction-driven paradigm with
difficulty-aware importance sampling; and 2) Personalized modeling, which
applies semantic-preserving augmentations to effectively adapt the disentangled
representations for robust personalized generation. Extensive experiments on
two benchmarks demonstrate that DRC shows competitive performance while
effectively mitigating the guidance collapse issue, underscoring the importance
of disentangled representation learning for controllable and effective
personalized image generation.

</details>

### [65] [I-INR: Iterative Implicit Neural Representations](https://arxiv.org/abs/2504.17364)
*Ali Haider,Muhammad Salman Ali,Maryam Qamar,Tahir Khalil,Soo Ye Kim,Jihyong Oh,Enzo Tartaglione,Sung-Ho Bae*

Main category: cs.CV

TLDR: 论文提出了一种迭代隐式神经表示（I-INRs）框架，通过迭代细化过程提升信号重建质量，解决了传统INRs在细节捕捉和高频信息保留上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统隐式神经表示（INRs）因回归问题的固有特性，容易回归均值，难以捕捉细节和高频信息，且对噪声敏感。

Method: 提出I-INRs框架，通过迭代细化过程增强信号重建能力，兼容现有INRs架构。

Result: 实验表明I-INRs在图像恢复、去噪和物体占据预测等任务中优于基线方法（如WIRE、SIREN和Gauss）。

Conclusion: I-INRs显著提升了信号重建质量，具有广泛的应用潜力。

Abstract: Implicit Neural Representations (INRs) have revolutionized signal processing
and computer vision by modeling signals as continuous, differentiable functions
parameterized by neural networks. However, their inherent formulation as a
regression problem makes them prone to regression to the mean, limiting their
ability to capture fine details, retain high-frequency information, and handle
noise effectively. To address these challenges, we propose Iterative Implicit
Neural Representations (I-INRs) a novel plug-and-play framework that enhances
signal reconstruction through an iterative refinement process. I-INRs
effectively recover high-frequency details, improve robustness to noise, and
achieve superior reconstruction quality. Our framework seamlessly integrates
with existing INR architectures, delivering substantial performance gains
across various tasks. Extensive experiments show that I-INRs outperform
baseline methods, including WIRE, SIREN, and Gauss, in diverse computer vision
applications such as image restoration, image denoising, and object occupancy
prediction.

</details>

### [66] [TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer Commentary Generation](https://arxiv.org/abs/2504.17365)
*Ling You,Wenxuan Huang,Xinni Xie,Xiangyi Wei,Bangyan Li,Shaohui Lin,Yang Li,Changbo Wang*

Main category: cs.CV

TLDR: TimeSoccer是首个端到端的足球多模态大语言模型，用于全场比赛的单锚点密集视频描述（SDVC），通过联合预测时间戳和生成描述，实现了全局上下文建模。


<details>
  <summary>Details</summary>
Motivation: 现有足球MLLMs依赖时间先验，无法端到端处理视频；传统方法复杂且无法捕捉全局上下文，性能次优。

Method: 提出TimeSoccer，结合MoFA-Select帧压缩模块，通过粗到细策略自适应选择代表性帧，并采用互补训练范式增强长时序处理能力。

Result: 实验表明TimeSoccer在SDVC任务上达到最先进性能，生成高质量评论且时间对齐准确、语义相关性强。

Conclusion: TimeSoccer解决了现有方法的局限性，为足球视频的端到端密集描述提供了高效解决方案。

Abstract: Soccer is a globally popular sporting event, typically characterized by long
matches and distinctive highlight moments. Recent advances in Multimodal Large
Language Models (MLLMs) offer promising capabilities in temporal grounding and
video understanding, soccer commentary generation often requires precise
temporal localization and semantically rich descriptions over long-form video.
However, existing soccer MLLMs often rely on the temporal a priori for caption
generation, so they cannot process the soccer video end-to-end. While some
traditional approaches follow a two-step paradigm that is complex and fails to
capture the global context to achieve suboptimal performance. To solve the
above issues, we present TimeSoccer, the first end-to-end soccer MLLM for
Single-anchor Dense Video Captioning (SDVC) in full-match soccer videos.
TimeSoccer jointly predicts timestamps and generates captions in a single pass,
enabling global context modeling across 45-minute matches. To support long
video understanding of soccer matches, we introduce MoFA-Select, a
training-free, motion-aware frame compression module that adaptively selects
representative frames via a coarse-to-fine strategy, and incorporates
complementary training paradigms to strengthen the model's ability to handle
long temporal sequences. Extensive experiments demonstrate that our TimeSoccer
achieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-end
form, generating high-quality commentary with accurate temporal alignment and
strong semantic relevance.

</details>

### [67] [Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset](https://arxiv.org/abs/2504.17371)
*Oussema Dhaouadi,Johannes Meier,Luca Wahl,Jacques Kaiser,Luca Scalerandi,Nick Wandelburg,Zhuolun Zhou,Nijanthan Berinpanathan,Holger Banzhaf,Daniel Cremers*

Main category: cs.CV

TLDR: 论文介绍了DeepScenario Open 3D Dataset（DSC3D），一个通过无人机跟踪技术获取的高质量、无遮挡的3D轨迹数据集，旨在提升自动驾驶系统的环境感知能力。


<details>
  <summary>Details</summary>
Motivation: 传统数据集因固定传感器和遮挡问题限制了自动驾驶系统的环境重建能力，DSC3D通过无人机技术解决了这些问题。

Method: 采用单目相机无人机跟踪技术，采集了14类交通参与者的175,000多条轨迹，覆盖多种复杂场景和地理位置。

Result: DSC3D在多样性和规模上超越现有数据集，支持运动预测、行为建模等应用。

Conclusion: DSC3D为自动驾驶研究提供了更全面的3D环境表示，有望提升系统安全性和交互能力。

Abstract: Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet,
traditional datasets are usually captured by fixed sensors mounted on a car and
are susceptible to occlusion. Additionally, such an approach can precisely
reconstruct the dynamic environment in the close vicinity of the measurement
vehicle only, while neglecting objects that are further away. In this paper, we
introduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality,
occlusion-free dataset of 6 degrees of freedom bounding box trajectories
acquired through a novel monocular camera drone tracking pipeline. Our dataset
includes more than 175,000 trajectories of 14 types of traffic participants and
significantly exceeds existing datasets in terms of diversity and scale,
containing many unprecedented scenarios such as complex vehicle-pedestrian
interaction on highly populated urban streets and comprehensive parking
maneuvers from entry to exit. DSC3D dataset was captured in five various
locations in Europe and the United States and include: a parking lot, a crowded
inner-city, a steep urban intersection, a federal highway, and a suburban
intersection. Our 3D trajectory dataset aims to enhance autonomous driving
systems by providing detailed environmental 3D representations, which could
lead to improved obstacle interactions and safety. We demonstrate its utility
across multiple applications including motion prediction, motion planning,
scenario mining, and generative reactive traffic agents. Our interactive online
visualization platform and the complete dataset are publicly available at
app.deepscenario.com, facilitating research in motion prediction, behavior
modeling, and safety validation.

</details>

### [68] [SDVPT: Semantic-Driven Visual Prompt Tuning for Open-World Object Counting](https://arxiv.org/abs/2504.17395)
*Yiming Zhao,Guorong Li,Laiyun Qing,Amin Beheshti,Jian Yang,Michael Sheng,Yuankai Qi,Qingming Huang*

Main category: cs.CV

TLDR: 论文提出了一种名为SDVPT的框架，通过视觉提示调优提升预训练视觉语言模型在开放世界物体计数任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在微调时仅关注训练集中的类别，导致对未见类别的泛化能力有限。

Method: SDVPT采用两阶段视觉提示学习策略（CSPI和TGPR），生成并优化类别特定的视觉提示，动态合成未见类别的提示。

Result: 实验表明，SDVPT在FSC-147、CARPK和PUCPR+数据集上显著提升了开放世界物体计数模型的性能。

Conclusion: SDVPT是一种高效且适应性强的框架，能够显著提升模型对未见类别的计数能力。

Abstract: Open-world object counting leverages the robust text-image alignment of
pre-trained vision-language models (VLMs) to enable counting of arbitrary
categories in images specified by textual queries. However, widely adopted
naive fine-tuning strategies concentrate exclusively on text-image consistency
for categories contained in training, which leads to limited generalizability
for unseen categories. In this work, we propose a plug-and-play Semantic-Driven
Visual Prompt Tuning framework (SDVPT) that transfers knowledge from the
training set to unseen categories with minimal overhead in parameters and
inference time. First, we introduce a two-stage visual prompt learning strategy
composed of Category-Specific Prompt Initialization (CSPI) and Topology-Guided
Prompt Refinement (TGPR). The CSPI generates category-specific visual prompts,
and then TGPR distills latent structural patterns from the VLM's text encoder
to refine these prompts. During inference, we dynamically synthesize the visual
prompts for unseen categories based on the semantic correlation between unseen
and training categories, facilitating robust text-image alignment for unseen
categories. Extensive experiments integrating SDVPT with all available
open-world object counting models demonstrate its effectiveness and
adaptability across three widely used datasets: FSC-147, CARPK, and PUCPR+.

</details>

### [69] [Fine-tune Smarter, Not Harder: Parameter-Efficient Fine-Tuning for Geospatial Foundation Models](https://arxiv.org/abs/2504.17397)
*Francesc Marti-Escofet,Benedikt Blumenstiel,Linus Scheibenreif,Paolo Fraccaro,Konrad Schindler*

Main category: cs.CV

TLDR: 论文探讨了参数高效微调（PEFT）技术在地球观测（EO）领域的应用，通过实验证明PEFT在性能、泛化能力和资源效率上优于全微调。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型规模的增大，全微调的计算成本和资源需求限制了其可访问性和可扩展性，同时可能导致预训练特征的遗忘和泛化能力下降。

Method: 通过多种基础模型架构和PEFT技术，在五个不同的EO数据集上进行实验，评估其有效性。

Result: PEFT技术在性能上匹配甚至超越全微调，同时提升模型对未见地理区域的泛化能力，并减少训练时间和内存需求。

Conclusion: PEFT是适应预训练地理空间模型的高效方法，UNet解码器和无元数据的微调是推荐配置，相关技术已集成到开源工具TerraTorch中。

Abstract: Earth observation (EO) is crucial for monitoring environmental changes,
responding to disasters, and managing natural resources. In this context,
foundation models facilitate remote sensing image analysis to retrieve relevant
geoinformation accurately and efficiently. However, as these models grow in
size, fine-tuning becomes increasingly challenging due to the associated
computational resources and costs, limiting their accessibility and
scalability. Furthermore, full fine-tuning can lead to forgetting pre-trained
features and even degrade model generalization. To address this,
Parameter-Efficient Fine-Tuning (PEFT) techniques offer a promising solution.
In this paper, we conduct extensive experiments with various foundation model
architectures and PEFT techniques to evaluate their effectiveness on five
different EO datasets. Our results provide a comprehensive comparison, offering
insights into when and how PEFT methods support the adaptation of pre-trained
geospatial models. We demonstrate that PEFT techniques match or even exceed
full fine-tuning performance and enhance model generalisation to unseen
geographic regions, while reducing training time and memory requirements.
Additional experiments investigate the effect of architecture choices such as
the decoder type or the use of metadata, suggesting UNet decoders and
fine-tuning without metadata as the recommended configuration. We have
integrated all evaluated foundation models and techniques into the open-source
package TerraTorch to support quick, scalable, and cost-effective model
adaptation.

</details>

### [70] [S2S-Net: Addressing the Domain Gap of Heterogeneous Sensor Systems in LiDAR-Based Collective Perception](https://arxiv.org/abs/2504.17399)
*Sven Teufel,Jörg Gamerdinger,Oliver Bringmann*

Main category: cs.CV

TLDR: 该论文提出了一种名为S2S-Net的架构，用于解决车辆间集体感知中的传感器间域差距问题，并在SCOPE数据集上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 集体感知在自动驾驶中具有潜力，但不同传感器系统导致的域差距问题尚未解决。缺乏异构传感器数据集是主要原因。

Method: 提出了传感器域鲁棒架构S2S-Net，并在SCOPE数据集上进行了深入分析。

Result: S2S-Net在未见过的传感器域中保持高性能，并在SCOPE数据集上达到最先进水平。

Conclusion: S2S-Net有效解决了传感器间域差距问题，为集体感知提供了新方法。

Abstract: Collective Perception (CP) has emerged as a promising approach to overcome
the limitations of individual perception in the context of autonomous driving.
Various approaches have been proposed to realize collective perception;
however, the Sensor2Sensor domain gap that arises from the utilization of
different sensor systems in Connected and Automated Vehicles (CAVs) remains
mostly unaddressed. This is primarily due to the paucity of datasets containing
heterogeneous sensor setups among the CAVs. The recently released SCOPE
datasets address this issue by providing data from three different LiDAR
sensors for each CAV. This study is the first to tackle the Sensor2Sensor
domain gap in vehicle to vehicle (V2V) collective perception. First, we present
our sensor-domain robust architecture S2S-Net. Then an in-depth analysis of the
Sensor2Sensor domain adaptation capabilities of S2S-Net on the SCOPE dataset is
conducted. S2S-Net demonstrates the capability to maintain very high
performance in unseen sensor domains and achieved state-of-the-art results on
the SCOPE dataset.

</details>

### [71] [StereoMamba: Real-time and Robust Intraoperative Stereo Disparity Estimation via Long-range Spatial Dependencies](https://arxiv.org/abs/2504.17401)
*Xu Wang,Jialang Xu,Shuai Zhang,Baoru Huang,Danail Stoyanov,Evangelos B. Mazomenos*

Main category: cs.CV

TLDR: StereoMamba架构通过FE-Mamba和MFF模块优化了RAMIS中的立体视差估计，在精度、鲁棒性和速度间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法在机器人辅助微创手术（RAMIS）中的立体视差估计中，难以同时满足高精度、鲁棒性和快速推理的需求。

Method: 提出StereoMamba架构，包括增强长程空间依赖的FE-Mamba模块和融合多尺度特征的MFF模块。

Result: 在SCARED基准测试中，StereoMamba在EPE（2.64 px）、深度MAE（2.55 mm）和推理速度（21.28 FPS）上表现优异，同时在SSIM（0.8970）和PSNR（16.0761）上取得最佳成绩。

Conclusion: StereoMamba在RAMIS中实现了精度、鲁棒性和效率的最佳平衡，并展示了强大的零样本泛化能力。

Abstract: Stereo disparity estimation is crucial for obtaining depth information in
robot-assisted minimally invasive surgery (RAMIS). While current deep learning
methods have made significant advancements, challenges remain in achieving an
optimal balance between accuracy, robustness, and inference speed. To address
these challenges, we propose the StereoMamba architecture, which is
specifically designed for stereo disparity estimation in RAMIS. Our approach is
based on a novel Feature Extraction Mamba (FE-Mamba) module, which enhances
long-range spatial dependencies both within and across stereo images. To
effectively integrate multi-scale features from FE-Mamba, we then introduce a
novel Multidimensional Feature Fusion (MFF) module. Experiments against the
state-of-the-art on the ex-vivo SCARED benchmark demonstrate that StereoMamba
achieves superior performance on EPE of 2.64 px and depth MAE of 2.55 mm, the
second-best performance on Bad2 of 41.49% and Bad3 of 26.99%, while maintaining
an inference speed of 21.28 FPS for a pair of high-resolution images
(1280*1024), striking the optimum balance between accuracy, robustness, and
efficiency. Furthermore, by comparing synthesized right images, generated from
warping left images using the generated disparity maps, with the actual right
image, StereoMamba achieves the best average SSIM (0.8970) and PSNR (16.0761),
exhibiting strong zero-shot generalization on the in-vivo RIS2017 and StereoMIS
datasets.

</details>

### [72] [3DV-TON: Textured 3D-Guided Consistent Video Try-on via Diffusion Models](https://arxiv.org/abs/2504.17414)
*Min Wei,Chaohui Yu,Jingkai Zhou,Fan Wang*

Main category: cs.CV

TLDR: 3DV-TON是一种基于扩散的框架，用于生成高质量且时间一致的视频试穿效果，通过动态3D网格和矩形掩码策略解决现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂服装图案和多样身体姿势下难以生成高质量且时间一致的结果。

Method: 使用生成的动画纹理3D网格作为帧级指导，结合自适应管道生成动态3D指导，并引入矩形掩码策略减少伪影传播。

Result: 提出的方法在定量和定性评估中优于现有方法，并发布了高分辨率基准数据集HR-VVT。

Conclusion: 3DV-TON通过3D网格指导和掩码策略显著提升了视频试穿的质量和一致性。

Abstract: Video try-on replaces clothing in videos with target garments. Existing
methods struggle to generate high-quality and temporally consistent results
when handling complex clothing patterns and diverse body poses. We present
3DV-TON, a novel diffusion-based framework for generating high-fidelity and
temporally consistent video try-on results. Our approach employs generated
animatable textured 3D meshes as explicit frame-level guidance, alleviating the
issue of models over-focusing on appearance fidelity at the expanse of motion
coherence. This is achieved by enabling direct reference to consistent garment
texture movements throughout video sequences. The proposed method features an
adaptive pipeline for generating dynamic 3D guidance: (1) selecting a keyframe
for initial 2D image try-on, followed by (2) reconstructing and animating a
textured 3D mesh synchronized with original video poses. We further introduce a
robust rectangular masking strategy that successfully mitigates artifact
propagation caused by leaking clothing information during dynamic human and
garment movements. To advance video try-on research, we introduce HR-VVT, a
high-resolution benchmark dataset containing 130 videos with diverse clothing
types and scenarios. Quantitative and qualitative results demonstrate our
superior performance over existing methods. The project page is at this link
https://2y7c3.github.io/3DV-TON/

</details>

### [73] [Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs](https://arxiv.org/abs/2504.17432)
*Tiancheng Gu,Kaicheng Yang,Ziyong Feng,Xingjun Wang,Yanzhao Zhang,Dingkun Long,Yingda Chen,Weidong Cai,Jiankang Deng*

Main category: cs.CV

TLDR: UniME是一个两阶段框架，利用MLLMs学习多模态嵌入，通过知识蒸馏和硬负样本增强提升性能。


<details>
  <summary>Details</summary>
Motivation: CLIP框架在多模态表示学习中存在文本截断、孤立编码和组合性不足等问题，MLLMs的潜力尚未充分挖掘。

Method: 第一阶段通过LLM教师模型进行知识蒸馏，第二阶段引入硬负样本增强指令调优。

Result: 在MMEB基准和多种检索任务中，UniME表现优于现有方法。

Conclusion: UniME显著提升了多模态表示学习的判别性和组合性。

Abstract: The Contrastive Language-Image Pre-training (CLIP) framework has become a
widely used approach for multimodal representation learning, particularly in
image-text retrieval and clustering. However, its efficacy is constrained by
three key limitations: (1) text token truncation, (2) isolated image-text
encoding, and (3) deficient compositionality due to bag-of-words behavior.
While recent Multimodal Large Language Models (MLLMs) have demonstrated
significant advances in generalized vision-language understanding, their
potential for learning transferable multimodal representations remains
underexplored.In this work, we present UniME (Universal Multimodal Embedding),
a novel two-stage framework that leverages MLLMs to learn discriminative
representations for diverse downstream tasks. In the first stage, we perform
textual discriminative knowledge distillation from a powerful LLM-based teacher
model to enhance the embedding capability of the MLLM\'s language component. In
the second stage, we introduce hard negative enhanced instruction tuning to
further advance discriminative representation learning. Specifically, we
initially mitigate false negative contamination and then sample multiple hard
negatives per instance within each batch, forcing the model to focus on
challenging samples. This approach not only improves discriminative power but
also enhances instruction-following ability in downstream tasks. We conduct
extensive experiments on the MMEB benchmark and multiple retrieval tasks,
including short and long caption retrieval and compositional retrieval. Results
demonstrate that UniME achieves consistent performance improvement across all
tasks, exhibiting superior discriminative and compositional capabilities.

</details>

### [74] [Predict-Optimize-Distill: A Self-Improving Cycle for 4D Object Understanding](https://arxiv.org/abs/2504.17441)
*Mingxuan Wu,Huang Huang,Justin Kerr,Chung Min Kim,Anthony Zhang,Brent Yi,Angjoo Kanazawa*

Main category: cs.CV

TLDR: POD是一个自改进框架，通过预测、优化和蒸馏的循环过程，提升对4D物体理解的性能。


<details>
  <summary>Details</summary>
Motivation: 人类通过长时间观察物体运动来预测其3D状态，现有系统多依赖多视角观察或监督数据集训练。POD旨在通过自改进循环实现更优的4D物体理解。

Method: POD框架包括预测局部部件姿态、全局优化通过逆渲染细化姿态、以及通过自生成合成数据蒸馏优化结果回模型。此外，引入准多视角挖掘策略减少深度模糊。

Result: 在14个真实物体和5个合成物体上评估，POD显著优于纯优化基线，尤其在长视频中表现更优。性能随视频长度和迭代次数提升。

Conclusion: POD通过自改进循环和准多视角策略，实现了对物体姿态配置的持续学习，性能随观察时间和迭代次数提升。

Abstract: Humans can resort to long-form inspection to build intuition on predicting
the 3D configurations of unseen objects. The more we observe the object motion,
the better we get at predicting its 3D state immediately. Existing systems
either optimize underlying representations from multi-view observations or
train a feed-forward predictor from supervised datasets. We introduce
Predict-Optimize-Distill (POD), a self-improving framework that interleaves
prediction and optimization in a mutually reinforcing cycle to achieve better
4D object understanding with increasing observation time. Given a multi-view
object scan and a long-form monocular video of human-object interaction, POD
iteratively trains a neural network to predict local part poses from RGB
frames, uses this predictor to initialize a global optimization which refines
output poses through inverse rendering, then finally distills the results of
optimization back into the model by generating synthetic self-labeled training
data from novel viewpoints. Each iteration improves both the predictive model
and the optimized motion trajectory, creating a virtuous cycle that bootstraps
its own training data to learn about the pose configurations of an object. We
also introduce a quasi-multiview mining strategy for reducing depth ambiguity
by leveraging long video. We evaluate POD on 14 real-world and 5 synthetic
objects with various joint types, including revolute and prismatic joints as
well as multi-body configurations where parts detach or reattach independently.
POD demonstrates significant improvement over a pure optimization baseline
which gets stuck in local minima, particularly for longer videos. We also find
that POD's performance improves with both video length and successive
iterations of the self-improving cycle, highlighting its ability to scale
performance with additional observations and looped refinement.

</details>

### [75] [FRAG: Frame Selection Augmented Generation for Long Video and Long Document Understanding](https://arxiv.org/abs/2504.17447)
*De-An Huang,Subhashree Radhakrishnan,Zhiding Yu,Jan Kautz*

Main category: cs.CV

TLDR: 该论文提出了一种名为FRAG的框架，通过选择输入中的相关帧而非处理长上下文，提升了大型多模态模型（LMMs）在长视频和多页文档任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的长上下文LMMs在模型规模和性能上受限于计算成本，因此作者探索了一种无需长上下文处理的方法。

Method: FRAG框架通过独立评分选择相关帧（Top-K选择），并仅基于所选帧生成最终输出，适用于现有LMMs且无需微调。

Result: 实验表明，FRAG显著提升了LLaVA-OneVision和InternVL2在长视频和文档任务中的性能，达到SOTA水平。

Conclusion: FRAG是一种简单有效的框架，能够在不增加计算负担的情况下显著提升LMMs的长输入处理能力。

Abstract: There has been impressive progress in Large Multimodal Models (LMMs). Recent
works extend these models to long inputs, including multi-page documents and
long videos. However, the model size and performance of these long context
models are still limited due to the computational cost in both training and
inference. In this work, we explore an orthogonal direction and process long
inputs without long context LMMs. We propose Frame Selection Augmented
Generation (FRAG), where the model first selects relevant frames within the
input, and then only generates the final outputs based on the selected frames.
The core of the selection process is done by scoring each frame independently,
which does not require long context processing. The frames with the highest
scores are then selected by a simple Top-K selection. We show that this
frustratingly simple framework is applicable to both long videos and multi-page
documents using existing LMMs without any fine-tuning. We consider two models,
LLaVA-OneVision and InternVL2, in our experiments and show that FRAG
consistently improves the performance and achieves state-of-the-art
performances for both long video and long document understanding. For videos,
FRAG substantially improves InternVL2-76B by 5.8% on MLVU and 3.7% on
Video-MME. For documents, FRAG achieves over 20% improvements on MP-DocVQA
compared with recent LMMs specialized in long document understanding. Code is
available at: https://github.com/NVlabs/FRAG

</details>

### [76] [Unveiling Hidden Vulnerabilities in Digital Human Generation via Adversarial Attacks](https://arxiv.org/abs/2504.17457)
*Zhiying Li,Yeying Jin,Fan Shen,Zhi Liu,Weibin Chen,Pengju Zhang,Xiaomei Zhang,Boyu Chen,Michael Shen,Kejian Wu,Zhaoxin Fan,Jin Dong*

Main category: cs.CV

TLDR: 论文提出了一种名为Tangible Attack (TBA)的新框架，通过Dual Heterogeneous Noise Generator (DHNG)和自定义对抗损失函数，显著提高了对抗攻击在数字人生成模型中的效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注减少估计误差，但忽视了鲁棒性和安全性，导致系统易受对抗攻击。

Method: 使用VAE和ControlNet构建DHNG生成多样化噪声，并通过自定义对抗损失函数优化噪声，迭代优化对抗样本。

Result: TBA将估计误差提高了41.0%，平均改进约17.0%。

Conclusion: 当前EHPS模型存在严重安全漏洞，数字人生成系统需要更强的防御措施。

Abstract: Expressive human pose and shape estimation (EHPS) is crucial for digital
human generation, especially in applications like live streaming. While
existing research primarily focuses on reducing estimation errors, it largely
neglects robustness and security aspects, leaving these systems vulnerable to
adversarial attacks. To address this significant challenge, we propose the
\textbf{Tangible Attack (TBA)}, a novel framework designed to generate
adversarial examples capable of effectively compromising any digital human
generation model. Our approach introduces a \textbf{Dual Heterogeneous Noise
Generator (DHNG)}, which leverages Variational Autoencoders (VAE) and
ControlNet to produce diverse, targeted noise tailored to the original image
features. Additionally, we design a custom \textbf{adversarial loss function}
to optimize the noise, ensuring both high controllability and potent
disruption. By iteratively refining the adversarial sample through
multi-gradient signals from both the noise and the state-of-the-art EHPS model,
TBA substantially improves the effectiveness of adversarial attacks. Extensive
experiments demonstrate TBA's superiority, achieving a remarkable 41.0\%
increase in estimation error, with an average improvement of approximately
17.0\%. These findings expose significant security vulnerabilities in current
EHPS models and highlight the need for stronger defenses in digital human
generation systems.

</details>

### [77] [Enhanced Sample Selection with Confidence Tracking: Identifying Correctly Labeled yet Hard-to-Learn Samples in Noisy Data](https://arxiv.org/abs/2504.17474)
*Weiran Pan,Wei Wei,Feida Zhu,Yong Deng*

Main category: cs.CV

TLDR: 提出一种新的样本选择方法，通过跟踪模型预测置信度的趋势而非仅依赖损失值，以区分正确标注但难学习的样本与错误标注样本，从而提升样本选择的精度和召回率。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将小损失样本视为正确标注，但难学习的正确样本在训练初期也可能表现出高损失，导致样本选择时在精度和召回率之间存在权衡。

Method: 通过跟踪标注标签与其他类别之间的置信度差距，并使用Mann-Kendall Test评估其趋势，若所有置信度差距呈上升趋势，则认为样本可能正确标注。

Result: 在多个标准基准和真实数据集上的实验表明，该方法提升了现有噪声标签学习方法的性能。

Conclusion: 该方法作为一种即插即用组件，能有效缓解样本选择中的精度-召回率权衡问题。

Abstract: We propose a novel sample selection method for image classification in the
presence of noisy labels. Existing methods typically consider small-loss
samples as correctly labeled. However, some correctly labeled samples are
inherently difficult for the model to learn and can exhibit high loss similar
to mislabeled samples in the early stages of training. Consequently, setting a
threshold on per-sample loss to select correct labels results in a trade-off
between precision and recall in sample selection: a lower threshold may miss
many correctly labeled hard-to-learn samples (low recall), while a higher
threshold may include many mislabeled samples (low precision). To address this
issue, our goal is to accurately distinguish correctly labeled yet
hard-to-learn samples from mislabeled ones, thus alleviating the trade-off
dilemma. We achieve this by considering the trends in model prediction
confidence rather than relying solely on loss values. Empirical observations
show that only for correctly labeled samples, the model's prediction confidence
for the annotated labels typically increases faster than for any other classes.
Based on this insight, we propose tracking the confidence gaps between the
annotated labels and other classes during training and evaluating their trends
using the Mann-Kendall Test. A sample is considered potentially correctly
labeled if all its confidence gaps tend to increase. Our method functions as a
plug-and-play component that can be seamlessly integrated into existing sample
selection techniques. Experiments on several standard benchmarks and real-world
datasets demonstrate that our method enhances the performance of existing
methods for learning with noisy labels.

</details>

### [78] [RefVNLI: Towards Scalable Evaluation of Subject-driven Text-to-image Generation](https://arxiv.org/abs/2504.17502)
*Aviv Slobodkin,Hagai Taitelbaum,Yonatan Bitton,Brian Gordon,Michal Sokolik,Nitzan Bitton Guetta,Almog Gueta,Royi Rassin,Itay Laish,Dani Lischinski,Idan Szpektor*

Main category: cs.CV

TLDR: RefVNLI是一种新的评估指标，用于同时评估文本对齐和主题保留，优于现有方法，并显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法在主题驱动的文本到图像生成任务中不可靠，仅评估单一方面或与人类判断不一致。

Method: 基于大规模视频推理基准和图像扰动数据集训练RefVNLI，以同时评估文本对齐和主题保留。

Result: RefVNLI在多个基准测试中表现优异，文本对齐提升6.4分，主题一致性提升8.5分，且与人类偏好一致率达87%。

Conclusion: RefVNLI是一种高效且可靠的评估指标，适用于主题驱动的文本到图像生成任务。

Abstract: Subject-driven text-to-image (T2I) generation aims to produce images that
align with a given textual description, while preserving the visual identity
from a referenced subject image. Despite its broad downstream applicability --
ranging from enhanced personalization in image generation to consistent
character representation in video rendering -- progress in this field is
limited by the lack of reliable automatic evaluation. Existing methods either
assess only one aspect of the task (i.e., textual alignment or subject
preservation), misalign with human judgments, or rely on costly API-based
evaluation. To address this, we introduce RefVNLI, a cost-effective metric that
evaluates both textual alignment and subject preservation in a single
prediction. Trained on a large-scale dataset derived from video-reasoning
benchmarks and image perturbations, RefVNLI outperforms or matches existing
baselines across multiple benchmarks and subject categories (e.g.,
\emph{Animal}, \emph{Object}), achieving up to 6.4-point gains in textual
alignment and 8.5-point gains in subject consistency. It also excels with
lesser-known concepts, aligning with human preferences at over 87\% accuracy.

</details>

### [79] [Mamba-Sea: A Mamba-based Framework with Global-to-Local Sequence Augmentation for Generalizable Medical Image Segmentation](https://arxiv.org/abs/2504.17515)
*Zihan Cheng,Jintao Guo,Jian Zhang,Lei Qi,Luping Zhou,Yinghuan Shi,Yang Gao*

Main category: cs.CV

TLDR: 本文提出了一种基于Mamba架构的新框架Mamba-Sea，用于解决医学图像分割中的分布偏移问题，通过全局到局部的序列增强提升模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有领域泛化（DG）方法主要基于CNN或ViT架构，而Mamba在医学图像分割中表现出色，但其在DG中的应用尚未探索。本文旨在探索Mamba架构在DG中的潜力。

Method: 提出Mamba-Sea框架，结合全局和局部序列增强机制。全局机制模拟不同站点间的外观变化，抑制模型学习域特定信息；局部机制通过扰动连续子序列的令牌风格来增强鲁棒性。

Result: Mamba-Sea在Prostate数据集上首次超过90%的Dice系数，优于之前的SOTA（88.61%）。

Conclusion: Mamba-Sea是首个探索Mamba在医学图像分割DG中应用的工作，展示了其在域偏移问题中的强大鲁棒性和潜力。

Abstract: To segment medical images with distribution shifts, domain generalization
(DG) has emerged as a promising setting to train models on source domains that
can generalize to unseen target domains. Existing DG methods are mainly based
on CNN or ViT architectures. Recently, advanced state space models, represented
by Mamba, have shown promising results in various supervised medical image
segmentation. The success of Mamba is primarily owing to its ability to capture
long-range dependencies while keeping linear complexity with input sequence
length, making it a promising alternative to CNNs and ViTs. Inspired by the
success, in the paper, we explore the potential of the Mamba architecture to
address distribution shifts in DG for medical image segmentation. Specifically,
we propose a novel Mamba-based framework, Mamba-Sea, incorporating
global-to-local sequence augmentation to improve the model's generalizability
under domain shift issues. Our Mamba-Sea introduces a global augmentation
mechanism designed to simulate potential variations in appearance across
different sites, aiming to suppress the model's learning of domain-specific
information. At the local level, we propose a sequence-wise augmentation along
input sequences, which perturbs the style of tokens within random continuous
sub-sequences by modeling and resampling style statistics associated with
domain shifts. To our best knowledge, Mamba-Sea is the first work to explore
the generalization of Mamba for medical image segmentation, providing an
advanced and promising Mamba-based architecture with strong robustness to
domain shifts. Remarkably, our proposed method is the first to surpass a Dice
coefficient of 90% on the Prostate dataset, which exceeds previous SOTA of
88.61%. The code is available at https://github.com/orange-czh/Mamba-Sea.

</details>

### [80] [Towards One-Stage End-to-End Table Structure Recognition with Parallel Regression for Diverse Scenarios](https://arxiv.org/abs/2504.17522)
*Anyi Xiao,Cihui Yang*

Main category: cs.CV

TLDR: TableCenterNet是一种单阶段端到端表格结构解析网络，统一了表格空间和逻辑结构的预测，通过共享特征提取层和任务特定解码的协同架构，实现了高效训练和推理。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨场景适应性、鲁棒性和计算效率之间难以平衡，TableCenterNet旨在解决这一问题。

Method: 提出TableCenterNet，将表格空间和逻辑结构的预测统一为并行回归任务，并通过共享特征提取层和任务特定解码的协同架构学习单元格的空间-逻辑位置映射规律。

Result: 在基准数据集上，TableCenterNet在TableGraph-24k数据集上实现了最先进的性能。

Conclusion: TableCenterNet是一种高效且易于训练的表格结构解析方法，适用于多样化场景。

Abstract: Table structure recognition aims to parse tables in unstructured data into
machine-understandable formats. Recent methods address this problem through a
two-stage process or optimized one-stage approaches. However, these methods
either require multiple networks to be serially trained and perform more
time-consuming sequential decoding, or rely on complex post-processing
algorithms to parse the logical structure of tables. They struggle to balance
cross-scenario adaptability, robustness, and computational efficiency. In this
paper, we propose a one-stage end-to-end table structure parsing network called
TableCenterNet. This network unifies the prediction of table spatial and
logical structure into a parallel regression task for the first time, and
implicitly learns the spatial-logical location mapping laws of cells through a
synergistic architecture of shared feature extraction layers and task-specific
decoding. Compared with two-stage methods, our method is easier to train and
faster to infer. Experiments on benchmark datasets show that TableCenterNet can
effectively parse table structures in diverse scenarios and achieve
state-of-the-art performance on the TableGraph-24k dataset. Code is available
at https://github.com/dreamy-xay/TableCenterNet.

</details>

### [81] [ESDiff: Encoding Strategy-inspired Diffusion Model with Few-shot Learning for Color Image Inpainting](https://arxiv.org/abs/2504.17524)
*Junyan Zhang,Yan Li,Mengxiao Geng,Liu Shi,Qiegen Liu*

Main category: cs.CV

TLDR: 本文提出了一种基于编码策略的扩散模型，用于小样本学习的彩色图像修复，通过虚拟掩码和高维对象构建，提升了修复质量和细节保留。


<details>
  <summary>Details</summary>
Motivation: 传统图像修复方法难以保留复杂细节，而深度学习模型需要大量训练数据。本文旨在解决这些问题。

Method: 采用编码策略的扩散模型，利用虚拟掩码构建高维对象，结合低秩方法和迭代修复，实现精确信息输出。

Result: 实验表明，该方法在定量指标上优于现有技术，修复图像的纹理和结构完整性更优。

Conclusion: 该方法通过小样本学习实现了高质量的图像修复，为复杂场景下的图像修复提供了新思路。

Abstract: Image inpainting is a technique used to restore missing or damaged regions of
an image. Traditional methods primarily utilize information from adjacent
pixels for reconstructing missing areas, while they struggle to preserve
complex details and structures. Simultaneously, models based on deep learning
necessitate substantial amounts of training data. To address this challenge, an
encoding strategy-inspired diffusion model with few-shot learning for color
image inpainting is proposed in this paper. The main idea of this novel
encoding strategy is the deployment of a "virtual mask" to construct
high-dimensional objects through mutual perturbations between channels. This
approach enables the diffusion model to capture diverse image representations
and detailed features from limited training samples. Moreover, the encoding
strategy leverages redundancy between channels, integrates with low-rank
methods during iterative inpainting, and incorporates the diffusion model to
achieve accurate information output. Experimental results indicate that our
method exceeds current techniques in quantitative metrics, and the
reconstructed images quality has been improved in aspects of texture and
structural integrity, leading to more precise and coherent results.

</details>

### [82] [Text-to-Image Alignment in Denoising-Based Models through Step Selection](https://arxiv.org/abs/2504.17525)
*Paul Grimal,Hervé Le Borgne,Olivier Ferret*

Main category: cs.CV

TLDR: 提出了一种在关键去噪步骤选择性增强信号的方法，优化基于输入语义的图像生成。


<details>
  <summary>Details</summary>
Motivation: 解决视觉生成AI模型中文本-图像对齐和推理限制的问题。

Method: 在后期去噪阶段调整信号，而非早期阶段，以优化生成结果。

Result: 在Diffusion和Flow Matching模型上实现了语义对齐图像的最先进性能。

Conclusion: 明智选择采样阶段对提升性能和图像对齐至关重要。

Abstract: Visual generative AI models often encounter challenges related to text-image
alignment and reasoning limitations. This paper presents a novel method for
selectively enhancing the signal at critical denoising steps, optimizing image
generation based on input semantics. Our approach addresses the shortcomings of
early-stage signal modifications, demonstrating that adjustments made at later
stages yield superior results. We conduct extensive experiments to validate the
effectiveness of our method in producing semantically aligned images on
Diffusion and Flow Matching model, achieving state-of-the-art performance. Our
results highlight the importance of a judicious choice of sampling stage to
improve performance and overall image alignment.

</details>

### [83] [An Explainable Nature-Inspired Framework for Monkeypox Diagnosis: Xception Features Combined with NGBoost and African Vultures Optimization Algorithm](https://arxiv.org/abs/2504.17540)
*Ahmadreza Shateri,Negar Nourani,Morteza Dorrigiv,Hamid Nasiri*

Main category: cs.CV

TLDR: 提出了一种基于深度学习的猴痘皮肤病变图像自动检测框架，结合迁移学习、降维和优化算法，实现了高精度诊断。


<details>
  <summary>Details</summary>
Motivation: 猴痘在全球非传统流行区域的传播引发公共卫生担忧，早期准确诊断对疾病管理至关重要。

Method: 使用Xception架构提取特征，PCA降维，NGBoost分类，并通过AVOA优化超参数。

Result: 模型准确率达97.53%，F1-score为97.72%，AUC为97.47%，性能优异。

Conclusion: 该框架为资源有限环境提供了高效诊断工具，并增强模型可解释性。

Abstract: The recent global spread of monkeypox, particularly in regions where it has
not historically been prevalent, has raised significant public health concerns.
Early and accurate diagnosis is critical for effective disease management and
control. In response, this study proposes a novel deep learning-based framework
for the automated detection of monkeypox from skin lesion images, leveraging
the power of transfer learning, dimensionality reduction, and advanced machine
learning techniques. We utilize the newly developed Monkeypox Skin Lesion
Dataset (MSLD), which includes images of monkeypox, chickenpox, and measles, to
train and evaluate our models. The proposed framework employs the Xception
architecture for deep feature extraction, followed by Principal Component
Analysis (PCA) for dimensionality reduction, and the Natural Gradient Boosting
(NGBoost) algorithm for classification. To optimize the model's performance and
generalization, we introduce the African Vultures Optimization Algorithm (AVOA)
for hyperparameter tuning, ensuring efficient exploration of the parameter
space. Our results demonstrate that the proposed AVOA-NGBoost model achieves
state-of-the-art performance, with an accuracy of 97.53%, F1-score of 97.72%
and an AUC of 97.47%. Additionally, we enhance model interpretability using
Grad-CAM and LIME techniques, providing insights into the decision-making
process and highlighting key features influencing classification. This
framework offers a highly precise and efficient diagnostic tool, potentially
aiding healthcare providers in early detection and diagnosis, particularly in
resource-constrained environments.

</details>

### [84] [When Gaussian Meets Surfel: Ultra-fast High-fidelity Radiance Field Rendering](https://arxiv.org/abs/2504.17545)
*Keyang Ye,Tianjia Shao,Kun Zhou*

Main category: cs.CV

TLDR: Gaussian-enhanced Surfels (GESs) 是一种双尺度表示方法，用于辐射场渲染，结合2D不透明面元（surfels）和3D高斯分布，实现快速、高保真的渲染。


<details>
  <summary>Details</summary>
Motivation: 现有的辐射场渲染方法在速度和图像质量之间存在权衡，GESs旨在通过双尺度表示解决这一问题，同时提升渲染速度和视觉效果。

Method: GESs使用2D面元表示粗尺度几何和外观，3D高斯分布补充细节。渲染分为两阶段：面元光栅化和高斯分布叠加。优化采用从粗到细的策略。

Result: GESs实现了超快速的渲染，避免了视角变化时的闪烁问题，并通过扩展支持抗锯齿、加速渲染和紧凑存储。

Conclusion: GESs作为一种新型表示方法，在超快速高保真辐射场渲染中表现出色，推动了该领域的技术进步。

Abstract: We introduce Gaussian-enhanced Surfels (GESs), a bi-scale representation for
radiance field rendering, wherein a set of 2D opaque surfels with
view-dependent colors represent the coarse-scale geometry and appearance of
scenes, and a few 3D Gaussians surrounding the surfels supplement fine-scale
appearance details. The rendering with GESs consists of two passes -- surfels
are first rasterized through a standard graphics pipeline to produce depth and
color maps, and then Gaussians are splatted with depth testing and color
accumulation on each pixel order independently. The optimization of GESs from
multi-view images is performed through an elaborate coarse-to-fine procedure,
faithfully capturing rich scene appearance. The entirely sorting-free rendering
of GESs not only achieves very fast rates, but also produces view-consistent
images, successfully avoiding popping artifacts under view changes. The basic
GES representation can be easily extended to achieve anti-aliasing in rendering
(Mip-GES), boosted rendering speeds (Speedy-GES) and compact storage
(Compact-GES), and reconstruct better scene geometries by replacing 3D
Gaussians with 2D Gaussians (2D-GES). Experimental results show that GESs
advance the state-of-the-arts as a compelling representation for ultra-fast
high-fidelity radiance field rendering.

</details>

### [85] [A Comprehensive Survey of Knowledge-Based Vision Question Answering Systems: The Lifecycle of Knowledge in Visual Reasoning Task](https://arxiv.org/abs/2504.17547)
*Jiaqi Deng,Zonghan Wu,Huan Huo,Guandong Xu*

Main category: cs.CV

TLDR: 这篇论文是关于知识驱动的视觉问答（KB-VQA）的综述，系统整理了现有方法，并提出了知识表示、检索和推理的分类框架。


<details>
  <summary>Details</summary>
Motivation: KB-VQA结合视觉、文本和广泛知识，具有重要应用价值，但缺乏系统综述。本文旨在填补这一空白。

Method: 建立KB-VQA的结构化分类法，分为知识表示、检索和推理三个阶段，并探讨知识整合技术。

Result: 提出了KB-VQA的分类框架，总结了现有方法，并指出了未来研究方向。

Conclusion: 本文为KB-VQA的研究提供了系统综述和未来发展方向，推动了该领域的进步。

Abstract: Knowledge-based Vision Question Answering (KB-VQA) extends general Vision
Question Answering (VQA) by not only requiring the understanding of visual and
textual inputs but also extensive range of knowledge, enabling significant
advancements across various real-world applications. KB-VQA introduces unique
challenges, including the alignment of heterogeneous information from diverse
modalities and sources, the retrieval of relevant knowledge from noisy or
large-scale repositories, and the execution of complex reasoning to infer
answers from the combined context. With the advancement of Large Language
Models (LLMs), KB-VQA systems have also undergone a notable transformation,
where LLMs serve as powerful knowledge repositories, retrieval-augmented
generators and strong reasoners. Despite substantial progress, no comprehensive
survey currently exists that systematically organizes and reviews the existing
KB-VQA methods. This survey aims to fill this gap by establishing a structured
taxonomy of KB-VQA approaches, and categorizing the systems into main stages:
knowledge representation, knowledge retrieval, and knowledge reasoning. By
exploring various knowledge integration techniques and identifying persistent
challenges, this work also outlines promising future research directions,
providing a foundation for advancing KB-VQA models and their applications.

</details>

### [86] [Unsupervised Urban Land Use Mapping with Street View Contrastive Clustering and a Geographical Prior](https://arxiv.org/abs/2504.17551)
*Lin Che,Yizi Chen,Tanhua Jin,Martin Raubal,Konrad Schindler,Peter Kiefer*

Main category: cs.CV

TLDR: 该论文提出了一种基于无监督对比聚类模型的街景图像土地利用分类方法，结合地理先验知识，提高了分类性能，并展示了在两个城市数据集上的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有遥感技术在复杂城市环境中缺乏精度，而街景图像能提供地面细节，但现有方法依赖监督分类，面临标注数据稀缺和泛化能力不足的挑战。

Method: 提出了一种无监督对比聚类模型，结合地理先验知识，并通过简单的视觉分配实现土地利用分类。

Result: 实验证明，该方法能从两个城市的街景图像数据集中生成土地利用地图，具有灵活性和可扩展性。

Conclusion: 该方法基于地理空间数据的空间一致性，适用于街景图像可用的多种场景，为无监督土地利用分类提供了可扩展的解决方案。

Abstract: Urban land use classification and mapping are critical for urban planning,
resource management, and environmental monitoring. Existing remote sensing
techniques often lack precision in complex urban environments due to the
absence of ground-level details. Unlike aerial perspectives, street view images
provide a ground-level view that captures more human and social activities
relevant to land use in complex urban scenes. Existing street view-based
methods primarily rely on supervised classification, which is challenged by the
scarcity of high-quality labeled data and the difficulty of generalizing across
diverse urban landscapes. This study introduces an unsupervised contrastive
clustering model for street view images with a built-in geographical prior, to
enhance clustering performance. When combined with a simple visual assignment
of the clusters, our approach offers a flexible and customizable solution to
land use mapping, tailored to the specific needs of urban planners. We
experimentally show that our method can generate land use maps from geotagged
street view image datasets of two cities. As our methodology relies on the
universal spatial coherence of geospatial data ("Tobler's law"), it can be
adapted to various settings where street view images are available, to enable
scalable, unsupervised land use mapping and updating. The code will be
available at https://github.com/lin102/CCGP.

</details>

### [87] [Occlusion-Aware Self-Supervised Monocular Depth Estimation for Weak-Texture Endoscopic Images](https://arxiv.org/abs/2504.17582)
*Zebo Huang,Yinghui Wang*

Main category: cs.CV

TLDR: 提出了一种针对内窥镜场景的自监督单目深度估计网络，通过遮挡感知框架和语义分割改进深度重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设光照一致，但内窥镜场景中动态光照和遮挡导致几何解释错误和不可靠的自监督信号，影响深度估计质量。

Method: 引入遮挡感知自监督框架：1) 使用遮挡掩码进行数据增强，生成伪标签；2) 结合非负矩阵分解的语义分割，提升纹理缺失区域的深度估计。

Result: 在SCARED数据集上达到SOTA性能，并在Endo-SLAM和SERV-CT数据集上表现出强泛化能力。

Conclusion: 该方法有效解决了内窥镜场景中的光照和遮挡问题，提升了深度估计的鲁棒性和准确性。

Abstract: We propose a self-supervised monocular depth estimation network tailored for
endoscopic scenes, aiming to infer depth within the gastrointestinal tract from
monocular images. Existing methods, though accurate, typically assume
consistent illumination, which is often violated due to dynamic lighting and
occlusions caused by GI motility. These variations lead to incorrect geometric
interpretations and unreliable self-supervised signals, degrading depth
reconstruction quality. To address this, we introduce an occlusion-aware
self-supervised framework. First, we incorporate an occlusion mask for data
augmentation, generating pseudo-labels by simulating viewpoint-dependent
occlusion scenarios. This enhances the model's ability to learn robust depth
features under partial visibility. Second, we leverage semantic segmentation
guided by non-negative matrix factorization, clustering convolutional
activations to generate pseudo-labels in texture-deprived regions, thereby
improving segmentation accuracy and mitigating information loss from lighting
changes. Experimental results on the SCARED dataset show that our method
achieves state-of-the-art performance in self-supervised depth estimation.
Additionally, evaluations on the Endo-SLAM and SERV-CT datasets demonstrate
strong generalization across diverse endoscopic environments.

</details>

### [88] [Tamper-evident Image using JPEG Fixed Points](https://arxiv.org/abs/2504.17594)
*Zhaofeng Si,Siwei Lyu*

Main category: cs.CV

TLDR: JPEG压缩存在固定点现象，经过多次压缩和解压后图像趋于稳定，可用于防篡改。


<details>
  <summary>Details</summary>
Motivation: 研究JPEG压缩中的固定点现象，探索其在图像防篡改中的应用。

Method: 分析JPEG压缩和解压过程，证明固定点的存在及其特性。

Result: 固定点可在几次迭代内达到，且能保持图像视觉质量，用于开发防篡改方法。

Conclusion: 固定点现象为图像防篡改提供了新思路，具有实际应用潜力。

Abstract: An intriguing phenomenon about JPEG compression has been observed since two
decades ago- after repeating JPEG compression and decompression, it leads to a
stable image that does not change anymore, which is a fixed point. In this
work, we prove the existence of fixed points in the essential JPEG procedures.
We analyze JPEG compression and decompression processes, revealing the
existence of fixed points that can be reached within a few iterations. These
fixed points are diverse and preserve the image's visual quality, ensuring
minimal distortion. This result is used to develop a method to create a
tamper-evident image from the original authentic image, which can expose
tampering operations by showing deviations from the fixed point image.

</details>

### [89] [RGB-D Tracking via Hierarchical Modality Aggregation and Distribution Network](https://arxiv.org/abs/2504.17595)
*Boyue Xu,Yi Xu,Ruichao Hou,Jia Bei,Tongwei Ren,Gangshan Wu*

Main category: cs.CV

TLDR: HMAD网络通过层次化模态聚合与分布，提升RGB-D跟踪的鲁棒性和实时性能。


<details>
  <summary>Details</summary>
Motivation: 当前RGB-D跟踪器效率低且仅关注单层特征，导致融合鲁棒性差且速度慢，无法满足实际应用需求。

Method: 提出HMAD网络，利用RGB和深度模态的特征表示优势，采用层次化方法进行特征分布与融合。

Result: 在多个RGB-D数据集上实现最优性能，并在实时场景中有效应对多种跟踪挑战。

Conclusion: HMAD显著提升了RGB-D跟踪的鲁棒性和实时性，适用于实际应用。

Abstract: The integration of dual-modal features has been pivotal in advancing
RGB-Depth (RGB-D) tracking. However, current trackers are less efficient and
focus solely on single-level features, resulting in weaker robustness in fusion
and slower speeds that fail to meet the demands of real-world applications. In
this paper, we introduce a novel network, denoted as HMAD (Hierarchical
Modality Aggregation and Distribution), which addresses these challenges. HMAD
leverages the distinct feature representation strengths of RGB and depth
modalities, giving prominence to a hierarchical approach for feature
distribution and fusion, thereby enhancing the robustness of RGB-D tracking.
Experimental results on various RGB-D datasets demonstrate that HMAD achieves
state-of-the-art performance. Moreover, real-world experiments further validate
HMAD's capacity to effectively handle a spectrum of tracking challenges in
real-time scenarios.

</details>

### [90] [STCL:Curriculum learning Strategies for deep learning image steganography models](https://arxiv.org/abs/2504.17609)
*Fengchun Liu,Tong Zhang,Chunying Zhang*

Main category: cs.CV

TLDR: 本文提出了一种基于课程学习的隐写训练策略（STCL），通过逐步从易到难的图像训练，提升深度学习隐写模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度学习隐写模型生成的图像质量差、网络收敛慢的问题。

Method: 1. 基于教师模型的难度评估策略；2. 基于拐点的训练调度策略。

Result: 在ALASKA2、VOC2012和ImageNet数据集上，模型性能显著提升，PSNR、SSIM和解码准确率高，隐写分析分数低。

Conclusion: STCL策略有效提升了隐写模型的性能，适用于多种算法框架。

Abstract: Aiming at the problems of poor quality of steganographic images and slow
network convergence of image steganography models based on deep learning, this
paper proposes a Steganography Curriculum Learning training strategy (STCL) for
deep learning image steganography models. So that only easy images are selected
for training when the model has poor fitting ability at the initial stage, and
gradually expand to more difficult images, the strategy includes a difficulty
evaluation strategy based on the teacher model and an knee point-based training
scheduling strategy. Firstly, multiple teacher models are trained, and the
consistency of the quality of steganographic images under multiple teacher
models is used as the difficulty score to construct the training subsets from
easy to difficult. Secondly, a training control strategy based on knee points
is proposed to reduce the possibility of overfitting on small training sets and
accelerate the training process. Experimental results on three large public
datasets, ALASKA2, VOC2012 and ImageNet, show that the proposed image
steganography scheme is able to improve the model performance under multiple
algorithmic frameworks, which not only has a high PSNR, SSIM score, and
decoding accuracy, but also the steganographic images generated by the model
under the training of the STCL strategy have a low steganography analysis
scores. You can find our code at
\href{https://github.com/chaos-boops/STCL}{https://github.com/chaos-boops/STCL}.

</details>

### [91] [Enhancing CNNs robustness to occlusions with bioinspired filters for border completion](https://arxiv.org/abs/2504.17619)
*Catarina P. Coutinho,Aneeqa Merhab,Janko Petkovic,Ferdinando Zanchetta,Rita Fioresi*

Main category: cs.CV

TLDR: 通过模拟视觉皮层机制设计CNN滤波器，改进LeNet 5在遮挡MNIST图像上的准确率。


<details>
  <summary>Details</summary>
Motivation: 利用视觉皮层边界补全的数学模型，提升CNN在遮挡图像上的性能。

Method: 基于视觉皮层机制设计自定义滤波器，应用于改进的LeNet 5架构。

Result: 在遮挡MNIST图像测试中，准确率显著提升。

Conclusion: 视觉皮层机制建模为CNN滤波器设计提供了有效方法，提升了模型性能。

Abstract: We exploit the mathematical modeling of the visual cortex mechanism for
border completion to define custom filters for CNNs. We see a consistent
improvement in performance, particularly in accuracy, when our modified LeNet 5
is tested with occluded MNIST images.

</details>

### [92] [Improving Open-World Object Localization by Discovering Background](https://arxiv.org/abs/2504.17626)
*Ashish Singh,Michael J. Jones,Kuan-Chuan Peng,Anoop Cherian,Moitreya Chatterjee,Erik Learned-Miller*

Main category: cs.CV

TLDR: 论文提出了一种利用背景信息指导物体定位的新框架，通过识别非判别性区域来提升开放世界中的物体定位性能。


<details>
  <summary>Details</summary>
Motivation: 解决开放世界中物体定位问题，即在训练时仅使用有限类别边界框信息的情况下，推理时定位所有类别（包括未见类别）的物体。

Method: 提出了一种新颖框架，通过发现图像中的背景区域（非判别性区域），并训练物体提议网络避免在这些区域检测物体。

Result: 在标准基准测试中，该方法显著优于现有最优方法。

Conclusion: 通过利用背景信息，该方法有效提升了开放世界物体定位的性能。

Abstract: Our work addresses the problem of learning to localize objects in an
open-world setting, i.e., given the bounding box information of a limited
number of object classes during training, the goal is to localize all objects,
belonging to both the training and unseen classes in an image, during
inference. Towards this end, recent work in this area has focused on improving
the characterization of objects either explicitly by proposing new objective
functions (localization quality) or implicitly using object-centric
auxiliary-information, such as depth information, pixel/region affinity map
etc. In this work, we address this problem by incorporating background
information to guide the learning of the notion of objectness. Specifically, we
propose a novel framework to discover background regions in an image and train
an object proposal network to not detect any objects in these regions. We
formulate the background discovery task as that of identifying image regions
that are not discriminative, i.e., those that are redundant and constitute low
information content. We conduct experiments on standard benchmarks to showcase
the effectiveness of our proposed approach and observe significant improvements
over the previous state-of-the-art approaches for this task.

</details>

### [93] [A Guide to Structureless Visual Localization](https://arxiv.org/abs/2504.17636)
*Vojtech Panek,Qunjie Zhou,Yaqing Ding,Sérgio Agostinho,Zuzana Kukelova,Torsten Sattler,Laura Leal-Taixé*

Main category: cs.CV

TLDR: 本文首次全面讨论和比较了无结构视觉定位方法，发现基于经典几何推理的方法在姿态精度上优于基于姿态回归的方法，但灵活性略逊于基于结构的方法。


<details>
  <summary>Details</summary>
Motivation: 视觉定位算法是自动驾驶和增强现实等应用的核心组件，但现有基于结构的方法灵活性不足，而无结构方法的研究较少，本文旨在填补这一空白。

Method: 本文比较了多种无结构定位方法，包括基于经典绝对或半广义相对姿态估计的方法，以及基于姿态回归的方法。

Result: 实验表明，基于经典几何推理的方法在姿态精度上显著优于基于姿态回归的方法，但与基于结构的方法相比，精度稍低。

Conclusion: 无结构方法在灵活性上有优势，但精度略低，为未来研究提供了有趣的方向。

Abstract: Visual localization algorithms, i.e., methods that estimate the camera pose
of a query image in a known scene, are core components of many applications,
including self-driving cars and augmented / mixed reality systems.
State-of-the-art visual localization algorithms are structure-based, i.e., they
store a 3D model of the scene and use 2D-3D correspondences between the query
image and 3D points in the model for camera pose estimation. While such
approaches are highly accurate, they are also rather inflexible when it comes
to adjusting the underlying 3D model after changes in the scene. Structureless
localization approaches represent the scene as a database of images with known
poses and thus offer a much more flexible representation that can be easily
updated by adding or removing images. Although there is a large amount of
literature on structure-based approaches, there is significantly less work on
structureless methods. Hence, this paper is dedicated to providing the, to the
best of our knowledge, first comprehensive discussion and comparison of
structureless methods. Extensive experiments show that approaches that use a
higher degree of classical geometric reasoning generally achieve higher pose
accuracy. In particular, approaches based on classical absolute or
semi-generalized relative pose estimation outperform very recent methods based
on pose regression by a wide margin. Compared with state-of-the-art
structure-based approaches, the flexibility of structureless methods comes at
the cost of (slightly) lower pose accuracy, indicating an interesting direction
for future work.

</details>

### [94] [CLIPSE -- a minimalistic CLIP-based image search engine for research](https://arxiv.org/abs/2504.17643)
*Steve Göring*

Main category: cs.CV

TLDR: CLIPSE是一个基于CLIP嵌入的自托管图像搜索引擎，主要用于研究，设计简单且易于扩展。


<details>
  <summary>Details</summary>
Motivation: 为研究提供一个简单高效的图像搜索工具。

Method: 使用CLIP嵌入处理图像和文本查询，设计简单框架。

Result: 在小型数据集上表现良好，大型数据集需分布式处理。

Conclusion: CLIPSE适合小型数据集，大型数据集需分布式扩展。

Abstract: A brief overview of CLIPSE, a self-hosted image search engine with the main
application of research, is provided. In general, CLIPSE uses CLIP embeddings
to process the images and also the text queries. The overall framework is
designed with simplicity to enable easy extension and usage. Two benchmark
scenarios are described and evaluated, covering indexing and querying time. It
is shown that CLIPSE is capable of handling smaller datasets; for larger
datasets, a distributed approach with several instances should be considered.

</details>

### [95] [DiMeR: Disentangled Mesh Reconstruction Model](https://arxiv.org/abs/2504.17670)
*Lutao Jiang,Jiantao Lin,Kanghao Chen,Wenhang Ge,Xin Yang,Yifan Jiang,Yuanhuiyi Lyu,Xu Zheng,Yingcong Chen*

Main category: cs.CV

TLDR: DiMeR是一种新型的双流解耦前馈模型，用于稀疏视图网格重建，通过分离几何和纹理部分，显著提升了重建性能。


<details>
  <summary>Details</summary>
Motivation: RGB图像在几何重建中可能导致训练目标冲突且缺乏清晰性，因此需要一种更有效的方法。

Method: DiMeR将输入和框架解耦为几何和纹理部分，使用法线图作为几何分支的输入，并改进网格提取算法。

Result: 在多个任务中表现优异，Chamfer Distance在GSO和OmniObject3D数据集上提升超过30%。

Conclusion: DiMeR通过解耦设计显著提升了稀疏视图网格重建的性能，优于现有方法。

Abstract: With the advent of large-scale 3D datasets, feed-forward 3D generative
models, such as the Large Reconstruction Model (LRM), have gained significant
attention and achieved remarkable success. However, we observe that RGB images
often lead to conflicting training objectives and lack the necessary clarity
for geometry reconstruction. In this paper, we revisit the inductive biases
associated with mesh reconstruction and introduce DiMeR, a novel disentangled
dual-stream feed-forward model for sparse-view mesh reconstruction. The key
idea is to disentangle both the input and framework into geometry and texture
parts, thereby reducing the training difficulty for each part according to the
Principle of Occam's Razor. Given that normal maps are strictly consistent with
geometry and accurately capture surface variations, we utilize normal maps as
exclusive input for the geometry branch to reduce the complexity between the
network's input and output. Moreover, we improve the mesh extraction algorithm
to introduce 3D ground truth supervision. As for texture branch, we use RGB
images as input to obtain the textured mesh. Overall, DiMeR demonstrates robust
capabilities across various tasks, including sparse-view reconstruction,
single-image-to-3D, and text-to-3D. Numerous experiments show that DiMeR
significantly outperforms previous methods, achieving over 30% improvement in
Chamfer Distance on the GSO and OmniObject3D dataset.

</details>

### [96] [PICO: Reconstructing 3D People In Contact with Objects](https://arxiv.org/abs/2504.17695)
*Alpár Cseke,Shashank Tripathi,Sai Kumar Dwivedi,Arjun Lakshmipathy,Agniv Chatterjee,Michael J. Black,Dimitrios Tzionas*

Main category: cs.CV

TLDR: 论文提出了一种从单张彩色图像中恢复3D人-物交互（HOI）的方法，通过新数据集PICO-db和优化方法PICO-fit，解决了深度模糊、遮挡和物体多样性等问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在受控环境下效果有限，无法泛化到自然图像和新物体类别。本文旨在开发一种适用于自然场景和未知物体的方法。

Method: 1. 构建PICO-db数据集，通过视觉基础模型检索3D物体网格，并用新颖的投影方法标注密集接触。2. 提出PICO-fit方法，通过渲染-比较优化拟合3D人体和物体网格。

Result: PICO-fit能够处理多种现有方法无法应对的物体类别，显著提升了HOI理解的泛化能力。

Conclusion: 该方法为自然场景中的HOI理解提供了可扩展的解决方案，数据和代码已开源。

Abstract: Recovering 3D Human-Object Interaction (HOI) from single color images is
challenging due to depth ambiguities, occlusions, and the huge variation in
object shape and appearance. Thus, past work requires controlled settings such
as known object shapes and contacts, and tackles only limited object classes.
Instead, we need methods that generalize to natural images and novel object
classes. We tackle this in two main ways: (1) We collect PICO-db, a new dataset
of natural images uniquely paired with dense 3D contact on both body and object
meshes. To this end, we use images from the recent DAMON dataset that are
paired with contacts, but these contacts are only annotated on a canonical 3D
body. In contrast, we seek contact labels on both the body and the object. To
infer these given an image, we retrieve an appropriate 3D object mesh from a
database by leveraging vision foundation models. Then, we project DAMON's body
contact patches onto the object via a novel method needing only 2 clicks per
patch. This minimal human input establishes rich contact correspondences
between bodies and objects. (2) We exploit our new dataset of contact
correspondences in a novel render-and-compare fitting method, called PICO-fit,
to recover 3D body and object meshes in interaction. PICO-fit infers contact
for the SMPL-X body, retrieves a likely 3D object mesh and contact from PICO-db
for that object, and uses the contact to iteratively fit the 3D body and object
meshes to image evidence via optimization. Uniquely, PICO-fit works well for
many object categories that no existing method can tackle. This is crucial to
enable HOI understanding to scale in the wild. Our data and code are available
at https://pico.is.tue.mpg.de.

</details>

### [97] [Hierarchical and Multimodal Data for Daily Activity Understanding](https://arxiv.org/abs/2504.17696)
*Ghazal Kaviani,Yavuz Yarici,Seulgi Kim,Mohit Prabhushankar,Ghassan AlRegib,Mashhour Solh,Ameya Patil*

Main category: cs.CV

TLDR: DARai是一个多模态、分层标注的数据集，用于理解真实环境中的人类活动，包含50名参与者在10种环境中的200小时多传感器数据。


<details>
  <summary>Details</summary>
Motivation: 研究人类活动的复杂性，支持多模态传感器融合和分层活动识别。

Method: 构建包含脚本和非脚本活动的数据集，标注分为三个层次（L1独立任务、L2共享动作、L3执行步骤），并进行多模态实验。

Result: 实验展示了DARai在识别、定位和预测活动中的价值，并揭示了单个传感器的局限性。

Conclusion: DARai为人类中心应用提供了重要挑战和解决方案，数据集和代码已公开。

Abstract: Daily Activity Recordings for Artificial Intelligence (DARai, pronounced
"Dahr-ree") is a multimodal, hierarchically annotated dataset constructed to
understand human activities in real-world settings. DARai consists of
continuous scripted and unscripted recordings of 50 participants in 10
different environments, totaling over 200 hours of data from 20 sensors
including multiple camera views, depth and radar sensors, wearable inertial
measurement units (IMUs), electromyography (EMG), insole pressure sensors,
biomonitor sensors, and gaze tracker.
  To capture the complexity in human activities, DARai is annotated at three
levels of hierarchy: (i) high-level activities (L1) that are independent tasks,
(ii) lower-level actions (L2) that are patterns shared between activities, and
(iii) fine-grained procedures (L3) that detail the exact execution steps for
actions. The dataset annotations and recordings are designed so that 22.7% of
L2 actions are shared between L1 activities and 14.2% of L3 procedures are
shared between L2 actions. The overlap and unscripted nature of DARai allows
counterfactual activities in the dataset.
  Experiments with various machine learning models showcase the value of DARai
in uncovering important challenges in human-centered applications.
Specifically, we conduct unimodal and multimodal sensor fusion experiments for
recognition, temporal localization, and future action anticipation across all
hierarchical annotation levels. To highlight the limitations of individual
sensors, we also conduct domain-variant experiments that are enabled by DARai's
multi-sensor and counterfactual activity design setup.
  The code, documentation, and dataset are available at the dedicated DARai
website:
https://alregib.ece.gatech.edu/software-and-datasets/darai-daily-activity-recordings-for-artificial-intelligence-and-machine-learning/

</details>

### [98] [Generative Fields: Uncovering Hierarchical Feature Control for StyleGAN via Inverted Receptive Fields](https://arxiv.org/abs/2504.17712)
*Zhuo He,Paul Henderson,Nicolas Pugeault*

Main category: cs.CV

TLDR: 论文提出了一种基于生成场理论的新方法，通过通道风格潜在空间S改进StyleGAN的图像编辑能力，解决了传统W空间表达受限的问题。


<details>
  <summary>Details</summary>
Motivation: StyleGAN在生成高真实性人脸方面表现出色，但其低维潜在空间的强纠缠性导致生成图像特征难以控制。传统方法在W空间调制采样仍存在表达受限和预训练需求的问题。

Method: 引入生成场理论解释StyleGAN的分层特征合成，并提出基于通道风格潜在空间S的新图像编辑流程，利用CNN的固有结构特征实现解耦控制。

Result: 新方法在StyleGAN中实现了对特征合成的解耦控制，提升了图像编辑的灵活性和效果。

Conclusion: 生成场理论和通道风格潜在空间S为StyleGAN的图像编辑提供了更高效和灵活的方法。

Abstract: StyleGAN has demonstrated the ability of GANs to synthesize highly-realistic
faces of imaginary people from random noise. One limitation of GAN-based image
generation is the difficulty of controlling the features of the generated
image, due to the strong entanglement of the low-dimensional latent space.
Previous work that aimed to control StyleGAN with image or text prompts
modulated sampling in W latent space, which is more expressive than Z latent
space. However, W space still has restricted expressivity since it does not
control the feature synthesis directly; also the feature embedding in W space
requires a pre-training process to reconstruct the style signal, limiting its
application. This paper introduces the concept of "generative fields" to
explain the hierarchical feature synthesis in StyleGAN, inspired by the
receptive fields of convolution neural networks (CNNs). Additionally, we
propose a new image editing pipeline for StyleGAN using generative field theory
and the channel-wise style latent space S, utilizing the intrinsic structural
feature of CNNs to achieve disentangled control of feature synthesis at
synthesis time.

</details>

### [99] [DPMambaIR:All-in-One Image Restoration via Degradation-Aware Prompt State Space Model](https://arxiv.org/abs/2504.17732)
*Zhanwen Liu,Sai Zhou,Yuchao Dai,Yang Wang,Yisheng An,Xiangmo Zhao*

Main category: cs.CV

TLDR: DPMambaIR是一种新型的一体化图像修复框架，通过细粒度建模和高效全局集成解决多任务冲突，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要为每种图像退化类型设计专用模型，成本高且复杂。现有方法缺乏细粒度建模且难以平衡多任务冲突。

Method: 提出DPMambaIR框架，结合DP-SSM（退化感知提示状态空间模型）和HEB（高频增强块），实现细粒度建模和高效全局集成。

Result: 在包含七种退化类型的混合数据集上，DPMambaIR达到PSNR 27.69dB和SSIM 0.893的最佳性能。

Conclusion: DPMambaIR作为一种统一解决方案，在一体化图像修复中展现出潜力和优越性。

Abstract: All-in-One image restoration aims to address multiple image degradation
problems using a single model, significantly reducing training costs and
deployment complexity compared to traditional methods that design dedicated
models for each degradation type. Existing approaches typically rely on
Degradation-specific models or coarse-grained degradation prompts to guide
image restoration. However, they lack fine-grained modeling of degradation
information and face limitations in balancing multi-task conflicts. To overcome
these limitations, we propose DPMambaIR, a novel All-in-One image restoration
framework. By integrating a Degradation-Aware Prompt State Space Model (DP-SSM)
and a High-Frequency Enhancement Block (HEB), DPMambaIR enables fine-grained
modeling of complex degradation information and efficient global integration,
while mitigating the loss of high-frequency details caused by task competition.
Specifically, the DP-SSM utilizes a pre-trained degradation extractor to
capture fine-grained degradation features and dynamically incorporates them
into the state space modeling process, enhancing the model's adaptability to
diverse degradation types. Concurrently, the HEB supplements high-frequency
information, effectively addressing the loss of critical details, such as edges
and textures, in multi-task image restoration scenarios. Extensive experiments
on a mixed dataset containing seven degradation types show that DPMambaIR
achieves the best performance, with 27.69dB and 0.893 in PSNR and SSIM,
respectively. These results highlight the potential and superiority of
DPMambaIR as a unified solution for All-in-One image restoration.

</details>

### [100] [EgoCHARM: Resource-Efficient Hierarchical Activity Recognition using an Egocentric IMU Sensor](https://arxiv.org/abs/2504.17735)
*Akhil Padmanabha,Saravanan Govindarajan,Hwanmun Kim,Sergio Ortiz,Rahul Rajan,Doruk Senkal,Sneha Kadetotad*

Main category: cs.CV

TLDR: 提出了一种资源高效的机器学习算法EgoCHARM，用于通过头戴式IMU识别高低层次活动，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在头戴设备上的活动识别性能低或资源消耗大，需改进。

Method: 采用分层半监督学习策略，利用高层次活动标签训练，学习通用低层次运动嵌入。

Result: 在9种高层次和3种低层次活动上，F1分数分别为0.826和0.855，模型参数仅63k和22k。

Conclusion: EgoCHARM高效且性能优越，适合部署在现有IMU芯片上，同时分析了其局限性和机会。

Abstract: Human activity recognition (HAR) on smartglasses has various use cases,
including health/fitness tracking and input for context-aware AI assistants.
However, current approaches for egocentric activity recognition suffer from low
performance or are resource-intensive. In this work, we introduce a resource
(memory, compute, power, sample) efficient machine learning algorithm,
EgoCHARM, for recognizing both high level and low level activities using a
single egocentric (head-mounted) Inertial Measurement Unit (IMU). Our
hierarchical algorithm employs a semi-supervised learning strategy, requiring
primarily high level activity labels for training, to learn generalizable low
level motion embeddings that can be effectively utilized for low level activity
recognition. We evaluate our method on 9 high level and 3 low level activities
achieving 0.826 and 0.855 F1 scores on high level and low level activity
recognition respectively, with just 63k high level and 22k low level model
parameters, allowing the low level encoder to be deployed directly on current
IMU chips with compute. Lastly, we present results and insights from a
sensitivity analysis and highlight the opportunities and limitations of
activity recognition using egocentric IMUs.

</details>

### [101] [Step1X-Edit: A Practical Framework for General Image Editing](https://arxiv.org/abs/2504.17761)
*Shiyu Liu,Yucheng Han,Peng Xing,Fukun Yin,Rui Wang,Wei Cheng,Jiaqi Liao,Yingming Wang,Honghao Fu,Chunrui Han,Guopeng Li,Yuang Peng,Quan Sun,Jingwei Wu,Yan Cai,Zheng Ge,Ranchen Ming,Lei Xia,Xianfang Zeng,Yibo Zhu,Binxing Jiao,Xiangyu Zhang,Gang Yu,Daxin Jiang*

Main category: cs.CV

TLDR: 本文提出了一种名为Step1X-Edit的开源图像编辑模型，旨在缩小与闭源模型（如GPT-4o和Gemini2 Flash）的性能差距。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态模型在图像编辑领域取得了显著进展，但开源算法与闭源模型之间仍存在较大差距。本文旨在填补这一空白。

Method: 采用多模态LLM处理参考图像和用户编辑指令，提取潜在嵌入并与扩散图像解码器结合生成目标图像。通过数据生成管道构建高质量训练数据集。

Result: 在GEdit-Bench上的实验表明，Step1X-Edit显著优于现有开源基线，并接近领先闭源模型的性能。

Conclusion: Step1X-Edit为图像编辑领域做出了重要贡献，推动了开源模型的发展。

Abstract: In recent years, image editing models have witnessed remarkable and rapid
development. The recent unveiling of cutting-edge multimodal models such as
GPT-4o and Gemini2 Flash has introduced highly promising image editing
capabilities. These models demonstrate an impressive aptitude for fulfilling a
vast majority of user-driven editing requirements, marking a significant
advancement in the field of image manipulation. However, there is still a large
gap between the open-source algorithm with these closed-source models. Thus, in
this paper, we aim to release a state-of-the-art image editing model, called
Step1X-Edit, which can provide comparable performance against the closed-source
models like GPT-4o and Gemini2 Flash. More specifically, we adopt the
Multimodal LLM to process the reference image and the user's editing
instruction. A latent embedding has been extracted and integrated with a
diffusion image decoder to obtain the target image. To train the model, we
build a data generation pipeline to produce a high-quality dataset. For
evaluation, we develop the GEdit-Bench, a novel benchmark rooted in real-world
user instructions. Experimental results on GEdit-Bench demonstrate that
Step1X-Edit outperforms existing open-source baselines by a substantial margin
and approaches the performance of leading proprietary models, thereby making
significant contributions to the field of image editing.

</details>

### [102] [The Fourth Monocular Depth Estimation Challenge](https://arxiv.org/abs/2504.17787)
*Anton Obukhov,Matteo Poggi,Fabio Tosi,Ripudaman Singh Arora,Jaime Spencer,Chris Russell,Simon Hadfield,Richard Bowden,Shuaihang Wang,Zhenxin Ma,Weijie Chen,Baobei Xu,Fengyu Sun,Di Xie,Jiang Zhu,Mykola Lavreniuk,Haining Guan,Qun Wu,Yupei Zeng,Chao Lu,Huanran Wang,Guangyuan Zhou,Haotian Zhang,Jianxiong Wang,Qiang Rao,Chunjie Wang,Xiao Liu,Zhiqiang Lou,Hualie Jiang,Yihao Chen,Rui Xu,Minglang Tan,Zihan Qin,Yifan Mao,Jiayang Liu,Jialei Xu,Yifan Yang,Wenbo Zhao,Junjun Jiang,Xianming Liu,Mingshuai Zhao,Anlong Ming,Wu Chen,Feng Xue,Mengying Yu,Shida Gao,Xiangfeng Wang,Gbenga Omotara,Ramy Farag,Jacket Demby,Seyed Mohamad Ali Tousi,Guilherme N DeSouza,Tuan-Anh Yang,Minh-Quang Nguyen,Thien-Phuc Tran,Albert Luginov,Muhammad Shahzad*

Main category: cs.CV

TLDR: 第四版单目深度估计挑战赛（MDEC）聚焦于零样本泛化到SYNS-Patches基准测试，改进了评估协议和基线方法，最终提交的24个方法中有10个报告了方法，3D F-Score提升至23.05%。


<details>
  <summary>Details</summary>
Motivation: 改进单目深度估计的零样本泛化能力，特别是在自然和室内环境中的挑战性场景。

Method: 修订评估协议，使用最小二乘对齐支持视差和仿射不变预测；引入Depth Anything v2和Marigold作为基线方法。

Result: 24个提交方法中有10个报告了方法，3D F-Score从22.58%提升至23.05%。

Conclusion: 挑战赛成功推动了单目深度估计技术的进步，仿射不变预测成为主流方法。

Abstract: This paper presents the results of the fourth edition of the Monocular Depth
Estimation Challenge (MDEC), which focuses on zero-shot generalization to the
SYNS-Patches benchmark, a dataset featuring challenging environments in both
natural and indoor settings. In this edition, we revised the evaluation
protocol to use least-squares alignment with two degrees of freedom to support
disparity and affine-invariant predictions. We also revised the baselines and
included popular off-the-shelf methods: Depth Anything v2 and Marigold. The
challenge received a total of 24 submissions that outperformed the baselines on
the test set; 10 of these included a report describing their approach, with
most leading methods relying on affine-invariant predictions. The challenge
winners improved the 3D F-Score over the previous edition's best result,
raising it from 22.58% to 23.05%.

</details>

### [103] [Dynamic Camera Poses and Where to Find Them](https://arxiv.org/abs/2504.17788)
*Chris Rockwell,Joseph Tung,Tsung-Yi Lin,Ming-Yu Liu,David F. Fouhey,Chen-Hsuan Lin*

Main category: cs.CV

TLDR: 论文介绍了DynPose-100K，一个大规模动态互联网视频数据集，标注了相机姿态，解决了现有方法的挑战。


<details>
  <summary>Details</summary>
Motivation: 动态互联网视频的相机姿态标注对视频生成和仿真等领域至关重要，但现有数据集难以满足需求。

Method: 结合任务特定和通用模型进行过滤，并采用点跟踪、动态掩码和运动结构恢复技术进行姿态估计。

Result: DynPose-100K数据集规模大且多样化，优于现有方法。

Conclusion: 该数据集为下游应用提供了新的研究机会。

Abstract: Annotating camera poses on dynamic Internet videos at scale is critical for
advancing fields like realistic video generation and simulation. However,
collecting such a dataset is difficult, as most Internet videos are unsuitable
for pose estimation. Furthermore, annotating dynamic Internet videos present
significant challenges even for state-of-theart methods. In this paper, we
introduce DynPose-100K, a large-scale dataset of dynamic Internet videos
annotated with camera poses. Our collection pipeline addresses filtering using
a carefully combined set of task-specific and generalist models. For pose
estimation, we combine the latest techniques of point tracking, dynamic
masking, and structure-from-motion to achieve improvements over the
state-of-the-art approaches. Our analysis and experiments demonstrate that
DynPose-100K is both large-scale and diverse across several key attributes,
opening up avenues for advancements in various downstream applications.

</details>

### [104] [Token-Shuffle: Towards High-Resolution Image Generation with Autoregressive Models](https://arxiv.org/abs/2504.17789)
*Xu Ma,Peize Sun,Haoyu Ma,Hao Tang,Chih-Yao Ma,Jialiang Wang,Kunpeng Li,Xiaoliang Dai,Yujun Shi,Xuan Ju,Yushi Hu,Artsiom Sanakoyeu,Felix Juefei-Xu,Ji Hou,Junjiao Tian,Tao Xu,Tingbo Hou,Yen-Cheng Liu,Zecheng He,Zijian He,Matt Feiszli,Peizhao Zhang,Peter Vajda,Sam Tsai,Yun Fu*

Main category: cs.CV

TLDR: 论文提出了一种名为Token-Shuffle的新方法，通过减少Transformer中的图像token数量，解决了自回归模型在图像合成中的效率问题，并实现了高分辨率图像生成。


<details>
  <summary>Details</summary>
Motivation: 自回归模型在图像合成中因需要大量图像token而效率低下，限制了训练、推理效率和图像分辨率。

Method: 提出Token-Shuffle方法，通过合并局部token（token-shuffle）和恢复空间排列（token-unshuffle）来减少token数量，同时结合文本提示联合训练。

Result: 首次将自回归文本到图像生成的分辨率提升至2048x2048，在GenAI-benchmark中表现优于其他模型。

Conclusion: Token-Shuffle为多模态大语言模型中的高效高分辨率图像生成提供了基础设计。

Abstract: Autoregressive (AR) models, long dominant in language generation, are
increasingly applied to image synthesis but are often considered less
competitive than Diffusion-based models. A primary limitation is the
substantial number of image tokens required for AR models, which constrains
both training and inference efficiency, as well as image resolution. To address
this, we present Token-Shuffle, a novel yet simple method that reduces the
number of image tokens in Transformer. Our key insight is the dimensional
redundancy of visual vocabularies in Multimodal Large Language Models (MLLMs),
where low-dimensional visual codes from visual encoder are directly mapped to
high-dimensional language vocabularies. Leveraging this, we consider two key
operations: token-shuffle, which merges spatially local tokens along channel
dimension to decrease the input token number, and token-unshuffle, which
untangles the inferred tokens after Transformer blocks to restore the spatial
arrangement for output. Jointly training with textual prompts, our strategy
requires no additional pretrained text-encoder and enables MLLMs to support
extremely high-resolution image synthesis in a unified next-token prediction
way while maintaining efficient training and inference. For the first time, we
push the boundary of AR text-to-image generation to a resolution of 2048x2048
with gratifying generation performance. In GenAI-benchmark, our 2.7B model
achieves 0.77 overall score on hard prompts, outperforming AR models LlamaGen
by 0.18 and diffusion models LDM by 0.15. Exhaustive large-scale human
evaluations also demonstrate our prominent image generation ability in terms of
text-alignment, visual flaw, and visual appearance. We hope that Token-Shuffle
can serve as a foundational design for efficient high-resolution image
generation within MLLMs.

</details>

### [105] [LiDPM: Rethinking Point Diffusion for Lidar Scene Completion](https://arxiv.org/abs/2504.17791)
*Tetiana Martyniuk,Gilles Puy,Alexandre Boulch,Renaud Marlet,Raoul de Charette*

Main category: cs.CV

TLDR: 论文提出LiDPM方法，通过优化初始点选择，证明传统DDPM在场景级别点云补全中无需局部扩散近似即可取得更好效果。


<details>
  <summary>Details</summary>
Motivation: 解决传统扩散模型在室外场景点云补全中难以生成细粒度细节的问题，并弥合局部扩散与对象级别扩散之间的差距。

Method: 提出LiDPM方法，通过选择合适的初始点，直接使用传统DDPM进行场景级别点云补全，无需局部扩散近似。

Result: 在SemanticKITTI数据集上，LiDPM在场景补全任务中表现优于现有方法。

Conclusion: 传统DDPM在优化初始点的情况下，能够有效用于场景级别点云补全，无需复杂的局部扩散过程。

Abstract: Training diffusion models that work directly on lidar points at the scale of
outdoor scenes is challenging due to the difficulty of generating fine-grained
details from white noise over a broad field of view. The latest works
addressing scene completion with diffusion models tackle this problem by
reformulating the original DDPM as a local diffusion process. It contrasts with
the common practice of operating at the level of objects, where vanilla DDPMs
are currently used. In this work, we close the gap between these two lines of
work. We identify approximations in the local diffusion formulation, show that
they are not required to operate at the scene level, and that a vanilla DDPM
with a well-chosen starting point is enough for completion. Finally, we
demonstrate that our method, LiDPM, leads to better results in scene completion
on SemanticKITTI. The project page is https://astra-vision.github.io/LiDPM .

</details>

<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [106] [S2Vec: Self-Supervised Geospatial Embeddings](https://arxiv.org/abs/2504.16942)
*Shushman Choudhury,Elad Aharoni,Chandrakumari Suvarna,Iveel Tsogsuren,Abdul Rahman Kreidieh,Chun-Ta Lu,Neha Arora*

Main category: cs.SI

TLDR: S2Vec是一种自监督框架，用于学习通用的地理空间嵌入，通过S2几何库分区和掩码自编码技术生成任务无关的嵌入，并在社会经济预测任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 构建可扩展的通用地理空间表示对地理空间人工智能应用至关重要。

Method: 使用S2 Geometry库将大区域划分为离散的S2单元，将特征向量栅格化为图像，并应用掩码自编码技术生成嵌入。

Result: 在三个大规模社会经济预测任务中表现优异，且与图像嵌入的多模态融合可进一步提升性能。

Conclusion: S2Vec能有效学习通用地理空间表示，并与其他数据模态互补。

Abstract: Scalable general-purpose representations of the built environment are crucial
for geospatial artificial intelligence applications. This paper introduces
S2Vec, a novel self-supervised framework for learning such geospatial
embeddings. S2Vec uses the S2 Geometry library to partition large areas into
discrete S2 cells, rasterizes built environment feature vectors within cells as
images, and applies masked autoencoding on these rasterized images to encode
the feature vectors. This approach yields task-agnostic embeddings that capture
local feature characteristics and broader spatial relationships. We evaluate
S2Vec on three large-scale socioeconomic prediction tasks, showing its
competitive performance against state-of-the-art image-based embeddings. We
also explore the benefits of combining S2Vec embeddings with image-based
embeddings downstream, showing that such multimodal fusion can often improve
performance. Our results highlight how S2Vec can learn effective
general-purpose geospatial representations and how it can complement other data
modalities in geospatial artificial intelligence.

</details>

<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [107] [Can deep neural networks learn biological vision?](https://arxiv.org/abs/2504.16940)
*Drew Linsley,Pinyuan Feng,Thomas Serre*

Main category: q-bio.NC

TLDR: DNNs最初在计算机视觉任务中表现出与灵长类神经反应的趋同，但近年随着DNNs性能超越人类，这种趋同性减弱。未来生物视觉模型需脱离AI范式，专注于生物视觉特性。


<details>
  <summary>Details</summary>
Motivation: 探讨DNNs与生物视觉趋同性减弱的原因，并提出未来研究方向。

Method: 分析DNNs与灵长类视觉系统的差异，提出基于生物视觉特性的训练方法。

Result: 现代DNNs依赖与生物视觉不同的特征，导致趋同性减弱。

Conclusion: 未来生物视觉模型需采用更接近人类视觉的数据和训练方法。

Abstract: Deep neural networks (DNNs) once showed increasing alignment with primate
neural responses as they improved on computer vision benchmarks. This trend
raised the exciting possibility that better models of biological vision would
come as a byproduct of the deep learning revolution in artificial intelligence.
However, the trend has reversed over recent years as DNNs have scaled to human
or superhuman recognition accuracy, a divergence that may stem from modern DNNs
learning to rely on different visual features than primates to solve tasks.
Where will better computational models of biological vision come from? We
propose that vision science must break from artificial intelligence to develop
algorithms that are designed with biological visual systems in mind instead of
internet data benchmarks. We predict that the next generation of deep learning
models of biological vision will be trained with data diets, training routines,
and objectives that are closer to those that shape human vision than those that
are in use today.

</details>

<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [108] [Anatomy-constrained modelling of image-derived input functions in dynamic PET using multi-organ segmentation](https://arxiv.org/abs/2504.17114)
*Valentin Langer,Kartikay Tehlan,Thomas Wendler*

Main category: eess.IV

TLDR: 该论文提出了一种基于多器官分割的方法，通过整合来自主动脉、门静脉、肺动脉和输尿管的图像衍生输入函数（IDIFs），改进了动态PET中[$^{18}$F]FDG分布的动力学分析。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅从主动脉获取IDIFs，忽略了解剖变异和复杂血管贡献，限制了动力学分析的准确性。

Method: 利用高分辨率CT分割肝脏、肺、肾脏和膀胱，结合器官特异性血液供应来源，优化动力学建模。

Result: 在9名患者的动态[$^{18}$F]FDG PET数据中，肝脏和肺的均方误差（MSE）分别降低了13.39%和10.42%。

Conclusion: 多IDIFs方法有望提升解剖建模效果，推动示踪动力学建模在临床中的应用。

Abstract: Accurate kinetic analysis of [$^{18}$F]FDG distribution in dynamic positron
emission tomography (PET) requires anatomically constrained modelling of
image-derived input functions (IDIFs). Traditionally, IDIFs are obtained from
the aorta, neglecting anatomical variations and complex vascular contributions.
This study proposes a multi-organ segmentation-based approach that integrates
IDIFs from the aorta, portal vein, pulmonary artery, and ureters. Using
high-resolution CT segmentations of the liver, lungs, kidneys, and bladder, we
incorporate organ-specific blood supply sources to improve kinetic modelling.
Our method was evaluated on dynamic [$^{18}$F]FDG PET data from nine patients,
resulting in a mean squared error (MSE) reduction of $13.39\%$ for the liver
and $10.42\%$ for the lungs. These initial results highlight the potential of
multiple IDIFs in improving anatomical modelling and fully leveraging dynamic
PET imaging. This approach could facilitate the integration of tracer kinetic
modelling into clinical routine.

</details>

### [109] [Physiological neural representation for personalised tracer kinetic parameter estimation from dynamic PET](https://arxiv.org/abs/2504.17122)
*Kartikay Tehlan,Thomas Wendler*

Main category: eess.IV

TLDR: 提出了一种基于隐式神经表示（INRs）的个性化动力学参数估计方法，解决了传统方法和深度神经网络（DNNs）在计算和数据需求上的局限性，并在动态PET/CT数据上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统动力学参数估计方法计算量大且空间分辨率有限，而DNNs需要大量训练数据和计算资源。为解决这些问题，提出了基于INRs的新方法。

Method: 利用INRs学习连续函数，结合3D CT基础模型的解剖先验，实现高效、高分辨率的参数成像。

Result: 在动态PET/CT数据集上验证，相比DNNs，具有更高的空间分辨率、更低的均方误差和更好的解剖一致性。

Conclusion: INRs在个性化、数据高效的示踪动力学建模中具有潜力，适用于肿瘤表征、分割和预后评估。

Abstract: Dynamic positron emission tomography (PET) with [$^{18}$F]FDG enables
non-invasive quantification of glucose metabolism through kinetic analysis,
often modelled by the two-tissue compartment model (TCKM). However, voxel-wise
kinetic parameter estimation using conventional methods is computationally
intensive and limited by spatial resolution. Deep neural networks (DNNs) offer
an alternative but require large training datasets and significant
computational resources. To address these limitations, we propose a
physiological neural representation based on implicit neural representations
(INRs) for personalized kinetic parameter estimation. INRs, which learn
continuous functions, allow for efficient, high-resolution parametric imaging
with reduced data requirements. Our method also integrates anatomical priors
from a 3D CT foundation model to enhance robustness and precision in kinetic
modelling. We evaluate our approach on an [$^{18}$F]FDG dynamic PET/CT dataset
and compare it to state-of-the-art DNNs. Results demonstrate superior spatial
resolution, lower mean-squared error, and improved anatomical consistency,
particularly in tumour and highly vascularized regions. Our findings highlight
the potential of INRs for personalized, data-efficient tracer kinetic
modelling, enabling applications in tumour characterization, segmentation, and
prognostic assessment.

</details>

### [110] [A Spatially-Aware Multiple Instance Learning Framework for Digital Pathology](https://arxiv.org/abs/2504.17379)
*Hassan Keshvarikhojasteh,Mihail Tifrea,Sibylle Hess,Josien P. W. Pluim,Mitko Veta*

Main category: eess.IV

TLDR: 论文提出了一种改进的ABMIL框架（GABMIL），通过显式捕捉实例间依赖关系，提升了病理图像分类性能，且计算效率高。


<details>
  <summary>Details</summary>
Motivation: 传统MIL方法（如ABMIL）忽略了病理图像中关键的空间交互信息，而现有方法（如TransMIL）虽引入空间上下文但计算复杂。本文旨在验证在ABMIL中显式建模补丁关系是否能提升性能。

Method: 提出GABMIL模型，在ABMIL框架中集成交互感知表示，显式捕捉实例间依赖关系，同时保持计算效率。

Result: 在乳腺癌和肺癌亚型分类任务中，GABMIL相比ABMIL在AUPRC和Kappa分数上分别提升7%和5%，且计算开销几乎不变。

Conclusion: 研究表明，在MIL框架中显式建模补丁交互关系对性能提升至关重要，且GABMIL在性能和效率间取得了平衡。

Abstract: Multiple instance learning (MIL) is a promising approach for weakly
supervised classification in pathology using whole slide images (WSIs).
However, conventional MIL methods such as Attention-Based Deep Multiple
Instance Learning (ABMIL) typically disregard spatial interactions among
patches that are crucial to pathological diagnosis. Recent advancements, such
as Transformer based MIL (TransMIL), have incorporated spatial context and
inter-patch relationships. However, it remains unclear whether explicitly
modeling patch relationships yields similar performance gains in ABMIL, which
relies solely on Multi-Layer Perceptrons (MLPs). In contrast, TransMIL employs
Transformer-based layers, introducing a fundamental architectural shift at the
cost of substantially increased computational complexity. In this work, we
enhance the ABMIL framework by integrating interaction-aware representations to
address this question. Our proposed model, Global ABMIL (GABMIL), explicitly
captures inter-instance dependencies while preserving computational efficiency.
Experimental results on two publicly available datasets for tumor subtyping in
breast and lung cancers demonstrate that GABMIL achieves up to a 7 percentage
point improvement in AUPRC and a 5 percentage point increase in the Kappa score
over ABMIL, with minimal or no additional computational overhead. These
findings underscore the importance of incorporating patch interactions within
MIL frameworks.

</details>

### [111] [Beyond Labels: Zero-Shot Diabetic Foot Ulcer Wound Segmentation with Self-attention Diffusion Models and the Potential for Text-Guided Customization](https://arxiv.org/abs/2504.17628)
*Abderrachid Hamrani,Daniela Leizaola,Renato Sousa,Jose P. Ponce,Stanley Mathis,David G. Armstrong,Anuradha Godavarty*

Main category: eess.IV

TLDR: ADZUS是一种基于文本引导的扩散模型，用于糖尿病足溃疡的无监督分割，无需标注数据，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 糖尿病足溃疡的精确评估对患者治疗至关重要，传统方法依赖标注数据，ADZUS旨在解决这一限制。

Method: ADZUS利用零样本学习和文本提示动态适应分割任务，无需标注数据。

Result: 在慢性伤口数据集上，ADZUS的IoU达86.68%，精度94.69%，显著优于FUSegNet等监督方法。

Conclusion: ADZUS为医学影像分割提供了高效、灵活的解决方案，但计算成本和微调需求仍需改进。

Abstract: Diabetic foot ulcers (DFUs) pose a significant challenge in healthcare,
requiring precise and efficient wound assessment to enhance patient outcomes.
This study introduces the Attention Diffusion Zero-shot Unsupervised System
(ADZUS), a novel text-guided diffusion model that performs wound segmentation
without relying on labeled training data. Unlike conventional deep learning
models, which require extensive annotation, ADZUS leverages zero-shot learning
to dynamically adapt segmentation based on descriptive prompts, offering
enhanced flexibility and adaptability in clinical applications. Experimental
evaluations demonstrate that ADZUS surpasses traditional and state-of-the-art
segmentation models, achieving an IoU of 86.68\% and the highest precision of
94.69\% on the chronic wound dataset, outperforming supervised approaches such
as FUSegNet. Further validation on a custom-curated DFU dataset reinforces its
robustness, with ADZUS achieving a median DSC of 75\%, significantly surpassing
FUSegNet's 45\%. The model's text-guided segmentation capability enables
real-time customization of segmentation outputs, allowing targeted analysis of
wound characteristics based on clinical descriptions. Despite its competitive
performance, the computational cost of diffusion-based inference and the need
for potential fine-tuning remain areas for future improvement. ADZUS represents
a transformative step in wound segmentation, providing a scalable, efficient,
and adaptable AI-driven solution for medical imaging.

</details>

<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [112] [A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions](https://arxiv.org/abs/2504.16939)
*Emre Can Acikgoz,Cheng Qian,Hongru Wang,Vardhan Dongre,Xiusi Chen,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur*

Main category: cs.AI

TLDR: 本文综述了基于大语言模型（LLM）的对话代理的现状、挑战及未来方向，提出了一种新的分类法，并指出了关键研究缺口。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM驱动的对话代理的能力、局限性和未来发展路径，以推动更接近人类智能的可扩展系统。

Method: 通过将对话代理的能力分为推理、监控和控制三个维度，系统分析现有研究，并提出新的分类法。

Result: 识别了研究缺口，如长期多轮推理能力、自我进化能力等，并提出了未来研究方向。

Conclusion: 本文为对话代理提供了结构化基础，指出了局限性，并展望了未来研究，以推动人工通用智能（AGI）的发展。

Abstract: Recent advances in Large Language Models (LLMs) have propelled conversational
AI from traditional dialogue systems into sophisticated agents capable of
autonomous actions, contextual awareness, and multi-turn interactions with
users. Yet, fundamental questions about their capabilities, limitations, and
paths forward remain open. This survey paper presents a desideratum for
next-generation Conversational Agents - what has been achieved, what challenges
persist, and what must be done for more scalable systems that approach
human-level intelligence. To that end, we systematically analyze LLM-driven
Conversational Agents by organizing their capabilities into three primary
dimensions: (i) Reasoning - logical, systematic thinking inspired by human
intelligence for decision making, (ii) Monitor - encompassing self-awareness
and user interaction monitoring, and (iii) Control - focusing on tool
utilization and policy following. Building upon this, we introduce a novel
taxonomy by classifying recent work on Conversational Agents around our
proposed desideratum. We identify critical research gaps and outline key
directions, including realistic evaluations, long-term multi-turn reasoning
skills, self-evolution capabilities, collaborative and multi-agent task
completion, personalization, and proactivity. This work aims to provide a
structured foundation, highlight existing limitations, and offer insights into
potential future research directions for Conversational Agents, ultimately
advancing progress toward Artificial General Intelligence (AGI). We maintain a
curated repository of papers at:
https://github.com/emrecanacikgoz/awesome-conversational-agents.

</details>

### [113] [AUTHENTICATION: Identifying Rare Failure Modes in Autonomous Vehicle Perception Systems using Adversarially Guided Diffusion Models](https://arxiv.org/abs/2504.17179)
*Mohammad Zarei,Melanie A Jutras,Eliana Evans,Mike Tan,Omid Aaramoon*

Main category: cs.AI

TLDR: 论文提出了一种利用生成和可解释AI技术解决自动驾驶车辆（AVs）中罕见故障模式（RFMs）问题的新方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆依赖AI检测物体，但难以识别罕见故障模式（RFMs），即“长尾挑战”。

Method: 通过提取对象分割掩码并反转生成环境掩码，结合文本提示输入定制扩散模型，利用对抗噪声优化生成多样化环境图像以暴露AI系统漏洞。

Result: 生成包含RFMs的图像及自然语言描述，帮助提升AV系统的鲁棒性和可靠性。

Conclusion: 该方法为开发者和政策制定者提供了改进AV安全性和可靠性的工具。

Abstract: Autonomous Vehicles (AVs) rely on artificial intelligence (AI) to accurately
detect objects and interpret their surroundings. However, even when trained
using millions of miles of real-world data, AVs are often unable to detect rare
failure modes (RFMs). The problem of RFMs is commonly referred to as the
"long-tail challenge", due to the distribution of data including many instances
that are very rarely seen. In this paper, we present a novel approach that
utilizes advanced generative and explainable AI techniques to aid in
understanding RFMs. Our methods can be used to enhance the robustness and
reliability of AVs when combined with both downstream model training and
testing. We extract segmentation masks for objects of interest (e.g., cars) and
invert them to create environmental masks. These masks, combined with carefully
crafted text prompts, are fed into a custom diffusion model. We leverage the
Stable Diffusion inpainting model guided by adversarial noise optimization to
generate images containing diverse environments designed to evade object
detection models and expose vulnerabilities in AI systems. Finally, we produce
natural language descriptions of the generated RFMs that can guide developers
and policymakers to improve the safety and reliability of AV systems.

</details>

<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [114] [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org/abs/2504.17004)
*Amin Karbasi,Omar Montasser,John Sous,Grigoris Velegkas*

Main category: cs.LG

TLDR: 论文探讨了自动检测大语言模型（LLM）幻觉的可行性，通过理论框架分析其与语言识别的等价性，并指出专家标注反馈对实现检测的关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索是否可以通过算法自动检测LLM产生的幻觉，为可靠部署LLM提供理论支持。

Method: 方法包括建立幻觉检测与语言识别的等价性，并分析不同训练数据（仅正确示例与专家标注的正负示例）对检测能力的影响。

Result: 结果表明，仅使用正确示例训练时，幻觉检测在大多数语言集合中不可行；而加入专家标注反馈后，检测对所有可数语言集合成为可能。

Conclusion: 结论强调了专家标注示例在训练幻觉检测器中的重要性，并为基于反馈的方法（如RLHF）提供了理论支持。

Abstract: Is automated hallucination detection possible? In this work, we introduce a
theoretical framework to analyze the feasibility of automatically detecting
hallucinations produced by large language models (LLMs). Inspired by the
classical Gold-Angluin framework for language identification and its recent
adaptation to language generation by Kleinberg and Mullainathan, we investigate
whether an algorithm, trained on examples drawn from an unknown target language
$K$ (selected from a countable collection) and given access to an LLM, can
reliably determine whether the LLM's outputs are correct or constitute
hallucinations.
  First, we establish an equivalence between hallucination detection and the
classical task of language identification. We prove that any hallucination
detection method can be converted into a language identification method, and
conversely, algorithms solving language identification can be adapted for
hallucination detection. Given the inherent difficulty of language
identification, this implies that hallucination detection is fundamentally
impossible for most language collections if the detector is trained using only
correct examples from the target language.
  Second, we show that the use of expert-labeled feedback, i.e., training the
detector with both positive examples (correct statements) and negative examples
(explicitly labeled incorrect statements), dramatically changes this
conclusion. Under this enriched training regime, automated hallucination
detection becomes possible for all countable language collections.
  These results highlight the essential role of expert-labeled examples in
training hallucination detectors and provide theoretical support for
feedback-based methods, such as reinforcement learning with human feedback
(RLHF), which have proven critical for reliable LLM deployment.

</details>

### [115] [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org/abs/2504.17449)
*Jun Zhang,Jue Wang,Huan Li,Lidan Shou,Ke Chen,Gang Chen,Qin Xie,Guiming Xie,Xuejian Gong*

Main category: cs.LG

TLDR: HMI是一种基于分层知识管理的多租户推理系统，通过分层管理PLM知识，显著减少GPU内存使用，支持高效服务大量租户。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型（PLM）的计算需求高，多租户环境下效率低，需专用硬件，HMI旨在解决这一问题。

Method: 1. 将PLM知识分为通用、领域特定和任务特定三类，构建分层PLM（hPLM）；2. 通过频率更新领域知识树和参数交换管理任务知识；3. 系统优化包括分层知识预取和并行矩阵乘法。

Result: 实验表明，HMI能在单个GPU上高效服务10,000个hPLM（hBERT和hGPT），精度损失可忽略。

Conclusion: HMI通过分层知识管理和系统优化，显著提升了多租户环境下PLM的推理效率和资源利用率。

Abstract: The significant computational demands of pretrained language models (PLMs),
which often require dedicated hardware, present a substantial challenge in
serving them efficiently, especially in multi-tenant environments. To address
this, we introduce HMI, a Hierarchical knowledge management-based Multi-tenant
Inference system, designed to manage tenants with distinct PLMs
resource-efficiently. Our approach is three-fold: Firstly, we categorize PLM
knowledge into general, domain-specific, and task-specific. Leveraging insights
on knowledge acquisition across different model layers, we construct
hierarchical PLMs (hPLMs) by extracting and storing knowledge at different
levels, significantly reducing GPU memory usage per tenant. Secondly, we
establish hierarchical knowledge management for hPLMs generated by various
tenants in HMI. We manage domain-specific knowledge with acceptable storage
increases by constructing and updating domain-specific knowledge trees based on
frequency. We manage task-specific knowledge within limited GPU memory through
parameter swapping. Finally, we propose system optimizations to enhance
resource utilization and inference throughput. These include fine-grained
pipelining via hierarchical knowledge prefetching to overlap CPU and I/O
operations with GPU computations, and optimizing parallel implementations with
batched matrix multiplications. Our experimental results demonstrate that the
proposed HMI can efficiently serve up to 10,000 hPLMs (hBERTs and hGPTs) on a
single GPU, with only a negligible compromise in accuracy.

</details>

### [116] [Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications](https://arxiv.org/abs/2504.16972)
*Hossein Ahmadi,Sajjad Emdadi Mahdimahalleh,Arman Farahat,Banafsheh Saffari*

Main category: cs.LG

TLDR: 综述了自编码器和视觉变换器在无监督信号分析中的应用，探讨了其架构、应用和趋势，并指出了可解释性、可扩展性和领域泛化等挑战。


<details>
  <summary>Details</summary>
Motivation: 随着无线通信、雷达、生物医学工程和物联网等领域中未标记时间序列数据的快速增长，无监督学习的需求推动了相关技术的进步。

Method: 通过自编码器和视觉变换器进行特征提取、异常检测和分类，重点关注混合架构和自监督学习。

Result: 总结了这些模型在多种信号类型（如心电图、雷达波形和物联网传感器数据）中的应用，并强调了其优势。

Conclusion: 提出了开发鲁棒、自适应信号智能模型的路线图，同时指出了未来研究中的挑战。

Abstract: The rapid growth of unlabeled time-series data in domains such as wireless
communications, radar, biomedical engineering, and the Internet of Things (IoT)
has driven advancements in unsupervised learning. This review synthesizes
recent progress in applying autoencoders and vision transformers for
unsupervised signal analysis, focusing on their architectures, applications,
and emerging trends. We explore how these models enable feature extraction,
anomaly detection, and classification across diverse signal types, including
electrocardiograms, radar waveforms, and IoT sensor data. The review highlights
the strengths of hybrid architectures and self-supervised learning, while
identifying challenges in interpretability, scalability, and domain
generalization. By bridging methodological innovations and practical
applications, this work offers a roadmap for developing robust, adaptive models
for signal intelligence.

</details>

### [117] [OUI Need to Talk About Weight Decay: A New Perspective on Overfitting Detection](https://arxiv.org/abs/2504.17160)
*Alberto Fernández-Hernández,Jose I. Mestre,Manuel F. Dolz,Jose Duato,Enrique S. Quintana-Ortí*

Main category: cs.LG

TLDR: 论文提出了一种名为OUI的新工具，用于监控深度神经网络的训练动态并优化正则化超参数选择，无需验证数据即可判断模型是否过拟合或欠拟合。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖验证数据调整超参数，效率较低。OUI旨在通过训练动态直接指导超参数选择，提高效率和精度。

Method: 通过实验在多种数据集和模型（如DenseNet、EfficientNet、ResNet）上验证OUI的有效性，并比较其与传统指标（如损失和准确率）的表现。

Result: OUI能更快收敛，并在早期训练阶段识别最佳超参数值，显著提升泛化能力和验证分数。

Conclusion: OUI是一种高效工具，可优化正则化超参数选择，适用于多种深度神经网络和数据集。

Abstract: We introduce the Overfitting-Underfitting Indicator (OUI), a novel tool for
monitoring the training dynamics of Deep Neural Networks (DNNs) and identifying
optimal regularization hyperparameters. Specifically, we validate that OUI can
effectively guide the selection of the Weight Decay (WD) hyperparameter by
indicating whether a model is overfitting or underfitting during training
without requiring validation data. Through experiments on DenseNet-BC-100 with
CIFAR- 100, EfficientNet-B0 with TinyImageNet and ResNet-34 with ImageNet-1K,
we show that maintaining OUI within a prescribed interval correlates strongly
with improved generalization and validation scores. Notably, OUI converges
significantly faster than traditional metrics such as loss or accuracy,
enabling practitioners to identify optimal WD (hyperparameter) values within
the early stages of training. By leveraging OUI as a reliable indicator, we can
determine early in training whether the chosen WD value leads the model to
underfit the training data, overfit, or strike a well-balanced trade-off that
maximizes validation scores. This enables more precise WD tuning for optimal
performance on the tested datasets and DNNs. All code for reproducing these
experiments is available at https://github.com/AlbertoFdezHdez/OUI.

</details>

### [118] [Group Downsampling with Equivariant Anti-aliasing](https://arxiv.org/abs/2504.17258)
*Md Ashiqur Rahman,Raymond A. Yeh*

Main category: cs.LG

TLDR: 本文研究了在群等变架构（如G-CNNs）中均匀下采样层的泛化问题，提出了一种基于有限群和抗混叠的下采样方法。


<details>
  <summary>Details</summary>
Motivation: 下采样层在CNN架构中至关重要，但现有方法在群等变架构中的泛化能力不足，需要研究如何在下采样中保持群等变性并减少混叠。

Method: 提出了一种算法来选择适合的子群，并研究了带限性和抗混叠方法，将经典采样理论推广到有限群。

Result: 实验表明，该方法在图像分类任务中提高了准确性，更好地保持了等变性，并减少了模型大小。

Conclusion: 该方法成功地将经典下采样理论推广到群等变架构，为相关研究提供了新的思路。

Abstract: Downsampling layers are crucial building blocks in CNN architectures, which
help to increase the receptive field for learning high-level features and
reduce the amount of memory/computation in the model. In this work, we study
the generalization of the uniform downsampling layer for group equivariant
architectures, e.g., G-CNNs. That is, we aim to downsample signals (feature
maps) on general finite groups with anti-aliasing. This involves the following:
(a) Given a finite group and a downsampling rate, we present an algorithm to
form a suitable choice of subgroup. (b) Given a group and a subgroup, we study
the notion of bandlimited-ness and propose how to perform anti-aliasing.
Notably, our method generalizes the notion of downsampling based on classical
sampling theory. When the signal is on a cyclic group, i.e., periodic, our
method recovers the standard downsampling of an ideal low-pass filter followed
by a subsampling operation. Finally, we conducted experiments on image
classification tasks demonstrating that the proposed downsampling operation
improves accuracy, better preserves equivariance, and reduces model size when
incorporated into G-equivariant networks

</details>

### [119] [Class-Conditional Distribution Balancing for Group Robust Classification](https://arxiv.org/abs/2504.17314)
*Miaoyun Zhao,Qiang Zhang,Chenrong Li*

Main category: cs.LG

TLDR: 提出了一种无需偏置标注或预测的鲁棒学习方法，通过样本重加权平衡类条件分布，有效消除虚假相关性。


<details>
  <summary>Details</summary>
Motivation: 虚假相关性导致模型基于错误原因做出预测，现有方法依赖昂贵的偏置标注或大规模数据，难以适用于资源有限的罕见领域。

Method: 将虚假相关性重新定义为类条件分布的不平衡，采用样本重加权策略减少虚假因素与标签信息的互信息，实现分布平衡。

Result: 实验表明，该方法性能优异，媲美依赖偏置监督的方法。

Conclusion: 该方法简单有效，无需额外标注或数据，适用于资源受限场景，显著提升模型鲁棒性。

Abstract: Spurious correlations that lead models to correct predictions for the wrong
reasons pose a critical challenge for robust real-world generalization.
Existing research attributes this issue to group imbalance and addresses it by
maximizing group-balanced or worst-group accuracy, which heavily relies on
expensive bias annotations. A compromise approach involves predicting bias
information using extensively pretrained foundation models, which requires
large-scale data and becomes impractical for resource-limited rare domains. To
address these challenges, we offer a novel perspective by reframing the
spurious correlations as imbalances or mismatches in class-conditional
distributions, and propose a simple yet effective robust learning method that
eliminates the need for both bias annotations and predictions. With the goal of
reducing the mutual information between spurious factors and label information,
our method leverages a sample reweighting strategy to achieve class-conditional
distribution balancing, which automatically highlights minority groups and
classes, effectively dismantling spurious correlations and producing a debiased
data distribution for classification. Extensive experiments and analysis
demonstrate that our approach consistently delivers state-of-the-art
performance, rivaling methods that rely on bias supervision.

</details>

### [120] [The effects of Hessian eigenvalue spectral density type on the applicability of Hessian analysis to generalization capability assessment of neural networks](https://arxiv.org/abs/2504.17618)
*Nikita Gabdullin*

Main category: cs.LG

TLDR: 论文研究了神经网络Hessian矩阵的特征值谱密度（HESD）类型及其对泛化能力的影响，提出了统一的HESD分析方法。


<details>
  <summary>Details</summary>
Motivation: Hessian矩阵的特征值谱密度（HESD）能反映神经网络损失曲面的曲率，进而估计泛化能力。本文旨在进一步研究HESD类型的影响因素及其适用性。

Method: 通过大量实验，分析不同优化器、数据集及预处理方法对HESD类型的影响，并提出判断HESD类型的标准。

Result: 发现HESD主要为正值（MP-HESD）时适用于训练和微调，而负值（MN-HESD）则与外部梯度操作相关。同时观察到准奇异（QS）HESD现象。

Conclusion: 提出统一的HESD分析方法，并讨论了QS-HESD对传统Hessian特征值与损失曲面关系假设的影响。

Abstract: Hessians of neural network (NN) contain essential information about the
curvature of NN loss landscapes which can be used to estimate NN generalization
capabilities. We have previously proposed generalization criteria that rely on
the observation that Hessian eigenvalue spectral density (HESD) behaves
similarly for a wide class of NNs. This paper further studies their
applicability by investigating factors that can result in different types of
HESD. We conduct a wide range of experiments showing that HESD mainly has
positive eigenvalues (MP-HESD) for NN training and fine-tuning with various
optimizers on different datasets with different preprocessing and augmentation
procedures. We also show that mainly negative HESD (MN-HESD) is a consequence
of external gradient manipulation, indicating that the previously proposed
Hessian analysis methodology cannot be applied in such cases. We also propose
criteria and corresponding conditions to determine HESD type and estimate NN
generalization potential. These HESD types and previously proposed
generalization criteria are combined into a unified HESD analysis methodology.
Finally, we discuss how HESD changes during training, and show the occurrence
of quasi-singular (QS) HESD and its influence on the proposed methodology and
on the conventional assumptions about the relation between Hessian eigenvalues
and NN loss landscape curvature.

</details>

### [121] [Aerial Image Classification in Scarce and Unconstrained Environments via Conformal Prediction](https://arxiv.org/abs/2504.17655)
*Farhad Pourkamali-Anaraki*

Main category: cs.LG

TLDR: 本文对共形预测方法在复杂真实场景中的表现进行了实证分析，发现其能提供有价值的预测集，并探讨了校准和模型压缩的影响。


<details>
  <summary>Details</summary>
Motivation: 研究共形预测在数据稀缺且高度变化的真实环境中的有效性，填补标准基准测试的不足。

Method: 使用预训练模型（MobileNet、DenseNet、ResNet）微调后生成预测集，比较有无温度校准的两种流程，评估覆盖率和预测集大小。

Result: 共形预测即使在小样本下也能提供可靠的不确定性估计；温度校准不一定能缩小预测集；模型压缩在资源受限环境中潜力显著。

Conclusion: 未来研究应关注噪声标签对共形预测的影响，并探索有效的模型压缩策略。

Abstract: This paper presents a comprehensive empirical analysis of conformal
prediction methods on a challenging aerial image dataset featuring diverse
events in unconstrained environments. Conformal prediction is a powerful
post-hoc technique that takes the output of any classifier and transforms it
into a set of likely labels, providing a statistical guarantee on the coverage
of the true label. Unlike evaluations on standard benchmarks, our study
addresses the complexities of data-scarce and highly variable real-world
settings. We investigate the effectiveness of leveraging pretrained models
(MobileNet, DenseNet, and ResNet), fine-tuned with limited labeled data, to
generate informative prediction sets. To further evaluate the impact of
calibration, we consider two parallel pipelines (with and without temperature
scaling) and assess performance using two key metrics: empirical coverage and
average prediction set size. This setup allows us to systematically examine how
calibration choices influence the trade-off between reliability and efficiency.
Our findings demonstrate that even with relatively small labeled samples and
simple nonconformity scores, conformal prediction can yield valuable
uncertainty estimates for complex tasks. Moreover, our analysis reveals that
while temperature scaling is often employed for calibration, it does not
consistently lead to smaller prediction sets, underscoring the importance of
careful consideration in its application. Furthermore, our results highlight
the significant potential of model compression techniques within the conformal
prediction pipeline for deployment in resource-constrained environments. Based
on our observations, we advocate for future research to delve into the impact
of noisy or ambiguous labels on conformal prediction performance and to explore
effective model reduction strategies.

</details>

<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [122] [Seeing The Words: Evaluating AI-generated Biblical Art](https://arxiv.org/abs/2504.16974)
*Hidde Makimei,Shuai Wang,Willem van Peursen*

Main category: cs.CY

TLDR: 论文探讨了AI生成图像在圣经文本背景下的准确性，并提供了一个包含7K图像的数据集，通过神经网络工具进行评估，分析了宗教和美学视角。


<details>
  <summary>Details</summary>
Motivation: 研究AI是否能根据圣经文本生成符合其背景和语境的准确图像，填补系统性评估的空白。

Method: 构建大型数据集（7K图像），使用圣经文本作为提示，通过多种神经网络工具评估图像。

Result: 提供了准确性评估，并从宗教和美学角度进行了分析。

Conclusion: 讨论了生成图像的用途，并反思了AI生成器的表现。

Abstract: The past years witnessed a significant amount of Artificial Intelligence (AI)
tools that can generate images from texts. This triggers the discussion of
whether AI can generate accurate images using text from the Bible with respect
to the corresponding biblical contexts and backgrounds. Despite some existing
attempts at a small scale, little work has been done to systematically evaluate
these generated images. In this work, we provide a large dataset of over 7K
images using biblical text as prompts. These images were evaluated with
multiple neural network-based tools on various aspects. We provide an
assessment of accuracy and some analysis from the perspective of religion and
aesthetics. Finally, we discuss the use of the generated images and reflect on
the performance of the AI generators.

</details>

<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [123] [Plasma State Monitoring and Disruption Characterization using Multimodal VAEs](https://arxiv.org/abs/2504.17710)
*Yoeri Poels,Alessandro Pau,Christian Donner,Giulio Romanelli,Olivier Sauter,Cristina Venturini,Vlado Menkovski,the TCV team,the WPTE team*

Main category: physics.plasm-ph

TLDR: 该论文提出了一种基于变分自编码器（VAE）的数据驱动方法，用于表征等离子体状态，以预测和区分托卡马克中的等离子体破裂事件。


<details>
  <summary>Details</summary>
Motivation: 等离子体破裂是未来托卡马克设备的关键挑战之一，但目前对其理解有限，且现有数据驱动模型的可解释性不足。

Method: 扩展了VAE框架，用于连续投影等离子体轨迹、分离操作模式，并区分破裂状态，从而识别破裂率和破裂性的连续指标。

Result: 该方法在约1600次TCV放电数据集上验证，能够有效识别不同操作模式及其与破裂的关联，并支持下游分析。

Conclusion: 该方法以可解释的方式成功区分了不同操作模式及其与破裂的接近程度。

Abstract: When a plasma disrupts in a tokamak, significant heat and electromagnetic
loads are deposited onto the surrounding device components. These forces scale
with plasma current and magnetic field strength, making disruptions one of the
key challenges for future devices. Unfortunately, disruptions are not fully
understood, with many different underlying causes that are difficult to
anticipate. Data-driven models have shown success in predicting them, but they
only provide limited interpretability. On the other hand, large-scale
statistical analyses have been a great asset to understanding disruptive
patterns. In this paper, we leverage data-driven methods to find an
interpretable representation of the plasma state for disruption
characterization. Specifically, we use a latent variable model to represent
diagnostic measurements as a low-dimensional, latent representation. We build
upon the Variational Autoencoder (VAE) framework, and extend it for (1)
continuous projections of plasma trajectories; (2) a multimodal structure to
separate operating regimes; and (3) separation with respect to disruptive
regimes. Subsequently, we can identify continuous indicators for the disruption
rate and the disruptivity based on statistical properties of measurement data.
The proposed method is demonstrated using a dataset of approximately 1600 TCV
discharges, selecting for flat-top disruptions or regular terminations. We
evaluate the method with respect to (1) the identified disruption risk and its
correlation with other plasma properties; (2) the ability to distinguish
different types of disruptions; and (3) downstream analyses. For the latter, we
conduct a demonstrative study on identifying parameters connected to
disruptions using counterfactual-like analysis. Overall, the method can
adequately identify distinct operating regimes characterized by varying
proximity to disruptions in an interpretable manner.

</details>

<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [124] [BIM-Constrained Optimization for Accurate Localization and Deviation Correction in Construction Monitoring](https://arxiv.org/abs/2504.17693)
*Asier Bikandi,Muhammad Shaheer,Hriday Bavle,Jayan Jevanesan,Holger Voos,Jose Luis Sanchez-Lopez*

Main category: cs.RO

TLDR: 论文提出了一种基于BIM的漂移校正方法，用于解决建筑监控中AR应用因环境特征不足和动态变化导致的跟踪漂移问题。


<details>
  <summary>Details</summary>
Motivation: 建筑工地环境复杂，传统跟踪方法易因特征缺失和动态变化导致数字模型与物理世界错位，影响AR可视化准确性。

Method: 通过将实际检测到的平面与BIM中的计划平面对齐，利用优化技术计算SLAM与BIM坐标系间的变换矩阵，减少漂移。

Result: 实验表明，该方法显著减少了漂移误差，角偏差和距离误差分别平均降低了52.24%和60.8%。

Conclusion: 结合BIM作为先验结构知识，可提升建筑环境中AR的长期定位和可视化精度。

Abstract: Augmented reality (AR) applications for construction monitoring rely on
real-time environmental tracking to visualize architectural elements. However,
construction sites present significant challenges for traditional tracking
methods due to featureless surfaces, dynamic changes, and drift accumulation,
leading to misalignment between digital models and the physical world. This
paper proposes a BIM-aware drift correction method to address these challenges.
Instead of relying solely on SLAM-based localization, we align ``as-built"
detected planes from the real-world environment with ``as-planned"
architectural planes in BIM. Our method performs robust plane matching and
computes a transformation (TF) between SLAM (S) and BIM (B) origin frames using
optimization techniques, minimizing drift over time. By incorporating BIM as
prior structural knowledge, we can achieve improved long-term localization and
enhanced AR visualization accuracy in noisy construction environments. The
method is evaluated through real-world experiments, showing significant
reductions in drift-induced errors and optimized alignment consistency. On
average, our system achieves a reduction of 52.24% in angular deviations and a
reduction of 60.8% in the distance error of the matched walls compared to the
initial manual alignment by the user.

</details>

<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [125] [Automating tumor-infiltrating lymphocyte assessment in breast cancer histopathology images using QuPath: a transparent and accessible machine learning pipeline](https://arxiv.org/abs/2504.16979)
*Masoud Tafavvoghi,Lars Ailo Bongo,André Berli Delgado,Nikita Shvetsov,Anders Sildnes,Line Moi,Lill-Tove Rasmussen Busund,Kajsa Møllersen*

Main category: q-bio.QM

TLDR: 开发了一个基于QuPath的端到端TILs评估流程，利用现有工具自动完成复杂任务。


<details>
  <summary>Details</summary>
Motivation: 探索易用工具在乳腺癌H&E染色全切片图像中自动评估TILs的潜力。

Method: 训练像素分类器分割组织区域，使用预训练模型检测细胞并分类TILs，计算TIL密度并分类。

Result: 与病理学家评分相比，Cohen's kappa为0.71，验证了流程的可靠性。

Conclusion: 现有软件可为乳腺癌H&E切片中的TILs评估提供实用解决方案。

Abstract: In this study, we built an end-to-end tumor-infiltrating lymphocytes (TILs)
assessment pipeline within QuPath, demonstrating the potential of easily
accessible tools to perform complex tasks in a fully automatic fashion. First,
we trained a pixel classifier to segment tumor, tumor-associated stroma, and
other tissue compartments in breast cancer H&E-stained whole-slide images (WSI)
to isolate tumor-associated stroma for subsequent analysis. Next, we applied a
pre-trained StarDist deep learning model in QuPath for cell detection and used
the extracted cell features to train a binary classifier distinguishing TILs
from other cells. To evaluate our TILs assessment pipeline, we calculated the
TIL density in each WSI and categorized them as low, medium, or high TIL
levels. Our pipeline was evaluated against pathologist-assigned TIL scores,
achieving a Cohen's kappa of 0.71 on the external test set, corroborating
previous research findings. These results confirm that existing software can
offer a practical solution for the assessment of TILs in H&E-stained WSIs of
breast cancer.

</details>

<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [126] [Multifaceted Evaluation of Audio-Visual Capability for MLLMs: Effectiveness, Efficiency, Generalizability and Robustness](https://arxiv.org/abs/2504.16936)
*Yusheng Zhao,Junyu Luo,Xiao Luo,Weizhi Zhang,Zhiping Xiao,Wei Ju,Philip S. Yu,Ming Zhang*

Main category: cs.MM

TLDR: 论文对多模态大语言模型（MLLMs）的音频-视觉能力进行了全面评估，发现其在零样本和小样本任务中表现优异，但对视觉模态依赖性强，且在对抗样本下表现较弱。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对MLLMs音频-视觉能力的全面评估，尤其是在分布变化和对抗攻击等多样化场景中。

Method: 通过多维度（有效性、效率、泛化性和鲁棒性）评估MLLMs的音频-视觉能力，并进行大量实验。

Result: MLLMs在零样本和小样本任务中表现优异，但对视觉模态依赖性强，且在对抗样本下表现较弱。

Conclusion: 研究为MLLMs的音频-视觉能力提供了深入见解，指出了改进方向并为未来研究提供了指导。

Abstract: Multi-modal large language models (MLLMs) have recently achieved great
success in processing and understanding information from diverse modalities
(e.g., text, audio, and visual signals). Despite their growing popularity,
there remains a lack of comprehensive evaluation measuring the audio-visual
capabilities of these models, especially in diverse scenarios (e.g.,
distribution shifts and adversarial attacks). In this paper, we present a
multifaceted evaluation of the audio-visual capability of MLLMs, focusing on
four key dimensions: effectiveness, efficiency, generalizability, and
robustness. Through extensive experiments, we find that MLLMs exhibit strong
zero-shot and few-shot generalization abilities, enabling them to achieve great
performance with limited data. However, their success relies heavily on the
vision modality, which impairs performance when visual input is corrupted or
missing. Additionally, while MLLMs are susceptible to adversarial samples, they
demonstrate greater robustness compared to traditional models. The experimental
results and our findings provide insights into the audio-visual capabilities of
MLLMs, highlighting areas for improvement and offering guidance for future
research.

</details>

<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [127] [ePBR: Extended PBR Materials in Image Synthesis](https://arxiv.org/abs/2504.17062)
*Yu Guo,Zhiqiang Lao,Xiyun Song,Yubin Zhou,Zongfang Lin,Heather Yu*

Main category: cs.GR

TLDR: 论文提出了一种扩展的物理渲染（ePBR）材料方法，结合反射和透射特性，用于合成透明材料（如玻璃和窗户），并通过显式内在合成框架实现可控的图像合成。


<details>
  <summary>Details</summary>
Motivation: 基于学习的方法缺乏物理一致性，而传统物理渲染（PBR）计算成本高。内在图像表示提供了平衡的解决方案，但现有PBR材料难以处理高镜面和透明表面。

Method: 扩展内在图像表示以包含反射和透射特性，提出显式内在合成框架和ePBR材料。

Result: 能够有效合成和编辑透明材料，提供精确控制和可解释的图像合成。

Conclusion: ePBR材料和显式内在合成框架为透明材料的可控合成提供了高效且物理一致的解决方案。

Abstract: Realistic indoor or outdoor image synthesis is a core challenge in computer
vision and graphics. The learning-based approach is easy to use but lacks
physical consistency, while traditional Physically Based Rendering (PBR) offers
high realism but is computationally expensive. Intrinsic image representation
offers a well-balanced trade-off, decomposing images into fundamental
components (intrinsic channels) such as geometry, materials, and illumination
for controllable synthesis. However, existing PBR materials struggle with
complex surface models, particularly high-specular and transparent surfaces. In
this work, we extend intrinsic image representations to incorporate both
reflection and transmission properties, enabling the synthesis of transparent
materials such as glass and windows. We propose an explicit intrinsic
compositing framework that provides deterministic, interpretable image
synthesis. With the Extended PBR (ePBR) Materials, we can effectively edit the
materials with precise controls.

</details>

### [128] [CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from Casually Captured Videos](https://arxiv.org/abs/2504.17728)
*Shucheng Gong,Lingzhe Zhao,Wenpu Li,Hong Xie,Yin Zhang,Shiyu Zhao,Peidong Liu*

Main category: cs.GR

TLDR: 提出了一种名为CasualHDRSplat的单阶段方法，用于从自动曝光的视频中轻松且鲁棒地重建3D HDR场景，解决了现有方法依赖固定曝光时间和多视图图像的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于多视图图像的HDR场景重建方法需要固定相机位置和不同曝光时间的图像，耗时且不灵活。

Method: 提出CasualHDRSplat，包含一个统一的微分物理成像模型，通过连续时间轨迹约束联合优化曝光时间、相机响应函数、相机位姿和3D HDR场景。

Result: 实验表明，该方法在鲁棒性和渲染质量上优于现有方法。

Conclusion: CasualHDRSplat提供了一种灵活且高效的HDR场景重建方案。

Abstract: Recently, photo-realistic novel view synthesis from multi-view images, such
as neural radiance field (NeRF) and 3D Gaussian Splatting (3DGS), have garnered
widespread attention due to their superior performance. However, most works
rely on low dynamic range (LDR) images, which limits the capturing of richer
scene details. Some prior works have focused on high dynamic range (HDR) scene
reconstruction, typically require capturing of multi-view sharp images with
different exposure times at fixed camera positions during exposure times, which
is time-consuming and challenging in practice. For a more flexible data
acquisition, we propose a one-stage method: \textbf{CasualHDRSplat} to easily
and robustly reconstruct the 3D HDR scene from casually captured videos with
auto-exposure enabled, even in the presence of severe motion blur and varying
unknown exposure time. \textbf{CasualHDRSplat} contains a unified
differentiable physical imaging model which first applies continuous-time
trajectory constraint to imaging process so that we can jointly optimize
exposure time, camera response function (CRF), camera poses, and sharp 3D HDR
scene. Extensive experiments demonstrate that our approach outperforms existing
methods in terms of robustness and rendering quality. Our source code will be
available at https://github.com/WU-CVGL/CasualHDRSplat

</details>

<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [129] [SCALAR: A Part-of-speech Tagger for Identifiers](https://arxiv.org/abs/2504.17038)
*Christian D. Newman,Brandon Scholten,Sophia Testa,Joshua A. C. Behler,Syreen Banabilah,Michael L. Collard,Michael J. Decker,Mohamed Wiem Mkaouer,Marcos Zampieri,Eman Abdullah AlOmar,Reem Alsuhaibani,Anthony Peruma,Jonathan I. Maletic*

Main category: cs.SE

TLDR: SCALAR是一个专门用于将源代码标识符名称映射到其对应词性标签序列的工具，通过训练改进现有标注器的性能。


<details>
  <summary>Details</summary>
Motivation: 开发者使用的自然语言结构独特，现有标注器无法有效处理源代码标识符的词性标注。

Method: 使用scikit-learn的GradientBoostingClassifier训练内部模型，结合手动整理的标识符名称和语法模式数据库。

Result: SCALAR在标注标识符时优于现有标注器和现代通用词性标注器。

Conclusion: SCALAR为源代码标识符的词性标注提供了更准确的解决方案，代码已开源。

Abstract: The paper presents the Source Code Analysis and Lexical Annotation Runtime
(SCALAR), a tool specialized for mapping (annotating) source code identifier
names to their corresponding part-of-speech tag sequence (grammar pattern).
SCALAR's internal model is trained using scikit-learn's
GradientBoostingClassifier in conjunction with a manually-curated oracle of
identifier names and their grammar patterns. This specializes the tagger to
recognize the unique structure of the natural language used by developers to
create all types of identifiers (e.g., function names, variable names etc.).
SCALAR's output is compared with a previous version of the tagger, as well as a
modern off-the-shelf part-of-speech tagger to show how it improves upon other
taggers' output for annotating identifiers. The code is available on Github

</details>